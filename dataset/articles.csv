entry,title,keywords,abstract,year,journal
AZAZA20181,Context proposals for saliency detection,"Computational saliency, Object segmentation, Object proposals","One of the fundamental properties of a salient object region is its contrast with the immediate context. The problem is that numerous object regions exist which potentially can all be salient. One way to prevent an exhaustive search over all object regions is by using object proposal algorithms. These return a limited set of regions which are most likely to contain an object. Several saliency estimation methods have used object proposals. However, they focus on the saliency of the proposal only, and the importance of its immediate context has not been evaluated. In this paper, we aim to improve salient object detection. Therefore, we extend object proposal methods with context proposals, which allow to incorporate the immediate context in the saliency computation. We propose several saliency features which are computed from the context proposals. In the experiments, we evaluate five object proposal methods for the task of saliency segmentation, and find that Multiscale Combinatorial Grouping outperforms the others. Furthermore, experiments show that the proposed context features improve performance, and that our method matches results on the FT datasets and obtains competitive results on three other datasets (PASCAL-S, MSRA-B and ECSSD).",2018,Computer Vision and Image Understanding
BENSHABAT201812,Graph based over-segmentation methods for 3D point clouds,"3D point cloud over-segmentation, 3D point cloud segmentation, Super-points, Grouping","Over-segmentation, or super-pixel generation, is a common preliminary stage for many computer vision applications. New acquisition technologies enable the capturing of 3D point clouds that contain color and geometrical information. This 3D information can be utilized to improve the results of over-segmentation, which uses mainly color information, and to generate clusters of points we call super-points. We consider a variety of possible 3D extensions of the Local Variation (LV) graph based over-segmentation algorithms, and compare them thoroughly. We consider different alternatives for constructing the connectivity graph, for assigning the edge weights, and for defining the merge criterion, which must now account for the geometric information and not only color. Following this evaluation, we derive a new generic algorithm for over-segmentation of 3D point clouds. We call this new algorithm Point Cloud Local Variation (PCLV). The advantages of the new over-segmentation algorithm are demonstrated on both outdoor and cluttered indoor scenes. Performance analysis of the proposed approach compared to state-of-the-art 2D and 3D over-segmentation algorithms shows significant improvement according to the common performance measures.",2018,Computer Vision and Image Understanding
YANG201843,Text effects transfer via distribution-aware texture synthesis,"Text effects, Texture synthesis, Spatial distribution, Multi-scale, Style transfer","In this paper, we explore the problem of fantastic special-effects synthesis for the typography. The main challenge of this problem lies in the model diversities to illustrate varied text effects for different characters. To address this issue, we exploit the key analytics on the high regularity of the texture spatial distribution for text effects to guide the synthesis process. Specifically, we characterize the stylized patches by their normalized positions relative to the text skeleton and the optimal scales to depict their style elements. Our method first estimates these two features and derives their correlation statistically. They are then converted into soft constraints for texture transfer to accomplish adaptive multi-scale texture synthesis and to make style element distribution uniform. It allows our algorithm to produce artistic typography that well consists with both local texture patterns and the global spatial distribution in the source example. Furthermore, stroke similarities are considered to control the varieties of text effects among multiple characters in a word. Experimental results demonstrate the superiority of our distribution-aware method for various text effects over conventional style transfer methods. In addition, we validate the effectiveness of our algorithm with extensive artistic typography library generation and apply our method to a general application of special effects transfer for stroke-based graphics.",2018,Computer Vision and Image Understanding
BARATH201870,Efficient energy-based topological outlier rejection,"Stereo vision, Outlier filtering, Energy minimization, Point correspondences","An approach is proposed for outlier rejection from a set of 2D point correspondences which does not require any underlying models, e.g. fundamental matrix. The solution is obtained by minimizing an energy originated from the neighborhood-graphs in both images using a grab-cut-like algorithm: iterated graph-cut and re-fitting. The method is validated on publicly available datasets, it is real time for most of the problems and achieves more accurate results than RANSAC and its state-of-the-art variants in terms of outlier rejection ratio. It is applicable to scenes where a single fundamental matrix is not estimable, e.g. non-rigid or degenerate ones.",2018,Computer Vision and Image Understanding
ARRIGONI201895,Robust synchronization in SO(3) and SE(3) via low-rank and sparse matrix decomposition,"Absolute rotations, Global rotations, Structure-from-motion, Global registration, ℓ-Regularization, Matrix completion, Robust principal component analysis, Low-rank & sparse matrix decomposition","This paper deals with the synchronization problem, which arises in multiple 3D point-set registration and in structure-from-motion. The problem is formulated as a low-rank and sparse matrix decomposition that caters for missing data, outliers and noise, and it benefits from a wealth of available decomposition algorithms that can be plugged-in. A minimization strategy, dubbed R-GoDec, is also proposed. Experimental results on simulated and real data show that this approach offers a good trade-off between resistance to outliers and speed.",2018,Computer Vision and Image Understanding
TIAN201824,Ordinal space projection learning via neighbor classes representation,"Ordinal metric learning, Ordinal space projection learning, Neighbor class representation, Ordinal relationship","Ordinal metric learning (OML) is an important research branch of metric learning and has attracted increasing attention due to its wide applications where there typically exists a global order (i.e., ordinal) relationship among the data classes, such as human age estimation and head pose recognition, etc. Although several works have been proposed to perform OML, they suffer from two critical drawbacks: 1) only the local ordinal relationships among classes rather than the global one are considered, and 2) the very time-consuming semi-definite programming is commonly involved. To avoid these shortcomings, in this paper we propose a novel OML approach, named ordinal space projection learning (OSPL) by representing one class with its neighbor classes whose representation weights are proportional to their class distance (i.e., absolute label difference), in which the neighboring ordinal class similarities are taken into account in their reconstruction. Then, we present an alternating optimization algorithm to solve the proposed method to learn an ordinal distance space. Finally, extensive experiments on ordinal estimation tasks demonstrate effectiveness and superiority of the proposed method.",2018,Computer Vision and Image Understanding
BOULAHIA201857,CuDi3D: Curvilinear displacement based approach for online 3D action detection,"Online action recognition, Skeleton-based approach, Human action detection, Curvilinear displacement, Online segmentation, Skeleton data stream","Being able to interactively detect and recognize 3D actions based on skeleton data, in unsegmented streams, has become an important computer vision topic. It raises three scientific problems in relation with variability. The first one is the temporal variability that occurs when subjects perform gestures with different speeds. The second one is the inter-class spatial variability, which refers to disparities between the displacement amounts induced by different classes (i.e. long vs. short movements). The last one is the intra-class spatial variability caused by differences in style and gesture amplitude. In this paper, we design an original approach that better considers these three issues. To address temporal variability we introduce the notion of curvilinear segmentation. It consists in extracting features, not on temporally-based sliding windows, but on trajectory segments for which the cumulated displacement equals a class-based amount. Second, to tackle inter-class spatial variability, we define several competing classifiers with their dedicated curvilinear windows. Last, we address intra-class spatial variability by designing a fusion system that takes the decisions and confidence scores of every competing classifier into account. Extensive experiments on four challenging skeleton-based datasets demonstrate the relevance of the proposed approach for action recognition and online action detection.",2018,Computer Vision and Image Understanding
LI201841,"VideoLSTM convolves, attends and flows for action recognition","Action recognition, Video representation, Attention, LSTM","We present VideoLSTM for end-to-end sequence learning of actions in video. Rather than adapting the video to the peculiarities of established recurrent or convolutional architectures, we adapt the architecture to fit the requirements of the video medium. Starting from the soft-Attention LSTM, VideoLSTM makes three novel contributions. First, video has a spatial layout. To exploit the spatial correlation we hardwire convolutions in the soft-Attention LSTM architecture. Second, motion not only informs us about the action content, but also guides better the attention towards the relevant spatio-temporal locations. We introduce motion-based attention. And finally, we demonstrate how the attention from VideoLSTM can be exploited for action localization by relying on the action class label and temporal attention smoothing. Experiments on UCF101, HMDB51 and THUMOS13 reveal the benefit of the video-specific adaptations of VideoLSTM in isolation as well as when integrated in a combined architecture. It compares favorably against other LSTM architectures for action classification and especially action localization.",2018,Computer Vision and Image Understanding
WANG201881,An efficient solution to the perspective-three-point pose problem,"Perspective-three-point problem (P3P), Absolute position and attitude, Pose estimation, Monocular vision, Computer vision","In this paper, we present a new algebraic method to solve the perspective-three-point (P3P) problem, which directly computes the rotation and position of a camera in the world frame without the intermediate derivation of the points in the camera frame. Unlike other online methods, the proposed method uses an “object” coordinate frame, in which the known 3D coordinates are sparse, facilitating formulations of the P3P problem. Additionally, two auxiliary variables are introduced to parameterize the rotation and position matrix, and then a closed-form solution for the camera pose is obtained from subsequent substitutions. This algebraic approach makes the processes more easily followed and significantly improves the performance. Experimental results demonstrated that our method offers accuracy and precision comparable to the existing state-of-the art methods but it has better computational efficiency.",2018,Computer Vision and Image Understanding
FURUYA2018102,Learning part-in-whole relation of 3D shapes for part-based 3D model retrieval,"Part-based 3D model retrieval, Part-in-whole retrieval, Deep learning","Given a query that specifies partial 3D shape, a Part-based 3D Model Retrieval (P3DMR) system finds 3D shapes whose part or parts matches the query. An approach to P3DMR is to partition or segment whole models into sub-parts and performs query-part-to-target-parts matching. Whatever the definition of part, e.g., a rectangular volume in Euclidean space or a part segmented on a mesh manifold, the computation will be very costly. The part-whole matching must account for, for each 3D whole shape in a database, varying position, scale and orientation of the segmented sub parts. Another approach, in an attempt to make part-whole matching efficient, tries to approximate part-whole inclusion test with a single comparison between a pair of features, one representing the part-based query and the other representing the whole shape. Aggregation of local geometrical features of parts into a feature per whole 3D shape, e.g., via Bag-of-Features approach, is an example. This approach so far suffered from inaccuracy as the aggregation is not optimized for part-whole inclusion test of 3D shapes. This paper proposes a novel P3DMR algorithm called Part-Whole Relation Embedding network (PWRE-net) that effectively and efficiently performs part-whole inclusion test via learned embedding into a common feature space. Using deep neural network, the PWRE-net learns, from a large number of part-whole shape pairs, a common embedding of partial shapes and their associated whole shapes. For the training, training datasets containing part-whole shape pairs are created automatically from unlabeled 3D models. Experimental evaluation shows that PWRE-net outperforms existing algorithms both in terms of retrieval accuracy and efficiency.",2018,Computer Vision and Image Understanding
STUTZ20181,Superpixels: An evaluation of the state-of-the-art,"Superpixels, Superpixel segmentation, Image segmentation, Perceptual grouping, Benchmark, Evaluation","Superpixels group perceptually similar pixels to create visually meaningful entities while heavily reducing the number of primitives for subsequent processing steps. As of these properties, superpixel algorithms have received much attention since their naming in 2003 (Ren and Malik, 2003). By today, publicly available superpixel algorithms have turned into standard tools in low-level vision. As such, and due to their quick adoption in a wide range of applications, appropriate benchmarks are crucial for algorithm selection and comparison. Until now, the rapidly growing number of algorithms as well as varying experimental setups hindered the development of a unifying benchmark. We present a comprehensive evaluation of 28 state-of-the-art superpixel algorithms utilizing a benchmark focussing on fair comparison and designed to provide new insights relevant for applications. To this end, we explicitly discuss parameter optimization and the importance of strictly enforcing connectivity. Furthermore, by extending well-known metrics, we are able to summarize algorithm performance independent of the number of generated superpixels, thereby overcoming a major limitation of available benchmarks. Furthermore, we discuss runtime, robustness against noise, blur and affine transformations, implementation details as well as aspects of visual quality. Finally, we present an overall ranking of superpixel algorithms which redefines the state-of-the-art and enables researchers to easily select appropriate algorithms and the corresponding implementations which themselves are made publicly available as part of our benchmark at http://www.davidstutz.de/projects/superpixel-benchmark/.",2018,Computer Vision and Image Understanding
KIFORENKO201866,A performance evaluation of point pair features,"PPF, Point pair features, Object detection, Object recognition, Pose estimation, Feature description","More than a decade ago, the point pair features (PPFs) were introduced, showing a great potential for 3D object detection and pose estimation under very different conditions. Many modifications have been made to the original PPF, in each case showing varying degrees of improvement for specific datasets. However, to the best of our knowledge, no comprehensive evaluation of these features has been made. In this work, we evaluate PPFs on a large set of 3D scenes. We not only compare PPFs to local point cloud descriptors, but also investigate the internal variations of PPFs (different types of relations between two points). Our comparison is made on 7 publicly available datasets, showing variations on a number of parameters, e.g. acquisition technique, the number of objects/scenes and the amount of occlusion and clutter. We evaluate feature performance both at a point-wise object-scene correspondence level and for overall object detection and pose estimation in a RANSAC pipeline. Additionally, we also present object detection and pose estimation results for the original, voting based, PPF algorithm. Our results show that in general PPF is the top performer, however, there are datasets, which have low resolution data, where local histogram features show a higher performance than PPFs. We also found that PPFs compared to most local histogram features degrade faster under disturbances such as occlusion and clutter, however, PPFs still remain more descriptive on an absolute scale. The main contribution of this paper is a detailed analysis of PPFs, which highlights under which conditions PPFs perform particularly well as well as its main weaknesses.",2018,Computer Vision and Image Understanding
KOU201888,Proximal robust factorization for piecewise planar reconstruction,"Dense planar reconstruction, Robust factorization, Structure from motion, Non-convex optimization","In this paper, we aim to obtain a dense piecewise planar reconstruction of the scene from multiple image frames based on a factorization framework. Integrating all the relevant constraints in a global objective function, we are able to effectively leverage on the scene smoothness prior afforded by the dense formulation, as well as imposing the necessary algebraic constraints required by the shape matrix. These constraints also help to robustly decompose the measurement matrix into the underlying low-rank subspace and the sparse outlier part. Numerically, we achieve the constrained factorization and decomposition via modifying a recently proposed proximal alternating robust subspace minimization algorithm. The results show that our algorithm is effective in handling real life sequences, and outperforms other algorithms in recovering motions and dense scene estimate.",2018,Computer Vision and Image Understanding
KAZANTZIDIS201828,Vide-omics: A genomics-inspired paradigm for video analysis,"Computer vision, Freely moving camera, Genomics, Foreground detection, Segmentation, Scanlines","With the development of applications associated to ego-vision systems, smart-phones, and autonomous cars, automated analysis of videos generated by freely moving cameras has become a major challenge for the computer vision community. Current techniques are still not suitable to deal with real-life situations due to, in particular, wide scene variability and the large range of camera motions. Whereas most approaches attempt to control those parameters, this paper introduces a novel video analysis paradigm, ‘vide-omics’, inspired by the principles of genomics where variability is the expected norm. Validation of this new concept is performed by designing an implementation addressing foreground extraction from videos captured by freely moving cameras. Evaluation on a set of standard videos demonstrates both robust performance that is largely independent from camera motion and scene, and state-of-the-art results in the most challenging video. Those experiments underline not only the validity of the ‘vide-omics’ paradigm, but also its potential.",2018,Computer Vision and Image Understanding
BYEON201851,Unified optimization framework for localization and tracking of multiple targets with multiple cameras,"Multiple target tracking, Multiple cameras, Multidimensional assignment, 3D trajectory estimation","We present a method for three-dimensional (3D) localization and tracking of multiple targets by using images from multiple cameras with overlapping views. Most recent methods make an assumption on a flat ground plane and determine the 3D grounding location of each target based on this assumption. In contrast, we aim to find 3D locations of multiple head trajectories, regardless of their standing or sitting status without the flat ground plane assumption. For this purpose, we suggest a unified optimization formulation, which solves two coupled problems simultaneously: the spatio-temporal data association problem and the 3D trajectory estimation problem. To handle a large solution space, we develop an efficient optimization scheme that alternates the solving procedures between two coupled problems with a reasonable computational load. In the unified optimization formulation, we design a new cost function that describes 3D physical properties of each target. The experiments illustrate that the proposed method outperforms the state-of-the-art methods in 3D localization and tracking performance.",2018,Computer Vision and Image Understanding
STAFYLAKIS201822,Pushing the boundaries of audiovisual word recognition using Residual Networks and LSTMs,"Audiovisual speech recognition, Lipreading, Deep learning","Visual and audiovisual speech recognition are witnessing a renaissance which is largely due to the advent of deep learning methods. In this paper, we present a deep learning architecture for lipreading and audiovisual word recognition, which combines Residual Networks equipped with spatiotemporal input layers and Bidirectional LSTMs. The lipreading architecture attains 11.92% misclassification rate on the challenging Lipreading-In-The-Wild database, which is composed of excerpts from BBC-TV, each containing one of the 500 target words. Audiovisual experiments are performed using both intermediate and late integration, as well as several types and levels of environmental noise, and notable improvements over the audio-only network are reported, even in the case of clean speech. A further analysis on the utility of target word boundaries is provided, as well as on the capacity of the network in modeling the linguistic context of the target word. Finally, we examine difficult word pairs and discuss how visual information helps towards attaining higher recognition accuracy.",2018,Computer Vision and Image Understanding
FOGELTON201878,Eye blink completeness detection,"Blink detection, Incomplete blinks, Complete blinks, Recurrent neural network time shifting","Computer users often complain about eye discomfort caused by dry eye syndrome. This is sometimes caused and accompanied by incomplete blinks. There are several algorithms for eye blink detection, but none which would distinguish complete blinks from the incomplete ones. We introduce the first method which detects blink completeness. Blinks differ in speed and duration similar to speech, therefore Recurrent Neural Network (RNN) is used as a classifier due to its suitability for sequence-based features. We show that using unidirectional RNN with time shifting achieves higher performance compared to a bidirectional RNN, which is a suitable choice in this kind of problem where the feature pattern is not yet observed for the initial frames. We report the best results (increase by almost 8%) on the most challenging dataset: Researcher’s night. We formulate a new important problem and state an initial benchmark for further research.",2018,Computer Vision and Image Understanding
ZADRIJA20189,Sparse weakly supervised models for object localization in road environment,"Object localization, Weak supervision, Fisher vectors, Sparse models, Convolutional features, Geographic information system (GIS), OpenStreetMap","We propose a novel weakly supervised localization method based on Fisher-embedding of low-level features (CNN, SIFT), and model sparsity at the component level. Fisher-embedding provides an interesting alternative to raw low-level features, since it allows fast and accurate scoring of image subwindows with a model trained on entire images. Model sparsity reduces overfitting and enables fast evaluation. We also propose two new techniques for improving performance when our method is combined with nonlinear normalizations of the aggregated Fisher representation of the image. These techniques are (i) intra-component metric normalization and (ii) first-order approximation to the score of a normalized image representation. We evaluate our weakly supervised localization method on real traffic scenes acquired from driver’s perspective. The method dramatically improves the localization AP over the dense non-normalized Fisher vector baseline (16 percentage points for zebra crossings, 21 percentage points for traffic signs) and leads to a huge gain in execution speed (91× for zebra crossings, 74× for traffic signs).",2018,Computer Vision and Image Understanding
MADER201845,Detection and localization of spatially correlated point landmarks in medical images using an automatically learned conditional random field,"Automatic landmark detection and localization, Missing landmarks, Conditional random field, Weighting and selection of CRF potentials, Medical image analysis","The automatic detection and accurate localization of landmarks is a crucial task in medical imaging. It is necessary for tasks like diagnosis, surgical planning, and post-operative assessment. A common approach to localize multiple landmarks is to combine multiple independent localizers for individual landmarks with a spatial regularizer, e.g., a conditional random field (CRF). Its configuration, e.g., the CRF topology and potential functions, often has to be manually specified w.r.t. the application. In this paper, we present a general framework to automatically learn the optimal configuration of a CRF for localizing multiple landmarks. Furthermore, we introduce a novel “missing” label for each landmark (node in the CRF). The key idea is to define a pool of potentials and optimize their CRF weights and the potential values for missing landmarks in a learning framework. Potentials with a low weight are removed, thus optimizing the graph topology. This allows to easily transfer our framework to new applications, and to integrate different localizers. Further advantages of our algorithm are its low test runtime, low amount of training data, and interpretability. We illustrate its feasibility in a detailed evaluation on three medical datasets featuring high degrees of pathologies and outliers.",2018,Computer Vision and Image Understanding
AZIZ201854,Generic spatial-color metric for scale-space processing of catadioptric images,"Catadioptric images, Riemannian metric, Color processing, Gaussian kernel","Images produced by omnidirectional catadioptric systems provide a larger field of view than conventional cameras. However, these images contain significant radial distortions making classical processing unadapted. In addition, color information is almost neglected in omnidirectional imaging. In this paper, we propose a unifying framework, for central catadioptric color image processing, using Riemannian embedding that deals simultaneously with the geometric deformation due to the use of curved mirrors, and the multi-dimensional characteristic of the image. Based on the introduced Riemannian metric, we derive an adapted Gaussian kernel which is essential in widely used image processing. The resulting new formulation is then applied to various image processing: Image smoothing, Difference of Gaussians filtering and scale-space analysis, edge extraction and corner feature detection using Gaussian derivatives. The experiments illustrate the potential of the proposed approach, and show the higher quality of the adapted processing.",2018,Computer Vision and Image Understanding
CIOCCA201870,CNN-based features for retrieval and classification of food images,"Food retrieval, Food dataset, Food recognition, CNN-based features","Features learned by deep Convolutional Neural Networks (CNNs) have been recognized to be more robust and expressive than hand-crafted ones. They have been successfully used in different computer vision tasks such as object detection, pattern recognition and image understanding. Given a CNN architecture and a training procedure, the efficacy of the learned features depends on the domain-representativeness of the training examples. In this paper we investigate the use of CNN-based features for the purpose of food recognition and retrieval. To this end, we first introduce the Food-475 database, that is the largest publicly available food database with 475 food classes and 247,636 images obtained by merging four publicly available food databases. We then define the food-domain representativeness of different food databases in terms of the total number of images, number of classes of the domain and number of examples for class. Different features are then extracted from a CNN based on the Residual Network with 50 layers architecture and trained on food databases with diverse food-domain representativeness. We evaluate these features for the tasks of food classification and retrieval. Results demonstrate that the features extracted from the Food-475 database outperform the other ones showing that we need larger food databases in order to tackle the challenges in food recognition, and that the created database is a step forward toward this end.",2018,Computer Vision and Image Understanding
ZHANG201833,Mining deep And-Or object structures via cost-sensitive question-answer-based active annotations,"Hierarchical graphical model, Part semantics","This paper presents a cost-sensitive active Question-Answering (QA) framework for learning a nine-layer And-Or graph (AOG) from web images. The AOG explicitly represents object categories, poses/viewpoints, parts, and detailed structures within the parts in a compositional hierarchy. The QA framework is designed to minimize an overall risk, which trades off the loss and query costs. The loss is defined for nodes in all layers of the AOG, including the generative loss (measuring the likelihood of the images) and the discriminative loss (measuring the fitness to human answers). The cost comprises both the human labor of answering questions and the computational cost of model learning. The cost-sensitive QA framework iteratively selects different storylines of questions to update different nodes in the AOG. Experiments showed that our method required much less human supervision (e.g. labeling parts on 3–10 training objects for each category) and achieved better performance than baseline methods.",2018,Computer Vision and Image Understanding
YANG2018660,"Enhancing multi-factor cheating prevention in visual cryptography based minimum (k, n)-connected graph","Visual cryptography, Cheating attack, Cheating prevention, Verification image, Shadow image","Recently, Lin et al. [29] introduced a (k, n) multi-factor cheating prevention visual cryptographic scheme (MCPVCS) by hiding verification images into shadow images. Through authenticating the verification image and the reconstructed image simultaneously, Lin et al.’s MCPVCS can prevent cheating attack that dishonest participants may collude and cheat the honest one to get a wrong secret image. However, the large n reduces the size of verification image and makes the verification difficult. In this paper, a (k, n)-MCPVCS with the large size of verification image is proposed. There are three main contributions for the proposed (k, n)-MCPVCS: (i) the verification condition in (k, n)-MCPVCS is redefined, (ii) a new minimum (k, n)-connected graph problem is introduced, on which the minimum number of verification images is determined, and (iii) the proposed (k, n)-MCPVCS with the large size of verification image can more easily authenticate the unambiguity of verification image.",2018,Journal of Visual Communication and Image Representation
FAKHAR2018489,Learning an event-oriented and discriminative dictionary based on an adaptive label-consistent K-SVD method for event detection in soccer videos,"Soccer videos, Event detection, Sparse coding, Supervised dictionary learning, Adaptive discriminative dictionary learning","In this paper, we formulate the soccer video event detection task as a sparse representation problem by learning a supervised, discriminative and event-oriented dictionary based on learned weighted local features. To this end, we present a novel framework based on two ideas: First, we propose an approach for computing the representativeness of each video frame for each soccer event. Second, we propose an Adaptive Label-Consistent K-SVD (ALC-KSVD) algorithm to learn an event-oriented and discriminative dictionary based on the computed representativeness of frames to transfer video frames to a sparse space. To improve discrimination among frames of different events, we proposed a weighting method to identify local features that are more representative in each event category. Next, the representativeness score of each frame is calculated by aggregating the weighted local features within each frame. The calculated representativeness score of each frame indicates its belonging degree to each event. The representativeness score matrix, being a discriminative term, is combined with the reconstruction error to form an objective function to improve the discrimination ability in the sparse representation during the dictionary learning process. The obtained objective function is efficiently and optimally solved by the K-SVD algorithm. The representativeness score matrix, which is automatically calculated based on the training samples, defines an adaptive correspondence between the dictionary atoms and the labels of the frames. We demonstrate the effectiveness of the proposed framework on the detection and classification of several soccer events based on an extensive experimental investigation that was conducted using a large collection of video data. The experimental results indicate that our approach maintains good classification performance and outperforms the state-of-the-art methods.",2018,Journal of Visual Communication and Image Representation
DAI2018761,A new deep representation for large-scale scene classification,"Scene classification, Graphlets, Finished bag, Region adjacency graph","Large scale scene classification based on image is an important problem in computer vision. In this paper, we propose a method to fuse the local features of scene images into a geometric feature that can reflect both the geometric features of the scene image and the color intensity distribution. First, each scene image is segmented into a set of individually connected regions according to their color intensity distribution. A region adjacency graph is constructed to encode the geometric properties and color intensity of scene images. Later, a 5 tier CNN architecture was constructed to study regional features. Then, a thinning process is carried out to obtain a discriminant and compact template set from the training rag. These templates are used to extract graphlets finished bag (r-bogs) images represented by each scene. Finally, the strategy of boosting development is to classify the extracted r-bogs scenes. Experimental results on different datasets demonstrate the effectiveness and effectiveness of the proposed method.",2018,Journal of Visual Communication and Image Representation
ZHU2018477,Non-negative matrix factorization via discriminative label embedding for pattern classification,"Non-negative matrix factorization (NMF), Discriminative label embedding, Orthogonality constraint, Pattern classification","As one of the most commonly used dimension reduction approaches, discriminant non-negative matrix factorization (NMF) has been widely used for data representation in the pattern classification task. However, the previous discriminant NMFs emphasize the Fisher criterion or maximum margin criterion which has high requirement to the distribution of data. Therefore, this work proposes a discriminative label embedded NMF (LENMF) algorithm. LENMF takes into account the discriminative label embedding to obtain the low-dimensional projected data and orthogonal property of the non-negative basis to strength the ability of parts-based representation. Besides, LENMF is extended in the kernel space to explore the nonlinear relations of data. By integrating the non-negative constraint, discriminative label embedding, and the orthogonal property into the proposed objective, the multiplicative updating rules have been given in this work. Experiment results on the challenging face, object, document, and digit databases illustrate the performance of the proposed algorithm.",2018,Journal of Visual Communication and Image Representation
MI2018648,A sound-based video clipping framework toward sports scenes,"Sonogram, Deep representation, Convolutional neural network","Video clipping system is very important in many intelligent applications. In order to shorten the time of video and extract the framework of the video, many methods have been proposed. But these methods just considered videos without taking sound into account. As we know, sound is also an important information for image processing. For example, many sport match videos include rich sound of audience and commentator such as NBA. In addition, human pay more attention to some video clips of interest (VCOI) such as scoring time instead of pause. So in this paper, we propose a sound-based video clipping framework toward specific sports scenes. First, we convert sound of sport videos to sonogram. For some aesthetically-pleasing images (APIM) such as slam dunk or jump shot, a set of object patches are selected using BING feature. Then, these object patches are ordered by our active object patches ranking algorithm. After that, ordered object patches and sonogram are fed into CNN respectively to obtain patch-level deep feature. In order to obtain image-level deep representation, deep feature extracted from ordered object patches are aggregated statistically into a deep representation. Finally, probabilistic model is used to select VCOI and APIM. Experiments on some NBA basketball matches have shown the effectiveness of our video clipping framework.",2018,Journal of Visual Communication and Image Representation
RIBAL2018529,Efficient graph cut optimization for shape from focus,"Shape from focus, Depth map estimation, Graph cuts, Multi-labels","Shape From Focus refers to the inverse problem of recovering the depth in every point of a scene from a set of differently focused 2D images. Recently, some authors stated it in the variational framework and solved it by minimizing a non-convex functional. However, the global optimality on the solution is not guaranteed and evaluations are often application-specific. To overcome these limits, we propose to globally and efficiently minimize a convex functional by decomposing it into a sequence of binary problems using graph cuts. To illustrate the genericity of such a decomposition-based approach, data-driven strategies are considered, allowing us to optimize (in terms of reconstruction error) the choice of the depth values for a given number of possible depths. We provide qualitative and quantitative evaluation on Middlebury datasets and we show that, according to classic statistics on error values, the proposed approach exhibits high performance and robustness against corrupted data.",2018,Journal of Visual Communication and Image Representation
KAMRANIAN2018201,Co-segmentation via visualization,"Co-segmentation, Convolutional Neural Network (CNN), Feature visualization, Occlusion sensitivity, Adaptive learning","This paper addresses the co-segmentation problem using feature visualization for CNNs. Visualization is exploited as an auxiliary information to discriminate salient image regions (dubbed as “heat-regions”) from non-salient ones. Region occlusion sensitivity is proposed for feature visualization. The co-segmentation problem is formulated via a convex quadratic optimization which is initialized by the heat-regions. The information obtained through the visualization is considered as an extra energy term in the cost function. The results of the visualization demonstrate that there exist some heat-regions which are not productive in the co-segmentation. To detect helpful regions among them, an adaptive strategy in the form of an iterative algorithm is proposed according to the consistency among all images. Comparison experiments conducted on two benchmark datasets, iCoseg and MSRC, illustrate the superior performance of the proposed approach over state-of-the-art algorithms.",2018,Journal of Visual Communication and Image Representation
MORILLAS2018142,Using suprathreshold color-difference ellipsoids to estimate any perceptual color-difference,"Color-difference formulas, Fuzzy logic, Fuzzy Metrics, STRESS","Relating instrumentally measured to visually perceived colour-differences is one of the challenges of advanced colorimetry. Lately, the use of color difference formulas is becoming more important in the computer vision field as it is a key tool in advancing towards perceptual image processing and understanding. In the last decades, the study of contours of equal color-differences around certain color centers has been of special interest. In particular, the contour of threshold level difference that determines the just noticeable differences (JND) has been deeply studied and, as a result, a set of 19 different ellipsoids of suprathreshold color-difference is available in the literature. In this paper we study whether this set of ellipsoids could be used to compute any color difference in any region of the color space. To do so, we develop a fuzzy multi-ellipsoid model using the ellipsoids information along with two different metrics. We see that the performance of the two metrics vary significantly for very small, small, medium and large color differences. Therefore, we also study how to adapt two metric parameters to optimize performance. The obtained results outperform the currently CIE-recommended color-difference formula CIEDE2000.",2018,Journal of Visual Communication and Image Representation
KIM201812,Multipath-based transmission scheme for improving the QoE of HTTP adaptive streaming,"HTTP adaptive streaming, Quality of experience, Multipath","The number of users using multimedia streaming services in various environments is increasing. Accordingly, HyperText Transfer Protocol (HTTP) adaptive streaming has attracted attention. Recently, there have been many studies on schemes for improving the Quality of Experience (QoE) by using multipaths in HTTP adaptive streaming. Downloading segments at the same time using multipaths can take up a high amount of bandwidth and make the transmission robust to data loss. However, when the bandwidths of the multipaths are aggregated, the variation of the bandwidth fluctuation increases, so quality changes occur more frequently. Additionally, it takes time to reorder the segments due to different segment download times received through the multipath. To this end, we propose a multipath-based transmission scheme to improve the QoE of HTTP adaptive streaming in the multipath environment. The proposed scheme improves the QoE by increasing the average video quality and reducing the frequency of video quality changes.",2018,Journal of Visual Communication and Image Representation
GAO2018586,Single fog image restoration with multi-focus image fusion,"Image restoration, Histogram analysis, Adaptive boundary constraint, Multi-focus image fusion","The images and videos captured in bad weather usually have low quality caused by reduced contrast and faded color. However, traditional techniques are not sufficient to solve the problems of halo artifacts and brightness distortion. In this paper, a multi-focus fusion method for single fog image restoration is proposed. Firstly, we estimate the global atmospheric light only in the sky regions to minimize interference from other regions. Secondly, we introduce a novel fast local Laplacian filtering with adaptive boundary constraint to optimize the transmission properly so as to reduce the halo artifacts. Finally, we remove the haze and produce a more natural effect on visual recovery by using a new multi-focus image fusion method. Experimental results show that the proposed method outperforms state-of-the-art haze removal methods in terms of efficiency and dehazing visual effect.",2018,Journal of Visual Communication and Image Representation
OZCINAR2018166,Spatio-temporal constrained tone mapping operator for HDR video compression,"High dynamic range, Video compression, Tone mapping operator, Convex optimization","With the growing popularity of high dynamic range (HDR) imaging, efficient compression techniques are demanded, as HDR video entails typically higher raw data rate than traditional video. For this purpose, we introduce a hybrid spatially and temporally constrained content-adaptive tone mapping operator (TMO) to convert the input HDR video into a tone mapped video sequence, which is then encoded using the high efficiency video coding (HEVC) standard. The proposed TMO simultaneously exploits intra-frame spatial redundancies and preserves inter-frame temporal coherence of the tone mapped video sequence. Extensive experimental results show that the developed spatio-temporal TMO (ST-TMO) solution yields higher coding performance than existing frame-by-frame TMO’s, and compares favorably with state-of-the-art methods based on a fixed transfer function.",2018,Journal of Visual Communication and Image Representation
WANG2018778,Evolution modeling with multi-scale smoothing for action recognition,"Action recognition, Multi-scale representation, Rank pooling, Evolution modeling, Dynamics","The aim of this paper is to model long-term evolution of an action video with temporal multi-scale representation. This task is tough due to huge intra-class variations in motion speed. Most of the existing methods consider evolution modeling and multi-scale feature fusion in two separated phases, which generates sub-optimal representation. To address this issue, this paper proposes a novel method to integrate the evolution modeling and multi-scale representation into a unified framework. The core idea is to introduce a temporal multi-scale smoothing vector, which is used to define how the representations at different temporal scales are combined together for frame smoothing. By formulating the smoothing vector learning, evolution modeling and classifier training jointly, our method can learn a discriminative and flexible representation of multi-scale rather than a single scale or a fixed multi-scale smoothing. Experimental results on three datasets demonstrate the effectiveness of our method.",2018,Journal of Visual Communication and Image Representation
CHEN2018393,Toward a unified scheme for fast interactive segmentation,"Interactive, Image segmentation, Manifold ranking, Machine-assisted","This paper presents an efficient and effective interactive segmentation scheme for extracting the region of a foreground object in an image. Our goal is to design an interactive segmentation algorithm that unifies the bounding-box-based, seed-based, and query-based interaction mechanisms for pursuing (i) high efficiency in simple interaction mechanism, (ii) few interaction rounds, and (iii) short response time. The proposed algorithm starts with a user-provided bounding box and obtains candidate background superpixels for inferring the foreground object. Our algorithm tolerates imprecise bounding boxes and provides two kinds of interactions for acquiring correct labels from the user. The user can either input the seed/scribble annotations or label the algorithm-queried regions. Our algorithm selects the most uncertain region as a query, and this query-based interaction mechanism reduces the burden of the user on deciding suitable annotation locations. The average response time per-interaction of our algorithm is merely 0.014 s. Our experiments demonstrate that the algorithm achieves an efficient unified scheme for interactive image segmentation.",2018,Journal of Visual Communication and Image Representation
HUANG2018677,Expression-targeted feature learning for effective facial expression recognition,"Facial expression recognition, Multi-task learning, Feature learning, Convolutional neural network","In this paper, we propose a novel expression-targeted feature learning (ETFL) method for effective facial expression recognition, which takes advantage of multi-task learning for discriminative feature learning. Specifically, the common features are firstly extracted from the lower layers of CNN. Then, based on the common features, the expression-specific features (ESF) are respectively learned for each facial expression via multi-task learning. In order to enhance the discriminability of ESF, we develop a joint loss (the combination of the center loss and a novel inter-class loss) to explicitly reduce intra-class variations while enlarging inter-class differences. Furthermore, we introduce the sample-sensitive weights and the soft-expression weights to balance the joint loss for better performance. Finally, all ESFs are combined for final classification. ETFL effectively exploits the relationship among all facial expressions, which leads to superiority feature discriminability. Experiments on public facial expression databases demonstrate the effectiveness of ETFL compared with several state-of-the-art methods.",2018,Journal of Visual Communication and Image Representation
JEYABHARATHI2018434,Cut set-based Dynamic Key frame selection and Adaptive Layer-based Background Modeling for background subtraction,"Cut set-based Dynamic Key frame selection, Adaptive Layer-based Background Modeling, Background subtraction, Object tracking","Background subtraction has been widely discussed in video surveillance, but it still has open challenges such as dynamic background, illumination variation. To address these challenges a novel Cut set-based Dynamic Key frame selection (CDK) and Adaptive Layer-based Background Modeling (ALBM) approach for background subtraction is proposed which adaptively changes layers in the background model for each scenario such as static, dynamic background and high illumination. The concept of key frame is used to choose representative frames from the video. In order to capture the invariant directional codes of each spatio-temporal patch symmetric operators such as line and rotational symmetry are used. The proposed method identifies highly similar static spatio-temporal patches and sets it as background there by reducing the computational complexity in the foreground detection step. Both qualitative and quantitative evaluations on challenging video sequences demonstrate that the proposed algorithm performs background subtraction more favorably than the state-of-the-art methods.",2018,Journal of Visual Communication and Image Representation
YEH2018342,Coding unit complexity-based predictions of coding unit depth and prediction unit mode for efficient HEVC-to-SHVC transcoding with quality scalability,"HEVC (high efficiency video coding), SHVC (scalability extension of HEVC), Video transcoding, Scalable video coding, Early termination, Coding unit complexity","To support good video quality of experiences in heterogeneous environments, transcoding an existed HEVC (high efficiency video coding) video bitstream to a SHVC (scalability extension of HEVC) bitstream with quality scalability is highly required. A straightforward way is to first fully decode the input HEVC bitstream and then fully re-encode it with the SHVC encoder, which requires a tremendous computational complexity. To solve the problem, in this paper, a coding unit complexity (CUC)-based prediction method for predictions of CU (coding unit) depth and PU (prediction unit) mode for efficient HEVC-to-SHVC transcoding with quality scalability is proposed to significantly reduce the transcoding complexity. The proposed method contains two prediction techniques, including (i) early termination and (ii) adaptive confidence interval, and predicts the CU depth and PU mode relying on the decoded information from the input HEVC bitstream. Experimental results have shown that the proposed method significantly outperforms the traditional HEVC-to-SHVC method by 74.14% on average in reductions of encoding time for SHVC enhancement layer.",2018,Journal of Visual Communication and Image Representation
ZHANG2018654,Robust eye detection using deeply-learned gaze shifting path,"Eye detection, Gaze shifting path, Deep feature","Eye detection is a very useful technique in many intelligent applications. Since the importance of eyes to human beings, eye detection technique is an indispensable component in intelligent systems, e.g., emotional analysis, iris detection and gaze estimation. Recently, there have been proposed a large number of methods for eye detection, wherein good performances have been achieved. But these methods cannot take human visual perception into account, that is to say, human beings will first pay attention to the eyes when they are communicating with each other, and then nose, then mouth. In addition, their geometric positions are almost fixed, i.e., eyes are above the nose and mouth, and eyes are on both sides of the nose. So in our work, a novel method for eye detection is proposed using human visual perception. More specifically, we first derive object patches from a large quantity of training images. Then, a geometry-preserved object patches ranking method is designed to effectively mimic human visual mechanism when human beings are communicating with each other. After that, these ordered object patches will be fed into CNN to extract patch-level deep features, then patch-level deep features will be represented by deep representations. Finally, eye detection can be achieved using learned deep representation. Experimental results on different database show that our method can achieve high efficiency and accuracy of eye detection.",2018,Journal of Visual Communication and Image Representation
WAZARKAR2018596,A survey on image data analysis through clustering techniques for real world applications,"Image clustering, Feature extraction, Real world applications","A huge amount of image data is being collected in real world sectors. Image data analytics provides information about important facts and issues of a particular domain. But, it is challenging to handle voluminous, unstructured and unlabeled image collection. Clustering provides groups of homogeneous unlabeled data. Therefore, it is used quite often to access the interesting data easily and quickly. Image clustering is a process of partitioning image data into clusters on the basis of similarities. Whereas, features extracted from images are used for the computation of similarities among them. In this paper, significant feature extraction approaches and clustering methods applied on the image data from nine important applicative areas are reviewed. Medical, 3D imaging, oceanography, industrial automation, remote sensing, mobile phones, security and traffic control are considered applicative areas. Characteristics of images, suitable clustering approaches for each domain, challenges and future research directions for image clustering are discussed.",2018,Journal of Visual Communication and Image Representation
ZHANG2018711,Cross-camera multi-person tracking by leveraging fast graph mining algorithm,"Multiple person, Tracking, Video surveillance, Matching","Multiple person tracking is a very useful task in intelligent video surveillance, which is hindered by many challenges such as the variations of illumination, the irregular changes of human shapes and the particle occlusions. To tackle these challenges, in this paper, we propose a new online learning tracking system to generate the complete trajectory for each tracking object. In detection stage, we build a classifier for each tracking object by online learning in order to provide more accurate detection results. Online learning could real-time update the classifier for an accurately tracking results in the future. In the tracklet generation stage, we apply the spatiotemporal constrain to generate a set of reliable tracklets. Finally, we propose a new Part-based matching method to get the correlation between different tracklets and apply linear programming and greedy algorithm to handle the data association problem to generate the complete trajectory for each tracking object. In particular, our approach is able to cast the multiple cameras tracking problem as a data association problem. The experiments on our proposed method demonstrate state-of-the-art performance in multiple person tracking.",2018,Journal of Visual Communication and Image Representation
ZHANG2018640,Small sample image recognition using improved Convolutional Neural Network,"Image recognition, Convolutional Neural Network (CNN), General Regression Neural Network (GRNN), Small sample, Real-time","In recent years, with the raise of the neural network and deep learning, significant progress has been achieved in the field of image recognition. Convolutional Neural Network (CNN) has been widely used in multiple image recognition tasks, but the recognition accuracy still has a lot of room for improvement. In this paper, we proposed a hybrid model CNN-GRNN to improve recognition accuracy. The model uses CNN to extract multilayer image representation and it uses General Regression Neural Network (GRNN) to classify image using the extracted feature. The CNN-GRNN model replace Back propagation (BP) neural network inside CNN with GRNN to improve generalization and robustness of CNN. Furthermore, we validate our model on the Oxford-IIIT Pet Dataset database and the Keck Gesture Dataset, the experiment result indicate that our model is superior to Gray Level Co-occurrency (GLCM),HU invariant moments, CNN and CNN_SVM on small sample dataset. Our model has favorable real-time characteristic at the same time.",2018,Journal of Visual Communication and Image Representation
HAN2018449,Guided filtering based data fusion for light field depth estimation with L0 gradient minimization,"Data fusion, Guided filtering, Light field, gradient minimization, Defocus response, Occlusion, Stereo matching","In this paper, we propose guided filtering based data fusion for light field depth estimation with L0 gradient minimization. Stereo disparity produces good depth edge, while defocus response yields good depth information in homogeneous regions. We fuse stereo disparity and defocus response from light filed data in a guided filtering framework. In the guided filtering framework, we adopt L0 gradient minimization as the regularization term instead of penalizing linear coefficients to consider depth characteristics that have similar depth in the same object. Moreover, we utilize edge direction in stereo matching to prevent the confusion caused by occlusion. Experimental results on both synthetic and real light field datasets show that the proposed method achieves clearer edge and less error in depth than state-of-the-arts.",2018,Journal of Visual Communication and Image Representation
BAISA2018464,Long-term correlation tracking using multi-layer hybrid features in sparse and dense environments,"Visual tracking, Correlation filter, CNN features, Hybrid features, Online learning, GM-PHD filter","Tracking a target of interest in both sparse and crowded environments is a challenging problem, not yet successfully addressed in the literature. In this paper, we propose a new long-term visual tracking algorithm, learning discriminative correlation filters and using an online classifier, to track a target of interest in both sparse and crowded video sequences. First, we learn a translation correlation filter using a multi-layer hybrid of convolutional neural networks (CNN) and traditional hand-crafted features. Second, we include a re-detection module for overcoming tracking failures due to long-term occlusions using online SVM and Gaussian mixture probability hypothesis density (GM-PHD) filter. Finally, we learn a scale correlation filter for estimating the scale of a target by constructing a target pyramid around the estimated or re-detected position using the HOG features. We carry out extensive experiments on both sparse and dense data sets which show that our method significantly outperforms state-of-the-art methods.",2018,Journal of Visual Communication and Image Representation
ZHOU201830,No-reference quality assessment of DIBR-synthesized videos by measuring temporal flickering,"Video quality evaluation, View synthesis, DIBR, Flickering, Singular value decomposition","Depth-image-based-rendering (DIBR) is the most popular view synthesis method. The rendering process in DIBR introduces artifacts to synthesized views. Temporal inconsistency of these artifacts causes flickering, which is one of the dominant distortions in DIBR-synthesized videos. We propose a no-reference quality index for DIBR-synthesized videos. A two-stage flickering region detection method is first proposed by calculating the gradient distance between the matching blocks in adjacent frames followed by a refinement operation. Subsequently, the distortion intensity of flickering regions is measured in singular value decomposition domain. The average flickering intensity is computed as the quality score. Experimental results show that our method outperforms the state-of-the-arts on the IRCCyN/IVC database and ranks the second on the SIAT database, which is only slightly worse than the best-performing one. Furthermore, the presented method is applied to improve the performances of existing metrics and benchmark DIBR algorithms, which achieves very promising results for both tasks.",2018,Journal of Visual Communication and Image Representation
BARROS2018363,Single-shot underwater image restoration: A visual quality-aware method based on light propagation model,"Image restoration, Underwater vision, Feature-preserving, Visibility, Inverse problem","In this paper, we present a novel method to restore the visual quality of images from scenes immersed in participating media, in particular water. Our method builds upon existing physics-based model and estimates the scene radiance by removing the medium interference on light propagation. Our approach requires a single image as input and, by combining a physics-based model for light propagation and a set of quality metrics, reduces the artifacts and degradation imposed by the attenuation, forward scattering, and backscattering effects. We show that the resulting images produced by our technique from underwater images are amenable to be directly used as input to algorithms which do not assume disturbances from the media. Our experiments demonstrate that, as far as visual image quality is concerned, our methodology outperforms both traditional image based restoration approaches and the state-of-the-art methods. Our approach brings advantages regarding descriptor distinctiveness which enables the use of underwater images in legacy non-participating media algorithms such as keypoint detection and description.",2018,Journal of Visual Communication and Image Representation
AMIRI2018816,Leveraging multi-modal fusion for graph-based image annotation,"Image annotation, Tag, Manifold, Multi-modal representation, Graph-based learning, Supergraph","Considering each of the visual features as one modality in image annotation task, efficient fusion of different modalities is essential in graph-based learning. Traditional graph-based methods consider one node for each image and combine its visual features into a single descriptor before constructing the graph. In this paper, we propose an approach that constructs a subgraph for each modality in such a way that edges of subgraph are determined using a search-based approach that handles class-imbalance challenge in the annotation datasets. Multiple subgraphs are then connected to each other to have a supergraph. This follows by introducing a learning framework to infer the tags of unannotated images on the supergraph. The proposed approach takes advantages of graph-based semi-supervised learning and multi-modal representation simultaneously. We evaluate the performance of the proposed approach on different datasets. The results reveal that the proposed approach improves the accuracy of annotation systems.",2018,Journal of Visual Communication and Image Representation
GREGORI2018518,Fuzzy averaging filter for impulse noise reduction in colour images with a correction step,"Color image filter, Correction step, Fuzzy filter, Impulse noise","In this paper we propose a fuzzy detection and reduction method for impulse noise in colour images. Detection is based on the fuzzyfication of a well-known statistic called ROD. The noise degrees obtained are used to reduce impulses by employing a fuzzy averaging between the input colour vector and a robust estimate of noise-free colour vector within the input neighbourhood. Fuzzy averaging has some advantages in terms of both noise reduction and detail preservation in front of detect and replace approaches because of threshold based decisions of the latter. However, robustness of the former is lower. We solve this problem by including a correction mechanism that checks the fuzzy noise degree of the output and replaces it with a robust colour vector either when noise has not been properly reduced or when a colour artefact has been introduced. We carry out a thorough study of the method parameter setting and give a convenient and robust setting. Experimental results show that our approach is very robust in front of four different types of impulse noise.",2018,Journal of Visual Communication and Image Representation
LEE201891,Photographic composition classification and dominant geometric element detection for outdoor scenes,"Image classification, Photographic composition, Composition element detection, Geometric element detection, Sky detection, Rule of thirds","Despite the practical importance of photographic composition for improving or assessing the aesthetical quality of photographs, only a few simple composition rules have been considered for its classification. In this work, we propose novel techniques to classify photographic composition rules of outdoor scenes and detect dominant geometric elements, called composition elements, for each composition class. Specifically, we first categorize composition rules of outdoor photographs into nine classes: RoT, center, horizontal, symmetric, diagonal, curved, vertical, triangle, and pattern. Then, we develop a photographic composition classification algorithm using a convolutional neural network (CNN). To train the CNN, we construct a photographic composition database, which is publicly available. Finally, for each composition class, we propose an effective scheme to locate composition elements, i.e., bounding boxes for main subjects, leading lines, axes of symmetry, triangles, and sky regions. Extensive experimental results demonstrate that the proposed algorithm classifies composition classes reliably and detects composition elements accurately.",2018,Journal of Visual Communication and Image Representation
PERROT2018841,Sampling strategies for performance improvement in cascaded face regression,"Face landmarking, Regression, Sampling, Data augmentation","Automatic face landmarking has received a lot of attention in the past decades. It is now mature enough to be implemented in fully autonomous video systems. As cascade-of-regression based algorithms have become state of the art in such systems, two major (and still relevant) sources of interest have slowly faded away: the need for semantic-driven learning beyond ground truth annotation, and full video chain performance i.e. tracking efficiency, which in the case of said methods strongly relates to their robustness towards shape initialization before fitting. In this paper, we investigate how data sampling using face priors can affect their performance in terms of convergence and robustness. We propose new strategies based on said priors to overcome inconsistencies observed during cascade-of-regression learning on purely random sampling-based stages. We will show that simple choices can be easily integrated within regression-based face tracking systems to increase accuracy and robustness.",2018,Journal of Visual Communication and Image Representation
KARIMI2018853,Nonparametric blind SAR image super resolution based on combination of the compressive sensing and sparse priors,"Blind super resolution, Synthetic aperture radar, Point spread function estimation, Compressive sensing, Anisotropic total variation, Conjugate gradient least squares","This paper by proposing a novel approach, is one the first works that addresses the highly ill-posed problem of nonparametric blind single image super resolution (SISR) of the synthetic aperture radar (SAR) images. Combination of an adaptive compressive sensing (CS) technique and some effective sparse priors, as a powerful regularizer in the both high resolution (HR) image reconstruction and the point spread function (PSF) estimation domains is the fundamental idea of the proposed method. This task is formulated as a new cost function to be minimized with respect to an intermediate reconstructed HR image patch and a nonparametric PSF kernel, according to the alternative minimization (AM) algorithm. To solve the optimization of cost function, a numerical scheme based on the conjugate gradient least squares (CGLS) method is proposed. Experimental results for the both synthetic and realistic low resolution (LR) SAR images demonstrate that the proposed method achieves the state-of-the-art performance.",2018,Journal of Visual Communication and Image Representation
ZHANG2018215,An effective motion object detection method using optical flow estimation under a moving camera,"Optical flow estimation, The moving camera, The horizontal flow, The vertical flow, Motion object detection, Motion object boundary","Optical flow techniques have been applied to motion object detection under a moving camera over the years. In this paper, we propose an effective motion object detection method based on optical flow estimation, characterized in that the complete boundary of the motion object can be extracted from the combination of the optimized horizontal flow with the optimized vertical flow. The optimized horizontal flow and the optimized vertical flow can be obtained as follows: introducing a third frame into the two frames to obtain the horizontal flow and the vertical flow, and then optimizing the horizontal flow and the vertical flow by applying gradient function and threshold method, respectively. The complete boundary of the motion object, after being subjected to region filling, could be optimized by Gaussian filtering technique to obtain the final detection results. Our proposed method is tested on the following datasets consisting of Cdnet2014, KITTI2015, MPI Sintel datasets, natural YouTube sequences and the collected data, respectively. The results show that our proposed method outperforms state-of-the-art significantly.",2018,Journal of Visual Communication and Image Representation
JIN20181,Video oriented filter for impulse noise reduction,"Video denoising, Window-adaptive filter, Orientation estimation, Impulse noise","A window-adaptive video filter for removal of impulse noise from grayscale videos is proposed. The new method is based on local orientation estimation. The dominant orientation of the pattern in a local spatial neighborhood is computed by minimizing an expression of directional derivatives, and at the same time the orientation strength is also computed. Based on the local spatial orientation and its strength, the size, shape, and orientation of 3D filter window are adaptively determined, which leads to the proposed window-adaptive 3D median filter. To further enhance denoising performance, a new noise detection mechanism is developed and integrated to the proposed video filter. By using this noise detector, video pixels are classified into noise-free and noisy ones. For the noisy pixels detected, the proposed window-adaptive 3D filter is performed. Experimental results show that the proposed method outperforms other state-of-the-art video denoising methods in both objective measure and visual evaluation.",2018,Journal of Visual Communication and Image Representation
ZHENG201867,Incremental generalized multiple maximum scatter difference with applications to feature extraction,"Feature extraction, Generalized multiple maximum scatter difference, Incremental GMMSD+","In this paper, we propose a new algorithm to implement the generalized multiple maximum scatter difference (GMMSD). Due to enhanced features of this algorithm over the original GMMSD, we named it GMMSD+. By employing a different projection from both the range of the between-class scatter matrix and the null space of the within-class scatter matrix, GMMSD+ can divide the centroid vector of each class into two components: intrinsic common component (ICC) and discriminant difference component (DCC), and then automatically discards ICC which contains little discriminative information, while keeping DCC which contains the true discriminative power. Next, we introduce a practical implementation of GMMSD+, which can accurately and efficiently update the discriminant vectors with new training samples incrementally, eliminating the complete re-computation of the training process. Our experiments demonstrate that incremental version of GMMSD+(IGMMSD+) eliminates the complete re-computation of the training process when new training samples are presented, leading to significantly reduced computational cost.",2018,Journal of Visual Communication and Image Representation
SHI2018229,Depth sensing with coding-free pattern based on topological constraint,"Coding-free, Depth sensing, Structured light, Topological constraint, Dynamic programming","Structured light depth sensing with a single-shot pattern is widely employed to capture depth maps for dynamic scenes. For conventional structured light techniques, the projected pattern has to be coded delicately in regards to color, shape, and intensity, in order to assign each pixel with a unique label. However, using such a complicated pattern is a double-edged sword, as although it is effective in labelling pixels, it is also sensitive to environmental noise such as: ambient illumination, textures, uneven albedos, or colors of objects in a scene. In contrast, a coding-free pattern is simply constructed and also insensitive to various environmental noise. Therefore, the coding-free pattern method is capable of robustly sensing the depth for complex scenes. The main challenge in coding-free depth sensing is the ‘correspondence retrieval’ between the projected and captured pattern (i.e. matching pixels between the projected and captured pattern). In this study, we focused on evaluating the correspondence retrieval in a coding-free binary grid pattern. A graph based topological labelling (GBTL) algorithm is proposed to determine the topological coordinates of the intersections of the grid. Then we retrieved the correspondence by using the topology of the grid and the epipolar constraint. We also demonstrated the upper bounds of depth variance by employing the proposed method. The proposed technique alleviates many of the limitations faced with traditional correspondence retrieval. Experimental results showed that the proposed technique performed better (i.e. in terms of precision) than the popular RGB-D cameras Kinect v1 and Kinect v2. Compared with the traditional single-shot techniques, which require complicated patterns, the proposed technique significantly improved the robustness and ease of work, while achieving comparable precision. Additionally, this proposed technique could also be used for both the binary coding-free and the traditional chromatic grid patterns.",2018,Journal of Visual Communication and Image Representation
MENG2018572,Merged region based image retrieval,"Image retrieval (IR), Regional convolution mapping feature (RCMF), Convolution neural networks (CNN), Integrated category matching (ICM)","In Region based Image Retrieval (RBIR) methods, region matching mainly focuses on region-to-region and image-to-image methods. The former may cause loss of image information and the latter may lead to similar regions being matched repeatedly. To solve these problems, we propose a new image retrieval method based on merged regions, and feature extraction and matching are processed at the category level. Merged regions in an image belong to the same category to some extent, and are obtained by a statistical region merging and affinity propagation (SRM-AP) algorithm. For feature extraction, regional convolution mapping feature (RCMF) based on the convolutional neural networks (CNN) are extracted. RCMF is further combined with the number and distribution of regions to represent the characteristics of merged regions. Moreover, to match the merged regions according to their significance in images, an integrated category matching (ICM) method is designed. Experimental results on Corel-1000 and Caltech-256 show that the proposed method is more effective than some existing RBIR methods.",2018,Journal of Visual Communication and Image Representation
ZHANG2018263,A multi-view camera-based anti-fraud system and its applications,"Anti-fraud, Key frames, Face recognition","Anti-fraud system is very useful in many intelligent applications. With the development of the financial field, anti-fraud system is becoming more and more important. But conventional face recognition techniques cannot distinguish real faces and masks effectively from the video stream. In addition, computing the whole video stream is redundant and time-consuming. So computing some key frames selected from video stream is more effective, but many frames gotten randomly from video stream don’t contain any faces. So in this paper, we propose a new method only with a camera to estimate a person’s behavior to detect whether a person is fraudulent. A camera-based anti-fraud system requires a series of representative video frames (i.e. key frames) from the video stream. First, a set of key frames are extracted from the video stream using our active key frame selection algorithm. The criterion is that the contents of the video stream are maximally covered by these frames. Then, face features are obtained using Dlib. Finally, a probabilistic model is proposed to estimate a person’s behavior. Experimental results have demonstrated that: 1) our key frame selection algorithm can reduce redundant frames effectively; 2) our system can estimate a person’s behavior in real time.",2018,Journal of Visual Communication and Image Representation
LIU2018766,"Progressive (k,n) secret image sharing Scheme with meaningful shadow images by GEMD and RGEMD","Progressive secret sharing scheme, Meaningful shadow image, GEMD, RGEMD","In (k,n) progressive secret image sharing (PSIS) schemes, a secret image is shared into n shadows in such way that: (1) fewer than k-1 shadows get no information on the secret image; (2) k to n shadows can progressively recover the secret image. In most PSIS schemes, the shadows are noise-like images which would cause suspicious of attackers. The combination of secret image sharing and steganography can share a secret image into meaningful shadow images that can reduce attention of attackers. However most existing secret image sharing schemes with meaningful shadow images do not possess progressive property, a group of shadow images can either reconstruct entire secret image or get nothing on it. In this paper, we construct a new (k,n) PSIS with meaningful shadow images using GEMD and RGEMD. The property of progressive reconstruction is proved both in theoretical analysis and experimental results. The approaches of GEMD and RGEMD enable our Scheme high embedding capacity and resistance of RS detection. Comparing with other PSISs with meaningful shadow images, our Scheme has advantages in shadow size and shadow visual quality.",2018,Journal of Visual Communication and Image Representation
WU2018415,Joint entropy based learning model for image retrieval,"joint entropy, learning instance, image retrieval, watershed segmentation, precise-recall curve, AP value, AUC value","As one classic technique of computer vision, image retrieval could retrieve the target images from hundreds of thousands of images effectively. Furthermore, with the rapid development of deep learning, the quality of retrieval is increased obviously. However, under normal conditions, the high-quality retrieval is supported by a large number of learning instances. The large number of learning instances not only need much human source in the process of selection, but also need much computing source in the process of computation. More importantly, for some special categories, it’s difficult to obtain a large number of learning instances. Aiming at the problem above, we proposed one joint entropy based learning model which could reduce the number of learning instances through optimizing the distribution of learning instances. Firstly, the learning instances are pre-selected using improved watershed segmentation method. Then, joint entropy model is used for reducing the possibility of double, useless even mistaken instances existence. After that, a database using a large number of images is built up. Sufficient experiments based on the database show the model’s superiority that our model not only could reduce the number of learning instances but also could keep the accuracy of retrieval.",2018,Journal of Visual Communication and Image Representation
LIN2018504,Moving cast shadow detection using scale-relation multi-layer pooling features,"Shadow removal, Moving cast shadow, Scale-relation, Multi-layer pooling, Ensemble decision scheme","Moving cast shadows detection and removal are indispensable for object detection and are the problems in visual surveillance applications which have been studied over the years. However, finding an efficient model that can handle the issue of moving cast shadow in various situations is still challenging. Unlike prior methods, we use a data-driven method without strong parametric assumptions or complex models to address the problem of moving cast shadow. In this paper, we propose a novel feature-extracting framework called Scale-Relation Multi-Layer Pooling Feature Extracting (SMPF) which includes two main tasks: (1) Scale-Relation Scheme (SRS), (2) Multi-Layer Pooling Scheme (MLPS). By leveraging the scale space, SRS firstly decomposes feature images of each shadow properties into various scales and further considers the relationship between adjacent scaled feature images of each shadow properties to extract the scale-relation features. Then, we design the multi-layer pooling scheme (MLPS) to integrate the features in a local region and to reduce the dimension of extracting features. After that, the density map is generated for various properties of shadow with low dimension. Finally, to seek the criteria for discriminating moving cast shadow, we use random forest algorithm as the ensemble decision scheme. The main contributions of this study are (1) we design the features with multi-scale which can provide abundant information to describe the moving cast shadow, (2) the multi-layer pooling scheme generates the density map to integrate and reduce the dimensions of features. Experiments on the popular benchmarks and the proposed dataset with benchmarks demonstrate that the proposed method can achieve the performances of the popular methodologies.",2018,Journal of Visual Communication and Image Representation
ZHENG2018157,Integrating support vector machine and graph cuts for medical image segmentation,"Support vector machine, Graph cuts, Medical image segmentation","Medical image segmentation remains a challenged problem because of intensity inhomogeneity and surrounding complex background. In this paper, we propose a novel method for medical image segmentation by integrating support vector machine and graph cuts. Particularly, a novel localized training scheme is proposed to train a classifier for each pixel based on the target image information, and then a novel graph cuts-based segmentation method that combines the constraint information of machine learning result, the edge information, the local information, and the remote-local information is proposed for post-processing. Instead of delineating an initialized curve around the object boundary, we directly draw a narrowband mask for the initialization in the paper. Experiments on synthetic and medical images demonstrate that the proposed method can achieve better performance than the state-of-the-art.",2018,Journal of Visual Communication and Image Representation
WANG2018404,Region ensemble network: Towards good practices for deep 3D hand pose estimation,"Convolutional network, Hand pose estimation, Human pose estimation, Fingertip detection, Ensemble learning, Depth imaging","3D hand pose estimation is an important and challenging problem for human-computer interaction. Recently convolutional networks (ConvNet) with sophisticated design have been employed to address it, but the improvement is not so significant. To exploit good practice and promote the performance for hand pose estimation, we propose a Region Ensemble Network (REN) for directly 3D coordinate regression. It first partitions the last convolutional outputs of ConvNet into several grid regions. Results from separate fully-connected (FC) regressors on each regions are integrated by another FC layer to perform estimation. By exploitation of several training strategies including data augmentation and smooth L1 loss, REN significantly improves the performance of ConvNet for hand pose estimation. Experiments demonstrate that our approach achieves strong performance on par or better than state-of-the-art algorithms on three public hand pose datasets. We also experiment our methods on fingertip detection and human pose datasets and obtain state-of-the-art accuracy.",2018,Journal of Visual Communication and Image Representation
NIKAN2018742,A modified technique for face recognition under degraded conditions,"Face recognition, Global based, Block based, Decision fusion","In this paper an improved face recognition algorithm under degrading conditions is proposed. The proposed algorithm uses a combination of preprocessing techniques coupled with discriminative feature extractors to obtain the best distinctive features for classification. Preprocessing approach is the fusion of multi-scale Weber and enhanced complex wavelet transform. Combination of multiple feature extraction based on Gabor filters, block-based local phase quantization (LPQ) coupled with principal component analysis (PCA) proved to be very effective to improve correct rate of recognition. We have also used two known classifiers, extreme learning machine (ELM), and sparse classifier (SC), and fused their outputs to obtain best recognition rate. Experimental results show improved performance of proposed algorithm under poor illumination, partial occlusion and low-quality images in uncontrolled conditions. Our best recognition results using second version of face recognition grand challenge (FRGC 2.0.4) which is the most challenging database, indicated more than 28% improvement over previous works.",2018,Journal of Visual Communication and Image Representation
TANG2018253,Visual adaptive tracking for monocular omnidirectional camera,"Visual tracking, Omnidirectional camera, Multi-feature integration","This paper presents a sophisticated patch-based visual tracking algorithm using an omnidirectional camera with distortion adaptation. The omnidirectional camera is modeled using the equivalent projection theory, so that a nonlinear deformed neighbourhood can be accurately estimated in the image plane, which significantly facilitates feature coding. In order to improve the omnidirectional tracking performance, a patch-based multi-feature matching method is proposed under a probability framework. In particular, the distributions of patches covering key parts of the target are weighted adaptively according to their joint-feature response, which is able to track target robustly and filter out the outliers effectively. Extensive experiments have been conducted to verify the performance of the proposed omnidirectional tracking algorithm, which obtains promising results on challenging datasets and outperforms many state-of-the-art methods.",2018,Journal of Visual Communication and Image Representation
LI2018319,Single image super-resolution via adaptive sparse representation and low-rank constraint,"Super-resolution, Adaptive sparse representation, Self-similarity learning, Robust principal component analysis","Sparse representation theory shows effectiveness in single image super-resolution (SR). Existing image super-resolution methods usually make use of l1-regularization, l2-regularization or their combination to restrict the sparsity. However, the nonlocal similarity of images, which can be helpful to image SR, is often neglected. In order to utilize the nonlocal similarity and improve SR results in this paper, we propose a new single image super-resolution method by combining the adaptive sparse representation and robust principal component analysis (RPCA). Furthermore, we adopt the self-similarity learning framework to construct the dictionary pair. In our method, we first compute the sparse coefficient of each testing image patch through adaptive sparse representation with the constructed dictionary. Then, for each testing image block, we search for its similar patches and use RPCA as a low-rank optimization strategy to the corresponding coefficients. Extensive experiment results demonstrate that the proposed method can possesses better performance compared with some state-of-the-art methods.",2018,Journal of Visual Communication and Image Representation
WANG201880,Blind forensics of image gamma transformation and its application in splicing detection,"Blind forensics, Gamma transformation, Manipulation detection, Splicing, Tampered area location","Image forensics technology based on image manipulation detection has aroused great interest of researchers in recent decades. By revealing the traces of image manipulations, it could contribute to the location of tampered areas. This paper addresses the detection of image gamma transformation and its application in image splicing detection. A 5-dimensional feature vector is constructed based on the effects of gamma transformation on the histogram, and then Support Vector Machine (SVM) is trained to detect gamma transformation. For splicing tampered area locating, the investigated image is divided into overlapping blocks based on the sliding window, and then each pixel gets a probability of being gamma transformed according to the detection results in image blocks, based on which the tampered area is located. The experimental results validate the effectiveness of the proposed method when no post-operations are applied. Meanwhile, the proposed method is robust to the attack of rank filtering.",2018,Journal of Visual Communication and Image Representation
ZHANG2018540,Dynamic 3D reconstruction improvement via intensity video guided 4D fusion,"High-speed 3D video sensor, Multi-frame 4D fusion, Intensity tracking, Dynamic object, Noise reduction","The availability of high-speed 3D video sensors has greatly facilitated 3D shape acquisition of dynamic and deformable objects, but high frame rate 3D reconstruction is always degraded by spatial noise and temporal fluctuations. This paper presents a simple yet powerful dynamic 3D reconstruction improvement algorithm based on intensity video guided multi-frame 4D fusion. Temporal tracking of intensity image points (of moving and deforming objects) allows registration of the corresponding 3D model points, whose 3D noise and fluctuations are then reduced by spatio-temporal multi-frame 4D fusion. We conducted simulated noise tests and real experiments on four 3D objects using a 1000 fps 3D video sensor. The results demonstrate that the proposed algorithm is effective at reducing 3D noise and is robust against intensity noise. It outperforms existing algorithms with good scalability on both stationary and dynamic objects.",2018,Journal of Visual Communication and Image Representation
JI2018354,Correlation filter tracker based on sparse regularization,"Object tracking, Correlation filter, Adaptive regularization, Occlusion handling","Recently, correlation filter-based trackers have achieved the competitive performance both on accuracy and robustness. To learn a classifier effectively, these methods exploit a periodic assumption of the training samples to model the processing of dense sampling in Fourier domain. However, the periodic assumption introduces unwanted boundary effects, which severely degrades the performance of tracking model. To lower the boundary effects, we propose a multi-scale ℓ1 regularized correlation filter tracker (MSL1CFT), which leverages the different regularization parameters to penalize each correlation filter coefficient in the learning process. Our method can learn the correlation filter model on a significantly larger set of negative training samples, without worsening the positive samples. We further present a fast solver to our model utilizing the Alternating Direction Method of Multipliers (ADMM) technique. The extensive empirical evaluations on two benchmark datasets: OTB2013 and VOT2015 demonstrate that our method outperforms the state-of-the-art approaches in tracking accuracy and robustness.",2018,Journal of Visual Communication and Image Representation
JIN2018720,Content-based image retrieval model based on cost sensitive learning,"Content-based image retrieval, Distance metric learning, Cost sensitive learning, Classification performance, Misclassification cost, Class imbalance","How to retrieve the desired images quickly and accurately from the large scale image database has become a hot topic in the field of multimedia research. Many content-based image retrieval (CBIR) technologies already exist, but they are not always satisfactory. In many applications, the CBIR model based on machine learning relies heavily on the distance metric between samples. Although the traditional distance metric methods are simple and convenient, it is not always appropriate for CBIR tasks. In this paper, a novel distance metric learning (DML) method based on cost sensitive learning (CSL) is studied, and then it is used in a large margin distribution learning machine (LDM) to replace the traditional kernel functions. The improved LDM also takes into account CSL, and which is called CS-DLDM. Finally, CS-DLDM model is applied to CBIR tasks for implementation classification. We compare the proposed CS-DLDM model with other classifiers based on CSL. The experimental results show that the proposed CS-DLDM model not only has satisfactory classification performance but also the lowest misclassification cost, can effectively avoid the class imbalance of sample.",2018,Journal of Visual Communication and Image Representation
FAN201840,Deepdiary: Lifelogging image captioning and summarization,"Lifelogging, First-person, Image captioning, Diary, Privacy","Automatic image captioning has been studied extensively over the last few years, driven by breakthroughs in deep learning-based image-to-text translation models. However, most of this work has considered captioning web images from standard data sets like MS-COCO, and has considered single images in isolation. To what extent can automatic captioning models learn finer-grained contextual information specific to a given person’s day-to-day visual experiences? In this paper, we consider captioning image sequences collected from wearable, life-logging cameras. Automatically-generated captions could help people find and recall photos among their large-scale life-logging photo collections, or even to produce textual “diaries” that summarize their day. But unlike web images, photos from wearable cameras are often blurry and poorly composed, without an obvious single subject. Their content also tends to be highly dependent on the context and characteristics of the particular camera wearer. To address these challenges, we introduce a technique to jointly caption sequences of photos, which allows captions to take advantage of temporal constraints and evidence across time, and we introduce a technique to increase the diversity of generated captions, so that they can describe a photo from multiple perspectives (e.g., first-person versus third-person). To test these techniques, we collect a dataset of about 8000 realistic lifelogging images, a subset of which are annotated with nearly 5000 human-generated reference sentences. We evaluate the quality of image captions both quantitatively and qualitatively using Amazon Mechanical Turk, finding that while these algorithms are not perfect, they could be an important step towards helping to organize and summarize lifelogging photos.",2018,Journal of Visual Communication and Image Representation
TURAN2018331,Histogram-based local descriptors for facial expression recognition (FER): A comprehensive study,"Feature extraction, Local descriptors, Facial expression recognition","This paper aims to present histogram-based local descriptors applied to Facial Expression Recognition (FER) from static images and provide a systematic review and analysis of them. First, we describe the main steps in encoding binary patterns in a local patch, which are required in every histogram-based local descriptor. Then, we list the existing local descriptors, while analysing their strengths and weaknesses. Finally, we present the experimental results of all these descriptors on commonly used facial expression databases, with varying resolution, noise, occlusion, and number of sub-regions, as well as comparing them with the results obtained by the state-of-the-art deep learning methods. This paper aims to bring together different studies of the visual features for FER by evaluating their performances under the same experimental setup, and critically reviewing various classifiers making use of the local descriptors.",2018,Journal of Visual Communication and Image Representation
REN2018131,Context-Assisted 3D (C3D) Object Detection from RGB-D Images,"3D Object Detection, Indoor Scene Understanding, Convolutional Neural Network, Conditional Random Field","We study the problem of 3D object detection from RGB-D images so as to achieve localization (i.e., producing a bounding box around the object) and classification (i.e., determining the object category) simultaneously. Its challenges arise from high intra-class variability, illumination change, background clutter and occlusion. To solve this problem, we propose a novel solution that integrates the 2D information (RGB images), the 3D information (RGB-D images) and the object/scene context information together, and call it the Context-Assisted 3D (C3D) method. In the proposed C3D method, we first use a convolutional neural network (CNN) to jointly detect a 3D object in a scene and its scene category. Then, we improve the detection result furthermore with a Conditional Random Field (CRF) model that incorporates the object potential, the scene potential, the scene/object context, the object/object context, and the room geometry. Extensive experiments are conducted to demonstrate that the proposed C3D method achieves the state-of-the-art performance for 3D object detection against the SUN RGB-D benchmark dataset.",2018,Journal of Visual Communication and Image Representation
ZHU2018243,Multiple disjoint dictionaries for representation of histopathology images,"Image retrieval, Image representation, Histopathology, Wholeslide imaging, Bag-of-words, Dictionary learning, LBP, SVM, Deep learning","With the availability of whole-slide imaging in pathology, high-resolution images offer a more convenient disease observation but also require content-based retrieval of large scans. The bag-of-visual-words methodology has shown a high ability to describe the image content for recognition and retrieval purposes. In this work, a variant of the bag-of-visual-words with multiple dictionaries for histopathology image classification is proposed and tested on the image dataset Kimia Path24 with more than 27,000 patches of size 1000 × 1000 belonging to 24 different classes. Features are extracted from patches and clustered to form multiple codebooks. The histogram intersection approach and support vector machines are exploited to build multiple classifiers. At last, the majority voting determines the final classification for each patch. The experiments demonstrate the superiority of the proposed method for histopathology images that surpasses deep networks, LBP and other BoW results.",2018,Journal of Visual Communication and Image Representation
ZHANG2018756,A method of multi-criteria set recognition based on deep feature representation,"Person re-identification, Convolutional neural network, Multiple metric ensembles","The large variations in the angle of different camera views and illumination can change the appearance of a lot of people, which makes human re identification is still a challenging problem. Therefore, the development of robust feature descriptors and the design of discriminative distance metrics to measure similarity between pedestrian images are two key aspects of human re identification. In this paper, we propose a method to improve the performance of the re identification using depth learning and multiple metric ensembles. First, we use a variety of data sets to train the general convolutional neural network (CNN), which is used to extract the features of the training and test set after deep level. Deep architecture makes it possible for people to learn more abstract and internal features that are robust to changes in viewpoint and illumination. Then, we utilize the deep features of the training set to learn a specific distance metric and combine it with the cosine distance metric. Multi metric sets can be used to measure the similarity between different images. Finally, a large number of experiments show that our method can effectively improve the recognition performance compared to the state-of-the-art methods.",2018,Journal of Visual Communication and Image Representation
ZHENG2018688,Visual tracking via Graph Regularized Kernel Correlation Filer and Multi-Memory Voting,"Visual object tracking, Graph Regularized Kernel Correlation Filer, Multi-Memory Voting, Drift handling","Correlation filter based tracking approach has been an important branch of visual tracking. However, most correlation filter based trackers fail to work under occlusion due to their frame-by-frame model update strategy, and the tracking performance can be further enhanced by optimizing the energy equation. The target appearance during tracking is nearly moving on a manifold. So, the classification scores should be similar on the target manifold. K Nearest Neighbor graphs are constructed and the classification scores on the neighborhood are regularized to have similar values. Through the local score propagation on the graph, the learned Graph Regularized Kernel Correlation Filer can represent different appearances of the object. Furthermore, in the proposed Multi-Memory Voting scheme, occlusion problem is addressed by voting from multiple target snapshots in the memory pool. An extensive evaluation on two recent benchmarks shows that the proposed tracker achieves competitive performance compared to nine other state-of-the-art trackers.",2018,Journal of Visual Communication and Image Representation
RABBOUCH2018115,A wavelet-assisted subband denoising for tomographic image reconstruction,"Denoising, Wavelets, Non-local means, Radon transform, Tomography, Medical imaging, Simulation","Many methods of image acquisition from medical multidimensional data rely on continuous techniques whereas in fact they are used in a finite discrete field. The discretization step is often accompanied by residuals diminishing the quality of the produced images. In addition, the acquisition phase does not occur in an ideal way and may cause artifacts and nonstandard noise. Therefore, denoising is mandatory for many algorithms in computer vision and image processing. In this paper, we propose a new denoising strategy for the tomographic image reconstruction. The method is based on a coupling of the wavelet techniques with the well-known Non Local Means (NLM) filter and operates adaptively during the data acquisition stage. Unlike other well-known denoising techniques, which are mainly based on the smoothing of the resultant image, this approach is instead based on the sinogram preprocessing. The numerical simulations show that the tomographic reconstruction based on the new denoising strategy is able to reduce enough noises present in various forms in the data. Additional robustness tests prove that the proposed approach is more stable than the basic NLM and other homologous methods.",2018,Journal of Visual Communication and Image Representation
NG2018548,Orthogonal filter banks with region Log-TiedRank covariance matrices for face recognition,"Orthogonal filters, Region covariance matrices, Log-TiedRank, Face recognition","With the capability of fusing varying features from a specific image region, the Region Covariance Matrices (RCM) image descriptor has been evidenced plausible in face recognition. However, a systematic study for RCM, regarding which features to be fused in particular, remains absent. This paper therefore explores several features derived from the orthogonal filter ensembles, i.e., Identity Transform, Discrete Haar Transform, Discrete Cosine Transform, and Karhunen-Loève Transform, for feature encoding in RCM. Aside from that, we also outline a RCM variant, dubbed Region Log-TiedRank Covariance Matrices (RLTCM) in this paper. The RLTCM descriptor, on average, exhibits dramatic performance gain over RCM as well as state-of-the-art descriptors, especially when probe sets far deviated from the face gallery. Furthermore, we discern that the RLTCM descriptor defined based on Identity Transform, i.e., the simplest form of orthogonal filters, and other learning-free orthogonal filters yield impressive performance on par with the learning-based counterparts.",2018,Journal of Visual Communication and Image Representation
ROY2018829,Discriminative body part interaction mining for mid-level action representation and classification,"Action recognition, Mid level feature, Zero shot learning","In this paper, we propose a novel mid-level feature representation for the recognition of actions in videos. This descriptor proves to posses relevant discriminative power when used in a generic action recognition pipeline. It is well known that mid-level feature descriptors learnt using class-oriented information are potentially more distinctive than the low-level features extracted in a bottom-up unsupervised fashion. In this regard, we introduce the notion of concepts, a mid-level feature representation capable of tracking the dynamics of motion salient regions over consecutive frames in a video sequence. Our feature representation is based on the idea of region correspondence over consecutive frames and we make use of an unsupervised iterative bipartite graph matching algorithm to extract representative visual concepts from action videos. The progression of such salient regions, which are also consistent in appearance, are henceforth represented as chain graphs. Finally, we adopt an intuitive time-series pooling strategy to extract discriminant features from the chains, which are then used in a dictionary learning based classification framework. Given the high variability of the movements of different human body parts in separate actions, the extracted conceptual descriptors are proved to capture the different dynamic characteristics by exclusively encoding the interaction parts associated to the chains. Further, we use such descriptors in a semi-supervised, clustering-based zero-shot action recognition setting, showing good performance and without resorting to costly attribute annotation. We validate the proposed framework on four public datasets namely KTH, UCF-101, HOHA and HMDB-51, reporting increased (and comparable in some cases) classification accuracies with respect to the state of the art.",2018,Journal of Visual Communication and Image Representation
TANAKA201856,Iterative applications of image completion with CNN-based failure detection,"Image completion, Image inpainting, Convolutional neural network, Failure detection","Image completion is a technique to fill missing regions in a damaged or redacted image. A patch-based approach is one of major approaches, which solves an optimization problem that involves pixel values in missing regions and similar image patch search. One major problem of this approach is that it sometimes duplicates implausible texture in the image or overly smooths down a missing region when the algorithm cannot find better patches. As a practical remedy, the user may provide an interaction to identify such regions and re-apply image completion iteratively until she/he gets a desirable result. In this work, inspired by this idea, we propose a framework of human-in-the-loop style image completion with automatic failure detection using a deep neural network instead of human interaction. Our neural network takes small patches extracted from multiple feature maps obtained from the completion process as input for the automated interaction process, which is iterated several times. We experimentally show that our neural network outperforms a conventional linear support vector machine. Our subjective evaluation demonstrates that our method drastically improves the visual quality of resulting images compared to non-iterative application.",2018,Journal of Visual Communication and Image Representation
CHEN2018149,Binary image steganalysis based on local texture pattern,"Binary image steganalysis, Local texture pattern, Manhattan distance, Ensemble classifier","In this paper, we propose a novel steganalytic scheme based on local texture pattern (LTP) to detect binary image steganography. We first assess how the expanded LTPs capture embedding distortions exactly. Considering curse of dimensionality when expanding LTPs, we employ Manhattan distance to measure the pixels correlation in a 5×5 sized block and select the pixels with closely correlation to remove some LTPs that are not interested. Although the stego image can maintain good visual quality, steganography scheme changes the inter-pixels correlation of binary image. Therefore we utilize totally 8192 LTPs histogram to define a 8192-dimensional steganalytic feature set. Original images and stego images are classified by ensemble classifier. Experimental results show that the proposed steganalytic method can more effectively detect state-of-the-art binary image steganography schemes compared with other steganalytic schemes.",2018,Journal of Visual Communication and Image Representation
DAI2018789,Deep network for visual saliency prediction by encoding image composition,"Deep network, Visual saliency regions, Image composition","This article will be visual significance into the graphical guidance (the chart is a medium-sized join subgraph). Deep structure, from the level of learning a significant map. The original image pixel to the object level graphic (oGL), and further Space level graphics (sGL). In particular, we first sample Super pixels from each image, and they are used as buildings Block of each object. In order to seamlessly describe different objects, the number of oGLs is generated by spatial adjacent links. The super pixel oGL object response mapping is obtained by obtaining, Transfer, the semantics of the image tag to oGL. As space, the layout of the object plays an important role in the prominence of the object based on the relevant learning distribution proposed sGL OGL position between. Finally, in order to imitate the “winner of all” Biological vision mechanism, the largest majority of voting programs, The sGL of the image, is probabilistically combined into a significant graph. Experimental results show that oGLs and sGLs capture the object level well and space-level visual cues, resulting in competitiveness significant detection accuracy.",2018,Journal of Visual Communication and Image Representation
MARINJIMENEZ2018627,3D human pose estimation from depth maps using a deep combination of poses,"3D human pose, Body limbs, Depth maps, ConvNets","Many real-world applications require the estimation of human body joints for higher-level tasks as, for example, human behaviour understanding. In recent years, depth sensors have become a popular approach to obtain three-dimensional information. The depth maps generated by these sensors provide information that can be employed to disambiguate the poses observed in two-dimensional images. This work addresses the problem of 3D human pose estimation from depth maps employing a Deep Learning approach. We propose a model, named Deep Depth Pose (DDP), which receives a depth map containing a person and a set of predefined 3D prototype poses and returns the 3D position of the body joints of the person. In particular, DDP is defined as a ConvNet that computes the specific weights needed to linearly combine the prototypes for the given input. We have thoroughly evaluated DDP on the challenging ‘ITOP’ and ‘UBC3V’ datasets, which respectively depict realistic and synthetic samples, defining a new state-of-the-art on them.",2018,Journal of Visual Communication and Image Representation
LU2018374,Spherically contoured exponential scale mixture prior based nonlocal image restoration with ADMM framework,"Image restoration, Nonlocal self-similarity, Spherically contoured exponential scale mixture, Weighted group-based simultaneous sparse coding, ADMM","According to the nonlocal self-similarity property of natural images, group-based simultaneous sparse coding (GSSC) model assumes that nonlocal similar patches have similar sparse representations in a given dictionary and have been widely used in various image inverse problems. Inspired by the success of the GSSC mode in image restoration problems, this paper proposes a weighted group-based simultaneous sparse coding (WGSSC) model based on the spherically contoured exponential scale mixture (SCESM) prior for image restoration. Compared with traditional GSSC models, which often characterize the similar sparse coefficients by a common set of zero supports and lack spatial adaption and principled fashion, the proposed model considers the dependent relation and adaptivity of similar sparse coefficient, so it is more rational than the GSSC model. The similar sparse coefficients and scale variables can be jointly estimated by the alternating minimization algorithm with the SCESM prior. Based on the estimated sparse coefficients, we can reconstruct the clear patch group and obtain the global denoised image by averaging these patch groups. We refer this denoised method as WGSSC-SCESM based denoiser prior, which can be effectively plugged into general image restoration problems by the alternating direction method of multipliers (ADMM) techniques. Extensive experiments on various types of image restoration problems, e.g., image denoising, inpainting, deblurring and single image super-resolution, demonstrate that the proposed method outperforms many state-of-the-art restored methods in term of the objective and subjective metrics.",2018,Journal of Visual Communication and Image Representation
CHEN2018795,Face-mask recognition for fraud prevention using Gaussian mixture model,"Gussian Mixture Model (GMM), Dlib, Deep learning, Fraud prevention","With the rapid development of biometric identification technology, face recognition has been one of the most widely used as its important component. It facilitates a series of applications such as security, military, transportation, education and other fields. The demand for face feature recognition is increasing. However the current techniques still exist some deficiencies. In this paper, we proposed a face-mask recognition method for fraud prevention based on Gaussian Mixture Model. We address the problem of identifying the face and mask in the area of financial security precaution. And we show how to combine opencv with dlib to recognition face and extract it. We use Gaussian Mixture Model (GMM) to construct the model of human faces. According to this, we calculate the similarity between the face sample and the model. By analyzing and learning the features of faces, we can predict whether the image of which we test is a human face or a mask. Compared with other traditional method of face recognition, our approach has been targeted to strengthen the ability to recognize abnormal faces such as sunglasses, masks and respirator, and reduce the potential danger of these unusual faces in the security field. It is simple to be calculated and has a higher accuracy. In addition, our method have enhanced the robustness of the algorithm about mask recognition.",2018,Journal of Visual Communication and Image Representation
HU201821,Learning spatial-temporal features for video copy detection by the combination of CNN and RNN,"Video copyright, CNN, Sequence matching, SiamesLSTM","Following the rapid developments of network multimedia, video copyright protection online has become a hot topic in recent researches. However, video copy detection is still a challenging task in the domain of video analysis and computer vision, due to the large variations in scale and illumination of the copied contents. In this paper, we propose a novel deep learning based approach, in which we jointly use the Convolution Neural Network (CNN) and Recurrent Neural Network (RNN) to solve the specific problem of detecting copied segments in videos. We first utilize a Residual Convolutional Neural Network(ResNet) to extract content features of frame-levels, and then employ a SiameseLSTM architecture for spatial-temporal fusion and sequence matching. Finally, the copied segments are detected by a graph based temporal network. We evaluate the performance of the proposed CNN-RNN based approach on a public large scale video copy dataset called VCDB, and the experiment results demonstrate the effectiveness and high robustness of our method which achieves the significant performance improvements compared to the state of the art.",2018,Journal of Visual Communication and Image Representation
LIU2018270,An automatic and serialized ROI extraction framework for the slow-motion video frames,"Slow-motion video, Serialized extraction, Color frame image, Automatic seed point generation","Currently, high-speed cameras has been a very common equipment in many important application fields. How to effectively and automatically extract the ROI (region of interest) for the slow-motion video has been a novel interesting challenge. In recent research work, we designed a ROI extraction framework for the video frames produced by high-speed cameras. The entire framework includes two parts: a novel but simple color similarity measure model is improved to distinguish different pixels; a skeleton feature points based serialized segmentation tactics is proposed to generate seed points. By using the multithreading patterns of parallelizing computations in the extraction process, the ROI in the serialized color slow-motion video frames can be marked automatically and accurately. Comparing with the common methods, this method has advantage in segmentation effect and computational efficiency. It can establish the technical basis for the pertinent subsequent studies.",2018,Journal of Visual Communication and Image Representation
GHODSI2018729,Simultaneous joint and object trajectory templates for human activity recognition from 3-D data,"Human activity recognition, RGB-D sensors, Trajectory-based representation, Action template, Dynamic time warping (DTW), Human object interaction","Availability of low-cost range sensors and the development of relatively robust algorithms for the extraction of skeleton joint locations have inspired many researchers to develop human activity recognition methods using 3-D data. In this paper, an effective method for the recognition of human activities from the normalized joint trajectories is proposed. We represent the actions as multidimensional signals and introduce a novel method for generating action templates by averaging the samples in a “dynamic time” sense. Then, in order to deal with the variations in speed and style of performing actions, we warp the samples with action templates by an efficient algorithm and employ wavelet filters to extract meaningful spatiotemporal features. The proposed method is also capable of modeling the human-object interactions, by performing the template generation and temporal warping procedure via the joint and object trajectories simultaneously. Experimental evaluations on several challenging datasets demonstrates the effectiveness of our method compared to the state-of-the-arts as well as its robustness against different sources of noise.",2018,Journal of Visual Communication and Image Representation
ZHANG2018106,Probabilistic collaborative representation based orthogonal discriminative projection for image set classification,"Image set, Face recognition, Probabilistic collaborative representation, Orthogonal discriminative projection","Image set based collaborative representation and classification(ISCRC) has been proposed and achieved state-of-the-art performance. Though ISCRC works well for Image set based face recognition(ISFR), the classification mechanism of ISCRC is still unclear. Besides, another challenge that ISCRC encountered is to deal with the high-dimensional data. In this paper, we first propose a novel Probabilistic Collaborative Representation based Classifier for Image Set (ProCRCIS), which is interpreted from a probabilistic viewpoint. Then, according to the reconstruction residual-based classification rule of ProCRCIS, we propose a novel dimensionality reduction method, called Probabilistic Collaborative Representation based Orthogonal Discriminative Projection for Image Set(ProCR-ODP-IS). The goal of ProCR-ODP-IS is to find a projection space such that the between-class reconstruction residual is maximized and the within-class reconstruction residual is minimized simultaneously. Hence, this projected space can fit ProCRCIS very well. Extensive experimental results on different datasets demonstrate the superiority of the proposed method compared to the state-of-the-arts.",2018,Journal of Visual Communication and Image Representation
YUNG2018561,Efficient feature-based image registration by mapping sparsified surfaces,"Triangulated image, Image registration, Coarse triangulation, Map interpolation","With the advancement in the digital camera technology, the use of high resolution images and videos has been widespread in the modern society. In particular, image and video frame registration is frequently applied in computer graphics and film production. However, conventional registration approaches usually require long computational time for high resolution images and video frames. This hinders the application of the registration approaches in the modern industries. In this work, we first propose a new image representation method to accelerate the registration process by triangulating the images effectively. For each high resolution image or video frame, we compute an optimal coarse triangulation which captures the important features of the image. Then, we apply a surface registration algorithm to obtain a registration map which is used to compute the registration of the high resolution image. Experimental results suggest that our overall algorithm is efficient and capable to achieve a high compression rate while the accuracy of the registration is well retained when compared with the conventional grid-based approach. Also, the computational time of the registration is significantly reduced using our triangulation-based approach.",2018,Journal of Visual Communication and Image Representation
WU2018424,Feedback weight convolutional neural network for gait recognition,"Gait recognition, Deep learning, Convolutional neural network, Weighted receptive field","Gait recognition is an important issue currently. In this paper, we propose to combine deep features and hand-crafted representations into a globally trainable deep model. Specifically, a set of deep feature vectors are firstly extracted by a pre-trained CNN model from the input sequences. Then, a kernel function with respect to the fully connected vector is trained as the guiding weight of the respective receptive fields of the input sequences. Therefore, the hand-crafted features are extracted based on the guiding weight. Finally, the hand-crafted features and the deep features are combined into a unified deep network to complete classification. The optimized gait descriptor, termed as deep convolutional location weight descriptor (DLWD), is capable of effectively revealing the importance of different body parts to gait recognition accuracy. Experiments on two gait data sets (i.e., CASIA-B, OU-ISIR) show that our method outperforms the other existing methods for gait recognition.",2018,Journal of Visual Communication and Image Representation
WANG2018698,Multi-task based object tracking via a collaborative model,"Collaborative model, Alternating direction method of multipliers, Multi-task sparse learning, Generative model, Discriminative model","This paper presents a multi-task based object tracking algorithm via a collaborative model. Under the framework of particle filtering, we develop a multi-task sparse learning based generative and discriminative classifier model. In the generative model, we propose a histogram based subspace learning method which takes advantage of adaptive templates update. In the discriminative model, we introduce an effective method to compute the confidence value which assigns more weights to the foreground than the background. A decomposition model is employed to take the common features and outliers of each particle into consideration. The alternating direction method of multipliers (ADMM) algorithm guarantees the optimization problem can be solved robustly and accurately. Qualitative and quantitative comparisons with nine state-of-the-art methods demonstrate the effectiveness and efficiency of our method in handling various challenges during tracking.",2018,Journal of Visual Communication and Image Representation
HANNANE2018179,MSKVS: Adaptive mean shift-based keyframe extraction for video summarization and a new objective verification approach,"Keyframe extraction, Video summarization, Mean shift, Features extraction, Summarization quality, Objective video summary evaluation","Video abstraction is an interesting topic that aims at briefly representing the entire video stream by producing a short summary either statically or dynamically. In this paper, we present an optimal static video summarization method based on keyframe extraction, termed as MSKVS. The proposed MSKVS has three major components: A new feature representation is exploited to describe the visual content of the video, a simple and fast algorithm is proposed to eliminate most similar and redundant frames, and an adaptive mean shift algorithm is used to select the most representative keyframes. We further develop a novel verification technique to measure the amount of information preserved by the produced summary and to make sure that it deserves to present the entire video stream regardless of human opinion impact. We report experimental results on six challenging datasets using different evaluation metrics, showing that MSKVS achieves state-of-the-art performances in a short computation time.",2018,Journal of Visual Communication and Image Representation
YOUSIF2018802,Object detection from dynamic scene using joint background modeling and fast deep learning classification,"Human-animal detection, Camera-trap images, Background subtraction, Deep convolutional neural networks, Wildlife monitoring","In this paper, we couple effective dynamic background modeling with fast deep learning classification to develop an accurate scheme for human-animal detection from camera-trap images with cluttered moving objects. We introduce a new block-wise background model, named as Minimum Feature Difference (MFD), to model the variation of the background of the camera-trap sequences and generate the foreground object proposals. We then develop a region proposals verification to reduce the number of false alarms. Finally, we perform complexity-accuracy analysis of DCNN to construct a fast deep learning classification scheme to classify these region proposals into three categories: human, animals, and background patches. The optimized DCNN is able to maintain high level of accuracy while reducing the computational complexity by 14 times, which allows near real-time implementation of the proposed method on CPU machines. Our experimental results demonstrate that the proposed method outperforms existing methods on our and Alexander von Humboldt Institute camera-trap datasets in both foreground segmentation and object detection.",2018,Journal of Visual Communication and Image Representation
NIU2018457,Learning an video frame-based face detection system for security fields,"Video frame-based face detection, Libfacedetection, Deep learning, Gaussian mixture model","It is know that face detection as a kind of artificial intelligence (AI) technology has become an indispensable tool in our daily life, which produce effects on every aspect of us. The demand for detection and recognition is higher accuracy and higher speed in different areas. So a new video frame-based face detection system is designed to help us making good safety precautions in recognition between normal face and abnormal face. Abnormal face means that face is partially occluded by some objects such as mask, sunglass and so on. Since these abnormal faces are easily recognized as normal faces in previous detection systems, they are often ignored. And it brings us some potential dangers, especially in the area of residential face detection access, bank business login and other security areas. This system provides a complete set of process for detecting faces from video and distinction them, which achieves a good real-time performance in accuracy and speed. We adopt libfacedetection to detect faces from each frame. In addition, we introduce a dlib library which is a deep learning tools to help aligning face and extract the characteristic value. And a GMM clustering algorithm is provided to train and test images for the system. This system can help us to make a distinction between normal face and abnormal face, which is of great significance to the security field in the future.",2018,Journal of Visual Communication and Image Representation
KAPLAN201843,Location disclosure risks of releasing trajectory distances,"Privacy, Spatio-temporal data, Trajectory data, Data mining","Location tracking devices enable trajectories to be collected for new services and applications such as vehicle tracking and fleet management. While trajectory data is a lucrative source for data analytics, it also contains sensitive and commercially critical information. This has led to the development of systems that enable privacy-preserving computation over trajectory databases, but many of such systems in fact (directly or indirectly) allow an adversary to compute the distance (or similarity) between two trajectories. We show that the use of such systems raises privacy concerns when the adversary has a set of known trajectories. Specifically, given a set of known trajectories and their distances to a private, unknown trajectory, we devise an attack that yields the locations which the private trajectory has visited, with high confidence. The attack can be used to disclose both positive results (i.e., the victim has visited a certain location) and negative results (i.e., the victim has not visited a certain location). Experiments on real and synthetic datasets demonstrate the accuracy of our attack.",2018,Data & Knowledge Engineering
PALOMARES201864,Multi-view fuzzy information fusion in collaborative filtering recommender systems: Application to the urban resilience domain,"Collaborative filtering recommender systems, Multi-view similarity information fusion, Fuzzy aggregation, Ordered weighted averaging, Uninorm, Urban resilience","Recommender systems play an increasingly important role in on-line web services for the personalization and recommendation of content to individual users. The quantity and quality of user-based information has progressed presenting the opportunity to further tailor recommendations to users based on feature view integration. In this work, we propose a hybrid framework which combines a collaborative filtering recommendation system with fuzzy decision-making approaches (based on the use of aggregation functions) to improve the accuracy of domain-specific recommendations. We extend upon the classical, neighborhood-based collaborative filtering process by conflating preference information with user-profile data in the recommendation process. This is performed using intelligent information fusion techniques whereby Ordered Weighted Averaging (OWA) operators and uninorm aggregation functions are implemented in the fusion of multiple views of pairwise similarity degrees between users. To address the shortcoming of generating sensible recommendations to cold users, we incorporate a novel weighting scheme based on fuzzy set modeling within the uninorm-based aggregation of similarity views. We finally outline the application of the proposed approach through an empirical study based in the Urban Resilience domain, along with an example to movie recommendation.",2018,Data & Knowledge Engineering
SATTARI2018155,A spreading activation-based label propagation algorithm for overlapping community detection in dynamic social networks,"Spreading activation, Label propagation algorithm, Overlapping community detection, Dynamic social networks","Community detection in temporal social networks is an increasingly challenging subject in network analysis. The Label Propagation Algorithm (LPA) is a simple and fast approach for community detection in dynamic networks. However, it tends to generate monster communities which decrease the accuracy of community detection, especially in dynamic social networks. In this paper, we propose a modified LPA, called Spreading Activation Label Propagation Algorithm in order to solve the problem. This method assigns a property, called activation value, to each label, where pairs (label name, activation value) are propagated by spreading activation process and the LPA. Furthermore, this algorithm uses two weighting algorithms, where each of them corresponds to one variation of the proposed method. Here, the variations of the proposed method and other available methods on real and synthetic networks are implemented. Experimental results on both real and synthetic networks show that all variations of the proposed method detect communities more accurately compared to the benchmark methods while they are slower than these methods.",2018,Data & Knowledge Engineering
BASSILIADES201881,PaaSport semantic model: An ontology for a platform-as-a-service semantically interoperable marketplace,"Cloud computing, Platform-as-a-Service, Cloud Marketplace, Semantic interoperability, Ontologies, Quality and metrics","PaaS is a Cloud computing service that provides a computing platform to develop, run, and manage applications without the complexity of infrastructure maintenance. SMEs are reluctant to enter the growing PaaS market due to the possibility of being locked in to a certain platform, mostly provided by the market's giants. The PaaSport Marketplace aims to avoid the provider lock-in problem by allowing Platform provider SMEs to roll out semantically interoperable PaaS offerings and Software SMEs to deploy or migrate their applications on the best-matching offering, through a thin, non-intrusive Cloud broker. In this paper, we present the PaaSport semantic model, namely an OWL ontology, extension of the DUL ontology. The ontology is used for semantically representing (a) PaaS offering capabilities and (b) requirements of applications to be deployed. The ontology has been designed to optimally support a semantic matchmaking and ranking algorithm that recommends the best-matching PaaS offering to the application developer. The DUL ontology offers seamless extensibility, since both PaaS Characteristics and parameters are defined as classes; therefore, extending the ontology with new characteristics and parameters requires the addition of new specialized subclasses of the already existing classes, which is less complicated than adding ontology properties. The PaaSport ontology is evaluated through verification tools, competency questions, human experts, application tasks and query performance tests.",2018,Data & Knowledge Engineering
CORRADINI2018129,A Guidelines framework for understandable BPMN models,"Models understandability, Business process modeling, BPMN, Modeling guidelines, Model quality, Tool","Business process modeling allows abstracting and reasoning on how work is structured within complex organizations. Business process models represent blueprints that can serve different purposes for a variety of stakeholders. For example, business analysts can use these models to better understand how the organization works; employees playing a role in the process can use them to learn the tasks that they are supposed to perform; software analysts/developers can refer to the models to understand the system-as-is before designing the system-to-be. Given the variety of stakeholders that need to interpret these models, and considering the pivotal function that models play within organizations, understandability becomes a fundamental quality that need to be taken into particular account by modelers. In this paper we provide a set of fifty guidelines that can help modelers to improve the understandability of their models. The work focuses on the Business Process Modelling Notation 2.0 standard published by the Object Management Group, which has acquired a clear predominance among the modeling notations for business processes. Guidelines were derived by means of a thoughtful literature review – which allowed identifying around one hundred guidelines – and through successive activities of synthesis and homogenization. In addition, we implemented a freely available open source tool, named BEBoP (understandaBility vErifier for Business Process models), to check the adherence of a model to the guidelines. Finally, guidelines violation has been checked with BEBoP on a dataset of 11,294 models available in a publicly accessible repository. Our tests show that, although the majority of the guidelines are respected by the models, some guidelines, which are recognized as fundamental by the literature, are frequently violated.",2018,Data & Knowledge Engineering
CABRERADIEGO2018184,SummTriver: A new trivergent model to evaluate summaries automatically without human references,"Automatic text summarization, Summarization evaluation, Jensen-Shanon divergence, Kullback-Leibler divergence, Trivergence of probabilities","The automatic evaluation of summaries is a hard task that continues to be open. The assessment aims to measure simultaneously the informativeness and readability of summaries. The scientific community has tackled this problem with partial solutions, in terms of informativeness, using ROUGE. However, to use this method, it is necessary to have multiple summaries made by humans (the references). Methods without human references have been implemented, but there are still far from being highly correlated to manual evaluations. In this paper we present SummTriver, an automatic evaluation method that tries to be more correlated to manual evaluation by using multiple divergences. The results are promising, especially for summarization campaigns. Besides this, we also present an interesting analysis, at micro-level, of how correlated the manual and automatic summaries evaluation methods are, when we make use of a large quantity of observations.",2018,Data & Knowledge Engineering
OUKSILI2018171,Pattern oriented RDF graphs exploration,"RDF graph exploration, Theme discovery, Keyword search, Pattern","An increasing number of RDF datasets are available on the Web. In order to query these datasets, users must have some information about their content as well as some knowledge of a query language such as SPARQL. Our goal is to facilitate the exploration of these datasets. In this paper, we introduce two complementary approaches designed to explore RDF(S)/OWL data: theme-based exploration and keyword search. These two approaches rely on the definition of patterns to formalize users' requirements during the exploration process. We present PatEx, a system designed to explore RDF(S)/OWL datasets using the two exploration strategies, allowing the user to interactively switch between them. We also present some experiments on real datasets to illustrate the effectiveness of our approach.",2018,Data & Knowledge Engineering
BEDO201818,The Merkurion approach for similarity searching optimization in Database Management Systems,"Similarity searching, Query optimization, Selectivity estimation, Design and implementation techniques","Modern Database Management Systems (DBMSs) retrieve songs that resemble those in a music dataset, identify plagiarism in a set of documents, or provide past cases to physicians by taking into account the characteristics of a query exam. All such tasks require the comparison of data by similarity, which can be expressed in terms of distance-based queries in metric spaces. Traditional query processing relies mostly on histograms for describing the data distribution space and choosing a data retrieval path that quickly leads to the answer, discarding comparisons of most unwanted data. However, DBMSs still lack adequate support for selectivity estimation of query operators for data types embedded in metric spaces. This article addresses a novel strategy that extends the query optimizer of a DBMS, so that it can also perform both logical and physical query plan optimizations in searches that include similarity predicates. The proposal, named Merkurion, updates the concept of Data Distribution Space and captures data distributions according to the distances between the elements within a dataset. Moreover, it employs concise representations of such distributions, called synopses, for the definition of rules that enable similarity searching optimization. An extensive evaluation of Merkurion in real-world datasets has proven its effectiveness and broad applicability to many data domains.",2018,Data & Knowledge Engineering
FAKAS20181,Thematic ranking of object summaries for keyword search,"Keyword search, Object summaries, Top- Queries, Relational databases","An Object Summary (OS) is a tree structure of tuples that summarizes the context of a particular Data Subject (DS) tuple. The OS has been used as a model of keyword search in relational databases; where given a set of keywords, the objective is to identify the DSs tuples relevant to the keywords and their corresponding OSs. However, a query result may return a large amount of OSs, which brings in the issue of effectively and efficiently ranking them in order to present only the most important ones to the user. In this paper, we propose a model that ranks OSs containing a set of identifying keywords (e.g., Chen) according to their relevance to a set of thematic keywords (e.g. Mining). We argue that the effective thematic ranking of OSs should combine gracefully IR-style properties, authoritative ranking and affinity. Our ranking problem is modeled and solved as a top-k group-by join; we propose an algorithm that computes the join efficiently, taking advantage of appropriate count statistics and compare it with baseline approaches. An experimental evaluation on the DBLP and TPC-H databases verifies the effectiveness and efficiency of our proposal.",2018,Data & Knowledge Engineering
LEE2018116,An information-theoretic filter approach for value weighted classification learning in naive Bayes,"Feature weighting, Feature selection, Naive Bayes, Kullback-Leibler","Assigning weights in features has been an important topic in some classification learning algorithms. In this paper, we propose a new paradigm of assigning weights in classification learning, called value weighting method. While the current weighting methods assign a weight to each feature, we assign a different weight to the values of each feature. The performance of naive Bayes learning with value weighting method is compared with that of some other traditional methods for a number of datasets. The experimental results show that the value weighting method could improve the performance of naive Bayes significantly.",2018,Data & Knowledge Engineering
SANTIPUTRI2017112,Mining task post-conditions: Automating the acquisition of process semantics,"Business process semantics, Mining post-conditions, Semantic annotation","Semantic annotation of business process model in the business process designs has been addressed in a large and growing body of work, but these annotations can be difficult and expensive to acquire. This paper presents a data-driven approach to mining and validating these annotations (and specifically context-independent semantic annotations). We leverage event objects in process execution histories which describe both activity execution events (typically represented as process events) and state update events (represented as object state transition events). We present an empirical evaluation, which suggests that the approach provides generally reliable results.",2017,Data & Knowledge Engineering
WANG201770,Probabilistic object deputy model for uncertain data and lineage management,"Uncertain data, Data modeling, Lineage, Probability computation","Lineage is important in uncertain data management since it can be used for finding out which part of data contributes to a result and computing the probability of the result. Nonetheless, the existing works consider an uncertain tuple as a set of tuples that can be stored in a relational table. Lineage can derive each tuple in the table, with which one can only find out the tuples rather than specific attributes that contribute to the result. If uncertain tuples have multiple uncertain attributes, for a result tuple with low probability, users cannot know which attribute is the main cause of it. In this paper, we propose an approach to model uncertain data. Compared with the alternative way based on the relational model, our model achieves a low maintenance cost and avoids a large number of redundant storage and join operations. Based on our model, some operations are defined for querying data, generating lineage, computing probability and derivation of results. Further, we discuss how to correctly compute probability with lineage and an algorithm is proposed to transform lineage for correct probability computation. We also discuss how to realize result derivation with the lineage. Experiments show the advantages of the proposed model on uncertain data management.",2017,Data & Knowledge Engineering
CARVALHO20173,Multi-level ontology-based conceptual modeling,"Ontology, Conceptual modeling, Multi-level modeling","Since the late 1980s, there has been a growing interest in the use of foundational ontologies to provide a sound theoretical basis for the discipline of conceptual modeling. This has led to the development of ontology-based conceptual modeling techniques whose modeling primitives reflect the conceptual categories defined in a foundational ontology. The ontology-based conceptual modeling language OntoUML, for example, incorporates the distinctions underlying the taxonomy of types in the Unified Foundational Ontology (UFO) (e.g., kinds, phases, roles, mixins, etc.). This approach has focused so far on the support to types whose instances are individuals in the subject domain, with no provision for types of types (or categories of categories). In this paper we address this limitation by extending the Unified Foundational Ontology with the MLT multi-level theory. The UFO-MLT combination serves as a foundation for conceptual models that can benefit from the ontological distinctions of UFO as well as MLT's basic concepts and patterns for multi-level modeling. We discuss the impact of the extended foundation to multi-level conceptual modeling.",2017,Data & Knowledge Engineering
RUY201741,From reference ontologies to ontology patterns and back,"Ontology patterns, Conceptual ontology patterns, Ontology reuse, Ontology engineering","Building proper reference ontologies is a hard task. There are a number of methods and tools that traditionally have been used to support this task. These include the use of foundational theories, the reuse of domain and core ontologies, the adoption of development methods, as well as the support of proper software tools. In this context, an approach that has gained increasing attention in recent years is the systematic application of ontology patterns. However, a pattern-based approach to ontology engineering requires: the existence of a set of suitable patterns that can be reused in the construction of new ontologies; a proper methodological support for eliciting these patterns, as well as for applying them in the construction of these new models. The goal of this paper is twofold: (i) firstly, we present an approach for deriving conceptual ontology patterns from ontologies. These patterns are derived from ontologies of different generality levels, ranging from foundational to domain ontologies; (ii) secondly, we present guidelines that describe how these patterns can be applied in combination for building reference domain ontologies in a reuse-oriented process. In summary, this paper is about the construction of ontology patterns from ontologies, as well as the construction of ontologies from ontology patterns.",2017,Data & Knowledge Engineering
SELWAY201785,A conceptual framework for large-scale ecosystem interoperability and industrial product lifecycles,"Metamodelling, Conceptual models, Multilevel modelling, Ecosystem Interoperability","One of the most significant challenges in information system design is the constant and increasing need to establish interoperability between heterogeneous software systems at increasing scale. The automated translation of data between the data models and languages used by information ecosystems built around official or de facto standards is best addressed using model-driven engineering techniques, but requires handling both data and multiple levels of metadata within a single model. Standard modelling approaches are generally not built for this, compromising modelling outcomes. We establish the SLICER conceptual framework built on multilevel modelling principles and the differentiation of basic semantic relations (such as specialisation, instantiation, specification and categorisation) that dynamically structure the model. Moreover, it provides a natural propagation of constraints over multiple levels of instantiation. The presented framework is novel in its flexibility towards identifying the multilevel structure, the differentiation of relations often combined in other frameworks, and a natural propagation of constraints over multiple levels of instantiation.",2017,Data & Knowledge Engineering
GUIMARAES201725,Planning runtime software adaptation through pragmatic goal model,"Requirements engineering, Adaptive systems, Context-awareness, Quality of service","Adaptivity is a capability that enables a system to choose amongst various alternatives to satisfy or maintain the satisfaction of certain requirements. The criteria of requirements satisfaction could be pragmatic and context-dependent. Contextual Goal Models (CGM) capture the power of context on banning or allowing certain alternatives to reach requirements (goals) and also deciding the quality of those alternatives with regards to certain quality measures (softgoals). It is used to depict facets of the decision making strategy and rationale of an adaptive system at the preliminary level of requirements. In this paper we argue the case for pragmatic requirements and extend the CGM with additional constructs to capture them and allow their analysis. We also develop an automated analysis which aids the planning and scheduling of tasks execution to meet pragmatic goals. Moreover, we evaluate our modelling and analysis regarding correctness and performance. Such an evaluation showed the applicability of the approach and its usefulness in aiding sensible decisions. It has also shown its capability to do so in a time short enough to suit run-time adaptation decision making.",2017,Data & Knowledge Engineering
GHORBEL201832,An extension of kernel learning methods using a modified Log-Euclidean distance for fast and accurate skeleton-based Human Action Recognition,"Kernel methods, Symmetric positive semi-definite matrices, Human action recognition, SVM, Covariance matrices, RGB-D cameras, Log-Euclidean distance","In this article, we introduce a fast, accurate and invariant method for RGB-D based human action recognition using a Hierarchical Kinematic Covariance (HKC) descriptor. Recently, non singular covariance matrices of pattern features which are elements of the space of Symmetric Definite Positive (SPD) matrices, have been proven to be very efficient descriptors in the field of pattern recognition. However, in the case of action recognition, singular covariance matrices cannot be avoided because the dimension of features could be higher than the number of samples. Such covariance matrices (non singular and singular) belong to the space of Symmetric Positive semi-Definite (SPsD) matrices. Thus, in order to classify actions, we propose to adapt kernel methods such as Support Vector Machines (SVM) and Multiple Kernel Learning (MKL) to the space of SPsD matrices by using a perturbed Log-Euclidean distance (Arsigny et al., 2006). The mathematical validity of this perturbed distance (called Modified Log-Euclidean distance) for SPsD is therefore studied. The offline experiments are conducted on three challenging benchmarks, namely MSRAction3D, UTKinect and Multiview3D datasets. A fair comparison demonstrates that our approach competes with state-of-the-art methods in terms of accuracy and computational latency. Finally, our method is extended to an online scenario and experiments on MSRC12 prove the efficiency of this extension.",2018,Computer Vision and Image Understanding
LHUILLIER201852,Surface reconstruction from a sparse point cloud by enforcing visibility consistency and topology constraints,"Surface reconstruction, Manifold, Genus, Visibility, Sparse features, Environment modeling","There are reasons to reconstruct a surface from a sparse cloud of 3D points estimated from an image sequence: to avoid computationally expensive dense stereo, e.g. for applications that do not need high level of details and have limited resources, or to initialize dense stereo in other cases. It is also interesting to enforce topology constraints (like manifoldness) for both surface regularization and applications. In this article, we improve by several ways a previous method that enforces the manifold constraint given a sparse point cloud. We enforce lowered genus, i.e. simplified topology, as a further regularization constraint for maximizing the visibility consistency encoded in a 3D Delaunay triangulation of the points. We also provide more efficient escapes from local extrema, an acceleration of the manifold test and more efficient removals of surface singularities. We experiment on a sparse point cloud reconstructed from videos, that are taken by a helmet-held omnidirectional multi-camera moving in an university campus.",2018,Computer Vision and Image Understanding
WANG201824,Back to the beginning: Starting point detection for early recognition of ongoing human actions,"Action early recognition, Online action detection, Event detection","We address the task of recognizing the category of an ongoing human action from a video stream. This task is challenging because of the need to output categorization decisions based on partial evidence—the action has not finished and not all information about the action has been observed. This task is further complicated because the ongoing action is submerged in the stream of data and the start of the action is not given. Existing methods for early recognition usually ignore this issue, making unrealistic assumption about the availability of the starting point of the ongoing action. In this paper, we prove the importance of starting point detection and subsequently propose a method to determine the start of an ongoing action. Our method is based on a bidirectional recurrent neural network that computes the probability of a frame to be the starting point by comparing the dynamics of the actions before and after the frame. Experiments on three datasets show that our method can reliably detect the starting point of an ongoing action, improving the early recognition accuracy.",2018,Computer Vision and Image Understanding
CHEN201844,A resample strategy and artificial bee colony optimization-based 3d range imaging registration,"Range image registration, Low overlapping rate, Resample strategy, Artificial bee colony algorithm, Bionic intelligence optimization","For two point clouds with low overlapping rate, the registration process is more difficult and the registration speed is slow. In this paper, we reduce the number of sampling points to simplify the calculation, and then propose a new idea based on equal interval method called resample strategy, it can effectively avoid ambiguity during the registration process by improving the ergodicity and utilization of the sampling point set. In addition, we also introduce a new solution search equation that has more exploitation performance to alternatively search with an enhanced artificial bee colony algorithm. The computation time has been effectively reduced by using these two proposed strategies. The registration experimental results aiming to a variety of point cloud models show that our 3d image registration algorithm is better than many other algorithms based on classical or improved bionic intelligence optimization methods.",2018,Computer Vision and Image Understanding
FAN20181,Hierarchical coherency sensitive hashing and interpolation with RANSAC for large displacement optical flow,"Nearest neighbor field, Sparse to dense interpolation, Optical flow","Nearest Neighbor Field (NNF) has shown excellent performance for large displacement optical flow estimation recently. However, it contains much noise and lacks of global constraint. In this paper we present an effective approach, named HCSH (Hierarchical Coherency Sensitive Hashing), which combines the coarse-to-fine scheme and random search strategy, to enable NNF to enjoy the inherent smooth of coarse-to-fine framework. Then besides the forward–backward check for NNF, we also use auto-correlation to remove the unreliable correspondences in flat regions, where the NNF is often considered ambiguous and the motion can be naturally recovered by the latter interpolation. Inspired by EpicFlow, we propose edge-aware interpolation (EAI-Flow) to filling the gaps by removing correspondence. RANSAC is introduced to improve the locality-weighted affine transformation estimation, with neighbor propagation of affine model to reduce required iterations and speed up the computation. Experimental validation shows that our approach outperforms the state-of-the-art with more accurate optical flow.",2018,Computer Vision and Image Understanding
LI201811,Active target tracking: A simplified view aligning method for binocular camera model,"Video surveillance, Active target tracking, Dual camera system, View aligning problem, Camera control","While monitoring large-scale scenes, visual surveillance systems are often confronted with a dilemma between obtaining efficient coverage of the scene and getting sufficient resolution of the targets of interest. To alleviate the contradiction, a solution based on binocular cameras has been proposed. In the solution, an active pan–tilt–zoom (PTZ) camera and a fixed camera operate in a collaborative way by dynamically aligning their fields of view. However, due to the asymmetric camera distribution structure and fast-changing scenario, the accurate alignment is yet challenging. In this paper, a novel view aligning method is presented which introduces three reasonable and mild simplifications to transform the complex view aligning problem into a simple arctangent control function. These simplifications not only relax the restrictions of target depth and the intrinsic parameters of PTZ camera, but also constrain the relative external parameters with a coaxial structure. Meanwhile, a corresponding calibration method is designed to estimate the model parameters off-line. The proposed method was tested in comprehensive cases with relatively close target, wide-range scene and altitude variation. Both the simulation and real scene experiments demonstrate that our method outperforms other state-of-the-art methods on accuracy and effectiveness for active target tracking tasks.",2018,Computer Vision and Image Understanding
NEVEROVA201756,Hand pose estimation through semi-supervised and weakly-supervised learning,"Hand pose estimation, Deep learning, Semantic segmentation","We propose a method for hand pose estimation based on a deep regressor trained on two different kinds of input. Raw depth data is fused with an intermediate representation in the form of a segmentation of the hand into parts. This intermediate representation contains important topological information and provides useful cues for reasoning about joint locations. The mapping from raw depth to segmentation maps is learned in a semi- and weakly-supervised way from two different datasets: (i) a synthetic dataset created through a rendering pipeline including densely labeled ground truth (pixelwise segmentations); and (ii) a dataset with real images for which ground truth joint positions are available, but not dense segmentations. Loss for training on real images is generated from a patch-wise restoration process, which aligns tentative segmentation maps with a large dictionary of synthetic poses. The underlying premise is that the domain shift between synthetic and real data is smaller in the intermediate representation, where labels carry geometric and topological meaning, than in the raw input domain. Experiments on the NYU dataset (Tompson et al., 2014b) show that the proposed training method decreases error on joints over direct regression of joints from depth data by 15.7%.",2017,Computer Vision and Image Understanding
BAIG2017111,Multiple hypothesis colorization and its application to image compression,"Colorization, Deep learning, Image compression","In this work we focus on the problem of colorization for image compression. Since color information occupies a large proportion of the total storage size of an image, a method that can predict accurate color from its grayscale version can produce a dramatic reduction in image file size. But colorization for compression poses several challenges. First, while colorization for artistic purposes simply involves predicting plausible chroma, colorization for compression requires generating output colors that are as close as possible to the ground truth. Second, many objects in the real world exhibit multiple possible colors. Thus, in order to disambiguate the colorization problem some additional information must be stored to reproduce the true colors with good accuracy. To account for the multimodal color distribution of objects we propose a deep tree-structured network that generates for every pixel multiple color hypotheses, as opposed to a single color produced by most prior colorization approaches. We show how to leverage the multimodal output of our model to reproduce with high fidelity the true colors of an image by storing very little additional information. In the experiments we show that our proposed method outperforms traditional JPEG color coding by a large margin, producing colors that are nearly indistinguishable from the ground truth at the storage cost of just a few hundred bytes for high-resolution pictures!",2017,Computer Vision and Image Understanding
MILLETARI201792,Hough-CNN: Deep learning for segmentation of deep brain regions in MRI and ultrasound,"Convolutional neural networks, Deep learning, Segmentation, Hough voting, Hough CNN, Ultrasound, MRI","In this work we propose a novel approach to perform segmentation by leveraging the abstraction capabilities of convolutional neural networks (CNNs). Our method is based on Hough voting, a strategy that allows for fully automatic localisation and segmentation of the anatomies of interest. This approach does not only use the CNN classification outcomes, but it also implements voting by exploiting the features produced by the deepest portion of the network. We show that this learning-based segmentation method is robust, multi-region, flexible and can be easily adapted to different modalities. In the attempt to show the capabilities and the behaviour of CNNs when they are applied to medical image analysis, we perform a systematic study of the performances of six different network architectures, conceived according to state-of-the-art criteria, in various situations. We evaluate the impact of both different amount of training data and different data dimensionality (2D, 2.5D and 3D) on the final results. We show results on both MRI and transcranial US volumes depicting respectively 26 regions of the basal ganglia and the midbrain.",2017,Computer Vision and Image Understanding
PEREZDESANROMAN201782,Saliency Driven Object recognition in egocentric videos with deep CNN: toward application in assistance to Neuroprostheses,"Psycho-visual attention, Saliency, Egocentric video, Object recognition, Deep Convolutional Neural Networks","The problem of object recognition in natural scenes has been recently successfully addressed with Deep Convolutional Neuronal Networks giving a significant break-through in recognition scores. The computational efficiency of Deep CNNs as a function of their depth, allows for their use in real-time applications. One of the key issues here is to reduce the number of windows selected from images to be submitted to a Deep CNN. This is usually solved by preliminary segmentation and selection of specific windows, having outstanding “objectiveness” or other value of indicators of possible location of objects. In this paper we propose a Deep CNN approach and the general framework for recognition of objects in a real-time scenario and in an egocentric perspective. Here the window of interest is built on the basis of visual attention map computed over gaze fixations measured by a glass-worn eye-tracker. The application of this set-up is an interactive user-friendly environment for upper-limb amputees. Vision has to help the subject to control his worn neuro-prosthesis in case of a small amount of remaining muscles when the EMG control becomes inefficient. The recognition results on a specifically recorded corpus of 151 videos with simple geometrical objects show the mean Average Precision (mAP) of 64,6% and the computational time at the generalization lower than a time of a visual fixation on the object of interest.",2017,Computer Vision and Image Understanding
MHALLA20173,SMC faster R-CNN: Toward a scene-specialized multi-object detector,"Transfer learning, Deep learning, Specialization, Faster R-CNN, Sequential monte carlo filter, Traffic object detection","Generally, the performance of a generic detector decreases significantly when it is tested on a specific scene due to the large variation between the source training dataset and the samples from the target scene. To solve this problem, we propose a new formalism of transfer learning based on the theory of a Sequential Monte Carlo (SMC) filter to automatically specialize a scene-specific Faster R-CNN detector. The suggested framework uses different strategies based on the SMC filter steps to approximate iteratively the target distribution as a set of samples in order to specialize the Faster R-CNN detector towards a target scene. Moreover, we put forward a likelihood function that combines spatio-temporal information extracted from the target video sequence and the confidence-score given by the output layer of the Faster R-CNN, to favor the selection of target samples associated with the right label. The effectiveness of the suggested framework is demonstrated through experiments on several public traffic datasets. Compared with the state-of-the-art specialization frameworks, the proposed framework presents encouraging results for both single and multi-traffic object detections.",2017,Computer Vision and Image Understanding
VO201768,Harnessing noisy Web images for deep representation,"Representation learning, Deep learning, Convolutional networks, Semi-supervised learning, Domain adaptation, Noisy data","The keep-growing content of Web images is probably the next important data source to scale up deep neural networks which recently surpass human in image classification tasks. The fact that deep networks are hungry for labelled data limits themselves from extracting valuable information of Web images which are abundant and cheap. There have been efforts to train neural networks such as autoencoders with respect to either unsupervised or semi-supervised settings. Nonetheless they are less performant than supervised methods partly because the loss function used in unsupervised methods, for instance Euclidean loss, failed to guide the network to learn discriminative features and ignore unnecessary details. We instead train convolutional networks in a supervised setting but use weakly labelled data which are large amounts of unannotated Web images downloaded from Flickr and Bing. Our experiments are conducted at several data scales, with different choices of network architecture, and alternating between different data preprocessing techniques. The effectiveness of our approach is shown by the good generalization of the learned representations with new six public datasets.",2017,Computer Vision and Image Understanding
ALOTAIBI2017103,Improved gait recognition based on specialized deep convolutional neural network,"Convolutional neural networks, Gait recognition, Deep learning","Gait recognition is a biometric technique used in determining the identity of humans based on the style and the manner of their walk. Its performance is often degraded by covariate factors such as carrying condition changes, clothing condition changes, and viewing angle variations. Recently, machine learning based techniques have produced promising results for challenging classification problems. Since, a deep convolutional neural network (CNN) is one of the most advanced machine learning techniques with the ability to approximate complex non-linear functions, we develop a specialized deep CNN architecture for Gait Recognition. The proposed architecture is less sensitive to several cases of the common variations and occlusions that affect and degrade gait recognition performance. It can also handle relatively small data sets without using any augmentation or fine-tuning techniques. The majority of previous approaches to gait recognition have used subspace learning methods which have several shortcomings that we avoid. Our specialized deep CNN model can obtain competitive performance when tested on the CASIA-B large gait dataset.",2017,Computer Vision and Image Understanding
ZAGORUYKO201738,Deep compare: A study on using convolutional neural networks to compare image patches,"Descriptor learning, Stereo, Similarity learning, Supervised learning, Convolutional neural networks","Comparing patches across images is probably one of the most fundamental tasks in computer vision and image analysis, that has given rise to the development of many hand-designed feature descriptors over the past years, including SIFT, that had a huge impact in the computer vision community. Yet, such manually designed descriptors may be unable to take into account in an optimal manner all the different factors that can affect the final appearance of image patches. On the other hand, nowadays one can easily gain access to (or even generate using available software) large datasets that contain patch correspondences between images. This begs the following question: can we make proper use of such datasets to automatically learn a similarity function for image patches ? Our goal in this work is to affirmatively address the above question. We show how to learn directly from image data (i.e., without resorting to manually-designed features) a general similarity function for comparing image patches. To encode such a function, we opt for a CNN-based model that is trained to account for a wide variety of changes in image appearance. To that end, we explore and study multiple neural network architectures, including novel NCC-networks, which are specifically adapted to this task. We show that such an approach can significantly outperform the state-of-the-art on several problems and benchmark datasets.",2017,Computer Vision and Image Understanding
HOLLIDAY201716,Speedup of deep learning ensembles for semantic segmentation using a model compression technique,"Semantic segmentation, Model compression, Transfer learning, Real-time application","Deep Learning (DL) has been proven as a powerful recognition method as evidenced by its success in recent computer vision competitions. The most accurate results have been obtained by ensembles of DL models that pool their results. However, such ensembles are computationally costly, making them inapplicable to real-time applications. In this paper, we apply model compression techniques to the problem of semantic segmentation, which is one of the most challenging problems in computer vision. Our results suggest that compressed models can approach the accuracy of full ensembles on this task, combining the diverse strengths of networks of very different architectures, while maintaining real-time performance.",2017,Computer Vision and Image Understanding
BUI201727,Compact descriptors for sketch-based image retrieval using a triplet loss convolutional neural network,"Sketch based image retrieval (SBIR), Deep learning, Triplet loss function, Cross-domain modelling, Compact feature representations","We present an efficient representation for sketch based image retrieval (SBIR) derived from a triplet loss convolutional neural network (CNN). We treat SBIR as a cross-domain modelling problem, in which a depiction invariant embedding of sketch and photo data is learned by regression over a siamese CNN architecture with half-shared weights and modified triplet loss function. Uniquely, we demonstrate the ability of our learned image descriptor to generalise beyond the categories of object present in our training data, forming a basis for general cross-category SBIR. We explore appropriate strategies for training, and for deriving a compact image descriptor from the learned representation suitable for indexing data on resource constrained e. g. mobile devices. We show the learned descriptors to outperform state of the art SBIR on the defacto standard Flickr15k dataset using a significantly more compact (56 bits per image, i. e. ≈ 105KB total) search index than previous methods. Datasets and models are available from the CVSSP datasets server at www.cvssp.org.",2017,Computer Vision and Image Understanding
GARCIAGARCIA2017124,A study of the effect of noise and occlusion on the accuracy of convolutional neural networks applied to 3D object recognition,"Deep learning, 3D object recognition, Convolutional neural networks, Noise, Occlusion, Caffe","In this work, we carry out a study of the effect of adverse conditions, which characterize real-world scenes, on the accuracy of a Convolutional Neural Network applied to 3D object class recognition. Firstly, we discuss possible ways of representing 3D data to feed the network. In addition, we propose a set of representations to be tested. Those representations consist of a grid-like structure (fixed and adaptive) and a measure for the occupancy of each cell of the grid (binary and normalized point density). After that, we propose and implement a Convolutional Neural Network for 3D object recognition using Caffe. At last, we carry out an in-depth study of the performance of the network over a 3D CAD model dataset, the Princeton ModelNet project, synthetically simulating occlusions and noise models featured by common RGB-D sensors. The results show that the volumetric representations for 3D data play a key role on the recognition process and Convolutional Neural Network can be considerably robust to noise and occlusions if a proper representation is chosen.",2017,Computer Vision and Image Understanding
GARDUNORAMON201736,A new method for inpainting of depth maps from time-of-flight sensors based on a modified closing by reconstruction algorithm,"Time-of-flight, Depth maps, Mathematical morphology, Morphological reconstruction, Modified closing by reconstruction","Time-of-Flight (ToF) sensors are popular devices that extract 3D information from a scene but result to be susceptible to noise and loss of data creating holes and gaps in the boundaries of the objects. The most common approaches to tackling this problem are supported by color images with good results, however, not all ToF devices produce color information. Mathematical morphology provides operators that can manage the problem of noise in single depth frames. In this paper, a new method for the filtering of single depth maps, when no color image is available, is presented, based on a modification to the morphological closing by reconstruction algorithm. The proposed method eliminates noise, emphasizing a high contour preservation, and it is compared, both qualitative and quantitatively, with other state-of-the-art filters. The proposed method represents an improvement to the closing by reconstruction algorithm that can be applied for filter depth maps of ToF devices.",2017,Journal of Visual Communication and Image Representation
MOHAMMADI20171,A joint dictionary learning and regression model for intensity estimation of facial AUs,"Facial action units, Intensity measurement, Spontaneous facial behavior, Sparse representation, Supervised dictionary learning","Automated intensity estimation of spontaneous Facial Action Units (AUs) defined by Facial Action Coding System (FACS) is a relatively new and challenging problem. This paper presents a joint supervised dictionary learning (SDL) and regression model for solving this problem. The model is casted as an optimization function consisting of two terms. The first term in the optimization concerns representing the facial images in a sparse domain using dictionary learning whereas the second term concerns estimating AU intensities using a linear regression model in the sparse domain. The regression model is designed in a way that considers disagreement between raters by a constant biasing factor in measuring the AU intensity values. Furthermore, since the intensity of facial AU is a non-negative value (i.e., the intensity values are between 0 and 5), we impose a non-negative constraint on the estimated intensities by restricting the search space for the dictionary learning and the regression function. Our experimental results on DISFA and FERA2015 databases show that this approach is very promising for automated measurement of spontaneous facial AUs.",2017,Journal of Visual Communication and Image Representation
HUANG201710,"Discriminant analysis via jointly L2,1-norm sparse tensor preserving embedding for image classification","Sparse representation, Tensor, Discriminant analysis, Local preserving embedding","There exits an increasing interest on sparse subspace learning (SSL) for dimensionality reduction and pattern recognition. In this paper, we propose a novel sparse subspace learning method named discriminant sparse tensor neighborhood preserving embedding (DSTNPE) which incorporates discriminant information into tensor sparse neighborhood preserving embedding to perform robust image classification. DSTNPE introduces the L2,1-norm to sparse neighborhoods and criterion, in which the within-neighborhood tensor scatter and between-neighborhood tensor scatter are defined for sparse regression. One virtue of DSTNPE is that it can avoid selecting the scale of local neighborhood of the manifold learning algorithms. Additionally, DSTNPE can iteratively obtain the transformation matrices by the sparse tensor neighborhoods preservation. Furthermore, by means of virtue of maximum margin criterion(MMC), the discriminant performance of DSTNPE is further enhanced. To evaluate the proposed method, extensive experiments conducted on five public databases demonstrate that our proposed algorithm outperforms many state-of-the-art algorithms.",2017,Journal of Visual Communication and Image Representation
LEE201762,Performance evaluation of local descriptors for maximally stable extremal regions,"Local feature, Feature descriptor, Performance evaluation, Affine-invariant region detectors, MSER","Visual feature descriptors are widely used in most computer vision applications. Over the past several decades, local feature descriptors that are robust to challenging environments have been proposed. Because their characteristics differ according to the imaging condition, it is necessary to compare their performance consistently. However, no pertinent research has attempted to establish a benchmark for performance evaluation, especially for affine region detectors, which are mainly used in object classification and recognition. This paper presents an intensive and informative performance evaluation of local descriptors for the state-of-the-art affine-invariant region detectors, i.e., maximally stable extremal region detectors. We evaluate patch-based and binary descriptors, including SIFT, SURF, BRIEF, FREAK, the shape descriptor, LIOP, DAISY, GSURF, RFDg, and CNN descriptors. The experimental results reveal the relative performance and characteristics of each descriptor.",2017,Journal of Visual Communication and Image Representation
LIMA201723,Per-pixel mirror-based method for high-speed video acquisition,"Compressive sensing, Computational photography, High-speed imaging","High-speed imaging requires high-bandwidth, fast image sensors that are generally only available in high-end specialized cameras. Nevertheless, with the use of compressive sensing theory and computational photography techniques, new methods emerged that use spatial light modulators to reconstruct high-speed videos with low speed sensors. Although these methods represent a big step in the field, they still present some limitations, such as low light efficiency and the generation of measurements with time dependency. To tackle these problems, we propose a per-pixel mirror-based acquisition method that is based on a new kind of light modulator. The proposed method uses moving mirrors to scramble the light coming from different positions, thus ensuring better light efficiency and generating time independent measurements. Our results show that the proposed method and its variations perform better than methods available in the literature, generating videos that are less noisy and that display better content separation.",2017,Journal of Visual Communication and Image Representation
WEI201748,Video synthesis from stereo videos with iterative depth refinement,"View synthesis, Depth refinement","We propose a novel depth maps refinement algorithm and generate multi-view video sequences from two-view video sequences for modern autostereoscopic display. In order to generate realistic contents for virtual views, high-quality depth maps are very critical to the view synthesis results. Therefore, refining the depth maps is the main challenging problem in the task. We propose an iterative depth refinement algorithm, including error detection and error correction, to correct errors in depth map. Error detection aims at two types of error: across-view color-depth-inconsistency error and local color-depth-inconsistency error. Then, error pixels are corrected based on sampling local candidates. A trilateral filter that considers intensity, spatial and temporal terms into the filter weighting is applied to enhance the spatial and temporal consistency across frames. So the virtual views can be better synthesized according to the refined depth maps. To combine both warped images, disparity-based view interpolation is introduced to alleviate the translucent artifacts. Finally, a directional filter is applied to reduce the aliasing around the object boundaries to generate multiple high-quality virtual views between the two views. We demonstrate the superior image quality of the synthesized virtual views by using the proposed algorithm over the state-of-the-art view synthesis methods through experiments on benchmarking image and video datasets.",2017,Journal of Visual Communication and Image Representation
OZAWA2018140,Single color image photometric stereo for multi-colored surfaces,"3D reconstruction, Photometric stereo, Multi-spectral illumination, Single capture","We present a photometric stereo method that requires only a single color image. Conventional color photometric stereo methods for single color images cannot deal with multi-colored surfaces, since a color observation at a surface point is insufficient for determining the reflectances and the surface normal at that point. We exploit the global information of surface color and geometry by introducing a surface-color feature that enables classification of a surface into regions of the same color and simultaneously estimate surface normals. The surface-color feature, being invariant in geometry, qualifies the spatial distribution of the square norm of RGB reflectances and attributes surface points of a reflectance norm to the correct color. We discuss the theoretical validity of our surface classification and present a practical algorithm for multi-colored surface recovery. Although some classification ambiguities remain in principle, we show that they can be resolved under a smoothness constraint on the surface geometry. We evaluated the accuracy of our method through simulations and we demonstrated its effectiveness on real scenes.",2018,Computer Vision and Image Understanding
CHOI201810,Real-time visual tracking by deep reinforced decision making,"Visual tracking, Object tracking, Deep learning, Reinforcement learning","One of the major challenges of model-free visual tracking problem has been the difficulty originating from the unpredictable and drastic changes in the appearance of objects we target to track. Existing methods tackle this problem by updating the appearance model on-line in order to adapt to the changes in the appearance. Despite the success of these methods however, inaccurate and erroneous updates of the appearance model result in a tracker drift. In this paper, we introduce a novel real-time visual tracking algorithm based on a template selection strategy constructed by deep reinforcement learning methods. The tracking algorithm utilizes this strategy to choose the appropriate template for tracking a given frame. The template selection strategy is self-learned by utilizing a simple policy gradient method on numerous training episodes randomly generated from a tracking benchmark dataset. Our proposed reinforcement learning framework is generally applicable to other confidence map based tracking algorithms. The experiment shows that our tracking algorithm runs in real-time speed of 43 fps and the proposed policy network effectively decides the appropriate template for successful visual tracking.",2018,Computer Vision and Image Understanding
SAVELONAS20181,Spatially sensitive statistical shape analysis for pedestrian recognition from LIDAR data,"Local shape descriptors, Fisher encoding, LIDAR, Pedestrian recognition","Range-based pedestrian recognition is instrumental towards the development of autonomous driving and driving assistance systems. This work introduces encoding methods for pedestrian recognition, based on statistical shape analysis of 3D LIDAR data. The proposed approach has two variants, based on the encoding of local shape descriptors either in a spatially agnostic or spatially sensitive fashion. The latter method derives more detailed cues, by enriching the ‘gross’ information reflected by overall statistics of local shape descriptors, with ‘fine-grained’ information reflected by statistics associated with spatial clusters. Experiments on artificial LIDAR datasets, which include challenging samples, as well as on a large scale dataset of real LIDAR data, lead to the conclusion that both variants of the proposed approach (i) obtain high recognition accuracy, (ii) are robust against low-resolution sampling, (iii) are robust against increasing distance, and (iv) are robust against non-standard shapes and poses. On the other hand, the spatially-sensitive variant is more robust against partial occlusion and bad clustering.",2018,Computer Vision and Image Understanding
SANKAR201869,Model-based active learning to detect an isometric deformable object in the wild with a deep architecture,"Active learning, Object detection, Convolutional neural networks","In the recent past, algorithms based on Convolutional Neural Networks (CNNs) have achieved significant milestones in object recognition. With large examples of each object class, standard datasets train well for inter-class variability. However, gathering sufficient data to train for a particular instance of an object within a class is impractical. Furthermore, quantitatively assessing the imaging conditions for each image in a given dataset is not feasible. By generating sufficient images with known imaging conditions, we study to what extent CNNs can cope with hard imaging conditions for instance-level recognition in an active learning regime. Leveraging powerful rendering techniques to achieve instance-level detection, we present results of training three state-of-the-art object detection algorithms namely, Fast R-CNN, Faster R-CNN and YOLO9000, for hard imaging conditions imposed into the scene by rendering. Our extensive experiments produce a mean Average Precision score of 0.92 on synthetic images and 0.83 on real images using the best performing Faster R-CNN. We show for the first time how well detection algorithms based on deep architectures fare for each hard imaging condition studied.",2018,Computer Vision and Image Understanding
ARDESHIR201861,An exocentric look at egocentric actions and vice versa,"Egocentric vision, Transfer learning, Action recognition,","In this work we address the task of relating action information across two drastically different visual domains, namely, first-person (egocentric) and third-person (exocentric). We investigate two different yet highly interconnected problems including cross-view action classification and action based video retrieval. First, we perform action classification in one domain using the knowledge transferred from the other domain. Second, given a video in one view, we retrieve videos from the same action class in the other view. In order to evaluate our models, we collect a new cross-domain dataset of egocentric-exocentric action videos containing 14 action classes and 3569 videos (1676 collected egocentric videos and 1893 exocentric videos borrowed from the UCF 101 dataset). Our results demonstrate the possibility of transferring action information across the two domains and suggest new directions in relating first and third person vision for other tasks.",2018,Computer Vision and Image Understanding
ZHANG201848,Structure preserving image denoising based on low-rank reconstruction and gradient histograms,"Image denoising, Low-rank reconstruction (LRR), Gradient histograms, Dynamic thresholding, ADMM","One of the main challenges of denoising approaches is preserving images details, like textures and edges, while suppressing noise. The preservation of such details is essential to ensure good quality, especially in high-resolution images. This paper presents a novel denoising method that combines a low-rank regularization of similar non-local patches with a texture preserving prior based on the histogram of gradients. A dynamic thresholding operator, deriving from the weighted nuclear norm, is also used to reconstruct groups of similar patches more accurately, by applying less shrinkage to the larger singular values. Moreover, an efficient iterative approach based on the ADMM algorithm is proposed to compute the denoised image, under low-rank and histogram preservation constraints. Experiments on two benchmark datasets of high-resolution images show that the proposed method to outperform state-of-the-art approaches, for all noise levels.",2018,Computer Vision and Image Understanding
AGHAEI2018104,Towards social pattern characterization in egocentric photo-streams,"Social pattern characterization, Social signal extraction, Lifelogging, Convolutional and recurrent neural networks","Following the increasingly popular trend of social interaction analysis in egocentric vision, this article presents a comprehensive pipeline for automatic social pattern characterization of a wearable photo-camera user. The proposed framework relies merely on the visual analysis of egocentric photo-streams and consists of three major steps. The first step is to detect social interactions of the user where the impact of several social signals on the task is explored. The detected social events are inspected in the second step for categorization into different social meetings. These two steps act at event-level where each potential social event is modeled as a multi-dimensional time-series, whose dimensions correspond to a set of relevant features for each task; finally, LSTM is employed to classify the time-series. The last step of the framework is to characterize social patterns of the user. Our goal is to quantify the duration, the diversity and the frequency of the user social relations in various social situations. This goal is achieved by the discovery of recurrences of the same people across the whole set of social events related to the user. Experimental evaluation over EgoSocialStyle - the proposed dataset in this work, and EGO-GROUP demonstrates promising results on the task of social pattern characterization from egocentric photo-streams.",2018,Computer Vision and Image Understanding
TM201820,Generating high quality pan-shots from motion blurred videos,"Pan-shot, Motion blur, Deblurring","In this paper, we demonstrate a method to generate a pan photo from a video captured using a hand-held camera. We handle three relevant scenarios (no blur, only foreground blurred, both foreground and background blurred) that arise while capturing a video with a fixed frame-rate and under different relative object velocities and camera motion. Our method first segments out the moving object by motion compensation of the background and then estimates the inter-frame velocity and relative depth of the object. Automatic gradient-based identification is then performed to classify the video into one of the above three scenarios. If only the foreground is blurred, we perform non-blind restoration by judiciously harnessing the background motion and foreground velocity to estimate the foreground blur. When the background is blurred too, a blind multi-frame deblurring approach is advocated to get the background motion which is used to infer the foreground blur to obtain the latent frames. Once clean frames are obtained, we align the object and rewarp the background with respect to the net displacement of the object in each frame which when averaged produces the required realistic pan-photo. We demonstrate our method on a number of videos captured using different consumer cameras as well as on videos downloaded from the Internet.",2018,Computer Vision and Image Understanding
ZHANG201895,Exemplar-based Cascaded Stacked Auto-Encoder Networks for robust face alignment,"Auto-Encoder, Deep learning, Exemplar-based, Cascaded architecture, Face alignment","In this paper, we present a novel Exemplar-based Cascaded Stacked Auto-Encoder Network (ECSAN) for facial landmarks detection. The proposed framework consists of a Global Exemplar Constraint Stacked Auto-Encoder Network (GECSAN) and a set of Local Information Preserve Stacked Auto-Encoder Networks (LIPSANs). In our work, GECSAN utilizes successive stacked auto-encoder network and some well-designed exemplars to obtain an initial shape estimation from a holistic facial image. Then LIPSANs are presented which take the local features extracted around current landmarks as input and generate a facial landmark refinement. Different from existing deep models, a prior exemplar-based shape is utilized to handle the partial occlusion in the image so that our model can achieve robustness against local occlusions. Experimental results on several datasets demonstrate that our model acquires better performance over the state-of-the-art methods with respect to occlusion handling and attain higher alignment accuracy.",2018,Computer Vision and Image Understanding
WANG2018118,RGB-D-based human motion recognition with deep learning: A survey,"Human motion recognition, RGB-D data, Deep learning, Survey","Human motion recognition is one of the most important branches of human-centered research activities. In recent years, motion recognition based on RGB-D data has attracted much attention. Along with the development in artificial intelligence, deep learning techniques have gained remarkable success in computer vision. In particular, convolutional neural networks (CNN) have achieved great success for image-based tasks, and recurrent neural networks (RNN) are renowned for sequence-based problems. Specifically, deep learning methods based on the CNN and RNN architectures have been adopted for motion recognition using RGB-D data. In this paper, a detailed overview of recent advances in RGB-D-based motion recognition is presented. The reviewed methods are broadly categorized into four groups, depending on the modality adopted for recognition: RGB-based, depth-based, skeleton-based and RGB+D-based. As a survey focused on the application of deep learning to RGB-D-based motion recognition, we explicitly discuss the advantages and limitations of existing techniques. Particularly, we highlighted the methods of encoding spatial-temporal-structural information inherent in video sequence, and discuss potential directions for future research.",2018,Computer Vision and Image Understanding
ZHOU201834,Multiple view image denoising using 3D focus image stacks,"Multi-view denoising, 3D focus image stacks, Image reconstruction, Disparity map, Occlusion handling, Low rank minimization","In this paper, we introduce a novel multi-view image denoising algorithm using 3D focus image stacks (3DFIS) to exploit image redundancy within and across views. Robust disparity map is first estimated using the 3DFIS with texture-based view selection and patch-size variation scheme. Leveraging both 3DFIS and the estimated disparity map, the proposed algorithm effectively denoises the target view from multiple views through a low rank minimization approach that incorporates robust similarity metrics and occlusion handling techniques. The paper combs through a number of existing image denoising methods, including the preliminary results in our earlier research efforts, and then details the ways, means and merits of our proposed algorithm. With extensive experiments, we conclude that this novel algorithm is superior over various existing state-of-the-art approaches in terms of both visual and quantitative performance.",2018,Computer Vision and Image Understanding
BAE201713,Robust skin-roughness estimation based on co-occurrence matrix,"Skin roughness, Gray-level co-occurrence matrix (GLCM), Texture domain, Skin image","As the interest in one’s appearance has recently increased, the demand for diagnosing skin conditions has also increased. However, conventional specialized skin diagnostic devices are generally expensive, and people have to visit a skin-care shop to diagnose their skin condition. This is time consuming and troublesome. In this paper, we propose a skin-roughness estimation method that uses a mobile-phone camera in daily environments. In order to achieve accurate evaluation, the illumination variation is alleviated using texture components of the facial skin image. We also propose a new feature-extraction method based on the gray-level co-occurrence matrix, which effectively measures the skin roughness from the texture components. The performance of the proposed method is compared with the conventional commonly used features, and we verify the superiority of the proposed method.",2017,Journal of Visual Communication and Image Representation
CAO2017260,Sparse representation for robust face recognition by dictionary decomposition,"Sparse representation, Face recognition, Dictionary decomposition, Projection matrix","Sparse representation-based classification (SRC) method has gained great success in face recognition due to its encouraging and impressive performance. However, in SRC the data used to train or test are usually corrupted, and hence the performance is affected. This paper proposes a robust face recognition approach by means of learning a class-specific dictionary and a projection matrix. Firstly, the training data are decomposed into class-specific dictionary, non-class-specific dictionary, and sparse error matrix. Secondly, in order to correct the corrupted test data, the data are projected onto their corresponding underlying subspace, and a projection matrix between the original training data and the class-specific dictionary is learned. Then, the features of the class-specific dictionary and the corrected test data are extracted by using Eigenface method. Finally, the SRC is performed to classify. Extensive experiments conducted on publicly available data sets show that the proposed algorithm performs better than some state-of-the-art methods.",2017,Journal of Visual Communication and Image Representation
YANG201781,Robust player detection and tracking in broadcast soccer video based on enhanced particle filter,"Object tracking, Particle filter, Salient region detection, Otsu algorithm","It is significant to detect and track soccer players in broadcast sports video, which is helpful to analysis player activity and team tactics. However, it is challenging to efficiently detect and track soccer players with shots switched and noise caused by auditorium and billboards. And for multi-player tracking how to treat the increase or decrease of player are also difficult. In this paper, a robust player detection algorithm based on salient region detection and tracking based on enhanced particle filtering are proposed. Salient region detection is used to segment sports fields, and then soccer players are detected by edge detection combined with Otsu algorithm. For soccer players tracking, we use an enhanced particle filter which we improve the algorithm in sample and the likelihood function combing the color feature and edge feature. Experimental results show the proposed algorithm can quickly and accurately detect and track soccer players in broadcast video.",2017,Journal of Visual Communication and Image Representation
ASIF2017176,Multinational vehicle license plate detection in complex backgrounds,"License plate detection, Traffic surveillance, Intelligent transport systems, Color space conversion, Adaptive thresholding, Vehicle identification","Many methods for multinational License Plate Detection (LPD) have been proposed in recent times but most of them are not sophisticated enough to handle complex backgrounds. Moreover, their ability to handle various environmental and illumination conditions has been limited and still needs improvement. In this paper, we propose a novel technique to detect license plates of vehicles regardless of their color, size, and content. As the rear vehicle lights are an essential part of any vehicle, we reduce the image processing area to eliminate the complex background by detecting the rear-lights as the license plates are in a certain range of these lights. Heuristic Energy Map (HEM) of the vertical edge information in the Region of Interest (ROI) is calculated and area with the dense edges is selected using a unique histogram approach which is considered to be the license plate. The proposed algorithm is tested on 855 images from various countries including China, Pakistan, Serbia, Italy and various states of America. Experimental results show that the proposed method is able to detect license plates 90.4% of times despite of complex backgrounds in 0.25s on average that can achieve real time performance.",2017,Journal of Visual Communication and Image Representation
FITSCHEN2017312,Unsupervised multi class segmentation of 3D images with intensity inhomogeneities,"Image processing, Image segmentation, Variational methods, Non-convex optimization, PALM, Biconvex model, Illumination correction, Intensity inhomogeneities, FIB tomography","Intensity inhomogeneities in images cause problems in gray-value based image segmentation since the varying intensity often dominates over gray-value differences of the image structures. In this paper we propose a novel biconvex variational model that includes the intensity inhomogeneities to tackle this task. We combine a total variation approach for multi class segmentation with a multiplicative model to handle the inhomogeneities. In our model we assume that the image intensity is the product of a smoothly varying part and a component which resembles important image structures such as edges. Therefore, we penalize in addition to the total variation of the label assignment matrix a quadratic difference term to cope with the smoothly varying factor. A critical point of the resulting biconvex functional is computed by a modified proximal alternating linearized minimization method (PALM). We show that the assumptions for the convergence of the algorithm are fulfilled. Various numerical examples demonstrate the very good performance of our method. Particular attention is paid to the segmentation of 3D FIB tomographical images serving as a motivation for our work.",2017,Journal of Visual Communication and Image Representation
FENG2017119,Steganalysis of content-adaptive binary image data hiding,"Binary image, Content-adaptive data hiding, Steganography, Steganalysis, -shape pattern","Most state-of-the-art binary image data hiding methods concentrate the embedding changes on the centers of l-shape patterns. This embedding criterion, however, introduces an unbalanced modification on boundary structures. This paper proposes a steganalytic scheme to detect recently developed content-adaptive binary image data hiding by exploiting the embedding effect associated with the l-shape pattern-based embedding criterion. We first assess how changing l-shape patterns affects the distribution of a special 4×3 sized pattern. Based on the assessment, 4 classes of patterns that model the distribution of two pixels oriented the direction of pattern changing are employed to define a 32-dimensional steganalytic feature set. Experimental results show that, despite of the low dimensionality, the proposed steganalytic features can effectively detect state-of-the-art binary image data hiding schemes, especially those pattern-tracing-based approaches.",2017,Journal of Visual Communication and Image Representation
CHANDRIKA201723,Perceptually lossless coder for volumetric medical image data,"Image compression, Visual perception, Human visual system, Bilateral symmetry, MRI and CT images","With the development of modern imaging techniques, every medical examination would result in a huge volume of image data. Analysis, storage and/or transmission of these data demands high compression without any loss of diagnostically significant data. Although, various 3-D compression techniques have been proposed, they have not been able to meet the current requirements. This paper proposes a novel method to compress 3-D medical images based on human vision model to remove visually insignificant information. The block matching algorithm applied to exploit the anatomical symmetry remove the spatial redundancies. The results obtained are compared with those of lossless compression techniques. The results show better compression without any degradation in visual quality. The rate-distortion performance of the proposed coders is compared with that of the state-of-the-art lossy coders. The subjective evaluation performed by the medical experts confirms that the visual quality of the reconstructed image is excellent.",2017,Journal of Visual Communication and Image Representation
FEIZ201748,A splitting method for total least squares color image restoration problem,"Structured total least squares (STLS), Color image restoration, Wavelet, Splitting","Color image restoration is an important problem in image processing. Using the structured total least squares (STLS) for fidelity term of the restoration process gives better results in comparison with the least squares (LS) approach. The main drawback of the STLS approach is its complexity. To overcome this issue, in this paper by an appropriate transformation the color image restoration is substituted with two smaller subproblems corresponding to smooth and oscillatory parts of the image. The first and second subproblems are modeled via STLS and LS approaches, respectively. We show that the proposed method is faster than STLS and gives competitive solutions with it. Also, we demonstrate that Haar wavelet perseveres the structure of the blurring operator, which causes a considerable reduction in computational and storage complexity of the proposed method.",2017,Journal of Visual Communication and Image Representation
HE201758,Efficient PVO-based reversible data hiding using multistage blocking and prediction accuracy matrix,"Reversible data hiding, Pixel value ordering, Multistage blocking, Prediction accuracy matrix","In recent years, pixel value ordering based reversible data hiding has become a hot research topic for its high-fidelity. In this approach, only the maximum and minimum of pixel block are predicted and modified to embed data and the preservation of pixel values order guarantees the reversibility. So far, the optimal block size can only be exhaustively searched until Wang et al. propose the dynamic blocking strategy which enables the combination of two various-sized blocks. By further dividing flat block into four sub-blocks to retain larger embedding capacity, dynamic blocking can employ less high complexity blocks for a given embedding capacity. However, the lack of host image dependent automatic block classification mechanism still exposes the fact that their work is far from efficient and comprehensive. In this paper, to address this drawback and to better exploit image redundancy, a really efficient and more comprehensive blocking strategy namely multistage blocking is proposed. High efficiency lies in prediction accuracy matrix based thresholds determination, which enables infinitely extended multistage blocking in theory. The superiority of the proposed scheme is also experimentally verified.",2017,Journal of Visual Communication and Image Representation
LIU2017208,Cross-layer optimized authentication and error control for wireless 3D medical video streaming over LTE,"Cross-layer optimization, 3D medical video, Authentication, LTE, Error control","3D video for tele-medicine applications is gradually gaining momentum since the 3D technology can provide precise location information. However, the weak link for 3D video streaming is the necessary wireless link of the communication system. Neglecting the wireless impairments can severely degrade the performance of 3D video streaming that communicates complex critical medical data. In this paper, we propose systematic methodology for ensuring high performance of the 3D medical video streaming system. First, we present a recursive end-to-end distortion estimation approach for MVC (multiview video coding)-based 3D video streaming over error-prone networks by considering the 3D inter-view prediction. Then, based on the previous model, we develop a cross-layer optimization scheme that considers the LTE wireless physical layer (PHY). In this optimization, the authentication requirements of 3D medical video are also taken into account. The proposed cross-layer optimization approach jointly controls and manages the authentication, video coding quantization of 3D video, and the modulation and channel coding scheme (MCS) of the LTE wireless PHY to minimize the end-to-end video distortion. Experimental results show that the proposed approach can provide superior 3D medical video streaming performance in terms of peak signal-to-noise ratio (PSNR) when compared to state-of-the-art approaches that include joint source-channel optimized streaming with multi-path hash-chaining based-authentication, and also conventional video streaming with single path hash-chaining-based authentication.",2017,Journal of Visual Communication and Image Representation
YANG2017139,Single-shot dense depth sensing with frequency-division multiplexing fringe projection,"Range finding, Three-dimensional sensing, Three-dimensional image acquisition, Depth sensing, Structured light","In structured light illumination (SLI) systems, multi-shot fringe patterns can reach higher precision than a single-shot fringe pattern. However, multi-shot methods are not suitable for dynamic scenes while single-shot ones are limited in the measurement accuracy. In this paper, a novel single-shot depth sensing method with frequency-division multiplexing (FDM) framework is proposed. To achieve a simultaneous casting, two fringe patterns with coprime periods are modulated into a single pattern. The method of fringe pattern extraction is similar to the demodulation in communication systems. The Gabor filter is adopted to get the phase information in the pattern, and the coprime theorem is used to solve the phase ambiguity. Quantitative and qualitative evaluations have proved that our method achieves higher accuracy in depth sensing compared with the Kinect v1 and ToF camera. In addition, benefiting from the single-shot pattern, our method is suitable for dynamic scenes.",2017,Journal of Visual Communication and Image Representation
LIU2017150,MRI reconstruction using a joint constraint in patch-based total variational framework,"CS-MRI, Total variation, Joint constraint, LMMSE","Compressed sensing (CS) as an efficient means has been widely applied in magnetic resonance imaging (MRI). As a regularization term to enforce the sparsity in the finite difference domain, the conventional total variation (TV) has been introduced in this field, where the staircase effect is presented. To overcome this issue, a new framework in the difference domain called joint constraint patch-based total variation (JCTV) is proposed. First, the image patch is utilized as the unit for TV norm to improve the adaptativity. Second, JCTV introduces a new nonlocal constraint term that exploits the estimated coefficients of the fully sampled image via linear minimum mean square error (LMMSE) criterion to improve the reconstruction performance. Finally, an alternative minimization algorithm is developed to seek the solution. Extensive experiments on a set of in vivo MR images demonstrate that the proposed algorithm outperforms the state-of-the-art approaches in terms of peak signal-to-noise ratio and visual quality.",2017,Journal of Visual Communication and Image Representation
YUAN2017280,Depth map super-resolution via low-resolution depth guided joint trilateral up-sampling,"Joint trilateral upsampling, Super-resolution, De-noising, Texture copying","In this paper, a new method is proposed to address the depth map super resolution (SR) and denoising problems simultaneously. Unlike the existing methods, the proposed approach uses LR depth map as a guidance in each filtering iteration during the whole process to fully exploit the geometric information in it. A joint trilateral upsampling model is proposed to fuse the projected spatial distance measured from the LR depth map, the intensity variance extracted from the associated color image and the HR depth map generated in the last iteration to refine the HR depth map iteratively. Compared with the existing approaches, the proposed approach presents superior results in avoiding texture copying artifacts as misalignments existing between the depth map and color image. Also, for the depth with noises, it can provide stronger de-noising effects with much clearer edges in the processed results. On average, it only requires 7.67 iterations to reach convergence, which is very efficient and outperforms the representative approaches in terms of computational complexity, objective quality and subjective quality.",2017,Journal of Visual Communication and Image Representation
JIANG2017269,Stereoscopic image quality assessment by learning non-negative matrix factorization-based color visual characteristics and considering binocular interactions,"Stereoscopic image quality assessment, Non-negative matrix factorization, Schmidt orthogonalization, Monocular perception, Binocular interaction","In this paper, we propose a novel stereoscopic image quality assessment (SIQA) method by learning non-negative matrix factorization (NMF)-based color visual characteristics for monocular perception and considering binocular interactions. In training phase, a feature basis matrix is learned based on NMF by considering color information and a feature detector is designed by performing Schmidt orthogonalization on the feature basis matrix. In construction of SIQA phase, for monocular perception, visual saliency regions are selected and parts-based feature similarity indexes of left and right views based on the feature vectors extracted by the feature detector are calculated. For binocular interactions, we calculate cyclopean feature similarity index by considering binocular fusion and rivalry. Finally, support vector regression is used to simulate nonlinear relationship between monocular perception and binocular interactions. Experimental results on LIVE 3D image databases and NBU 3D IQA database demonstrate that the proposed SIQA method is more consistent with human perception.",2017,Journal of Visual Communication and Image Representation
LAKEHAL2017107,Multiple illuminant estimation from the covariance of colors,"Computer vision, Color constancy, White balancing, Multiple illuminant estimation, Dichromatic reflection model, Color space, Principal component analysis","In this paper we present a single and a multiple illuminant estimation physics-based algorithm. Both algorithms are based on the mean projections maximization assumption and un-centered component analysis. The proposed assumption is validated for a large collection of images and later used to estimate the illuminant color. The multiple illuminant estimator assumes that the spectral power distribution of the light source is not the same for the whole scene, which is the case for a wide range of images. In such cases, our new multiple illuminant estimator recovers an accurate illuminants estimates map for each input image while maintaining speed. The evaluation of the proposed algorithms on different real image datasets is realized. The experimental results are satisfying; our algorithms maximize the trade-off between accuracy (illuminant estimation error) and computational complexity.",2017,Journal of Visual Communication and Image Representation
XIAO2017199,A global and local consistent ranking model for image saliency computation,"Saliency detection, Markov chain, Graph ranking","Image saliency detection is an important issue in computer vision and has been widely used in many applications. In this paper, we propose a new global and local consistent ranking (GLR) model for image saliency computation. Firstly, we propose to use an absorbed Markov chain model to obtain a kind of global ranking for image superpixels, in which the absorbing nodes represent the virtual boundary superpixels and the transient nodes denote the general superpixels of image. Then, the absorbed time from each transient node to boundary absorbing nodes are computed. This absorbing time of transient node measures its global similarity with all absorbing nodes and thus provides a kind of global ranking for each transient node w.r.t. absorbing nodes. At last, we further exploit the local manifold structure and incorporate the local manifold smooth information into ranking process and thus propose a general global and local consistent ranking for saliency detection. Experimental results on several large benchmark databases show the effectiveness of the proposed GLR method.",2017,Journal of Visual Communication and Image Representation
WANG2017292,VideoSet: A large-scale compressed video quality dataset based on JND measurement,"Human visual system (HVS), Just noticeable difference (JND), Video quality, Video coding","A new methodology to measure coded image/video quality using the just-noticeable-difference (JND) idea was proposed in Lin et al. (2015). Several small JND-based image/video quality datasets were released by the Media Communications Lab at the University of Southern California in Jin et al. (2016) and Wang et al. (2016) [3]. In this work, we present an effort to build a large-scale JND-based coded video quality dataset. The dataset consists of 220 5-s sequences in four resolutions (i.e., 1920×1080,1280×720,960×540 and 640×360). For each of the 880 video clips, we encode it using the H.264/AVC codec with QP=1,…,51 and measure the first three JND points with 30+subjects. The dataset is called the “VideoSet”, which is an acronym for “Video Subject Evaluation Test (SET)”. This work describes the subjective test procedure, detection and removal of outlying measured data, and the properties of collected JND data. Finally, the significance and implications of the VideoSet to future video coding research and standardization efforts are pointed out. All source/coded video clips as well as measured JND data included in the VideoSet are available to the public in the IEEE DataPort (Wang et al., 2016 [4]).",2017,Journal of Visual Communication and Image Representation
LIU201770,Quality assessment for real out-of-focus blurred images,"Visual quality assessment, Out-of-focus blur, Blind/no-reference, Phase congruency, Visual saliency","Images are vulnerable to different kinds of distortions, such as blur, noise, blockiness etc, which all degrade the image quality. Among the distorted images, out-of-focus blurred images are frequently-encountered and occupy a large proportion. However, few efforts have been done to quality evaluation for these images. In this paper, we devise a dedicated quality evaluation scheme to automatically infer the quality of out-of-focus blurred images, which is named GPSQ (Gradient magnitude and Phase congruency-based and Saliency-guided Quality model). In GPSQ, a pair of low-level features, including gradient magnitude (GM) and phase congruency (PC), are extracted to characterize the image local blurriness. Then saliency detection is performed on the image to generate a corresponding saliency map. Finally, we weight the local structure map with the saliency map to estimate the visual quality of the out-of-focus blurred image. Experimental results demonstrate the proposed GPSQ delivers high consistency with subjective evaluation results.",2017,Journal of Visual Communication and Image Representation
FURNARI2017165,Distortion adaptive Sobel filters for the gradient estimation of wide angle images,"Gradient estimation, Adaptive filters, Radial distortion, Wide angle images","We introduce a set of distortion adaptive Sobel filters for the direct estimation of geometrically correct gradients of wide angle images. The definition of the filters is based on Sobel’s rationale and accounts for the geometric transformation undergone by wide angle images due to the presence of radial distortion. Moreover, we show that a local normalization of the filters magnitude is essential to achieve state-of-the-art results. To perform the experimental analysis, we propose an evaluation pipeline and a benchmark dataset of images belonging to different scene categories. Experiments on both, synthetic and real images, show that our approach outperforms the current state-of-the-art in both gradient estimation and keypoint matching for images characterized by large amounts of radial distortion. The collected dataset and the MATLAB code of the proposed method can be downloaded at our web page http://iplab.dmi.unict.it/DASF/.",2017,Journal of Visual Communication and Image Representation
MITTAL2017187,Rotation and script independent text detection from video frames using sub pixel mapping,"Multi-oriented text detection, Low resolution videos, Sub pixel mapping, Script independent text segmentation","Text detection and recognition in video frames is a challenging task due to low contrast and noise from background that hinder the processing. In this paper we have proposed a robust multi-oriented text detection approach in video frames. Proposed method uses sub pixel mapping based super resolution approach to enhance the image. Next, in this enhanced image, Histogram of Oriented Moment feature is extracted from connected components and Support Vector Machine (SVM) classifier is used for multi-oriented text/non-text identification. Finally, Recurrent Neural Network (RNN) based classifier is used for recognition of text characters. We have performed our experiment in ICDAR2013 Robust Reading Competition Karatzas et al. (2013). To evaluate the script independent text extraction performance, we tested our framework in IITR dataset Verma et al. (2016) that contains text of multiple scripts in scene images. We have obtained F-measure of 0.82 which surpasses the current state of art techniques in ICDAR2013 Karatzas et al. (2013) and 0.8 in IITR Dataset Verma et al. (2016) for text detection.",2017,Journal of Visual Communication and Image Representation
FARHI2017303,Adaptive stochastic segmentation via energy-convergence for brain tumor in MR images,"Active contours, Level set, Statistical energies, Stochastic segmentation, MR images","An adaptive algorithm that formulates an energy based stochastic segmentation with a level set methodology is proposed.The hybrid method uses global and local energies, which are efficient in matching, segmenting and tracing anatomic structures by exploiting constraints computed from the data of the image. The algorithm performs autonomous stochastic segmentation of tumor in Magnetic Resonance Imaging (MRI) by combining region based level sets globally and three established energies (uniform, separation and histogram) in a local framework. The local region is defined by the segmentation boundary which, in the case of level set method, consists of global statistics and local energies of every individual point and the local region is then updated by minimizing (or maximizing) the energies. For analysis, the algorithm is tested on low grade and high grade MR images dataset. The obtained results show that the proposed methodology provides similarity between segmented and truth image up to 89.5% by dice method, and minimum distance of 0.5(mm) by Hausdorff algorithm. This adaptive stochastic segmentation algorithm can also be used to compute segmentation when binary thresholding level is greater than 0.2.",2017,Journal of Visual Communication and Image Representation
HUANG2017250,Vehicle detection and inter-vehicle distance estimation using single-lens video camera on urban/suburb roads,"Vehicle detection, Inter-vehicle distance estimation, Background subtraction, Histogram of oriented gradient (HOG), Support vector machine (SVM)","This paper presents a driver assistance system for vehicle detection and inter-vehicle distance estimation using a single-lens video camera on urban/suburb roads. The task of vehicle detection on urban/suburb roads is more challenging due to their high scene complexity. In this work, the still area of frame inside the host vehicle is first removed using temporal differencing, followed by detecting vanishing point. Segmentation of road regions is then conducted using vanishing point and road’s edge lines. Shadow regions at the bottoms of vehicles verified using the HOG feature and an SVM classifier are utilized to detect vehicle positions. The distances between the host and its front vehicles are estimated based on the locations of detected vehicles and vanishing point. Experimental results show varied performance of vehicle detection with different scenes of urban/suburb roads and the detection rate can achieve up to 94.08%, indicating the feasibility of the proposed method.",2017,Journal of Visual Communication and Image Representation
WARIF2017219,SIFT-Symmetry: A robust detection method for copy-move forgery with reflection attack,"Blind detection, Copy-move forgery, Image forensics, Reflection detection","Copy-move forgery (CMF) is a popular image manipulation technique that is simple and effective in creating forged illustrations. The bulk of CMF detection methods concentrate on common geometrical transformation attacks (e.g., rotation and scale) and post-processing attacks (e.g., Joint Photographic Experts Group (JPEG) compression and Gaussian noise addition). However, geometrical transformation that involves reflection attacks has not yet been highlighted in the literature. As the threats of reflection attack are inevitable, there is an urgent need to study CMF detection methods that are robust against this type of attack. In this study, we investigated common geometrical transformation attacks and reflection-based attacks. Also, we suggested a robust CMF detection method, called SIFT-Symmetry, that innovatively combines the Scale Invariant Feature Transform (SIFT)-based CMF detection method with symmetry-based matching. We evaluated the SIFT-Symmetry with three established methods that are based on SIFT, multi-scale analysis, and patch matching using two new datasets that cover simple transformation and reflection-based attacks. The results show that the F-score of the SIFT-Symmetry method surpassed the average 80% value for all geometrical transformation cases, including simple transformation and reflection-based attacks, except for the reflection with rotation case which had an average F-score of 65.3%. The results therefore show that the SIFT-Symmetry method gives better performance compared to the other existing methods.",2017,Journal of Visual Communication and Image Representation
HSU201733,Robust blind image watermarking using crisscross inter-block prediction in the DCT domain,"Blind image watermarking, Discrete cosine transform, Partly sign-altered, Mixed modulation, Crisscross inter-block prediction","Watermarking has been proposed as a solution to the problem protecting copyrighted multimedia in networked environments. This paper presents a simple but effective blind watermarking scheme capable of satisfying requirements pertaining to imperceptibility as well as robustness, while maintaining a sufficient payload capacity. In the proposed scheme, partly sign-altered mean modulation and mixed modulation are introduced to the crisscross discrete cosine transform (DCT)-based inter-block. Substituting a set of coefficients for a single coefficient enhances robustness against malign attacks. The inclusion of mixed modulation enables control over the parameters required to provide resistance against commonly encountered attacks while maintaining a high peak signal-to-noise ratio. Experiment results demonstrate that the proposed algorithm exceeds the performance of the seven other schemes in providing robust resistance to variety of attacks, particularly those associated with Gaussian noise and speckle noise.",2017,Journal of Visual Communication and Image Representation
PAN2017128,"Design, analysis and application of a volumetric convolutional neural network","Convolutional neural network, 3D shape classification, ModelNet40 shape dataset, Unsupervised learning, Anchor vector","The design, analysis and application of a volumetric convolutional neural network (VCNN) are studied in this work. Although many CNNs have been proposed in the literature, their design is empirical. In the design of the VCNN, we propose a feed-forward K-means clustering algorithm to determine the filter number and size at each convolutional layer systematically. For the analysis of the VCNN, the cause of confusing classes in the output of the VCNN is explained by analyzing the relationship between the filter weights (also known as anchor vectors) from the last fully-connected layer to the output. Furthermore, a hierarchical clustering method followed by a random forest classification method is proposed to boost the classification performance among confusing classes. For the application of the VCNN, we examine the 3D shape classification problem and conduct experiments on a popular ModelNet40 dataset. The proposed VCNN offers the state-of-the-art performance among all volume-based CNN methods.",2017,Journal of Visual Communication and Image Representation
CHU2017233,Camera as weather sensor: Estimating weather information from single images,"Cross-platform data association, Weather property estimation, Weather modeling, Random forests, Landmark classification","We estimate weather information from single images, as an important clue to unveil real-world characteristics available in the cyberspace, and as a complementary feature to facilitate computer vision applications. Based on an image collection with geotags, we crawl the associated weather and elevation properties from the web. With this large-scale and rich image dataset, various correlations between weather properties and metadata are observed, and are used to construct computational models based on random forests to estimate weather information for any given image. We describe interesting statistics linking weather properties with human behaviors, and show that image’s weather information can potentially benefit computer vision tasks such as landmark classification. Overall, this work proposes a large-scale image dataset with rich weather properties, and provides comprehensive studies on using cameras as weather sensors.",2017,Journal of Visual Communication and Image Representation
RAD20171,Image annotation using multi-view non-negative matrix factorization with different number of basis vectors,"Automatic image annotation, Non-negative matrix factorization (NMF), Multi-view NMF","Automatic Image Annotation (AIA) helps image retrieval systems by predicting tags for images. In this paper, we propose an AIA system using Non-negative Matrix Factorization (NMF) framework. The NMF framework discovers a latent space, by factorizing data into a set of non-negative basis and coefficients. To model the images, multiple features are extracted, each one represents images from a specific view. We use multi-view graph regularization NMF and allow NMF to choose a different number of basis vectors for each view. For tag prediction, each test image is mapped onto the multiple latent spaces. The distances of images in these spaces are used to form a unified distance matrix. The weights of distances are learned automatically. Then a search-based method is used to predict tags based on tags of nearest neighbors’. We evaluate our method on three datasets and show that it is competitive with the current state-of-the-art methods.",2017,Journal of Visual Communication and Image Representation
MAISELI201795,Recent developments and trends in point set registration methods,"Point matching, Registration, Performance, Optimization, Point set","Point set registration (PSR) is the process of computing a spatial transformation that optimally aligns pairs of point sets. The method helps to amalgamate multiple datasets into a common coordinate system. Because of their immense practical applications, several studies have attempted to address challenges inherent in the PSR problem. However, limited works exist to discuss recent developments, failures, and trends of the PSR methods. To date, a classical work of Tam et al., published in 2013, can be regarded as a comprehensive review paper for registration methods. Nevertheless, this work has inadequately revealed a range of possible knowledge gaps of the previous studies. Additionally, since the publication year of their work, more superior and state-of-the-art methods have been proposed. The present study surveys PSR approaches until 2017, and our primary focus is to expose central ideas and limitations of the methods to facilitate experts and practitioners advance the field.",2017,Journal of Visual Communication and Image Representation
VACACASTANO201792,Improved scene identification and object detection on egocentric vision of daily activities,"Scene classification, Object detection, Scene understanding, First camera person vision","This work investigates the relationship between scene and associated objects on daily activities under egocentric vision constraints. Daily activities are performed in prototypical scenes that share a lot of visual appearances independent of where or by whom the video was recorded. The intrinsic characteristics of egocentric vision suggest that the location where the activity is conducted remains consistent throughout frames. This paper shows that egocentric scene identification is improved by taking the temporal context into consideration. Moreover, since most of the objects are typically associated with particular types of scenes, we show that a generic object detection method can also be improved by re-scoring the results of the object detection method according to the scene content. We first show the case where the scene identity is explicitly predicted to improve object detection, and then we show a framework using Long Short-Term Memory (LSTM) where no labeling of the scene type is needed. We performed experiments in the Activities of Daily Living (ADL) public dataset (Pirsiavash and Ramanan,2012), which is a standard benchmark for egocentric vision.",2017,Computer Vision and Image Understanding
CASTRILLONSANTANA20174,MEG: Texture operators for multi-expert gender classification,"Automatic gender classification, Face images, Multi-feature classification, Feature level vs. score level fusion","In this paper we focus on gender classification from face images. Despite advances in equipment as well as methods, automatic face image processing for recognition or even just for the extraction of demographics, is still a challenging task in unrestricted scenarios. Our tests are aimed at carrying out an extensive comparison of a feature based approach with two score based ones. When directly using features, we first apply different operators to extract the corresponding feature vectors, and then stack such vectors. These are classified by a SVM-based approach. When using scores, the different operators are applied in a completely separate way, so that each of them produces the corresponding scores. Answers are then either fed to a SVM, or compared pairwise to exploit Likelihood Ratio. The testbeds used for experiments are EGA database, which presents a good balance with respect to demographic features of stored face images, and GROPUS, an increasingly popular benchmark for massive experiments. The obtained performances confirm that feature level fusion achieves an often better classification accuracy. However, it is computationally expensive. We contribute to the research on this topic in three ways: 1) we show that the proposed score level fusion approaches, though less demanding, can achieve results that are comparable to feature level fusion, or even slightly better given that we fuse a particular set of experts; the main advantage over the feature-based approach relying on chained vectors, is that it is not required to evaluate a complex multi-feature distribution and the training process: thanks to the individual training of experts the overall process is more efficient and flexible, since experts can be easily added or discarded from the final architecture; 2) we evaluate the number of uncertain/ambiguous cases, i.e., those that might cause classification errors depending on the classification thresholds used, and show that with our score level fusion these significantly decreases; despite the final rate of correct classifications, this results in a more robust system; 3) we achieve very good results with operators that are not computationally expensive.",2017,Computer Vision and Image Understanding
RICHARD201779,A bag-of-words equivalent recurrent neural network for action recognition,"Action recognition, Bag-of-words, Neural networks","The traditional bag-of-words approach has found a wide range of applications in computer vision. The standard pipeline consists of a generation of a visual vocabulary, a quantization of the features into histograms of visual words, and a classification step for which usually a support vector machine in combination with a non-linear kernel is used. Given large amounts of data, however, the model suffers from a lack of discriminative power. This applies particularly for action recognition, where the vast amount of video features needs to be subsampled for unsupervised visual vocabulary generation. Moreover, the kernel computation can be very expensive on large datasets. In this work, we propose a recurrent neural network that is equivalent to the traditional bag-of-words approach but enables for the application of discriminative training. The model further allows to incorporate the kernel computation into the neural network directly, solving the complexity issue and allowing to represent the complete classification system within a single network. We evaluate our method on four recent action recognition benchmarks and show that the conventional model as well as sparse coding methods are outperformed.",2017,Computer Vision and Image Understanding
KUZBORSKIJ2017174,Scalable greedy algorithms for transfer learning,"Transfer learning, Domain adaptation, Visual object detection, Greedy algorithms, Feature selection","In this paper we consider the binary transfer learning problem, focusing on how to select and combine sources from a large pool to yield a good performance on a target task. Constraining our scenario to real world, we do not assume the direct access to the source data, but rather we employ the source hypotheses trained from them. We propose an efficient algorithm that selects relevant source hypotheses and feature dimensions simultaneously, building on the literature on the best subset selection problem. Our algorithm achieves state-of-the-art results on three computer vision datasets, substantially outperforming both transfer learning and popular feature selection baselines in a small-sample setting. We also present a randomized variant that achieves the same results with the computational cost independent from the number of source hypotheses and feature dimensions. Also, we theoretically prove that, under reasonable assumptions on the source hypotheses, our algorithm can learn effectively from few examples.",2017,Computer Vision and Image Understanding
XU2017117,Detecting anomalous events in videos by learning deep representations of appearance and motion,"Video surveillance, Abnormal event detection, Unsupervised learning, Stacked denoising auto-encoders, Feature fusion","Anomalous event detection is of utmost importance in intelligent video surveillance. Currently, most approaches for the automatic analysis of complex video scenes typically rely on hand-crafted appearance and motion features. However, adopting user defined representations is clearly suboptimal, as it is desirable to learn descriptors specific to the scene of interest. To cope with this need, in this paper we propose Appearance and Motion DeepNet (AMDN), a novel approach based on deep neural networks to automatically learn feature representations. To exploit the complementary information of both appearance and motion patterns, we introduce a novel double fusion framework, combining the benefits of traditional early fusion and late fusion strategies. Specifically, stacked denoising autoencoders are proposed to separately learn both appearance and motion features as well as a joint representation (early fusion). Then, based on the learned features, multiple one-class SVM models are used to predict the anomaly scores of each input. Finally, a novel late fusion strategy is proposed to combine the computed scores and detect abnormal events. The proposed ADMN is extensively evaluated on publicly available video surveillance datasets including UCSD pedestian, Subway, and Train, showing competitive performance with respect to state of the art approaches.",2017,Computer Vision and Image Understanding
LOPRESTI201719,Boosting Hankel matrices for face emotion recognition and pain detection,"Emotion, Face processing, LTI systems, Hankel matrix, Boosting","Studies in psychology have shown that the dynamics of emotional expressions play an important role in face emotion recognition in humans. Motivated by these studies, in this paper the dynamics of face expressions are modeled and used for automatic emotion recognition and pain detection. Given a temporal sequence of face images, several appearance-based descriptors are computed at each frame. Over the sequence, the descriptors corresponding to the same feature type and spatial scale define a time series. The Hankel matrix built upon each time series is used to represent the dynamics of face expressions with respect to the used feature-scale pair. The set of Hankel matrices obtained by varying the feature type and the scale is used within a boosting approach to train a strong classifier. During training, random subspace projection is adopted for feature and scale selection. Experiments on two challenging publicly available datasets show that the dynamics of appearance-based face expression representations can be used to discriminate among different emotion classes and, within a boosting approach, attain state-of-the-art average accuracy values in classification.",2017,Computer Vision and Image Understanding
CAKIR2017162,Online supervised hashing,"Hashing, Fast similarity search, Approximate nearest neighbors, Retrieval","Fast nearest neighbor search is becoming more and more crucial given the advent of large-scale data in many computer vision applications. Hashing approaches provide both fast search mechanisms and compact index structures to address this critical need. In image retrieval problems where labeled training data is available, supervised hashing methods prevail over unsupervised methods. Most state-of-the-art supervised hashing approaches employ batch-learners. Unfortunately, batch-learning strategies may be inefficient when confronted with large datasets. Moreover, with batch-learners, it is unclear how to adapt the hash functions as the dataset continues to grow and new variations appear over time. To handle these issues, we propose OSH: an Online Supervised Hashing technique that is based on Error Correcting Output Codes. We consider a stochastic setting where the data arrives sequentially and our method learns and adapts its hashing functions in a discriminative manner. Our method makes no assumption about the number of possible class labels, and accommodates new classes as they are presented in the incoming data stream. In experiments with three image retrieval benchmarks, our method yields state-of-the-art retrieval performance as measured in Mean Average Precision, while also being orders-of-magnitude faster than competing batch methods for supervised hashing. Also, our method significantly outperforms recently introduced online hashing solutions.",2017,Computer Vision and Image Understanding
PAISITKRIANGKRAI201751,Structured learning of metric ensembles with application to person re-identification,"Person re-identification, Learning to rank, Metric ensembles, Structured learning","Matching individuals across non-overlapping camera networks, known as person re-identification, is a fundamentally challenging problem due to the large visual appearance changes caused by variations of viewpoints, lighting, and occlusion. Approaches in literature can be categorized into two streams: The first stream is to develop reliable features against realistic conditions by combining several visual features in a pre-defined way; the second stream is to learn a metric from training data to ensure strong inter-class differences and intra-class similarities. However, seeking an optimal combination of visual features which is generic yet adaptive to different benchmarks is an unsolved problem, and metric learning models easily get over-fitted due to the scarcity of training data in person re-identification. In this paper, we propose two effective structured learning based approaches which explore the adaptive effects of visual features in recognizing persons in different benchmark data sets. Our framework is built on the basis of multiple low-level visual features with an optimal ensemble of their metrics. We formulate two optimization algorithms, CMC triplet and CMC top, which directly optimize evaluation measures commonly used in person re-identification, also known as the Cumulative Matching Characteristic (CMC) curve. The more standard CMC triplet formulation works on the triplet information by maximizing the relative distance between a matched pair and a mismatched pair in each triplet unit. The CMC top formulation, modeled on a structured learning of maximizing the correct identification among top candidates, is demonstrated to be more beneficial to person re-identification by directly optimizing an objective closer to the actual testing criteria. The combination of these factors leads to a person re-identification system which outperforms most existing algorithms. More importantly, we advance state-of-the-art results by improving the rank-1 recognition rates from 40% to 61% on the iLIDS benchmark, 16% to 22% on the PRID2011 benchmark, 43% to 50% on the VIPeR benchmark, 34% to 55% on the CUHK01 benchmark and 21% to 68% on the CUHK03 benchmark.",2017,Computer Vision and Image Understanding
QIN2017104,Fast action retrieval from videos via feature disaggregation,"Similarity search, Video retrieval, Feature disaggregation, Learning based hashing","Learning based hashing methods, which aim at learning similarity-preserving binary codes for efficient nearest neighbor search, have been actively studied recently. A majority of the approaches address hashing problems for image collections. However, due to the extra temporal information, videos are usually represented by much higher dimensional (thousands or even more) features compared with images, causing high computational complexity for conventional hashing schemes. In this paper, we propose a simple and efficient hashing scheme for high-dimensional video data. This method, called Disaggregation Hashing (DH), exploits the correlations among different feature dimensions. An intuitive feature disaggregation method is first proposed, followed by a novel hashing algorithm based on different feature clusters. Additionally, a kernelized version of DH is proposed for better performance. We demonstrate the efficiency and effectiveness of our method by theoretical analysis and exploring its application on action retrieval from video databases. Extensive experiments show the superiority of our binary coding scheme over state-of-the-art hashing methods.",2017,Computer Vision and Image Understanding
SEGALIN201734,Social profiling through image understanding: Personality inference using convolutional neural networks,"Image understanding, Social signal processing, Convolutional neural networks, Computational aesthetics, Personality computing","The role of images in the last ten years has changed radically due to the advent of social networks: from media objects mainly used to communicate visual information, images have become personal, associated with the people that create or interact with them (for example, giving a “like”). Therefore, in the same way that a post reveals something of its author, so now the images associated to a person may embed some of her individual characteristics, such as her personality traits. In this paper, we explore this new level of image understanding with the ultimate goal of relating a set of image preferences to personality traits by using a deep learning framework. In particular, our problem focuses on inferring both self-assessed (how the personality traits of a person can be guessed from her preferred image) and attributed traits (what impressions in terms of personality traits these images trigger in unacquainted people), learning a sort of wisdom of the crowds. Our characterization of each image is locked within the layers of a CNN, allowing us to discover more entangled attributes (aesthetic patterns and semantic information) and to better generalize the patterns that identify a trait. The experimental results show that the proposed method outperforms state-of-the-art results and captures what visually characterizes a certain trait: using a deconvolution strategy we found a clear distinction of features, patterns and content between low and high values in a given trait.",2017,Computer Vision and Image Understanding
DAS201766,Continuous adaptation of multi-camera person identification models through sparse non-redundant representative selection,"Redundancy reduction, Representative selection, Continuous learning, Person identification/recognition","The problem of image-base person identification/recognition is to provide an identity to the image of an individual based on learned models that describe his/her appearance. Most traditional person identification systems rely on learning a static model on tediously labeled training data. Though labeling manually is an indispensable part of a supervised framework, for a large scale identification system labeling huge amount of data is a significant overhead. For large multi-sensor data as typically encountered in camera networks, labeling a lot of samples does not always mean more information, as redundant images are labeled several times. In this work, we propose a convex optimization based iterative framework that progressively and judiciously chooses a sparse but informative set of samples for labeling, with minimal overlap with previously labeled images. We also use a structure preserving sparse reconstruction based classifier to reduce the training burden typically seen in discriminative classifiers. The two stage approach leads to a novel framework for online update of the classifiers involving only the incorporation of new labeled data rather than any expensive training phase. We demonstrate the effectiveness of our approach on multi-camera person re-identification datasets, to demonstrate the feasibility of learning online classification models in multi-camera big data applications. Using three benchmark datasets, we validate our approach and demonstrate that our framework achieves superior performance with significantly less amount of manual labeling.",2017,Computer Vision and Image Understanding
MALMIR2017128,Deep active object recognition by joint label and action prediction,"Active object recognition, Deep learning, Q-learning","An active object recognition system has the advantage of acting in the environment to capture images that are more suited for training and lead to better performance at test time. In this paper, we utilize deep convolutional neural networks for active object recognition by simultaneously predicting the object label and the next action to be performed on the object with the aim of improving recognition performance. We treat active object recognition as a reinforcement learning problem and derive the cost function to train the network for joint prediction of the object label and the action. A generative model of object similarities based on the Dirichlet distribution is proposed and embedded in the network for encoding the state of the system. The training is carried out by simultaneously minimizing the label and action prediction errors using gradient descent. We empirically show that the proposed network is able to predict both the object label and the actions on GERMS, a dataset for active object recognition. We compare the test label prediction accuracy of the proposed model with Dirichlet and Naive Bayes state encoding. The results of experiments suggest that the proposed model equipped with Dirichlet state encoding is superior in performance, and selects images that lead to better training and higher accuracy of label prediction at test time.",2017,Computer Vision and Image Understanding
SRIKANTHA2017138,Weak supervision for detecting object classes from activities,"Weakly supervised, Object detection, Human-object interaction, RGB-D videos","Weakly supervised learning for object detection has been gaining significant attention in the recent past. Visually similar objects are extracted automatically from weakly labeled videos hence bypassing the tedious process of manually annotating training data. However, the problem as applied to small or medium sized objects is still largely unexplored. Our observation is that weakly labeled information can be derived from videos involving human-object interactions. Since the object is characterized neither by its appearance nor its motion in such videos, we propose a robust framework that taps valuable human context and models similarity of objects based on appearance and functionality. Furthermore, the framework is designed such that it maximizes the utility of the data by detecting possibly multiple instances of an object from each video. We show that object models trained in this fashion perform between 86% and 92% of their fully supervised counterparts on three challenging RGB and RGB-D datasets.",2017,Computer Vision and Image Understanding
MAI2017151,Efficient large-scale multi-class image classification by learning balanced trees,"Large-scale image classification, Multi-class classification, Label tree learning, Balanced tree, Hierarchical classification, Clustering","Large-scale multi-class image classification is essential for big data applications. One of the challenges is to deal with situations in which the number of classes is very large and for which the standard one-versus-all method is not appropriate because its computational complexity is linear in the number of classes. Using a label tree is a popular way to reduce complexity. By organizing classes into a hierarchical structure, the number of classifier evaluations of a test sample when traveling from the root node to a leaf node is significantly reduced. Having a balanced learned tree is essential to this approach. The current methods for learning the tree structure use clustering techniques, such as k-means or spectral clustering, to group confusing classes into clusters associated with the nodes. However, the output tree in such cases might not be balanced. In this paper, we propose a method for learning effective and balanced trees by jointly optimizing balance and confusion constraints. Experimental results on large-scale datasets including Caltech-256, SUN-397, ILSVRC2010-1K, and ImageNet-10K, show that our method outperforms other state-of-the-art methods.",2017,Computer Vision and Image Understanding
ZEPPELZAUER201874,A study on topological descriptors for the analysis of 3D surface texture,"Surface texture analysis, 3D surface classification, Surface topology analysis, Surface representation, Persistent homology, Persistence diagram, Persistence image","Methods from computational topology are becoming more and more popular in computer vision and have shown to improve the state-of-the-art in several tasks. In this paper, we investigate the applicability of topological descriptors in the context of 3D surface analysis for the classification of different surface textures. We present a comprehensive study on topological descriptors, investigate their robustness and expressiveness and compare them with state-of-the-art methods including Convolutional Neural Networks (CNNs). Results show that class-specific information is reflected well in topological descriptors. The investigated descriptors can directly compete with non-topological descriptors and capture complementary information. As a consequence they improve the state-of-the-art when combined with non-topological descriptors.",2018,Computer Vision and Image Understanding
ZHANG201837,DAAL: Deep activation-based attribute learning for action recognition in depth videos,"Attribute learning, Action recognition, Depth camera","In this paper, we propose a joint semantic preserving action attribute learning framework for action recognition from depth videos, which is built on multi-stream deep neural networks. More specifically, this paper describes the idea to explore action attributes learned from deep activations. Multiple stream deep neural networks rather than conventional hand-crafted low-level features are employed to learn the deep activations. An undirected graph is utilized to model the complex semantics among action attributes and is integrated into our proposed joint action attribute learning algorithm. Experiments on several public datasets for action recognition demonstrate that 1) the deep activations achieve the state-of-the-art discriminative performance as feature vectors and 2) the attribute learner can produce generic attributes, and thus obtains decent performance on zero-shot action recognition.",2018,Computer Vision and Image Understanding
AGUDO2018121,"A scalable, efficient, and accurate solution to non-rigid structure from motion","Probabilistic trajectory space, Time-varying scenes, Non-rigid structure from motion, Low-rank representation, Factorization","Most Non-Rigid Structure from Motion (NRSfM) solutions are based on factorization approaches that allow reconstructing objects parameterized by a sparse set of 3D points. These solutions, however, are low resolution and generally, they do not scale well to more than a few tens of points. While there have been recent attempts at bringing NRSfM to a dense domain, using for instance variational formulations, these are computationally demanding alternatives which require certain spatial continuity of the data, preventing their use for articulated shapes with large deformations or situations with multiple discontinuous objects. In this paper, we propose incorporating existing point trajectory low-rank models into a probabilistic framework for matrix normal distributions. With this formalism, we can then simultaneously learn shape and pose parameters using expectation maximization, and easily exploit additional priors such as known point correlations. While similar frameworks have been used before to model distributions over shapes, here we show that formulating the problem in terms of distributions over trajectories brings remarkable improvements, especially in generality and efficiency. We evaluate the proposed approach in a variety of scenarios including one or multiple objects, sparse or dense reconstructions, missing observations, mild or sharp deformations, and in all cases, with minimal prior knowledge and low computational cost.",2018,Computer Vision and Image Understanding
BARBOSA201850,Looking beyond appearances: Synthetic training data for deep CNNs in re-identification,"Re-identification, Deep learning, Training set, Automated training dataset generation, Re-identification photorealistic dataset","Re-identification is generally carried out by encoding the appearance of a subject in terms of outfit, suggesting scenarios where people do not change their attire. In this paper we overcome this restriction, by proposing a framework based on a deep convolutional neural network, SOMAnet, that additionally models other discriminative aspects, namely, structural attributes of the human figure (e.g. height, obesity, gender). Our method is unique in many respects. First, SOMAnet is based on the Inception architecture, departing from the usual siamese framework. This spares expensive data preparation (pairing images across cameras) and allows the understanding of what the network learned. Second, and most notably, the training data consists of a synthetic 100K instance dataset, SOMAset, created by photorealistic human body generation software. SOMAset will be released with a open source license to enable further developments in re-identification. Synthetic data represents a cost-effective way of acquiring semi-realistic imagery (full realism is usually not required in re-identification since surveillance cameras capture low-resolution silhouettes), while at the same time providing complete control of the samples in terms of ground truth. Thus it is relatively easy to customize the data w.r.t. the surveillance scenario at-hand, e.g. ethnicity. SOMAnet, trained on SOMAset and fine-tuned on recent re-identification benchmarks, matches subjects even with different apparel.",2018,Computer Vision and Image Understanding
RANTOSON201889,A 3D deformable model-based framework for the retrieval of near-isometric flattenable objects using Bag-of-Visual-Words,"3D/2D Retrieval, bag-of-Visual-Words, Isometry, 3D Deformable model, Shape-from-Template","We introduce a 3D deformable model-based framework for the retrieval of near-isometric flattenable objects using keypoints and BoVW (Bag-of-Visual-Words). By 3D deformable model we mean a texturemapped 3D shape which may deform isometrically. We assume that such a model is available for each object in the database. We exploit the 3D deformable models at the training and the retrieval phases. For our first contribution, we exploit the possibility of generating synthetic data from the 3D deformable models to define a new BoVW model for the database object representation. Our model chooses an optimal per-object representation by maximizing each object’s mean average precision. The maximization is done over multiple candidate representations which are generated using the criteria of keypoint repeatability, weight discriminance and stability. Our second contribution is the use of SfT (Shape-from-Template) to facilitate geometric verification at the retrieval phase, for a few objects hypothesized using the new BoVW model. Existing methods use a rigid model, such as the fundamental matrix, or a simple deformable model based on semi-local constraints. SfT however is a physics-based method which uses an object’s 3D deformable model to reconstruct its isometric 3D deformation from a single input image. The output of SfT thus directly provides a geometric verification score. A byproduct of our work is to extend the scope of SfT. The proposed object retrieval framework is used to provide SfT with a few object hypotheses which may be quickly tested for the 3D deformable object selection. Performance evaluation on synthetic and real images reveals the benefits of our retrieval framework using a database with size varying between 20 and 1000 objects. The use of the new BoVW model and SfT versus the BoVW baseline and a rigid model improves the retrieval performance by 4.2% and 11.3% with p-values of 5×10−6 and 7×10−30 respectively.",2018,Computer Vision and Image Understanding
WU201863,Structured deep hashing with convolutional neural networks for fast person re-identification,"Person re-identification, Convolutional neural networks, Deep hashing, Structured embedding","Given a pedestrian image as a query, the purpose of person re-identification is to identify the correct match from a large collection of gallery images depicting the same person captured by disjoint camera views. The critical challenge is how to construct a robust yet discriminative feature representation to capture the compounded variations in pedestrian appearance. To this end, deep learning methods have been proposed to extract hierarchical features against extreme variability of appearance. However, existing methods in this category generally neglect the efficiency in the matching stage whereas the searching speed of a re-identification system is crucial in real-world applications. In this paper, we present a novel deep hashing framework with Convolutional Neural Networks (CNNs) for fast person re-identification. Technically, we simultaneously learn both CNN features and hash functions to get robust yet discriminative features and similarity-preserving hash codes. Thereby, person re-identification can be resolved by efficiently computing and ranking the Hamming distances between images. A structured loss function defined over positive pairs and hard negatives is proposed to formulate a novel optimization problem so that fast convergence and more stable optimized solution can be attained. Extensive experiments on two benchmarks CUHK03 (Li et al., 2014) and Market-1501 (Zheng et al., 2015) show that the proposed deep architecture is efficacy over state-of-the-arts.",2018,Computer Vision and Image Understanding
YU2018109,A Novel perspective invariant feature transform for RGB-D images,"RGB-D images, Spatial invariant, Local visual feature","RGB-D cameras have been attracting increasing researches for solving traditional problems in the domain of computer vision and robotics. Among the existing local features, most are proposed for the color channel or depth channel separately, while little attention has been paid to designing new composite features based on the physical characteristics. In this work, we propose a novel perspective invariant feature transform (PIFT) for RGB-D images. We integrate the color and depth information together making full use of the intrinsic characteristics of the two types of information to enhance the robustness and adaptability to large spatial variations of local appearance. The depth information is used to project the feature patch to its tangent plane to make it consistent with different views. It also helps to filter out the “fake keypoints” which are unstable in 3D space. Binary descriptors are then generated in the feature patches using a color coding method. Experiments on publicly available RGB-D datasets show that the proposed method has the best precision and the second best recall rate comparing against state-of-the-art local features, when applied to feature matching with large spatial variations.",2018,Computer Vision and Image Understanding
BERMUDEZCAMEO2018134,Fitting line projections in non-central catadioptric cameras with revolution symmetry,"Geometry, Non-central cameras, Omnidirectional vision, Line-projections","Line-images in non-central cameras contain much richer information of the original 3D line than line projections in central cameras. The projection surface of a 3D line in most catadioptric non-central cameras is a ruled surface, encapsulating the complete information of the 3D line. The resulting line-image is a curve which contains the 4 degrees of freedom of the 3D line. That means a qualitative advantage with respect to the central case, although extracting this curve is quite difficult. In this paper, we focus on the analytical description of the line-images in non-central catadioptric systems with symmetry of revolution. As a direct application we present a method for automatic line-image extraction for conical and spherical calibrated catadioptric cameras. For designing this method we have analytically solved the metric distance from point to line-image for non-central catadioptric systems. We also propose a distance we call effective baseline measuring the quality of the reconstruction of a 3D line from the minimum number of rays. This measure is used to evaluate the different random attempts of a robust scheme allowing to reduce the number of trials in the process. The proposal is tested and evaluated in simulations and with both synthetic and real images.",2018,Computer Vision and Image Understanding
CONNOR20181,Biometric recognition by gait: A survey of modalities and features,"Gait biometrics, Gait recognition, Features, Silhouette, Ground reaction force, Covariates","The scientific literature on automated gait analysis for human recognition has grown dramatically over the past 15 years. A number of sensing modalities including those based on vision, sound, pressure, and accelerometry have been used to capture gait information. For each of these modalities, a number of methods have been developed to extract and compare human gait information, resulting in different sets of features. This paper provides an extensive overview of the various types of features that have been utilized for each sensing modality and their relationship to the appearance and biomechanics of gait. The features considered in this work include (a) static and dynamic (temporal) features; (b) model-based and model-free visual features; (c) ground reaction force-based and finely resolved underfoot pressure features; (d) wearable sensor features; and (e) acoustic features. We also review the factors that impact gait recognition, and discuss recent work on gait spoofing and obfuscation. Finally, we enumerate the challenges and open problems in the field of gait recognition.",2018,Computer Vision and Image Understanding
MOEINI20171,Gender dictionary learning for gender classification,"Gender classification, Real-world face images, Dictionary learning, Probability decision making, Sparse representation","Human gender is one of the important demographic distinctiveness for facial image description. In this paper, a novel method is proposed for gender classification from real-world images under wide ranges of pose, expression and so on. To this end, an automatic feature extraction method is proposed by two types of features. Then, two separate dictionaries for male and female genders are defined for representing the gender in facial images. Also, two dictionary learning methods are proposed to learn the defined dictionaries in training process. Then, the Sparse Representation Classification (SRC) is adopted for classification in the testing process. Finally, a probability decision making approach is proposed to classify the gender from estimated values by SRC and proposed gender formulation. Convincing results are obtained for gender classification on three publicity databases including the FERET, LFW and Groups databases compared to several state-of-the-arts.",2017,Journal of Visual Communication and Image Representation
JUNG201728,Low light image enhancement with dual-tree complex wavelet transform,"Contrast enhancement, Dual-tree complex wavelet transform, Noise reduction, Wavelet coefficient","In low light condition, low dynamic range of the captured image distorts the contrast and results in high noise levels. In this paper, we propose an effective contrast enhancement method based on dual-tree complex wavelet transform (DT-CWT) which operates on a wide range of imagery without noise amplification. In terms of enhancement, we employ a logarithmic function for global brightness enhancement based on the nonlinear response of human vision to luminance. Moreover, we enhance the local contrast by contrast limited adaptive histogram equalization (CLAHE) in low-pass subbands to make image structure clearer. In terms of noise reduction, based on the direction selective property of DT-CWT, we perform content-based total variation (TV) diffusion which controls the smoothing degree according to noise and edges in high-pass subbands. Experimental results demonstrate that the proposed method achieves a good performance in low light image enhancment and outperforms state-of-the-art ones in terms of contrast enhancement and noise reduction.",2017,Journal of Visual Communication and Image Representation
SU2017161,A practical design of digital watermarking for video streaming services,"Digital watermark, Videos streaming, Digital rights management, Copyright protection, Tracking","A practical design of digital watermarking for video streaming services is proposed in this research. The information of a legitimate recipient is represented as a watermark, which is embedded in the video stream to serve as a cue to trace the recipient in case a clone of the video is illegally distributed. The watermark signals are designed to embed in some areas of video frames to benefit the video stream server, as the result of only partial actions required, including decoding, processing and re-encoding. The invariance of feature points and the self-similarity of hidden signals are further exploited to enable watermark detection without involving the original video. The watermark can decently survive transcoding processes and geometrical modifications of frames. The experimental results demonstrate the advantages of the proposed scheme in terms of watermark visibility, capacity and detection methodology.",2017,Journal of Visual Communication and Image Representation
REN2017192,GAL: A global-attributes assisted labeling system for outdoor scenes,"Outdoor layout estimation, Semantic labeling, Global attribute vector, Convolutional neural network, 3D reconstruction","An approach that extracts global attributes from outdoor images to facilitate geometric layout labeling is investigated in this work. The proposed Global-attributes Assisted Labeling (GAL) system exploits both local features and global attributes. First, by following a classical method, we use local features to provide initial labels for all super-pixels. Then, we develop a set of techniques to extract global attributes from 2D outdoor images. They include sky lines, ground lines, vanishing lines, etc. Finally, we propose the GAL system that integrates global attributes in the conditional random field (CRF) framework to improve initial labels so as to offer a more robust labeling result. The performance of the proposed GAL system is demonstrated and benchmarked with several state-of-the-art algorithms against a popular outdoor scene layout dataset.",2017,Journal of Visual Communication and Image Representation
FEI2017207,Memorable and rich video summarization,"Key frame, Video summary, Memorability, Entropy","Video summarization can facilitate rapid browsing and efficient video indexing in many applications. A good summary should maintain the semantic interestingness and diversity of the original video. While many previous methods extracted key frames based on low-level features, this study proposes Memorability-Entropy-based video summarization. The proposed method focuses on creating semantically interesting summaries based on image memorability. Further, image entropy is introduced to maintain the diversity of the summary. In the proposed framework, perceptual hashing-based mutual information (MI) is used for shot segmentation. Then, we use a large annotated image memorability dataset to fine-tune Hybrid-AlexNet. We predict the memorability score by using the fine-tuned deep network and calculate the entropy value of the images. The frame with the maximum memorability score and entropy value in each shot is selected to constitute the video summary. Finally, our method is evaluated on a benchmark dataset, which comes with five human-created summaries. When evaluating our method, we find it generates high-quality results, comparable to human-created summaries and conventional methods.",2017,Journal of Visual Communication and Image Representation
HAGAG201714,HyperCast: Hyperspectral satellite image broadcasting with band ordering optimization,"Hyperspectral satellite images, Image broadcasting, Karhunen-Loève Transform (KLT), Hyperspectral band ordering, SoftCast, LineCast, Wireless communications","This paper presents a novel framework for hyperspectral satellite image broadcasting over wireless channels. We present a new hyperspectral band ordering algorithm that improves the compression performance. The proposed scheme employs the 1D low-complexity Karhunen-Loève transform (KLT) that uses a clustering approach for spectral decorrelation. After that, the 2D DCT is applied to remove the redundant information from the spatial bands. The DCT components are quantized using a simple DC-quantization algorithm. After that, the transmission power is directly allocated to the quantized data according to their distributions and magnitudes without forward error correction (FEC). These data are transformed by Hadamard matrix and transmitted over a dense constellation. Experiments demonstrate that the proposed scheme improves the average image quality by 6.98dB and 3.48dB over LineCast and SoftCast, respectively, and it achieves up to 6.14dB gain over JPEG2000 with FEC.",2017,Journal of Visual Communication and Image Representation
XIE2017112,A primal-dual method with linear mapping for a saddle point problem in image deblurring,"Total variational image deblurring, Sub-differential operator, Prediction and correction, Pairwise primal-dual stepsize","In this paper, a simple primal-dual method named PDL is proposed for a convex concave saddle problem and applied to total variational image deblurring. Introduction of linear mapping on proximal term relaxes convergence requirement on pairwise primal-dual stepsize. Simple proof is presented for O(1/N) convergence rate in ergodic sense. Experiments show that performance of PDL is comparable with proximal PDHG (Zhu et al., 2010; Bonettini and Ruggiero, 2012) and PDCP (Chambolle and Pock, 2011) on Gaussian or Salt-Pepper noisy image deblurring.",2017,Journal of Visual Communication and Image Representation
FENG201737,Blind compressive sensing using block sparsity and nonlocal low-rank priors,"Blind compressive sensing, Nonlocal low-rank regularization, Nuclear norm, Alternating direction method of multipliers","Without knowing the sparsity basis, Blind Compressive Sensing (BCS) can achieve similar results with those Compressive Sensing (CS) methods which rely on prior knowledge of the sparsity basis. However, BCS still suffers from two problems. First, compared with block-based sparsity, the global image sparsity ignores the local image features and BCS approaches based on it cannot obtain the competitive results. Second, since BCS only exploits the weaker sparsity prior than CS, the sampling rate required by BCS is still very high in practice. In this paper, we firstly propose a novel blind compressive sensing method based on block sparsity and nonlocal low-rank priors (BCS-BSNLR) to further reduce the sampling rate. In addition, we take alternating direction method of multipliers to solve the resulting optimization problem. Experimental results have demonstrated that the proposed algorithm can significantly reduce the sampling rate without sacrificing the quality of the reconstructed image.",2017,Journal of Visual Communication and Image Representation
IULIANI201765,Reliability assessment of principal point estimates for forensic applications,"Image Forensics, Scene level analysis, Geometric constraints, Minimum Vanishing Angle, Cropping detection, Splicing detection","Although quite recent as a forensic research domain, computer vision analysis of scenes is likely to become more and more important in the near future, thanks to its robustness to image alterations at the signal level, such as image compression and filtering. However, the experimental assessment of vision-based forensic algorithms is a particularly critical task, since they cannot be tested on massive amounts of data, and their performance can heavily depend on user skill. In this paper we investigate on the accuracy and reliability of a vision-based, user-supervised method for the estimation of the camera principal point, to be used in cropping and splicing detection. Results of an extensive experimental evaluation show how the estimation accuracy depends on perspective conditions as well as on the selected image features. Such evidence led us to define a novel visual feature, referred to as Minimum Vanishing Angle, which can be used to assess the reliability of the method.",2017,Journal of Visual Communication and Image Representation
NIE2017183,Robust multi-view stereo synthesized by various parameters model,"Multi-view stereo, Variational method, Matrix splitting, Low-rank matrix, Accelerated proximal gradient","In this paper, we have developed a novel and robust framework of combining a matrix splitting with multi-view stereo reconstructions to separate reconstruction inaccuracies from a various parameters model for high-accuracy multi-view stereo reconstruction. Instead of performing the fixed parameters reconstruction procedure, we apply the variational based 3D reconstruction algorithm multi-times with various parameters to derive a set of hypothetic 3D models, and then synthesized the final result by formulating the problem as a low-rank matrix splitting problem. Benefited from the matrix splitting formulation, the outliers and bad matches, which are treated as the noise in the synthesized model, are effectively removed and thus lead to a 3D reconstruction with higher accuracy than the existing fixed parameters reconstructions. Constrained convex optimization is introduced for matrix splitting with an accelerated proximal gradient (APG) algorithm integrated for fast convergence. Both the experiments on the Middlebury and real-world data sets have demonstrated the effectiveness of the proposed method.",2017,Journal of Visual Communication and Image Representation
DOU2017104,Segment-based view synthesis optimization scheme in 3D-HEVC,"3D-HEVC, 3D video coding, Depth coding, View synthesis optimization (VSO), Synthesized view distortion change (SVDC), Early skip mode",The 3D extension of high efficiency video coding (3D-HEVC) adopts a view synthesis optimization (VSO) technique to improve the quality of synthesized views for depth map coding. The exact synthesized view distortion change (SVDC) is calculated in VSO which in turn brings huge coding complexity to the 3D-HEVC encoder due to the real view synthesis process. This work presents a scheme aimed at reducing coding complexity of the SVDC calculating process in the 3D-HEVC encoder. It skips line segments of pixels with variable lengths based on information from both of the textures and depth maps in the SVDC calculation. Experimental results demonstrate that the proposed scheme can reduce the coding complexity without any significant loss in rate distortion performance for the synthesized views.,2017,Journal of Visual Communication and Image Representation
JUNG2017132,Intensity-guided edge-preserving depth upsampling through weighted L0 gradient minimization,"Depth upsampling, Edge-preserving, Weighted L sparsity, Alternating minimization, Half-quadratic splitting","Depth is an important visual cue to perceive real-world scenes. Although a time-of-flight (ToF) depth camera can provide depth information in dynamic scenes, captured depth images are often noisy and of low resolution. In this paper, we propose an intensity-guided edge-preserving depth upsampling method through weighted L0 gradient minimization to enhance both resolution and visual quality of depth images. Guided by the high-resolution intensity image, we perform optimization to preserve boundaries of objects. We apply L0 gradient to the regularization term, and compute its weight from both intensity and depth images. We optimize the objective function using alternating minimization and half-quadratic splitting. Experimental results on Middlebury 2005, 2014, and real-world scene datasets demonstrate that the proposed method produces boundary-preserving depth upsampling results and outperforms state-of-the-art ones in terms of accuracy.",2017,Journal of Visual Communication and Image Representation
SRIVASTAVA201778,"Integration of wavelet transform, Local Binary Patterns and moments for content-based image retrieval","Image retrieval, Discrete wavelet transform, Local Binary Pattern, Legendre moments","The proliferation of large number of images has made it necessary to develop systems for indexing and organizing images for easy access. This has made Content-Based Image Retrieval (CBIR) an important area of research in Computer Vision. This paper proposes a combination of features in multiresolution analysis framework for image retrieval. In this work, the concept of multiresolution analysis has been exploited through the use of wavelet transform. This paper combines Local Binary Pattern (LBP) with Legendre Moments at multiple resolutions of wavelet decomposition of image. First, LBP codes of Discrete Wavelet Transform (DWT) coefficients of images are computed to extract texture feature from image. The Legendre Moments of these LBP codes are then computed to extract shape feature from texture feature for constructing feature vectors. These feature vectors are used to search and retrieve visually similar images from large database. The proposed method has been tested on five benchmark datasets, namely, Corel-1K, Olivia-2688, Corel-5K, Corel-10K, and GHIM-10K, and performance of the proposed method has been measured in terms of precision and recall. The experimental results demonstrate that the proposed method outperforms some of the other state-of-the-art methods in terms of precision and recall.",2017,Journal of Visual Communication and Image Representation
YANG2017121,New privilege-based visual cryptography with arbitrary privilege levels,"Visual cryptography, Visual secret sharing, Threshold scheme, Privilege level, Contrast","Recently, Hou et al. introduced a novel (2,n) privilege-based visual cryptography scheme (PVCS) with various privilege levels of shadow images. In this scheme, a shadow with a higher privilege contributes more recovered information, while a lower privileged shadow has the less recovery capability. Moreover, the visual quality of stacked result depends on the total sum of privilege levels for all involved shadows in reconstruction. Unfortunately, the PVC scheme has the inconsistency of the contrast of recovered image and the sum of privilege levels. Accordingly, an enhanced Hou et al.’s (2,n)-PVC scheme (EPVCS) is proposed to solve this inconsistency problem. However, the EPVCS is not a general solution to implement all PVCSs with arbitrary privilege levels, and it also has the unequal whiteness of shadows. In this paper, we first extend Hou et al.’s (2,n)-EPVCS with a correct privilege levels achieving the consistency of the contrast and the sum of privilege levels. Then we construct a (2,n)-PVCS to allow arbitrary privilege levels and provide the equal whiteness for each shadow.",2017,Journal of Visual Communication and Image Representation
SINGH2017173,"Satellite image classification using Genetic Algorithm trained radial basis function neural network, application to the detection of flooded areas","Radial basis function, Genetic Algorithm, Landsat 8, Classification, Change detection","In this paper, a semi supervised method for classification of satellite images based on Genetic Algorithm (GA) and Radial Basis Function Neural Network (RBFNN) is proposed. Satellite image classification problem has two major concerns to be addressed. The first issue is mixed pixel problem and the second issue is handling large amount of data present in these images. RBFNN function is an efficient network with a large set of tunable parameters. This network is able to generalize the results and is immune to noise. A RBFNN has learning ability and can appropriately react to unseen data. This makes the network a good choice for satellite images. The efficiency of RBFNN is greatly influenced by the learning algorithm and seed point selection. Therefore, in this paper spectral indices are used for seed selection and GA is used to train the network. The proposed method is used to classify the Landsat 8 OLI images of Dongting Lake in South China. The application of this method is shown for detection of flooded area over this region. The performance of the proposed method was analyzed and compared with three existing methods and the error matrix was computed to test the performance of the method. The method yields high producer’s accuracy, consumer’s accuracy and kappa coefficient value which indicated that the proposed classifier is highly effective and efficient.",2017,Journal of Visual Communication and Image Representation
ZHOU201746,Complexity-based intra frame rate control by jointing inter-frame correlation for high efficiency video coding,"HEVC, Complexity, Intra-frame, R-lambda model, Region-based, Quality smoothness","Rate control is of great significance for the High Efficiency Video Coding (HEVC). Due to the high efficiency and low complexity, the R-lambda model has been applied to the HEVC as the default rate control algorithm. However, the video content complexity, which can help improve the code efficiency and rate control performance, is not fully considered in the R-lambda model. To address this problem, an intra-frame rate control algorithm, which aims to provide improved and smooth video quality, is developed in this paper by jointly taking into consideration the frame-level content complexity between the encoded intra frames and the encoded inter frame, as well as the CTU-level complexity among different CTUs in texture–different regions for intra-frame. Firstly, in order to improve the rate control efficiency, this paper introduces a new prediction measure of content complexity for CTUs of intra-frame by jointly considering the inter-frame correlations between encoding intra frame and previous encoded inter frames as well as correlations between encoding intra frame and previous encoded intra frame. Secondly, a frame-level complexity-based bit-allocation-balancing method, by jointly considering the inter-frame correlation between intra frame and previous encoded inter frame, is brought up so that the smoothness of the visual quality can be improved between adjacent inter- and intra-frames. Thirdly, a new region-division and complexity-based CTU-level bit allocation method is developed to improve the objective quality and to reduce PSNR fluctuation among CTUs in intra-frame. Intheend, related model parameters are updated during the encoding process to increase rate control accuracy. As a result, as can be seen from the extensive experimental results that compared with the state-of-the-art schemes, the video quality can be significantly improved. More specifically, up to 10.5% and on average 5.2% BD-Rate reduction was achieved compared to HM16.0 and up to 2.7% and an average of 2.0% BD-Rate reduction was achieved compared tostate-of-the-art algorithm. Besides, a superior performance in enhancing the smoothness of quality can be achieved, which outperforms the state-of-the-art algorithms in term of flicker measurement, frame and CTU-wise PSNR, as well as buffer fullness.",2017,Journal of Visual Communication and Image Representation
HAMZAH2017145,"Stereo matching algorithm based on per pixel difference adjustment, iterative guided filter and graph segmentation","Iterative guided filter, Disparity map, Gradient difference, Absolute difference, Undirected graph segmentation, Stereo matching algorithm","Stereo matching process is a difficult and challenging task due to many uncontrollable factors that affect the results. These factors include the radiometric variations and illumination inconsistence. The absolute differences (AD) algorithms work fast, but they are too sensitive to noise and low textured areas. Therefore, this paper proposes an improved algorithm to overcome these limitations. First, the proposed algorithm utilizes per-pixel difference adjustment for AD and gradient matching to reduce the radiometric distortions. Then, both differences are combined with census transform to reduce the effect of illumination variations. Second, a new approach of iterative guided filter is introduced at cost aggregation to preserve and improve the object boundaries. The undirected graph segmentation is used at the last stage in order to smoothen the low textured areas. The experimental results on the standard indoor and outdoor datasets show that the proposed algorithm produces smooth disparity maps and accurate results.",2017,Journal of Visual Communication and Image Representation
ZHOU2018131,Video saliency detection via bagging-based prediction and spatiotemporal propagation,"Spatiotemporal saliency, Unconstrained video, Bagging, Prediction, Propagation","The task of spatiotemporal saliency detection is to distinguish the salient objects from background across all the frames in the video. Although many spatiotemporal models have been designed from various aspects, it is still a very challenging task for handing the unconstrained videos with complicated motions and complex scenes. Therefore, in this paper we propose a novel spatiotemporal saliency model to estimate salient objects in unconstrained videos. Specifically, a bagging-based saliency prediction model, i.e. an ensembling regressor, which is the combination of random forest regressors learned from undersampled training sets, is first used to perform saliency prediction for each current frame. Then, both forward and backward propagation within a local temporal window are deployed on each current frame to make a complement to the predicted saliency map and yield the temporal saliency map, in which the backward propagation is constructed based on the temporary saliency estimation of the following frames. Finally, by building the appearance and motion based graphs in a parallel way, spatial propagation is employed over the temporal saliency map to generate the final spatiotemporal saliency map. Through experiments on two challenging datasets, the proposed model consistently outperforms the state-of-the-art models for popping out salient objects in unconstrained videos.",2018,Journal of Visual Communication and Image Representation
SANAEE201840,A structural post-processing method for enhancing intensity restoration of low-density impulse-noise for decision based filters,"Impulse-noise, Image denoising, Image restoration, Decision based filters, Edge and detail preserving","Intensity restoration of pixels corrupted by impulse-noise contributes greatly to the quality of decision based filters (DBF). In this paper, we present an efficient structural post-processing method, which is based on directional-correlation, linear-regression-analysis, and inverse-distance-weighted-mean techniques. The proposed method is adopted as a complementary part after DBFs to enhance the quality of the final restored image. We assume that by adopting the preliminary DBF, noisy-pixels are detected by noise-detection unit and afterwards their intensities are estimated by the noise-restoration unit. In our method for each detected noisy-pixel, the intensity variation of adjacent pixels of restored image on different directions are analyzed in the corresponding local window and based on this structural information, the intensity of the previously-restored noisy-pixel is modified more accurately. Since the structures in images are more recognizable for low-density impulse-noise, our method is more effective in this case however a gradual improvement is achieved for high-density impulse-noise.",2018,Journal of Visual Communication and Image Representation
ANAYA2018144,RENOIR – A dataset for real low-light image noise reduction,"Image denoising, Denoising dataset, Low light noise, Poisson-Gaussian noise model","Image denoising algorithms are evaluated using images corrupted by artificial noise, which may lead to incorrect conclusions about their performances on real noise. In this paper we introduce a dataset of color images corrupted by natural noise due to low-light conditions, together with spatially and intensity-aligned low noise images of the same scenes. We also introduce a method for estimating the true noise level in our images, since even the low noise images contain small amounts of noise. We evaluate the accuracy of our noise estimation method on real and artificial noise, and investigate the Poisson-Gaussian noise model. Finally, we use our dataset to evaluate six denoising algorithms: Active Random Field, BM3D, Bilevel-MRF, Multi-Layer Perceptron, and two versions of NL-means. We show that while the Multi-Layer Perceptron, Bilevel-MRF, and NL-means with soft threshold outperform BM3D on gray images with synthetic noise, they lag behind on our dataset.",2018,Journal of Visual Communication and Image Representation
FANG201823,Design of linear-phase nonsubsampled nonuniform directional filter bank with arbitrary directional partitioning,"Nonsubsampled nonuniform directional filter banks, Arbitrary directional partitioning, Multiresolution decomposition","In this paper, we propose a design method for linear phase (LP) nonsubsampled nonuniform directional filter bank (NUDFB) with arbitrary number of subbands and arbitrary directional partitioning. The proposed NUDFB is simply designed by windowing the analytical expressions of wedge-shaped filters in space domain. The direction and angular bandwidth of the filters are determined by only two angular parameters. It can extract directional information according to the directional distribution of images, making it efficient in the directional representation of images. In addition, the perfect reconstruction conditions are derived. Numerical experiments on image directional information extraction and image denoising are given to illustrate the performance of our NUDFB. The results show that our NUDFB outperforms various directional decomposition methods while possesses LP property and more flexibility.",2018,Journal of Visual Communication and Image Representation
XIE201829,Stroke-based stylization by learning sequential drawing examples,"Stroke-based stylization, Reinforcement learning, Inverse reinforcement learning","Among various traditional art forms, brush stroke drawing is one of the widely used styles in modern computer graphic tools such as GIMP, Photoshop and Painter. In this paper, we develop an AI-aided art authoring (A4) system of non-photorealistic rendering that allows users to automatically generate brush stroke paintings in a specific artist’s style. Within the reinforcement learning framework of brush stroke generation proposed by Xie et al. (2012), the first contribution in this paper is the application of regularized policy gradient method, which is more suitable for the stroke generation task; the other contribution is to learn artists’ drawing styles from video-captured stroke data by inverse reinforcement learning. Through experiments, we demonstrate that our system can successfully learn artists’ styles and render pictures with consistent and smooth brush strokes.",2018,Journal of Visual Communication and Image Representation
YUN201814,HTTP adaptive streaming scheme for improving the quality of experience in multi-server environments,"HTTP adaptive streaming, Multi-server environment, Quality of experience","Many studies have been conducted on multi-server HTTP Adaptive Streaming (HAS). The existing schemes can highly utilize the available bandwidth by aggregating the multipath bandwidth and improve the video quality by switching servers when network congestion occurs. However, these existing schemes have problems that adversely affect the Quality of Experience (QoE) in a multi-server environment. To cope with these problems, we analyze the existing HAS schemes in multi-server environments. Through simulation-based performance analysis, we prove that these existing schemes lead to playback stalling and frequent quality changes. Based on the analysis, we propose a new HAS scheme for multi-server environments. The proposed scheme improves the QoE by alleviating the problems of the existing schemes. Through the simulation results, we prove that the proposed scheme alleviates the shortcomings of the existing schemes and improves QoE metrics compared with the existing multi-server schemes.",2018,Journal of Visual Communication and Image Representation
MANCHANDA201876,An improved multimodal medical image fusion algorithm based on fuzzy transform,"Multimodal medical image fusion, Fuzzy transform, Fusion performance measures","Multimodal medical image fusion has become a powerful tool in clinical applications. The main aim is to fuse different multimodal medical images, obtained from different imaging modalities, into a single fused image that is extensively used by the physicians for explicit diagnosis and treatment of diseases. In this paper, an improved multimodal medical image fusion algorithm based on fuzzy transform (FTR) is proposed. The core idea behind the proposed algorithm is to improve the performance of multimodal medical image fusion algorithm by taking into consideration the error images obtained using FTR pair. Subjective as well as objective evaluations demonstrate that the fusion quality in terms of edge strength, standard deviation, feature mutual information, fusion factor, feature similarity and structural similarity has significantly improved in the proposed algorithm as compared to other state-of-art multimodal medical image fusion algorithms.",2018,Journal of Visual Communication and Image Representation
CHEN2018112,Face sketch-photo synthesis and recognition: Dual-scale Markov Network and multi-information fusion,"Sketch face synthesis and recognition, Dual-scale Markov Network, Structural information, Feature information, Fusion","Sketch face recognition (SFR) has been widely and successfully applied in law enforcement, which attracts a growing number of researchers. In this paper, a face sketch-photo synthesis and recognition method is proposed. Our method has two parts: Firstly, according to the different synthesis results for different scales, a cascade sketch-photo synthesis method via dual-scale Markov Network is utilized for image synthesis; Secondly, structural information and feature information-based data fusion method has been presented for face recognition. It is inspired by the Face Recognition Cognitive Theory, which applies both structural information and feature information for recognition. The experimental results on different databases based on the proposed method, demonstrate the outperformance of our method compared with state-of-the-art methods both in synthesis and recognition processes.",2018,Journal of Visual Communication and Image Representation
WANG2018122,A lossy compression scheme for encrypted images exploiting Cauchy distribution and weighted rate distortion optimization,"Compression of encrypted signals, Statistical model, Rate-distortion optimization, Lifting wavelet","How to improve the compression efficiency of encrypted signals remains a challenging problem. To alleviate this problem, this paper develops a new compression scheme on encrypted gray images by exploiting the Cauchy distribution and the weighted rate-distortion optimization (wRDO). In the scheme, the low-frequency and wavelet subbands generated through lifting wavelet transform are encrypted by stream and permutation ciphers, respectively. They are then compressed in lossless and lossy ways, respectively. Inverse operations are finally conducted at the receiver to reconstruct the original image. The lossy compression is formulated as a problem of wRDO and further solved by incorporating the Cauchy distribution that is demonstrated via extensive simulations to well characterize statistical distributions of wavelet subbands. Experimental results show that the proposed scheme is significantly better than other permutation-based prior arts and achieves comparable or even better performance in comparison to the conventional JPEG algorithm with original unencrypted images as input.",2018,Journal of Visual Communication and Image Representation
TANG2018162,Median filtering detection of small-size image based on CNN,"Median filtering forensics, CNN, Nearest neighbor interpolation","Existing median filtering detection methods are no longer effective for small size or highly compressed images. To deal with this problem, a new median filtering detection method based on CNN is proposed in this paper. Specifically, a new network structure called MFNet is constructed. First, for preprocessing, the nearest neighbor interpolation method is utilized to up-sample the small-size images. The property of median filtering can be well preserved by the up-sampling operation and enlarged difference between the original image and its median filtered version can be obtained. Then, the well-known mlpconv structure is employed in the first and second layers of MFNet. With mlpconv layers, the nonlinear classification ability of the proposed method can be enhanced. After that, three conventional convolutional layers are utilized to finally derive the feature maps. The experimental results show that the proposed method achieves significant improved detection performance. Moreover, the proposed method performs well for highly compressed image of size as small as 16 × 16.",2018,Journal of Visual Communication and Image Representation
SALLOUM2018201,Image Splicing Localization using a Multi-task Fully Convolutional Network (MFCN),"Image splicing, Image forensics, Convolutional neural network (CNN), Fully convolutional network (FCN), Multi-task network","In this work, we propose a technique that utilizes a fully convolutional network (FCN) to localize image splicing attacks. We first evaluated a single-task FCN (SFCN) trained only on the surface label. Although the SFCN is shown to provide superior performance over existing methods, it still provides a coarse localization output in certain cases. Therefore, we propose the use of a multi-task FCN (MFCN) that utilizes two output branches for multi-task learning. One branch is used to learn the surface label, while the other branch is used to learn the edge or boundary of the spliced region. We trained the networks using the CASIA v2.0 dataset, and tested the trained models on the CASIA v1.0, Columbia Uncompressed, Carvalho, and the DARPA/NIST Nimble Challenge 2016 SCI datasets. Experiments show that the SFCN and MFCN outperform existing splicing localization algorithms, and that the MFCN can achieve finer localization than the SFCN.",2018,Journal of Visual Communication and Image Representation
ZHANG201856,Face spoofing detection based on color texture Markov feature and support vector machine recursive feature elimination,"Face anti-spoofing, Color texture Markov feature, Adjacent facial pixels discrepancy, SVM-RFE","Aiming to counterstrike face spoofing attacks such as photo attacks and video attacks, a face spoofing detection scheme based on color texture Markov feature (CTMF) and support vector machine recursive feature elimination (SVM-RFE) is proposed. In this paper, the adjacent facial pixels discrepancy between the real and the fake face is analyzed, and texture information between the color channels is fully considered. Firstly, the directional difference filter is used to capture the facial texture difference between the real and the fake face, which can be regarded as low-level features of CTMF. Then, the facial texture difference is modeled by the Markov process to form a high-level representation of the low-level features. Meanwhile, the mutual information of facial texture between the color channels, which is ignored in the previous literature, is investigated. In addition, SVM-RFE is utilized to reduce the feature dimension and makes it suitable for real-time detection. Experiments on four public benchmark databases indicate that the proposed scheme can effectively resist photo and video spoofing attacks in face recognition.",2018,Journal of Visual Communication and Image Representation
MARTINEZDIAZ2018155,On Fisher vector encoding of binary features for video face recognition,"Fisher vector, Binary features, Face recognition, Video","Several approaches have been proposed for face recognition in videos. Fisher vector (FV) encoding of local Scale-Invariant Feature Transforms (SIFT) is among the best performing ones. Aiming at speed up the computation time of this approach, a method based on FV encoding of binary features was recently introduced. By using Binary Robust Independent Elementary Features (BRIEF), this method gained in efficiency but lost in accuracy. FV representation of binary features demands appropriated mathematical tools, which are not as easy available as for continuous features. This paper introduces a new way for obtaining FV encoding of binary features that is still efficient and also accurate. We show that BRIEF combined with FV are discriminative enough, and provide as good performance as the one obtained by using SIFT features for video face recognition. Besides, we discuss several insights and promising lines of future work in regard to FV encoding of binary features.",2018,Journal of Visual Communication and Image Representation
HAN2018191,Infrared image super-resolution using auxiliary convolutional neural network and visible image under low-light conditions,"Near-infrared and visible images, Super-resolution, Convolutional neural networks, Low-light images","Convolutional neural networks (CNN) have been successfully applied to visible image super-resolution (SR) methods. In this study, we propose a CNN-based SR algorithm for up-scaling near-infrared (NIR) images under low-light conditions, using corresponding visible images. Our algorithm first extracts high-frequency (HF) components from the up-scaled low-resolution (LR) NIR image and its corresponding high-resolution (HR) visible image, and then takes them as multiple inputs of the CNN. Next, the CNN outputs the HR HF component of the input NIR image. Finally, an HR NIR image is synthesized by adding the HR HF component to the up-scaled LR NIR image. The simulation results show that the proposed algorithm outperforms the state-of-the-art methods, in terms of both qualitative and quantitative aspects.",2018,Journal of Visual Communication and Image Representation
FAN201870,Early event detection based on dynamic images of surveillance videos,"Early detection, Event detection, Dynamic image, Deep ConvNet","Early event detection is intended to flag an event as early as possible, but before it terminates. It is critical for detecting on-going events in many applications such as spotting dangerous or criminal incidents. In this letter, we address this issue by converting video clips of a proceeding event into so-called dynamic images, which are capable of simultaneously capturing both the appearance and temporal evolution of the occurrence. By using the dynamic images of two categories of video clips (complete target event as the positive set and random segments that do not contain the target event as the negative set), we propose a novel method for training a detector based on deep learning techniques. The approach is capable of scoring partial events by monitoring the degree of event completion as it monotonically increases toward termination. In particular, we discuss experiments on the detection of humans falling and the breakout of a fighting. Experiments on several datasets illustrate the effectiveness of the proposed method.",2018,Journal of Visual Communication and Image Representation
TARIQ20181,Adaptive stopping strategies for fast intra mode decision in HEVC,"Early mode decision, HEVC, Intra mode, RMD, RDOQ, Sum of absolute difference, Video coding, Video coding","Fast intra mode decision strategies are proposed to overcome the brute force mode decision for the coding unit (CU) in High Efficiency Video Coding (HEVC). The proposed work improves the rough-mode-decision (RMD) by initializing the candidate intra mode list using the fusion of the Hadamard-cost and the statistical-inference formed using spatial/ temporal correlations. Then an early termination is predicted using optimal stopping theory that addresses early decision for a generic class of decision problems. Subsequently, a novel RD-cost prediction model is developed for early termination that is based on the RD-cost variation in the neighboring CUs with-respect-to their co-located CUs. Experimental results demonstrate that the RMD module of HEVC and the state-of-the-art fast intra mode prediction published method are outperformed by saving up to 0.61% and 0.91% Bjøntegaard delta bit rate (BDBR) on average, respectively.",2018,Journal of Visual Communication and Image Representation
SAHA201895,A novel method for automated correction of non-uniform/poor illumination of retinal images without creating false artifacts,"Color fundus image, Color correction, Illumination correction, Automated analysis of retinal image","Retinal images are frequently corrupted by unwanted variations in the brightness that occur due to over-all imperfections in the image acquisition process. This inhomogeneous illumination across the retina can limit the pathological information that can be gained from the image; and can lead to serious difficulties when performing image processing tasks that requires qualitative as well as quantitative analysis of feature presence on the image. On that perspective we have proposed a novel two-step approach for non-uniform and/or poor illumination correction in the context of retinal imaging. A subjective experiment was conducted to ensure that the proposed method did not create visually noticeable false color or artifacts on the images, especially on the areas that did not suffer non-uniform/poor illumination prior to correction. An objective experiment on 25,872 retinal images was performed to justify the significance of the proposed method for automated pathology detection/classification.",2018,Journal of Visual Communication and Image Representation
KUAI2018104,Learning adaptively windowed correlation filters for robust tracking,"Correlation filter, Target likelihood, Window adaptation","Visual tracking is a fundamental component for high-level video understanding problems such as motion analysis, event detection and action recognition. Recently, Discriminative Correlation Filters (DCF) have achieved enormous popularity in the tracking community due to high computational efficiency and fair robustness. However, the underlying boundary effect of DCF leads to a very restricted target search region at the detection step. Generally, a larger search area is adopted to overcome this disadvantage. Such an expansion of search area usually includes substantial amount of background information which will contaminate the tracking model in realist tracking scenarios. To alleviate this major drawback, we propose a generic DCF tracking framework which suppresses background information and highlights the foreground object with an object likelihood map computed from the color histograms. This object likelihood map is merged with the cosine window and then integrated into the DCF formulation. Therefore, DCF are less burdened in the training step by focusing more on pixels with higher object likelihood probability. Extensive experiments on the OTB50 and OTB100 benchmarks demonstrate that our adaptively windowed tracking framework can be combined with many DCF trackers and achieves significant performance improvement.",2018,Journal of Visual Communication and Image Representation
MEDITSKOS2018169,"Multi-modal activity recognition from egocentric vision, semantic enrichment and lifelogging applications for the care of dementia","Instrumental activity recognition, Egocentric camera, Mechanical measurements, Visual cues, Ontologies, Semantic knowledge graphs","We describe a framework for lifelogging monitoring in the scope of dementia care, based on activity recognition from egocentric vision and semantic context-enrichment. As pure vision-based approaches appear to be already saturating in terms of recognition accuracy, we propose their enhancement with wearable bracelet accelerometer information. For that purpose, we design and study appropriate early and late fusion schemes to increase accuracy. The incorporation of mechanical variables, such as jerk, improves the recognition accuracy of activities that require fine motion. In addition, we describe a framework for semantic activity representation and interpretation, using Semantic Web technologies for building interoperable activity graphs. The system is personalized, as deployment-specific activity models are authored, while problems related to the disease are detected by rules. Complemented by lifelogging applications, the system is able to support interventions by clinicians, and endorse a feeling of safety and inclusion for end-users and their carers.",2018,Journal of Visual Communication and Image Representation
COMINO201743,Error-aware construction and rendering of multi-scan panoramas from massive point clouds,"3D reconstruction, Range data, Massive point clouds, Error-aware reconstruction, Compression, Panoramas, Interactive inspection","Obtaining 3D realistic models of urban scenes from accurate range data is nowadays an important research topic, with applications in a variety of fields ranging from Cultural Heritage and digital 3D archiving to monitoring of public works. Processing massive point clouds acquired from laser scanners involves a number of challenges, from data management to noise removal, model compression and interactive visualization and inspection. In this paper, we present a new methodology for the reconstruction of 3D scenes from massive point clouds coming from range lidar sensors. Our proposal includes a panorama-based compact reconstruction where colors and normals are estimated robustly through an error-aware algorithm that takes into account the variance of expected errors in depth measurements. Our representation supports efficient, GPU-based visualization with advanced lighting effects. We discuss the proposed algorithms in a practical application on urban and historical preservation, described by a massive point cloud of 3.5 billion points. We show that we can achieve compression rates higher than 97% with good visual quality during interactive inspections.",2017,Computer Vision and Image Understanding
CHEN2017179,Efficient tree-structured SfM by RANSAC generalized Procrustes analysis,Structure-from-motion,"This paper proposes a tree-structured structure-from-motion (SfM) method that recovers 3D scene structures and estimates camera poses from unordered image sets. Starting from atomic structures spanning the scene, we build well-connected structure groups, and propose RANSAC generalized Procrustes analysis (RGPA) to glue structures in the same group. The grouping-aligning operations hierarchically proceed until the full scene is reconstructed. Our work is the first attempt of using GPA for modern 3D reconstruction tasks. RGPA is able to merge multiple structures at a time and automatically identify outliers. The reconstruction tree is much more compact and balanced than previous hierarchical SfM methods and has a very shallow depth. These advantages, along with the resulting removal of intermediate bundle adjustments, lead to significantly improved computational efficiency over state-of-the-art SfM methods. The cameras and 3D scene can be robustly recovered in the presence of moderate noise. We verify the efficacy of our method on a variety of datasets, and demonstrate that our method is able to produce metric reconstructions efficiently and robustly.",2017,Computer Vision and Image Understanding
BHOWMICK2017190,Divide and conquer: A hierarchical approach to large-scale structure-from-motion,"Structure-from-motion, Divide and conquer, Motion averaging, Global bundle adjustment, Multi-view stereo, Epipolar registration","In this paper we present a novel pipeline for large-scale SfM. We first organise the images into a hierarchical tree built using agglomerative clustering. The SfM problem is then solved by reconstructing smaller image sets and merging them into a common frame of reference as we move up the tree in a bottom-up fashion. Such an approach drastically reduces the computational load for matching image pairs without sacrificing accuracy. It also makes the resulting sequence of bundle adjustment problems well-conditioned at all stages of reconstruction. We use motion averaging followed by global bundle adjustment for reconstruction of each individual cluster. Our 3D registration or alignment of partial reconstructions based on epipolar relationships is both robust and reliable and works well even when the available camera-point relationships are poorly conditioned. The overall result is a robust, accurate and efficient pipeline for large-scale SfM. We present extensive results that demonstrate these attributes of our pipeline on a number of large-scale, real-world datasets and compare with the state-of-the-art.",2017,Computer Vision and Image Understanding
HADFIELD2017206,Stereo reconstruction using top-down cues,"Stereo reconstruction, Scene understanding, Biologically inspired, High level cues, Bottom up, Top down","We present a framework which allows standard stereo reconstruction to be unified with a wide range of classic top-down cues from urban scene understanding. The resulting algorithm is analogous to the human visual system where conflicting interpretations of the scene due to ambiguous data can be resolved based on a higher level understanding of urban environments. The cues which are reformulated within the framework include: recognising common arrangements of surface normals and semantic edges (e.g. concave, convex and occlusion boundaries), recognising connected or coplanar structures such as walls, and recognising collinear edges (which are common on repetitive structures such as windows). Recognition of these common configurations has only recently become feasible, thanks to the emergence of large-scale reconstruction datasets. To demonstrate the importance and generality of scene understanding during stereo-reconstruction, the proposed approach is integrated with 3 different state-of-the-art techniques for bottom-up stereo reconstruction. The use of high-level cues is shown to improve performance by up to 15% on the Middlebury 2014 and KITTI datasets. We further evaluate the technique using the recently proposed HCI stereo metrics, finding significant improvements in the quality of depth discontinuities, planar surfaces and thin structures.",2017,Computer Vision and Image Understanding
BRITO2017240,Autocalibration for Structure from Motion,"Structure from Motion (SfM), Calibration, Focal length, Radial distortion, Radial fundamental matrix","This paper is about the estimation of calibration parameters of images to be used in Structure from Motion (SfM) pipelines and 3D reconstruction from image feature correspondences. It addresses the estimation of calibration parameters when they are not available, so that additional images may be included in the 3D reconstruction and so that the initial model may be closer to the true geometry of the scene. The approach is to take advantage of known calibration information of some of the images, to estimate calibration information of uncalibrated views, calibration information is therefore extended to images where visual features of the same objects are detected. The approach is based on the standard fundamental matrix, and extended versions of the fundamental matrix that embed the radial distortion model, named radial fundamental matrices. It is shown that the distortion model may be extracted from radial fundamental matrices, along with the standard fundamental matrix, and that the focal length may be subsequently estimated from it. By integrating a few of methods, the number of images that can be used in a large scale 3D reconstruction may be augmented and a better geometric model may be reconstructed. With this approach, the initial values of the parameters and the reconstructed geometry are close to the true solution, so that an optimization step may converge without getting stuck in local minima.",2017,Computer Vision and Image Understanding
KOBYSHEV2017300,Efficient architectural structural element decomposition,"3D city model, Architecture, Structure, Element, Landmark, Decomposition, Optimization","Decomposing 3D building models into architectural elements is an essential step in understanding their 3D structure. Although we focus on landmark buildings, our approach generalizes to arbitrary 3D objects. We formulate the decomposition as a multi-label optimization that identifies individual elements of a landmark. This allows our system to cope with noisy, incomplete, outlier-contaminated 3D point clouds. We detect four types of structural cues, namely dominant mirror symmetries, rotational symmetries, shape primitives, and polylines capturing free-form shapes of the landmark not explained by symmetry. Our novel method combine these cues enables modeling the variability present in complex 3D models, and robustly decomposing them into architectural structural elements. Our proposed architectural decomposition facilitates significant 3D model compression and shape-specific modeling.",2017,Computer Vision and Image Understanding
BODISSZOMORU20173,Efficient edge-aware surface mesh reconstruction for urban scenes,"3D city model, Surface reconstruction, Meshing, Mesh simplification, Superpixel segmentation, Piecewise-planar, Digital Surface Model (DSM), Structure-from-Motion(SfM), Sparse point cloud","We propose an efficient approach for building compact, edge-preserving, view-centric triangle meshes from either dense or sparse depth data, with a focus on modeling architecture in large-scale urban scenes. Our method constructs a 2D base mesh from a preliminary view partitioning, then lifts the base mesh into 3D in a fast vertex depth optimization. Different view partitioning schemes are proposed for imagery and dense depth maps. They guarantee that mesh edges are aligned with crease edges and discontinuities. In particular, we introduce an effective plane merging procedure with a global error guarantee in order to maximally compact the resulting models. Moreover, different strategies for detecting and handling discontinuities are presented. We demonstrate that our approach provides an excellent trade-off between quality and compactness, and is eligible for fast production of polyhedral building models from large-scale urban height maps, as well as, for direct meshing of sparse street-side Structure-from-Motion (SfM) data.",2017,Computer Vision and Image Understanding
KURAZUME201725,Automatic large-scale three dimensional modeling using cooperative multiple robots,"Laser measurement, Multiple robots, 3D modeling, Automatic sensing planning","3D modeling of real objects by a 3D laser scanner has become popular in many applications, such as reverse engineering of petrochemical plants, civil engineering and construction, and digital preservation of cultural properties. Despite the development of lightweight and high-speed laser scanners, the complicated measurement procedure and long measurement time are still heavy burdens for widespread use of laser scanning. To solve these problems, a robotic 3D scanning system using multiple robots has been proposed. This system, named CPS-SLAM, consists of a parent robot with a 3D laser scanner and child robots with target markers. A large-scale 3D model is acquired by an on-board 3D laser scanner on the parent robot from several positions determined precisely by a localization technique, named the Cooperative Positioning System (CPS), that uses multiple robots. Therefore, this system can build a 3D model without complicated post-processing procedures such as ICP. In addition, this system is an open-loop SLAM system and a very precise 3D model can be obtained without closed loops. This paper proposes an automatic planning technique for a laser measurement by using CPS-SLAM. Planning a proper scanning strategy depending on a target structure makes it possible to perform laser scanning efficiently and accurately even for a large-scale and complex environment. The proposed technique plans an efficient scanning strategy automatically by taking account of several criteria, such as visibility between robots, error accumulation, and efficient traveling. We conducted computer simulations and outdoor experiments to verify the performance of the proposed technique.",2017,Computer Vision and Image Understanding
RUMPLER2017255,Evaluations on multi-scale camera networks for precise and geo-accurate reconstructions from aerial and terrestrial images with user guidance,"Photogrammetric computer vision, Unmanned aerial vehicles, Image-based 3D reconstruction, Mapping, Camera calibration, Image acquisition, Online feedback, Structure-from-motion, Georeferencing, Fiducial markers, Accuracy evaluation","During the last decades photogrammetric computer vision systems have been well established in scientific and commercial applications. Recent developments in image-based 3D reconstruction systems have resulted in an easy way of creating realistic, visually appealing and accurate 3D models. We present a fully automated processing pipeline for metric and geo-accurate 3D reconstructions of complex geometries supported by an online feedback method for user guidance during image acquisition. Our approach is suited for seamlessly matching and integrating images with different scales, from different view points (aerial and terrestrial), and with different cameras into one single reconstruction. We evaluate our approach based on different datasets for applications in mining, archaeology and urban environments and thus demonstrate the flexibility and high accuracy of our approach. Our evaluation includes accuracy related analyses investigating camera self-calibration, georegistration and camera network configuration.",2017,Computer Vision and Image Understanding
ALLETTO2017274,Video registration in egocentric vision under day and night illumination changes,"Video registration, Egocentric vision, Visual matching","With the spread of wearable devices and head mounted cameras, a wide range of application requiring precise user localization is now possible. In this paper we propose to treat the problem of obtaining the user position with respect to a known environment as a video registration problem. Video registration, i.e. the task of aligning an input video sequence to a pre-built 3D model, relies on a matching process of local keypoints extracted on the query sequence to a 3D point cloud. The overall registration performance is strictly tied to the actual quality of this 2D-3D matching, and can degrade if environmental conditions such as steep changes in lighting like the ones between day and night occur. To effectively register an egocentric video sequence under these conditions, we propose to tackle the source of the problem: the matching process. To overcome the shortcomings of standard matching techniques, we introduce a novel embedding space that allows us to obtain robust matches by jointly taking into account local descriptors, their spatial arrangement and their temporal robustness. The proposal is evaluated using unconstrained egocentric video sequences both in terms of matching quality and resulting registration performance using different 3D models of historical landmarks. The results show that the proposed method can outperform state of the art registration algorithms, in particular when dealing with the challenges of night and day sequences.",2017,Computer Vision and Image Understanding
KIM2017223,Indoor Manhattan spatial layout recovery from monocular videos via line matching,"3D reconstruction, Indoor spatial layout recovery, Structure from motion, Line matching, Manhattan world, Reconstruction from video","We present an end-to-end system for structure and motion computation in a Manhattan layout from monocular videos. Unlike most SFM algorithms that rely on point feature matching, only line matches are considered in this work. This may be convenient in indoor environment characterized by extended textureless walls, where point features may be scarce. Our system relies on the notion of “characteristic lines”, which are invariants of two views of the same parallel line pairs on a surface of known orientation. Experiments with indoor video sequences demonstrate the robustness of the proposed system.",2017,Computer Vision and Image Understanding
ALNUAIMI201772,6DOF decoupled roto-translation alignment of large-scale indoor point clouds,"Point cloud alignment, 3D registration, Point set registration","We address the problem of 6DOF alignment of large-scale point clouds of indoor spaces such that extensive 3D models can be assembled out of multiple point clouds. We present an algorithm that it is fast, insensitive to initial alignment and tolerates very low overlap. The algorithm is designed to exploit inherent characteristics of indoor spaces. It loosens the tight coupling between translation and rotation estimation such that these can be performed in consecutive steps with estimation problems of reduced complexity which can be reliably solved using strong features characteristic to indoor spaces. First, the point clouds are rotationally aligned to gravity using PCA. Then, the translation along gravity is computed through floor matching. Subsequently, the ground-plane rotation is determined by cross-correlating histogram signatures of surface normal directions. Finally, the ground-plane translation is determined by seeking the location where the bi-variate shift histogram of point pairs with high curvature values (called CPSHs) peaks. This voting-like approach avoids establishing correspondences through computationally demanding feature extraction and matching processes. To support very low overlap cases, the CPSH-based alignment is furthermore cast into a probabilistic framework that involves computing the CPSHs on segments of the point clouds and finally fused using an ML estimator. The results show that the proposed approach succeeds in the alignment of datasets for which general-purpose algorithms fail while being at least as efficient as the fastest methods previously proposed.",2017,Computer Vision and Image Understanding
SCHOPS2017151,Large-scale outdoor 3D reconstruction on a mobile device,"Dense 3D reconstruction, Mobile 3D reconstruction, Video-based stereo, Plane sweep stereo","This paper presents an approach for reconstructing large-scale outdoor scenes through monocular motion stereo at interactive frame rates on a modern mobile device (Google Project Tango Development Kit Tablet). The device’s fisheye camera enables a user to reconstruct large scenes in only a few minutes by simply walking through the scene. We utilize the device’s GPU to compute depth maps via plane sweep stereo. In contrast to reconstructing small objects, we observe that in large-scale scenarios using motion stereo, free-space measurements are less effective for suppressing outliers due to limited possibilities for camera placement and an unbounded reconstruction volume. Furthermore, the outlier ratio in depth maps from stereo matching is much higher compared to images from depth sensors. Consequently, we propose a set of filtering steps to detect and discard unreliable depth measurements. The remaining parts of the depth maps are then integrated into a volumetric representation of the scene using a truncated signed distance function. Ours is the first method to enable live reconstruction of large outdoor scenes on a mobile device. We extensively evaluate our approach, demonstrating the benefit of rigorously filtering depth maps.",2017,Computer Vision and Image Understanding
THOMAS2017103,Modeling large-scale indoor scenes with rigid fragments using RGB-D cameras,"3D Modeling, RGB-D Camera, Large-scale, Real-time, Loop closure, Bump image, Semi-global model","Hand-held consumer depth cameras have become a commodity tool for constructing 3D models of indoor environments in real time. Recently, many methods to fuse low quality depth images into a single dense and high fidelity 3D model have been proposed. Nonetheless, dealing with large-scale scenes remains a challenging problem. In particular, the accumulation of small errors due to imperfect camera localization becomes crucial (at large scale) and results in dramatic deformations of the built 3D model. These deformations have to be corrected whenever it is possible (when a loop exists for example). To facilitate such correction, we use a structured 3D representation where points are clustered into several planar patches that compose the scene. We then propose a two-stage framework to build in details and in real-time a large-scale 3D model. The first stage (the local mapping) generates local structured 3D models with rigidity constraints from short subsequences of RGB-D images. The second stage (the global mapping) aggregates all local 3D models into a single global model in a geometrically consistent manner. Minimizing deformations of the global model reduces to re-positioning the planar patches of the local models thanks to our structured 3D representation. This allows efficient, yet accurate computations. Our experiments using real data confirm the effectiveness of our proposed method.",2017,Computer Vision and Image Understanding
BROWN2017117,A generalised framework for saliency-based point feature detection,"Point detection, Feature detection, Feature matching, 2D-3D registration, Saliency","Here we present a novel, histogram-based salient point feature detector that may naturally be applied to both images and 3D data. Existing point feature detectors are often modality specific, with 2D and 3D feature detectors typically constructed in separate ways. As such, their applicability in a 2D-3D context is very limited, particularly where the 3D data is obtained by a LiDAR scanner. By contrast, our histogram-based approach is highly generalisable and as such, may be meaningfully applied between 2D and 3D data. Using the generalised approach, we propose salient point detectors for images, and both untextured and textured 3D data. The approach naturally allows for the detection of salient 3D points based jointly on both the geometry and texture of the scene, allowing for broader applicability. The repeatability of the feature detectors is evaluated using a range of datasets including image and LiDAR input from indoor and outdoor scenes. Experimental results demonstrate a significant improvement in terms of 2D-2D and 2D-3D repeatability compared to existing multi-modal feature detectors.",2017,Computer Vision and Image Understanding
HOFER2017167,Efficient 3D scene abstraction using line segments,"Structure-from-Motion, 3D reconstruction, Line segments, Scene abstraction, Multi-view Stereo","Extracting 3D information from a moving camera is traditionally based on interest point detection and matching. This is especially challenging in urban indoor- and outdoor environments, where the number of distinctive interest points is naturally limited. While common Structure-from-Motion (SfM) approaches usually manage to obtain the correct camera poses, the number of accurate 3D points is very small due to the low number of matchable features. Subsequent Multi-view Stereo approaches may help to overcome this problem, but suffer from a high computational complexity. We propose a novel approach for the task of 3D scene abstraction, which uses straight line segments as underlying features. We use purely geometric constraints to match 2D line segments from different images, and formulate the reconstruction procedure as a graph-clustering problem. We show that our method generates accurate 3D models with low computational costs, which makes it especially useful for large-scale urban datasets.",2017,Computer Vision and Image Understanding
GUISLAIN201790,Fine scale image registration in large-scale urban LIDAR point sets,"Large scale point sets, Image to geometry registration, Image comparison metric","Urban scenes acquisition is very often performed using laser scanners onboard a vehicle. In parallel, color information is also acquired through a set of coarsely aligned camera pictures. The question of combining both measures naturally arises for adding color to the 3D points or enhancing the geometry, but it faces important challenges. Indeed, 3D geometry acquisition is highly accurate while the images suffer from distortion and are only coarsely registered to the geometry. In this paper, we introduce a two-step method to register images to large-scale complex point clouds. Our method performs the image-to-geometry registration by iteratively registering the real image to a synthetic image obtained from the estimated camera pose and the point cloud, using either reflectance or normal information. First a coarse registration is performed by generating a wide-angle synthetic image and considering that small pitch and yaw rotations can be estimated as translations in the image plane. Then a fine registration is performed using a new image metric which is adapted to the difference of modality between the real and synthetic images. This new image metric is more resilient to missing data and large transformations than standard Mutual Information. In the process, we also introduce a method to generate synthetic images from a 3D point cloud that is adapted to large-scale urban scenes with occlusions and sparse areas. The efficiency of our algorithm is demonstrated both qualitatively and quantitatively on datasets of urban scans and associated images.",2017,Computer Vision and Image Understanding
TATENO2017138,Large scale and long standing simultaneous reconstruction and segmentation,"Dense SLAM, Segmentation, Real-time, Scalable, Long standing, Relocalization, Loop-closure","This work proposes a method to segment a 3D point cloud of a scene while simultaneously reconstructing it via Simultaneous Localization And Mapping (SLAM). The proposed method incrementally merges segments obtained from each input depth image in an unified global model leveraging the camera pose estimated via SLAM. Differently from other approaches, our method is able to yield segmentation of scenes reconstructed from multiple views in real-time and with a complexity that does not depend on the size of the global model. Moreover, we endow our system with two additional contributions: a loop closure approach and a failure recovery and re-localization approach, both specifically designed so to enforce global consistency between merged segments, thus making our system suitable for large scale and long standing reconstruction and segmentation. We validate our proposal against the state of the art in terms of computational efficiency and accuracy on several benchmark datasets, as well as by showing how our method enables real-time reconstruction and segmentation of diverse real indoor environments.",2017,Computer Vision and Image Understanding
LITANY2017284,ASIST: Automatic semantically invariant scene transformation,"Semantic segmentation, Object recognition, Random forest, Iterative closest point, Alternating minimization, Pose estimation, Registration","We present ASIST, a technique for transforming point clouds by replacing objects with their semantically equivalent counterparts. Transformations of this kind have applications in virtual reality, repair of fused scans, and robotics. ASIST is based on a unified formulation of semantic labeling and object replacement; both result from minimizing a single objective. We present numerical tools for the efficient solution of this optimization problem. The method is experimentally assessed on new datasets of both synthetic and real point clouds, and is additionally compared to two recent works on object replacement on data from the corresponding papers.",2017,Computer Vision and Image Understanding
SAKURADA201755,Temporal city modeling using street level imagery,"Change detection, SfM, CNN, City-scale, Vehicular imagery, City map","Estimation of the temporal changes to a city is useful for city management, disaster recovery operations, and understanding natural phenomena. When several types of data are available for this task, the optimal type should be chosen depending on the changes that need to be detected. However, data of the desired type are not always available, particularly historical data. In this study, we propose two methods for detecting changes in a city, which can be used in complement to process available data types and detect changes in selected targets. The first method estimates the presence of buildings by comparing street-level images and a 2D city map of buildings created at different points in time. This method uses the Structure from Motion (SfM) technique to reconstruct a point cloud of the structures of the city, and matches the point cloud with the 3D building structures recovered from its 2D map. While 2D city maps are available for most cities, most are not very accurate. Therefore, this method is designed to overcome these inaccuracies and thus is widely applicable. On the other hand, the method cannot detect the following types of scene change: wall paintings, buildings that were reconstructed and closely restored to their previous shape, pedestrians, cars, and vegetation. The second method uses a pair of street-level images that are roughly aligned with GPS data collected at different points in time to detect such scene changes. This method uses the features of a convolutional neural network (CNN) in combination with superpixel segmentation to address inaccurate image alignment and it also enables change detection with pixel-level accuracy. Additionally, the second method is scalable for large-scale estimation because it can quickly detect scene changes by merely using an image pair without performing large-scale SfM. The authors consider the proper use of these two methods to enable temporal city modeling in various situations. We experimentally apply these methods to cities damaged by the tsunami that struck Japan in 2011 and the results show their effectiveness.",2017,Computer Vision and Image Understanding
TEKLI2018133,Full-fledged semantic indexing and querying model designed for seamless integration in legacy RDBMS,"Semantic queries, Inverted index, NoSQL indexing, Semantic network, Semantic-aware data processing, Textual databases","In the past decade, there has been an increasing need for semantic-aware data search and indexing in textual (structured and NoSQL) databases, as full-text search systems became available to non-experts where users have no knowledge about the data being searched and often formulate query keywords which are different from those used by the authors in indexing relevant documents, thus producing noisy and sometimes irrelevant results. In this paper, we address the problem of semantic-aware querying and provide a general framework for modeling and processing semantic-based keyword queries in textual databases, i.e., considering the lexical and semantic similarities/disparities when matching user query and data index terms. To do so, we design and construct a semantic-aware inverted index structure called SemIndex, extending the standard inverted index by constructing a tightly coupled inverted index graph that combines two main resources: a semantic network and a standard inverted index on a collection of textual data. We then provide a general keyword query model with specially tailored query processing algorithms built on top of SemIndex, in order to produce semantic-aware results, allowing the user to choose the results' semantic coverage and expressiveness based on her needs. To investigate the practicality and effectiveness of SemIndex, we discuss its physical design within a standard commercial RDBMS allowing to create, store, and query its graph structure, thus enabling the system to easily scale up and handle large volumes of data. We have conducted a battery of experiments to test the performance of SemIndex, evaluating its construction time, storage size, query processing time, and result quality, in comparison with legacy inverted index. Results highlight both the effectiveness and scalability of our approach.",2018,Data & Knowledge Engineering
XIE201887,Uncertain data classification with additive kernel support vector machine,"Uncertain data, Additive kernel, Support vector machines, Classification","In this work, a classification learning algorithm is designed within the framework of support vector machines through modeling uncertain data with additive kernels, which are introduced to calculate the similarity between uncertain samples characterized by probability density functions (PDFs). The PDFs are used as features of the uncertain samples, where the value of a feature is not a single value, but a set of values that represent the probability distribution of the noise. This is different with the existing methods which represent an uncertain sample by a set of new samples around it, but use the farthest or nearest value in the distribution to construct the optimal hyperplane. With the properties of kernel functions, we can easily extend additive kernels to compute the similarity between samples described with multiple uncertain features. Furthermore, we introduce an efficient algorithm to compute the kernel functions, and solve the additive kernel SVMs. The experimental results show the efficiency of additive-kernel SVMs in uncertain data classification.",2018,Data & Knowledge Engineering
SAINTDIZIER2018290,Mining incoherent requirements in technical specifications: Analysis and implementation,"Requirement engineering, Linguistics of requirements, Incoherence analysis, Natural language processing","Requirements are designed to specify the features of systems. Even for a simple system, several thousands of requirements produced by different authors are needed. Overlap and incoherence problems are frequently observed. In this article, we propose a method to construct a corpus of various types of incoherences and a categorization that leads to the definition of patterns to mine incoherent requirements. We focus in this contribution on incoherences (1) which can be detected solely from linguistic factors and (2) which concern pairs of requirements. Together, these represent about 60% of the different types of incoherences; the other types require extensive domain knowledge and reasoning. The second part of this article develops several language-based patterns to detect incoherent requirements in texts. An indicative evaluation of the results concludes this contribution. More generally, this contribution opens new perspectives on incoherence analysis in texts.",2018,Data & Knowledge Engineering
HASHEM2018216,Comparative study of different binarization methods through their effects in characters localization in scene images,"Binarization methods, Characters localization, Naïve Bayes classifier, Connected-components analysis","In this paper, we focus on the binarization methods as a core step in most image processing algorithms especially localization of the characters in scene images. We have developed in this paper our previous scheme which based on shape properties and geometric features to define text region and adopt our binarization scheme which based on Naïve Bayes classifier to convert grayscale image to binary image. Then we compare this binarization scheme with four famous different methods and explore their effects on detection characters in scene images. We found that our method outperforms the other four prior methods in detection characters with respect to Recall metric and the Otsu method follow our methods.",2018,Data & Knowledge Engineering
PADMAJA2018174,Evaluating the influence of parameter values on the performance of random subset feature selection algorithm on scientific data,"RSFS, Optimization, Regression modeling, Scientific data","Random Subset Feature Selection (RSFS) is Feature Subset Selection (FSS) algorithm based on the random forest technique. This algorithm is useful for selecting relevant features from large datasets resulting from scientific experiments. The random selection process eliminates bias and offers superior performance compared to other feature selection algorithms. The performance of the RSFS algorithm, which is primarily used in data mining, depends on proper parameter selection. The RSFS algorithm parameters dummy features, stopping criteria (Delta), maximum number of iterations, and K nearest neighbor distance are used for selecting the feature subset. The resulting subset, which is a reduced dataset is subjected to further processing such as classification and, detection. This study, is based on the design of experiments approach and model the effects of parameter variation on the RSFS algorithm performance. In this study, the influence of algorithm parameters on classification accuracy is evaluated.",2018,Data & Knowledge Engineering
LIU20181,Log sequence clustering for workflow mining in multi-workflow systems,"Workflow mining, Sequence clustering, User behavior pattern, Probabilistic suffix tree, Non-negative matrix factorization","Current workflow mining efforts aim to discover process knowledge from user-system interaction logs and represent it as high-level workflow models. They assume there is one single workflow model in a system, or rely on the information that can explicitly link each log sequence to the underlying workflow model. Such assumptions may not be applicable to multi-workflow systems where the instances of different workflow models are mixed together without being differentiated. To address this issue, this paper proposes to apply sequence clustering methods to group similar log sequences together. Each sequence cluster corresponds to a workflow model and the log sequences in the cluster are the corresponding instances. This paper investigates different similarity measures, including structure-based and user-based, as well as different clustering algorithms, including one-side clustering and co-clustering. In order to incorporate user factors into sequence clustering, which is novel to the current sequence clustering methods, this paper proposes to model User Behavior Patterns (UBPs) as probabilistic distributions over sequences and learn it from the event log. We represent a UBP as a Probabilistic Suffix Tree and use it to measure sequence similarity. The co-clustering method leverages the dyad relationship between UBPs and log sequences to improve the clustering accuracy. An experimental study has been conducted and the result indicates that user-based methods outperform structure-based methods in terms of accuracy and they are more effective on dealing with noises in the log and the increase of log size. The UBP-sequence co-clustering method achieves the best performance which indicates the effectiveness of incorporating user factors and applying co-clustering.",2018,Data & Knowledge Engineering
WATTANAKITRUNGROJ201853,BEstream: Batch Capturing with Elliptic Function for One-Pass Data Stream Clustering,"Data stream clustering, One-pass learning, Elliptic-micro-cluster","Tremendous data have been generated in forms of streaming data and various distributions in most applications in different areas such as business, science, engineering, and medicine. This creates a new problem of space and time complexities where the incoming data can overflow the memory of an analysing machine and the flow of data may contain some scattered portions of data from different clusters. This situation leads to the incorrect clustering results. The challenge of the clustering on streaming data is clustering the data which continuously growing, unstable, and non-existent from time to time. This paper proposed the concept of discard-after-cluster based on the structure of adaptive hyper-elliptic micro-cluster components. Instead of gradually including each datum into its true cluster, a newly proposed set of algorithms capture the data in forms streaming batch and identify the cluster afterwards. The number of micro-clusters can be increased or decreased according to the dynamical distribution of incoming data as well as the overlap conditions of micro-clusters. A set of new recursive functions for updating parameters, checking overlap conditions, removing micro-clusters, and merging micro-clusters after discarding previously clustered data were introduced. The proposed algorithm was tested on synthetic and real data sets. The elliptic-micro-cluster structure is more suitable for capturing data than the other structures in the compared previous methods. In addition, our method named BEstream showed the more efficient results than the previous data stream clustering algorithms based on the rand index and normalized mutual information measures.",2018,Data & Knowledge Engineering
WEILAND2018114,Knowledge-rich image gist understanding beyond literal meaning,"Image understanding, Language and vision, Entity ranking","We investigate the problem of understanding the message (gist) conveyed by images and their captions as found, for instance, on websites or news articles. To this end, we propose a methodology to capture the meaning of image-caption pairs on the basis of large amounts of machine-readable knowledge that have previously been shown to be highly effective for text understanding. Our method identifies the connotation of objects beyond their denotation: where most approaches to image understanding focus on the denotation of objects, i.e., their literal meaning, our work addresses the identification of connotations, i.e., iconic meanings of objects, to understand the message of images. We view image understanding as the task of representing an image-caption pair on the basis of a wide-coverage vocabulary of concepts such as the one provided by Wikipedia, and cast gist detection as a concept-ranking problem with image-caption pairs as queries. Our proposed algorithm brings together aspects of entity linking and clustering, subgraph selection, semantic relatedness, and learning-to-rank in a novel way. In addition to this novel task and a complete evaluation of our approach, we introduce a novel dataset to foster further research on this problem. To enable a throughout investigation of the problem of gist understanding, we produce a gold standard of over 300 image-caption pairs and over 8000 gist annotations covering a wide variety of topics at different levels of abstraction. We use this dataset to experimentally benchmark the contribution of different kinds of signals from heterogeneous sources, namely image and text. The best result with a Mean Average Precision (MAP) of 0.69 indicate that by combining both dimensions we are able to better understand the meaning of our image-caption pairs than when using language or vision information alone. Our supervised approach relies on the availability of human-annotated gold standard datasets. Annotating images with, possibly complex, topic labels is arguably a very time-consuming task that must rely on expert human annotators. We accordingly investigate whether parts of this process could be automatized using automatic image annotation and caption generation techniques. Our results indicate the general feasibility of an end-to-end approach to gist detection when replacing one of the two dimensions with automatically generated input, i.e., using automatically generated image tags or generated captions. However, we also show experimentally that state-of-the-art image and text understanding is better at understanding literal meanings of image-caption pairs, with non-literal pairs being instead generally more difficult to detect, thus paving the way for future work on understanding the message of images beyond their literal content.",2018,Data & Knowledge Engineering
KICHERER2018252,"What you use, not what you do: Automatic classification and similarity detection of recipes","Recipe, Cooking food, Lassification, Multi-label, Text mining, Similarity search","Social media data is notoriously noisy and unclean. Recipe collections and their manual categorization built by users are no exception. However, a consistent and transparent categorization is vital to users who search for a specific entry. Similarly, curators are faced with the same challenge given a large collection of existing recipes: They first need to understand the data to be able to build a clean system of categories. This paper presents an empirical study using machine learning classifiers (logistic regression and decision trees) for the automatic classification of recipes on the German cooking website Chefkoch.de. The central question we aim at answering is: Which information is necessary to perform well at this task? In particular, we compare features extracted from the free text instructions of the recipe to those taken from the list of ingredients. On a sample of 5000 recipes with 87 classes, our feature analysis shows that a combination of nouns from the textual description of the recipe with ingredient features performs best in the logistic regression model (48% F1). Nouns alone achieve 45% F1 and ingredients alone 46% F1. However, other word classes do not complement the information from nouns. Decision trees constantly underperform the logistic regression, however, lead to an interpretable model. On a bigger training set of 50,000 instances, the best configuration shows an improvement to 57% highlighting the importance of a sizeable data set. In addition, we report on the use of these feature vectors for similarity search and ranking of recipes and evaluate on the task of (near) duplicate detection. We show that our method can reduce the manual curation with precision@3 = 0.52.",2018,Data & Knowledge Engineering
SEVENS2018264,Less is more: A rule-based syntactic simplification module for improved text-to-pictograph translation,"Syntactic simplification, Text-to-pictograph translation, Augmented and alternative communication, Social media","In order to enable or facilitate online communication for people with an intellectual disability, the Text-to-Pictograph translation system automatically translates Dutch written text into a series of Sclera or Beta pictographs. The baseline system presents the reader with a more or less verbatim pictograph-per-word translation. As a result, long and complex input sentences lead to long and complex pictograph translations, leaving the end users confused and distracted. To overcome these problems, we developed a rule-based simplification system for Dutch Text-to-Pictograph translation. By using recursion and applying the simplification operations in a logical way, only one syntactic parse is needed per message. Promising results are obtained.",2018,Data & Knowledge Engineering
PEREZ2018239,A case study on the use of machine learning techniques for supporting technology watch,"Text mining, Knowledge management applications, Multi-classification, Technology watch automation, Semantic annotations","Technology Watch human agents have to read many documents in order to manually categorize and dispatch them to the correct expert, that will later add valued information to each document. In this two step process, the first one, the categorization of documents, is time consuming and relies on the knowledge of a human categorizer agent. It does not add direct valued information to the process that will be provided in the second step, when the document is revised by the correct expert. This paper proposes Machine Learning tools and techniques to learn from the manually pre-categorized data to automatically classify new content. For this work a real industrial context was considered. Text from original documents, text from added value information and Semantic Annotations of those texts were used to generate different models, considering manually pre-established categories. Moreover, three algorithms from different approaches were used to generate the models. Finally, the results obtained were compared to select the best model in terms of accuracy and also on the reduction of the amount of document readings (human workload).",2018,Data & Knowledge Engineering
ROBLOT2018339,Cardinality constraints and functional dependencies over possibilistic data,"Data and knowledge visualization, Data models, Database semantics, Management of integrity constraints, Requirements engineering","Modern applications require advanced techniques and tools to process large volumes of uncertain data. For that purpose we study cardinality constraints and functional dependencies as a declarative mechanism to control the occurrences and interrelationships of uncertain data. Uncertainty is modeled qualitatively by assigning to each object a degree of possibility by which the object occurs in an uncertain instance. Cardinality constraints and functional dependencies are assigned a degree of certainty that stipulates on which objects they hold. Our framework empowers users to model uncertainty in an intuitive way, without the requirement to put a precise value on it. Our class of cardinality constraints and functional dependencies enjoys a natural possible world semantics, which is exploited to establish several tools to reason about them. We characterize the associated implication problem axiomatically and algorithmically in linear input time. Furthermore, we show how to visualize any given set of our cardinality constraints and functional dependencies in the form of an Armstrong sketch. Even though the problem of finding an Armstrong sketch is precisely exponential, our algorithm computes a sketch with conservative use of time and space. Data engineers may therefore compute Armstrong sketches that they can jointly inspect with domain experts in order to consolidate the set of cardinality constraints and functional dependencies meaningful for a given application domain.",2018,Data & Knowledge Engineering
BARZEGAR2018319,Classification of composite semantic relations by a distributional-relational model,"Semantic relation, Distributional semantic, Deep learning, Classification","Different semantic interpretation tasks such as text entailment and question answering require the classification of semantic relations between terms or entities within text. However, in most cases, it is not possible to assign a direct semantic relation between entities/terms. This paper proposes an approach for composite semantic relation classification using one or more relations between entities/term mentions, extending the traditional semantic relation classification task. The proposed model is different from existing approaches which typically use machine learning models built over lexical and distributional word vector features in that is uses a combination of a large commonsense knowledge base of binary relations, a distributional navigational algorithm and sequence classification to provide a solution for the composite semantic relation classification problem. The proposed approach outperformed existing baselines with regard to F1-score, Accuracy, Precision and Recall.",2018,Data & Knowledge Engineering
DELIMANETO2018225,A semiotic-inspired machine for personalized multi-criteria intelligent decision support,"Multi-criteria decision support, Computational intelligence, Computational semiotics, Intelligent semiotic machine","The need for appropriate decisions to tackle complex problems increases every day. Selecting destinations for vacation, comparing and optimizing resources to create valuable products, or purchasing a suitable car are just a few examples of puzzling situations in which there is no standard form to find an appropriate solution. Such scenarios become arduous when the number of possibilities, restrictions, and factors affecting the decision rise, thereby turning decision makers into almost mere spectators. In such circumstances, decision support systems (DSS) can play an important role in guiding people and organizations towards more accurate decision making. However, conventional DSS lack the necessary adaptability to account for dynamic changes and are frequently inadequate to tackle the subjectivity inherent in decision-maker's preferences and intention. We argue that these shortcomings can be addressed by a suitable combination of Semiotic Theory and Computational Intelligence algorithms, which together can make up a new generation of DSS. In this article, a formal description of an Intelligent Semiotic Machine is provided and tried out in practical decision contexts. The results obtained show that our approach can provide well-suited decisions based on user preferences, achieving appropriateness while fanning out subjective options without losing decision context, objectivity, or accuracy.",2018,Data & Knowledge Engineering
ALLAM201898,Improved suffix blocking for record linkage and entity resolution,"Database integration, Data warehouse and repository","Record linkage is the problem that identifies the different records that represent the same real-world object. Entity resolution is the problem that ensures that a real-world object is represented by a single record. The incremental versions of record linkage and entity resolution address the respective problems after the insertion of a new record in the dataset. Record linkage, entity resolution and their incremental versions are of paramount importance and arise in several contexts such as data warehouses, heterogeneous databases and data analysis. Blocking techniques are usually utilized to address these problems in order to avoid comparing all record pairs. Suffix blocking is one of the most efficient and accurate blocking techniques. In this paper, we consider the non-incremental variation of record linkage and present a method that is more than five times faster and achieves similar accuracy to the current state-of-the-art suffix-based blocking method. Then, we consider the incremental variation of record linkage and propose a novel incremental suffix-based blocking mechanism that outperforms existing incremental blocking methods in terms of blocking accuracy and efficiency. Finally, we consider incremental entity resolution and present two novel techniques based on suffix blocking that are able to handle the tested dataset in a few seconds (while a current state-of-the-art technique requires more than eight hours). Our second technique proposes a novel method that keeps a history of the deleted records and the merging process. Thus, we are able to discover alternative matches for the inserted record that are not possible for existing methods and improve the accuracy of the algorithm. We have implemented and extensively experimentally evaluated all our methods. We offer two implementations of our proposals. The first one is memory-based and offers the best efficiency while the second one is disk-based and scales seamlessly to very large datasets.",2018,Data & Knowledge Engineering
NALCHIGAR2018359,Business-driven data analytics: A conceptual modeling framework,"Conceptual modeling, Data analytics, Machine learning, Business analytics, Goal-oriented requirements engineering, Enterprise modeling","The effective development of advanced data analytics solutions requires tackling challenges such as eliciting analytical requirements, designing the machine learning solution, and ensuring the alignment between analytics initiatives and business strategies, among others. The use of conceptual modeling methods and techniques is seen to be of considerable value in overcoming such challenges. This paper proposes a modeling framework (including a set of metamodels and a set of design catalogues) for requirements analysis and design of data analytics systems. It consists of three complementary modeling views: business view, analytics design view, and data preparation view. These views are linked together to connect enterprise strategies to analytics algorithms and to data preparation activities. The framework includes a set of design catalogues that codify and represent an organized body of business analytics design knowledge. As the first attempt to validate the framework, three real-world data analytics case studies are used to illustrate the expressiveness and usability of the framework. Findings suggest that the framework provides an adequate set of concepts to support the design and implementation of analytics solutions.",2018,Data & Knowledge Engineering
AUGUSTO2018373,Automated discovery of structured process models from event logs: The discover-and-structure approach,"Automated process discovery, Process mining, Structured process model","This article tackles the problem of discovering a process model from an event log recording the execution of tasks in a business process. Previous approaches to this reverse-engineering problem strike different tradeoffs between the accuracy of the discovered models and their structural complexity. With respect to the latter property, empirical studies have demonstrated that block-structured process models are generally more understandable and less error-prone than unstructured ones. Accordingly, several methods for automated process model discovery generate block-structured models only. These methods however intertwine the objective of producing accurate models with that of ensuring their structuredness, and often sacrifice the former in favour of the latter. In this paper we propose an alternative approach that separates these concerns. Instead of directly discovering a structured process model, we first apply a well-known heuristic that discovers accurate but oftentimes unstructured (and even unsound) process models, and then we transform the resulting process model into a structured (and sound) one. An experimental evaluation on synthetic and real-life event logs shows that this discover-and-structure approach consistently outperforms previous approaches with respect to a range of accuracy and complexity measures.",2018,Data & Knowledge Engineering
ZHOU2018183,An overlapping community detection algorithm in complex networks based on information theory,"Overlapping community detection, Complex networks, Clustering, Data mining","In this paper, a new algorithm for overlapping community detection is proposed. First, we propose a node importance evaluation matrix to calculate the important degree for each node; second, we put forward the difference function to detect overlapping points in complex networks; finally, we use triangle principle to detect communities in complex networks. We adopt two measures of Normalized Mutual Information and Modularity to evaluate the algorithm. The experimental results show that our algorithm has a good performance on detecting overlapping community.",2018,Data & Knowledge Engineering
WAN201871,ICGT: A novel incremental clustering approach based on GMM tree,"Incremental data clustering, Streaming data, Gaussian mixture model (GMM), Tree structure","Streaming data presents new challenges to data mining algorithms. To conduct data clustering on the streaming data, this paper proposes a novel incremental clustering approach utilizing Gaussian Mixture Model (GMM), termed as ICGT (Incremental Construction of GMM Tree). The ICGT creates and dynamically adjusts a GMM tree consistent to the sequentially presented data. Each leaf node in the tree corresponds to a dense Gaussian distribution and each non-leaf node to a GMM. To update the GMM tree for insertion of the newly arrived data points, we introduce the definitions of node connectivity and connected subsets, and present the tree update algorithm. We further develop a clustering evaluation criterion and search strategy to determine the final partition of the data set based on the constructed GMM tree. We evaluated the proposed approach on synthetic and real-world data sets and compared ICGT with other incremental and static clustering methods. The experimental results confirm that our approach is effective and promising.",2018,Data & Knowledge Engineering
KUSS2018393,A probabilistic evaluation procedure for process model matching techniques,"Probabilistic evaluation, Process model matching, Evaluation techniques","Process model matching refers to the automatic identification of corresponding activities between two process models. It represents the basis for many advanced process model analysis techniques such as the identification of similar process parts or process model search. A central problem is how to evaluate the performance of process model matching techniques. Current evaluation methods require a binary gold standard that clearly defines which correspondences are correct. The problem is that often not even humans can agree on a set of correct correspondences. Hence, evaluating the performance of matching techniques based on a binary gold standard does not take the true complexity of the matching problem into account and does not fairly assess the capabilities of a matching technique. In this paper, we propose a novel evaluation procedure for process model matching techniques. In particular, we build on the assessments of multiple annotators to define the notion of a non-binary gold standard. In this way, we avoid the problem of agreeing on a single set of correct correspondences. Based on this non-binary gold standard, we introduce probabilistic versions of precision, recall, and F-measure as well as a distance-based performance measure. We use a dataset from the Process Model Matching Contest 2015 and a total of 16 matching systems to assess and compare the insights that can be obtained by using our evaluation procedure. We find that our probabilistic evaluation procedure allows us to gain more detailed insights into the performance of matching systems than a traditional evaluation based on a binary gold standard.",2018,Data & Knowledge Engineering
MARTINEZGIL2018195,Accurate and efficient profile matching in knowledge bases,"Profile, Lattice, Filter, Matching measure, Plausibility constraint, Top- query, Gap query","A profile describes a set of properties, e.g. a set of skills a person may have, a set of skills required for a particular job, or a set of abilities a football player may have with respect to a particular team strategy. Profile matching aims to determine how well a given profile fits to a requested profile and vice versa. The approach taken in this article is grounded in a matching theory that uses filters in lattices to represent profiles, and matching values in the interval [0,1]: the higher the matching value the better is the fit. Such lattices can be derived from knowledge bases to represent the knowledge about profiles. An interesting question is, how human expertise concerning the matching can be exploited to obtain most accurate matchings. It will be shown that if a set of filters together with matching values by some human expert is given, then under some mild plausibility assumptions a matching measure can be determined such that the computed matching values preserve the relevant rankings given by the expert. A second question concerns the efficient querying of databases of profile instances. For matching queries that result in a ranked list of profile instances matching a given one it will be shown how corresponding top-k queries can be evaluated on grounds of pre-computed matching values. In addition, it will be shown how the matching queries can be exploited for gap queries that determine how profile instances need to be extended in order to improve in the rankings.",2018,Data & Knowledge Engineering
LUO201837,A novel representation in three-dimensions for high dimensional data sets,"High dimensional data, Data mining, Representation, Information loss, Clustering, p-norm","Data representation is an important topic in the field of data engineering. In this paper, we focus on the representation of high dimensional data sets. We present the construction method of the set-valued mapping in 3-C representation and propose a novel representation algorithm based on K-means clustering method. The main contribution is to obtain the cluster centers of these high dimensional data sets, and get the correspondence coordinates in 3-C space with the projection along the center's direction. To verify the effectiveness of the proposed method, three sections of experiments had been completed. The first one is ten data sets from UCI. The second one is web images from Corel5k. The last one is the syllabus, a data set consists of text documents from the MIT OpenCourseWare project. All of the results can make sure that the corresponding similarity of data points or attributes are displayed clearly and show that the proposed algorithm's feasibility and scalability. Especially, the results on web images and syllabus are very excellent. As a result, the proposed representation algorithm in three dimension space will make significant influence on data classification and dimensionality reduction.",2018,Data & Knowledge Engineering
SENE201818,Data mining for decision support with uncertainty on the airplane,"Dempster-Shafer theory, Frequent pattern mining, Semantic reasoning, Decision support system, In-flight medical incidents","This study describes the formalization of the medical decision-making process under uncertainty underpinned by conditional preferences, the theory of evidence and the exploitation of high-utility patterns in data mining. To assist a decision maker, the medical process (clinical pathway) was implemented using a Conditional Preferences Base (CPB). Then for knowledge engineering, a Dempster-Shafer ontology integrating uncertainty underpinned by evidence theory was built. Beliefs from different sources are established with the use of data mining. The result is recorded in an In-flight Electronic Health Records (IEHR). The IEHR contains evidential items corresponding to the variables determining the management of medical incidents. Finally, to manage tolerance to uncertainty, a belief fusion algorithm was developed. There is an inherent risk in the practice of medicine that can affect the conditions of medical activities (diagnostic or therapeutic purposes). The management of uncertainty is also an integral part of decision-making processes in the medical field. Different models of medical decisions under uncertainty have been proposed. Much of the current literature on these models pays particular attention to health economics inspired by how to manage uncertainty in economic decisions. However, these models fail to consider the purely medical aspect of the decision that always remains poorly characterized. Besides, the models achieving interesting decision outcomes are those considering the patient's health variable and other variables such as the costs associated with the care services. These models are aimed at defining health policy (health economics) without a deep consideration for the uncertainty surrounding the medical practices and associated technologies. Our approach is to integrate the management of uncertainty into clinical reasoning models such as Clinical Pathway and to exploit the relationships between the determinants of incident management using data mining tools. To this end, how healthcare professionals see and conceive uncertainty has been investigated. This allowed for the identification of the characteristics determining people under uncertainty and to understand the different forms and representations of uncertainty. Furthermore, what an in-flight medical incident is and how its management is a decision under uncertainty issues was defined. This is the first phase of common data mining that will provide an evidential transaction basis. Subsequently an evidential and ontological reasoning to manage this uncertainty has been established in order to support decision making processes on the airplane.",2018,Data & Knowledge Engineering
SAVALCALVO2018119,3D non-rigid registration using color: Color Coherent Point Drift,"3D non-rigid registration, 3D deformable registration, CCPD","Research into object deformations using computer vision techniques has been under intense study in recent years. A widely used technique is 3D non-rigid registration to estimate the transformation between two instances of a deforming structure. Despite many previous developments on this topic, it remains a challenging problem. In this paper we propose a novel approach to non-rigid registration combining two data spaces in order to robustly calculate the correspondences and transformation between two data sets. In particular, we use point color as well as 3D location as these are the common outputs of RGB-D cameras. We have propose the Color Coherent Point Drift (CCPD) algorithm (an extension of the CPD method (Myronenko and Song, 2010)). Evaluation is performed using synthetic and real data. The synthetic data includes easy shapes that allow evaluation of the effect of noise, outliers and missing data. Moreover, an evaluation of realistic figures obtained using Blensor is carried out. Real data acquired using a general purpose Primesense Carmine sensor is used to validate the CCPD for real shapes. For all tests, the proposed method is compared to the original CPD showing better results in registration accuracy in most cases.",2018,Computer Vision and Image Understanding
LI2018108,Surface reconstruction from unorganized points with l0 gradient minimization,"Surface reconstruction, Point cloud, gradient minimization, sparsity, fast Fourier transform","To reconstruct surface from unorganized points in three-dimensional Euclidean space, we propose a novel efficient and fast method by using l0 gradient minimization, which can directly measure the sparsity of a solution and produce sharper surfaces. Therefore, the proposed method is particularly effective for sharpening major edges and removing noise. Unlike the Poisson surface reconstruction approach and its extensions, our method does not depend on the accurate directions of normal vectors of the unorganized points. The resulting algorithm is developed using a half-quadratic splitting method and is based on decoupled iterations that are alternating over a smoothing step realized by a Poisson approach and an edge-preserving step through an optimization formulation. This iterative algorithm is easy to implement. Various tests are presented to demonstrate that our method is robust to point noise, normal noise and data holes, and thus produces good surface reconstruction results.",2018,Computer Vision and Image Understanding
XIAO20181,Blind video denoising via texture-aware noise estimation,"Blind video denoising, Noise estimation, Principal component analysis, Weak texture block, Gaussian noise","Noise level is an important parameter for the design of video denoising algorithms in video processing applications. However, in practice, the noise level is unknown in most cases, but most existing denoising algorithms simply assume that the noise level is known beforehand, which severely limits their practical use. In this paper, we propose a novel blind video denoising algorithm via block-based optimal noise estimation that adaptively measures noise level by the principal component analysis. The adjacent frame images are searched to construct similar blocks by the block-matching method. The inter-frame differences of these similar blocks are used to estimate the video noise for the impact suppression of video motion, where the video noise is verified to comply with the normal distribution. The weak texture regions are selected by the thresholding function that is deduced based on the normal distribution. In addition, the proposed noise estimation approach is separately combined with several current popular non-blind video denoising methods to verify its superiority. Experimental results demonstrate that the proposed algorithm with low computational complexity not only has better estimation results, but also outperforms the state-of-the-art methods in most cases.",2018,Computer Vision and Image Understanding
YU201840,Hierarchical semantic image matching using CNN feature pyramid,"CNN feature, Image matching, Hierarchical framework, Dense correspondence, Visualization","Image matching remains an important and challenging problem in computer vision, especially for the dense correspondence estimation between images with high category-level similarity. The effectiveness of image matching largely depends on the advance of image descriptors. Inspired by the success of Convolutional Neural Network(CNN), we propose a hierarchal image matching method using the CNN feature pyramid, named as CNN Flow. The feature maps output by different layers of CNN tend to encode different information of the input image, such as the semantic information extracted from higher layers and the structural information extracted from lower layers. This nature of CNN feature pyramid is suitable to build the hierarchical image matching framework, which detects the patterns of different levels in an implicit coarse-to-fine manner. In particular, we take advantage of the complementarity of different layers using guidance from higher layer to lower layer. The high-layer features present semantic patterns to cope with the intra-class variations, and the guidance from high layers can resist the semantic ambiguity of low-layer features due to small receptive fields. The bottom-level matching utilize the low-layer features with more structural information to achieve finer matching. On one hand, extensive experiments and analysis demonstrate the superiority of CNN Flow in image dense matching under challenging variations. On the other hand, CNN Flow is demonstrated through various applications, such as fine alignment for intra-class object, scene label transfer and facial expression transfer.",2018,Computer Vision and Image Understanding
MOLNAR201890,A differential geometry approach to camera-independent image correspondence,"Camera-independent approach, Generalized epipolar geometry, Epipolar constraints, Differential geometry, Unified theory, Fundamental matrix","Projective geometry is a standard mathematical tool for image-based 3D reconstruction. Most reconstruction methods establish pointwise image correspondences using projective geometry. We present an alternative approach based on differential geometry using oriented patches rather than points. Our approach assumes that the scene to be reconstructed is observed by any camera, existing or potential, that satisfies very general conditions, namely, the differentiability of the surface and the bijective projection functions. We show how the notions of the differential geometry such as diffeomorphism, pushforward and pullback are related to the reconstruction problem. A unified theory applicable to various 3D reconstruction problems is presented. Considering two views of the surface, we derive reconstruction equations for oriented patches and pose equations to determine the relative pose of the two cameras. Then we discuss the generalized epipolar geometry and derive the generalized epipolar constraint (compatibility equation) along the epipolar curves. Applying the proposed theory to the projective camera and assuming that affine mapping between small corresponding regions has been estimated, we obtain the minimal pose equation for the case when a fully calibrated camera is moved with its internal parameters unchanged. Equations for the projective epipolar constraints and the fundamental matrix are also derived. Finally, two important nonlinear camera types, the axial and the spherical, are examined.",2018,Computer Vision and Image Understanding
KALTSA201828,Multiple Hierarchical Dirichlet Processes for anomaly detection in traffic,"Anomaly detection, Traffic scenes, Surveillance","This work introduces an unsupervised approach to scene analysis and anomaly detection in traffic video data, as captured from static surveillance cameras. A hybrid local-global scheme is introduced, so as to capture both local and global information, by extracting features in superpixel-generated spatiotemporal volumes, which are then merged into regions with dynamically varying boundaries. The resulting regions’ shapes vary according to the underlying motion in the scene, as captured by the superpixels. Representative descriptors are then calculated in these regions, and multiple local Hierarchical Dirichlet Process (HDP) models are deployed in them, one for each region, for the unsupervised characterization of normal and “abnormal” events. The extraction of meaningful descriptors in these regions, instead of the whole frame, increases the resolution of the algorithm, while avoiding noise induced artifacts, and thus resulting in the successful detection of a wide range of “anomalies”, both in the local and global scales. Experiments on benchmark datasets containing various scenarios in traffic scenes prove our method’s efficacy and generality, leading to higher accuracy than the current State of the Art (SoA), and at a lower computational cost. Systematic quantitative experimental results and comparisons are provided on benchmark datasets, setting up a valuable baseline for future comparisons and improvements.",2018,Computer Vision and Image Understanding
PANAREDABUSTO201875,Viewpoint refinement and estimation with adapted synthetic data,"Domain adaptation, Pose estimation, Synthetic data","Estimating the viewpoint of objects in images is an important task for scene understanding. The viewpoint estimation accuracy, however, depends highly on the amount of training data and the quality of the annotation. While humans excel at labelling images with coarse viewpoint annotations like front, back, left or right, the process becomes tedious and the quality of the annotations decreases when finer viewpoint discretisations are required. To solve this problem, we propose a refinement of coarse viewpoint annotations, which are provided by humans, with synthetic data automatically generated from 3D models. To compensate between the difference between synthetic and real images, we introduce a domain adaptation approach that aligns the domain of the synthesized images with the domain of the real images. Experiments show that the proposed approach significantly improves viewpoint estimation on several state-of-the-art datasets.",2018,Computer Vision and Image Understanding
ELKHADIRI201814,Local directional ternary pattern: A New texture descriptor for texture classification,"Local directional ternary pattern (LDTP), KNN classification, Texture classification, Frei–Chen masks, 2nd derivative of Gaussian filter","In this paper, the three level descriptions from LTP and the directional features from LDP are combined to form a new local feature descriptor, referred to as local directional ternary pattern (LDTP) for texture classification. LDTP is a framework, which consists in encoding both contrast information and directional pattern features in a compact way based on local derivative variations. To achieve robustness, the proposed operator first computes for each pixel within its 3 × 3 overlapping grayscale image patch, on the one hand, eight directional edge responses using the eight Frei–Chen masks, and on the other hand, central edge response through the 2nd derivative of Gaussian filter to capture more detailed information. This allows producing a more discriminative encoding than several state-of-the art methods based only on intensity information. Then, spatial relationships among the neighboring pixels through the edge responses are exploited independently with the help of both LDP’s and LTP’s concepts to enhance the discrimination capability. Indeed, the implicit utilization of both concepts of LTP and LDP encodes more information in comparison to the existing directional and derivative methods in less space, and simultaneously allows discriminating more textures. Finally, the resultant LDTP pattern is divided into two distinct parts: local directional ternary pattern upper (LDTPU) and local directional ternary pattern lower (LDTPL), and the final feature descriptor vector is obtained by linear concatenation of both LDTPU and LDTPL histograms. The experiments carried out on nine publicly available texture datasets demonstrated that the proposed LDTP descriptor achieves classification performance, which is competitive or better than several recent and old state-of-the-art LBP variants. Statistical significance of the achieved accuracy improvement by the proposed descriptor has been also demonstrated through the Wilcoxon signed rank test applied on all the tested datasets.",2018,Computer Vision and Image Understanding
CHANG201852,2D–3D pose consistency-based conditional random fields for 3D human pose estimation,"Human pose estimation, Conditional random fields, Deep learning","This study considers the 3D human pose estimation problem in a single RGB image by proposing a conditional random field (CRF) model over 2D poses, in which the 3D pose is obtained as a byproduct of the inference process. The unary term of the proposed CRF model is defined based on a powerful heat-map regression network, which has been proposed for 2D human pose estimation. This study also presents a regression network for lifting the 2D pose to 3D pose and proposes the prior term based on the consistency between the estimated 3D pose and the 2D pose. To obtain the approximate solution of the proposed CRF model, the N-best strategy is adopted. The proposed inference algorithm can be viewed as sequential processes of bottom-up generation of 2D and 3D pose proposals from the input 2D image based on deep networks and top-down verification of such proposals by checking their consistencies. To evaluate the proposed method, we use two large-scale datasets: Human3.6M and HumanEva. Experimental results show that the proposed method achieves the state-of-the-art 3D human pose estimation performance.",2018,Computer Vision and Image Understanding
KAWANA201862,Ensemble convolutional neural networks for pose estimation,"Human pose estimation, Ensemble models, Pose modality","Human pose estimation is a challenging task due to significant appearance variations. An ensemble of models, each of which is optimized for a limited variety of poses, is capable of modeling a large variety of human body configurations.However, ensembling models is not a straightforward task due to the complex interdependence among noisy and ambiguous pose estimation predictions acquired by each model.We propose to capture this complex interdependence using a convolutional neural network. Our network achieves this interdependence representation using a combination of deep convolution and deconvolution layers for robust and accurate pose estimation. We evaluate the proposed ensemble model on publicly available datasets and show that our model compares favorably against baseline models and state-of-the-art methods.",2018,Computer Vision and Image Understanding
JIN20171,Face alignment in-the-wild: A Survey,"Face alignment, Active appearance model, Constrained local model, Cascaded regression, Deep convolutional neural networks","Over the last two decades, face alignment or localizing fiducial facial points on 2D images has received increasing attention owing to its comprehensive applications in automatic face analysis. However, such a task has proven extremely challenging in unconstrained environments due to many confounding factors, such as pose, occlusions, expression and illumination. While numerous techniques have been developed to address these challenges, this problem is still far away from being solved. In this survey, we present an up-to-date critical review of the existing literatures on face alignment, focusing on those methods addressing overall difficulties and challenges of this topic under uncontrolled conditions. Specifically, we categorize existing face alignment techniques, present detailed descriptions of the prominent algorithms within each category, and discuss their advantages and disadvantages. Furthermore, we organize special discussions on the practical aspects of face alignment in-the-wild, towards the development of a robust face alignment system. In addition, we show performance statistics of the state of the art, and conclude this paper with several promising directions for future research.",2017,Computer Vision and Image Understanding
LI201734,Three-layer graph framework with the sumD feature for alpha matting,"Alpha matting, Graph model, Image feature, Nonlocal principle","Alpha matting, the process of extracting opacity mask of the foreground in an image, is an important task in image and video editing. All of the matting methods need exploit the relationships between pixels. The traditional propagation-based methods construct constrains based on nonlocal principle and color line model to reflect the relationships. However, these methods would produce artifacts if the constrains are not reliable. So we improve this problem in three points. Firstly, we design a novel feature called sumD feature to increase the pixel discrimination. This feature is simple and could encourage pixels with similar texture to have similar feature values. Secondly, we design a three-layer graph framework to construct nonlocal constrains. This framework finds constrains in multi-scale range and selects reliable constrains, then unifies nonlocal constrains according to their reliabilities. Thirdly, we develop a new label extension method to add hard constrains. Experimental results confirm that the effectiveness of the three changes, and the proposed method achieves high rank on the benchmark dataset.",2017,Computer Vision and Image Understanding
SONG2017135,Stylizing face images via multiple exemplars,"Style transfer, Image processing","We address the problem of transferring the style of a headshot photo to face images. Existing methods using a single exemplar lead to inaccurate results when the exemplar does not contain sufficient stylized facial components for a given photo. In this work, we propose an algorithm to stylize face images using multiple exemplars containing different subjects in the same style. Patch correspondences between an input photo and multiple exemplars are established using a Markov Random Field (MRF), which enables accurate local energy transfer via Laplacian stacks. As image patches from multiple exemplars are used, the boundaries of facial components on the target image are inevitably inconsistent. The artifacts are removed by a post-processing step using an edge-preserving filter. Experimental results show that the proposed algorithm consistently produces visually pleasing results.",2017,Computer Vision and Image Understanding
SHI201757,A local feature with multiple line descriptors and its speeded-up matching algorithm,"Local feature, Multiple line descriptors, Matching algorithm","This paper introduces a local feature with multiple line descriptors and its unique matching algorithm. Previous approaches describe the local feature based on image patch that uses single feature point as the approximate center. But there is no accurate information about orientation or scale in the image patch. On the contrary, line segment possesses it. For this reason, we extract a line descriptor from a model of line segment that links two randomly selected feature points. There forms a mesh topology due to the fact that a line descriptor links two feature points and meanwhile a feature point links multiple line descriptors. But as a price to pay for it, there comes a large number of line descriptors that is bad for matching descriptors. In order to speed up the matching process, we design a unique matching algorithm by exploiting the mesh topology. The result shows that the local feature with multiple line descriptors outperforms other classical features based on image patch on robustness.",2017,Computer Vision and Image Understanding
SAVRAN2017146,Non-rigid registration based model-free 3D facial expression recognition,"Facial expression recognition, 3D face analysis, Model-free, Non-rigid registration, Shift-invariance, Action units","We propose a novel feature extraction approach for 3D facial expression recognition by incorporating non-rigid registration in face-model-free analysis, which in turn makes feasible data-driven, i.e., feature-model-free recognition of expressions. The resulting simplicity of feature representation is due to the fact that facial information is adapted to the input faces via shape model-free dense registration, and this provides a dynamic feature extraction mechanism. This approach eliminates the necessity of complex feature representations as required in the case of static feature extraction methods, where the complexity arises from the necessity to model the local context; higher degree of complexity persists in deep feature hierarchies enabled by end-to-end learning on large-scale datasets. Face-model-free recognition implies independence from limitations and biases due to committed face models, bypassing complications of model fitting, and avoiding the burden of manual model construction. We show via information gain maps that non-rigid registration enables extraction of highly informative features, as it provides invariance to local-shifts due to physiognomy (subject invariance) and residual pose misalignments; in addition, it allows estimation of local correspondences of expressions. To maximize the recognition rate, we use the strategy of employing a rich but computationally manageable set of local correspondence structures, and to this effect we propose a framework to optimally select multiple registration references. Our features are re-sampled surface curvature values at individual coordinates which are chosen per expression-class and per reference pair. We show the superior performance of our novel dynamic feature extraction approach on three distinct recognition problems, namely, action unit detection, basic expression recognition, and emotion dimension recognition.",2017,Computer Vision and Image Understanding
LIU201723,Efficient single image dehazing and denoising: An efficient multi-scale correlated wavelet approach,"Image dehazing, Multi-scale correlated wavelet, Open dark channel model, Soft-thresholding","Images of outdoor scenes captured in bad weathers are often plagued by the limited visibility and poor contrast, and such degradations are spatially-varying. Differing from most previous dehazing approaches that remove the haze effect in spatial domain and often suffer from the noise problem, this paper presents an efficient multi-scale correlated wavelet approach to solve the image dehazing and denoising problem in the frequency domain. To this end, we have heuristically found a generic regularity in nature images that the haze is typically distributed in the low frequency spectrum of its multi-scale wavelet decomposition. Benefited from this separation, we first propose an open dark channel model (ODCM) to remove the haze effect in the low frequency part. Then, by considering the coefficient relationships between the low frequency and high frequency parts, we employ the soft-thresholding operation to reduce the noise and synchronously utilize the estimated transmission in ODCM to further enhance the texture details in the high frequency parts adaptively. Finally, the haze-free image can be well restored via the wavelet reconstruction of the recovered low frequency part and enhanced high frequency parts correlatively. The proposed approach aims not only to significantly increase the perceptual visibility, but also to preserve more texture details and reduce the noise effect as well. The extensive experiments have shown that the proposed approach yields comparative and even better performance in comparison with the state-of-the-art competing techniques.",2017,Computer Vision and Image Understanding
GONG201746,Naturally combined shape-color moment invariants under affine transformations,"Invariants, Color, Shape, Descriptor, Dual-affine transformations","We proposed a kind of naturally combined shape-color affine moment invariants (SCAMI), which consider both shape and color affine transformations simultaneously in one single system. In the real scene, color and shape deformations always exist in images simultaneously. Simple shape invariants or color invariants cannot be qualified for this situation. The conventional method is just to make a simple linear combination of the two factors. Meanwhile, the manual selection of weights is a complex issue. Our construction method is based on the multiple integration framework. The integral kernel is assigned as the continued product of the shape and color invariant cores. It is the first time to directly derive an invariant to dual affine transformations of shape and color. The manual selection of weights is no longer necessary, and both the shape and color transformations are extended to affine transformation group. With the various of invariant cores, a set of lower-order invariants are constructed and the completeness and independence are discussed detailed. A set of SCAMIs, which called SCAMI24, are recommended, and the effectiveness and robustness have been evaluated on both synthetic and real datasets.",2017,Computer Vision and Image Understanding
MOZAFARI2017116,Cluster-based adaptive SVM: A latent subdomains discovery method for domain adaptation problems,"SVM-based da method, Latent subdomains discovery methods, Domain adaptation, Image classification, Pedestrian detection","Machine learning algorithms often suffer from good generalization in testing domains especially when the training (source) and test (target) domains do not have similar distributions. To address this problem, several domain adaptation techniques have been proposed to improve the performance of the learning algorithms when they face accuracy degradation caused by the domain shift problem. In this paper, we focus on the non-homogeneous distributed target domains and propose a new latent subdomain discovery model to divide the target domain into subdomains while adapting them. It is expected that applying adaptation on subdomains increase the rate of detection in comparing with the situation that the target domain is seen as one single domain. The proposed division method considers each subdomain as a cluster which has the definite ratio of positive to negative samples, linear discriminability and conditional distribution similarity to the source domain. This method divides the target domain into subdomains while adapting the trained target classifier for each subdomain using Adapt-SVM adaptation method. It also has a simple solution for selecting the appropriate number of subdomains. We call our proposed method Cluster-based Adaptive SVM or CA-SVM in short. We test CA-SVM on two different computer vision problems, pedestrian detection and image classification. The experimental results show the advantage in accuracy rate for our approach in comparison to several baselines.",2017,Computer Vision and Image Understanding
ORTEGO201787,Stand-alone quality estimation of background subtraction algorithms,"Stand-alone quality estimation, Stand-alone evaluation, Foreground segmentation quality, Background subtraction","Foreground segmentation is a key stage in multiple computer vision applications, where existing algorithms are commonly evaluated making use of ground-truth data. Reference-free or stand-alone evaluations that estimate segmented foreground quality are an alternative methodology to overcome the limitations inherent to ground-truth based evaluations. In this work, we survey and explore existing stand-alone measures proposed in related research areas to determine good object properties for estimating the segmentation quality in background subtraction algorithms. We propose a new taxonomy for stand-alone evaluation measures and analyze 21 proposals. We demonstrate the utility of the selected measures to evaluate the segmentation masks of eight background subtraction algorithms. The experiments are performed over a large heterogeneous dataset with varied challenges (CDNET2014) and identify which properties of the measures are the most effective to estimate quality. The experiments also demonstrate that qualitative performance levels can be distinguished and background subtraction algorithms can be ranked without the need of ground-truth.",2017,Computer Vision and Image Understanding
GWAK2017103,Multi-object tracking through learning relational appearance features and motion patterns,"Multi-object tracking, Visual tracking, Data association, Relational appearance features, Object motion patterns","Absract Multi-object tracking (MOT) is to simultaneously track multiple targets, e.g., pedestrians in this work, through locating them and maintaining their identities to make their individual trajectories. Despite of recent advances in object detection, MOT based on the tracking-by-detection principle is a still yet challenging and difficult task in complex and crowded conditions. For example, due to occlusion, missed object detection, and frequent entering and leaving of object in a scene, tracking failures such as identity switches and trajectory fragmentation can often occur. To tackle the issues, a new data association approach, namely, the relational appearance features and motion patterns learning (RAFMPL)-based data association, is proposed for facilitating MOT. In RAFMPL-MOT, the proposed relational features-based appearance model is different from conventional approaches in that it generates tracklets based on relational information by selecting one reference object and utilizing the feature differences between the reference object and the other objects. In addition, the motion patterns learning-based motion model enables linear and nonlinear confident motions patterns to be considered in data association. The proposed approach can effectively cover the key difficulties of MOT. In particular, using RAFMPL-MOT, it is possible to assign the same ID for the object that has been disappeared (even for moderately long period) and then is reappeared in the scene more robustly. Further, it also improves its robustness for occlusion problems frequently occurring in real situations. The experimental results show that the RAFMPL-MOT could generally achieve outperformance compared to the existing competitive MOT approaches.",2017,Computer Vision and Image Understanding
URBAN201771,"mdBRIEF - a fast online-adaptable, distorted binary descriptor for real-time applications using calibrated wide-angle or fisheye cameras","Visual features, Feature detection, Feature description, Binary descriptors, Hamming distance","Fast binary descriptors build the core for many vision based applications with real-time demands like object detection, visual odometry or SLAM. Commonly it is assumed, that the acquired images and thus the patches extracted around keypoints originate from a perspective projection ignoring image distortion or completely different types of projections such as omnidirectional or fisheye. Usually the deviations from a perfect perspective projection are corrected by using standard undistortion models. The latter, however, introduce artifacts if the camera’s field-of-view gets larger. In addition, many applications (e.g. monocular SLAM) require only undistorted points and holistic undistortion of every image for descriptor extraction could be eluded. In this paper, we propose a distorted and masked version of the BRIEF descriptor for calibrated cameras, called dBRIEF and mdBRIEF respectively. Instead of correcting the distortion holistically, we distort the binary tests and thus adapt the descriptor to different image regions. The implementation of the proposed method along with evaluation scripts can be found online at https://github.com/urbste/mdBRIEF.",2017,Computer Vision and Image Understanding
NGUYEN2017166,Self-calibration of omnidirectional multi-cameras including synchronization and rolling shutter,"Bundle adjustment, Self-calibration, Synchronization, Rolling shutter, Multi-camera, Structure-from-motion","360° and spherical cameras become popular and are convenient for applications like immersive videos. They are often built by fixing together several fisheye cameras pointing in different directions. However their complete self-calibration is not easy since the consumer fisheyes are rolling shutter cameras which can be unsynchronized. Our approach does not require a calibration pattern. First the multi-camera model is initialized thanks to assumptions that are suitable to an omnidirectional camera without a privileged direction: the cameras have the same setting and are roughly equiangular. Second a frame-accurate synchronization is estimated from the instantaneous angular velocities of each camera provided by monocular structure-from-motion. Third both inter-camera poses and intrinsic parameters are refined using multi-camera structure-from-motion and bundle adjustment. Last we introduce a bundle adjustment that estimates not only the usual parameters but also a sub-frame-accurate synchronization and the rolling shutter. We experiment using videos taken by consumer cameras mounted on a helmet and moving along trajectories of several hundreds of meters or kilometers, and compare our results to ground truth.",2017,Computer Vision and Image Understanding
MAHMOOD2018202,A robust technique for copy-move forgery detection and localization in digital images via stationary wavelet and discrete cosine transform,"Copy-move forgery, Tampered images, Forgery detection, Authenticity, Passive authentication","In this era, due to the widespread availability of digital devices, various open source and commercially available image editing tools have made authenticity of image contents questionable. Copy-move forgery (CMF) is a common technique to produce tampered images by concealing undesirable objects or replicating desirable objects in the same image. Therefore, means are required to authenticate image contents and identify the tampered areas. In this paper, a robust technique for CMF detection and localization in digital images is proposed. The technique extracts stationary wavelet transform (SWT) based features for exposing the forgeries in digital images. SWT is adopted because of its impressive localization properties, in both spectral and spatial domains. More specifically approximation subband of the stationary wavelet transform is utilized as this subband holds most of the information that is best suited for forgery detection. The dimension of the feature vectors is reduced by applying discrete cosine transform (DCT). To evaluate the proposed technique, we use two standard datasets namely, the CoMoFoD and the UCID for experimentations. The experimental results reveal that the proposed technique outperforms the existing techniques in terms of true and false detection rate. Consequently, the proposed forgery detection technique can be applied to detect the tampered areas and the benefits can be obtained in image forensic applications.",2018,Journal of Visual Communication and Image Representation
SHEN2018161,A novel multi-view dimensionality reduction and recognition framework with applications to face recognition,"Multi-view learning, Canonical correlations, Dimensionality reduction, Face recognition","Multi-view data with each view corresponding to a type of feature generally provides more comprehensive information. Learning from multi-view data is a challenging research topic in pattern recognition. For recognition task, most multi-view learning methods separately learn multi-view dimensionality reduction (MvDR) and classification models. Thus, the connection between the two models has not been well studied. In this paper, we propose a novel multi-view dimensionality reduction and recognition framework, which can establish the connection between MvDR and classification. Specifically, a multi-view dimensionality reduction method, termed as sparse representation regularized multiset canonical correlation analysis (SR2MCC) is first proposed. SR2MCC considers both correlation and sparse discrimination among multiple views. In accord with SR2MCC, a classifier, called multi-view sparse representation based classifier (MvSRC) is further developed. MvSRC performs classification by comparing the reconstruction residuals of different classes among all views. An efficient iterative algorithm is proposed to solve the proposed model. Extensive experiments on the AR, CMU PIE, FERET, and FRGC datasets demonstrate that the proposed framework can achieve superior recognition performance than several state-of-the-art methods.",2018,Journal of Visual Communication and Image Representation
COLIBAN2018281,Reducing the oversegmentation induced by quasi-flat zones for multivariate images,"Quasi-flat zones, Mathematical morphology, Color image segmentation, Hyperspectral pixel classification, EDICS: 4.4 morphological image analysis","Quasi-flat zones are morphological operators which partition the image into homogeneous regions with respect to certain criteria. They are used in grayscale and multivariate image simplification and segmentation. However, they often induce an oversegmentation of the image, taking the shape of narrow transition regions between objects and small regions which are a few pixels wide. Various methods have been devised in order to reduce this oversegmentation, which remove the unwanted zones according to some criteria and then grow the remaining regions. In this paper we propose improvements in transition region and area threshold filtering. We also combine the two filtering methods for further-improved results. We apply the proposed approaches in color image segmentation and hyperspectral pixel classification.",2018,Journal of Visual Communication and Image Representation
ATTA201842,A high payload steganography mechanism based on wavelet packet transformation and neutrosophic set,"Image steganography, Wavelet packet transformation, Neutrosophic set, Edge detection","In this paper a steganographic method is proposed to improve the capacity of the hidden secret data and to provide an imperceptible stego-image quality. The proposed steganography algorithm is based on the wavelet packet decomposition (WPD) and neutrosophic set. First, an original image is decomposed into wavelet packet coefficients. Second, the generalized parent–child relationships of spatial orientation trees for wavelet packet decomposition are established among the wavelet packet subbands. An edge detector based on the neutrosophic set named (NSED) is then introduced and applied on a number of subbands. This leads to classify each wavelet packet tree into edge/non-edge tree to embed more secret bits into the coefficients in the edge tree than those in the non-edge tree. The embedding is done based on the least significant bit substitution scheme. Experimental results demonstrate that the proposed method achieves higher embedding capacity with better imperceptibility compared to the published steganographic methods.",2018,Journal of Visual Communication and Image Representation
PAGES2018192,Affordable content creation for free-viewpoint video and VR/AR applications,"Free-viewpoint video, 3D reconstruction, Texturing, View synthesis, Augmented reality, Virtual reality","We present a scalable pipeline for Free-Viewpoint Video (FVV) content creation, considering also visualisation in Augmented Reality (AR) and Virtual Reality (VR). We support a range of scenarios where there may be a limited number of handheld consumer cameras, but also demonstrate how our method can be applied in professional multi-camera setups. Our novel pipeline extends many state-of-the-art techniques (such as structure-from-motion, shape-from-silhouette and multi-view stereo) and incorporates bio-mechanical constraints through 3D skeletal information as well as efficient camera pose estimation algorithms. We introduce multi-source shape-from-silhouette (MS-SfS) combined with fusion of different geometry data as crucial components for accurate reconstruction in sparse camera settings. Our approach is highly flexible and our results indicate suitability either for affordable content creation for VR/AR or for interactive FVV visualisation where a user can choose an arbitrary viewpoint or sweep between known views using view synthesis.",2018,Journal of Visual Communication and Image Representation
FIROUZNIA20181,Chaotic particle filter for visual object tracking,"Object tracking, Chaos theory, Particle filter, Global motion estimation, Occlusion, Fast motion","In this paper, a chaotic particle filter method is introduced to improve the performance of particle filter based on chaos theory. The methodology of the algorithm includes two steps. First, the global motion estimation is used to predict target position using dynamical information of object movement over frames. Then, the color-based particle filter method is employed in the local region obtained from global motion estimation to localize the target. The algorithm significantly reduces the number of particles, search space, and the filter divergence because of high-order estimation. To verify the efficiency of the tracker, the proposed method is applied to two datasets, consisting of particle filter-based methods under the Bonn Benchmark on Tracking (BoBoT), the large Tracking Benchmark (TB), and Visual Object Tracking (VOT2014). The results demonstrate that the chaotic particle filter method outperforms other state-of-the-art methods on the abrupt motion, occlusion, and out of view. The precision of the proposed method is about 10% higher than that of other particle filter algorithms with low computational cost.",2018,Journal of Visual Communication and Image Representation
WANG201813,A set-to-set nearest neighbor approach for robust and efficient face recognition with image sets,"Face recognition, Set-to-set, Robust analysis, Weighted correlation analysis","Set-to-set face recognition has drawn much attention thanks to its rich set information. We propose a robust and efficient Set-to-Set Nearest Neighbor Classification (S2S-NNC) approach for face recognition by using the maximum weighted correlation between sets in low-dimensional projection subspaces. A pair of face sets is represented as two sets of Mutual Typical Samples (MTS) based on their maximum weighted correlation, and the S2S distance is equivalent to that between two sets of MTS. For the variation of objects within a set, the faces are partitioned into patches and projected onto a correlation subspace to find the MTS between two sets. Furthermore, we develop a S2S-NNC approach for image set-based face recognition. Compared with existing approaches, the S2S-NNC unifies the image-to-image, image-to-set and set-to-set recognition problems into one model. Experimental results show the S2S-NNC approach significantly outperforms the state-of-art approaches on large video samples and small occluded samples.",2018,Journal of Visual Communication and Image Representation
KOU2018235,Edge-preserving smoothing pyramid based multi-scale exposure fusion,"Exposure fusion, High dynamic range, Image pyramid, Gradient domain guided image filter, Edge-preserving smoothing","Multi-scale exposure fusion is an efficient approach to fuse multiple differently exposed images of a high dynamic range (HDR) scene directly for displaying on a conventional low dynamic range (LDR) display device without generating an intermediate HDR image. It can produce images with higher quality than single-scale exposure fusion, but has a risk of producing halo artifacts and cannot preserve details in brightest or darkest regions well in the fused image. In this paper, an edge-preserving smoothing pyramid is introduced for the multi-scale exposure fusion. Benefiting from the edge-preserving property of the filter used in the algorithm, the details in the brightest/darkest regions are preserved well and no halo artifacts are produced in the fused image. The complexity of the proposed edge-preserving smoothing pyramid could be an issue. A hybrid smoothing pyramid is proposed to obtain a good trade-off between the complexity of algorithm and the quality of fused images. The experimental results prove that the proposed algorithms produce better fused images than the state-of-the-art algorithms both qualitatively and quantitatively.",2018,Journal of Visual Communication and Image Representation
LIU201876,Rate control schemes for panoramic video coding,"Virtual reality, Panoramic video, Rate control, Video coding","The popularity of multi-view panoramic video has been considerably increased for producing Virtual Reality (VR) content, due to its immersive visual experience. We argue in this paper that PSNR is less effective in assessing objective visual quality of compressed panoramic video than Sphere-based PSNR (S-PNSR), in which sphere-to-plain mapping of panoramic videos is considered. We also argue that S-PSNR is less effective in assessing perceptual visual quality compared with Perceptual PSNR (P-PSNR), which considers the front-center-bias prior of human viewing direction. The conventional Rate Control (RC) schemes of 2-Dimensional (2D) video coding are optimized on PSNR, and thus they are not suitable for panoramic video coding. To optimize S-PSNR and P-PSNR, two novel RC schemes are proposed for panoramic video coding. In particular, we develop objective and perceptual RC formulations, corresponding to optimization on S-PSNR and P-PSNR, respectively. Then, solutions to these two formulations are provided, such that bits can be allocated to each coding block for achieving optimal S-PSNR or P-PSNR in panoramic video coding. Finally, the experiment results validate the effectiveness of the proposed RC schemes in improving S-PSNR and P-PSNR of panoramic video coding.",2018,Journal of Visual Communication and Image Representation
SINGH201886,A new robust watermarking system in integer DCT domain,"Digital watermarking, Integer discrete cosine transform, Chaotic map, Stochastic resonance","In this paper, a robust watermarking technique is proposed using integer discrete cosine transform, non-linear chaotic map and dynamic stochastic resonance (DSR). Firstly, the host image is transformed into integer DCT domain where the coefficients are partitioned into non-over-lapping blocks. A circulant matrix is then constructed from the selected blocks. Block selection is done using a non-linear chaotic map. This circulant matrix is used for embedding the watermark by computing the singular values. The extraction of the watermark is done by producing the dynamic stochastic resonance (DSR) phenomena and casting a verification step. This verification step essentially solves the false positive detection problem that arises in SVD based watermarking. The experimental results demonstrate that the proposed scheme is imperceptible and robust against a variety of intentional or unintentional attacks.",2018,Journal of Visual Communication and Image Representation
LIU201820,Single satellite imagery simultaneous super-resolution and colorization using multi-task deep neural networks,"Image super-resolution, Satellite image colorization, Deep neural networks, Multi-task learning","Satellite imagery is a kind of typical remote sensing data, which holds preponderance in large area imaging and strong macro integrity. However, for most commercial space usages, such as virtual display of urban traffic flow, virtual interaction of environmental resources, one drawback of satellite imagery is its low spatial resolution, failing to provide the clear image details. Moreover, in recent years, synthesizing the color for grayscale satellite imagery or recovering the original color of camouflage sensitive regions becomes an urgent requirement for large spatial objects virtual reality interaction. In this work, unlike existing works which solve these two problems separately, we focus on achieving image super-resolution (SR) and image colorization synchronously. Based on multi-task learning, we provide a novel deep neural network model to fulfill single satellite imagery SR and colorization simultaneously. By feeding back the color feature representations into the SR network and jointly optimizing such two tasks, our deep model successfully achieves the mutual cooperation between imagery reconstruction and image colorization. To avoid color bias, we not only adopt the non-satellite imagery to enrich the color diversity of satellite image, but also recalculate the prior color distribution and the valid color range based on the mixed data. We evaluate the proposed model on satellite images from different data sets, such as RSSCN7 and AID. Both the evaluations and comparisons reveal that the proposed multi-task deep learning approach is superior to the state-of-the-art methods, where image SR and colorization can be accomplished simultaneously and efficiently.",2018,Journal of Visual Communication and Image Representation
MA2018224,A new variational model for joint restoration and segmentation based on the Mumford-Shah model,"Image segmentation, Image restoration, Mumford-Shah model","Due to the typical challenges including image noise or blurriness, intensity inhomogeneity or various image modalities, image segmentation is still an open problem. In this paper, a new variational model is proposed for multiphase segmentation of gray and color images corrupted by noise or blur. Based on the aspects of image restoration, the coupled fidelity terms are utilized in order to effectively and robustly tackle images with a high level of noise or blurriness. For intensity inhomogeneous images, we use the bias-corrected fuzzy c-means method to eliminate the effect of bias field before our implementation. A partial result for the energy minimization problem is established. For solving the new variational model, the alternating minimization algorithm is studied. Experiments demonstrate that our method gives excellent results in terms of segmentation quality in comparison with other state-of-the-art segmentation methods.",2018,Journal of Visual Communication and Image Representation
HOU2018134,Reversible visual transformation via exploring the correlations within color images,"Reversible visual transformation, Image camouflage, Image encryption, Reversible data hiding","Reversible visual transformation reversibly transforms a secret image to a freely-selected target image and gets a camouflage image similar to the target image, which has been proved to be very useful in such two applications: privacy protection of images and reversible data hiding in encrypted images. Now, a new reversible transformation technique for color images is proposed by exploring and utilizing the correlations among three color channels and inside each color channel. The amount of the accessorial information for recording transformation parameters is largely reduced. Therefore, the visual quality of the created camouflage image is much improved by dividing the secret image and the target image into even smaller blocks for transformation.",2018,Journal of Visual Communication and Image Representation
GAN2018180,Online object tracking via motion-guided convolutional neural network (MGNet),"Object tracking, Online tracking, Convolutional neural network, Optical flow, Multi-domain learning","Tracking-by-detection (TBD) is widely used in visual object tracking. However, many TBD-based methods ignore the strong motion correlation between current and previous frames. In this work, a motion-guided convolutional neural network (MGNet) solution to online object tracking is proposed. The MGNet tracker is built upon the multi-domain convolutional neural network with two innovations: (1) a motion-guided candidate selection (MCS) scheme based on a dynamic prediction model is proposed to accurately and efficiently generate the candidate regions and (2) the spatial RGB and temporal optical flow are combined as inputs and processed in an unified end-to-end trained network, rather than a two-branch processing network. We compare the performance of the MGNet, the MDNet and several state-of-the-art online object trackers on the OTB and the VOT benchmark datasets, and demonstrate that the temporal correlation between any two consecutive frames in videos can be more effectively captured by the MGNet via extensive performance evaluation.",2018,Journal of Visual Communication and Image Representation
ZHANG2018102,Object-level saliency: Fusing objectness estimation and saliency detection into a uniform framework,"Object-level, Salient object detection, Saliency, Objectness, Background prior, Peeling","Most existing saliency detection algorithms concentrate on obtaining good results for images with single salient object, while it produces poor generalization power when tested on more realistic images. In this paper, we present a novel framework to detect saliency in object-level through fusing objectness estimation into the process of salient object detection. Different from most existing methods that evaluate saliency via aggregation of adjacent pixels or regions, our approach peels background regions step by step via evaluating each region’s saliency, objectness and background, until all the independent foreground objects are left. Instead of extracting from saliency map, the proposed method can obtain salient objects directly, and different salient scores can be assigned to different salient objects. Experimental results show that the proposed method is effective and achieves state-of-the-art performance in several benchmark datasets, especially on PASCAL_S and SED2 that offer salient objects in more complicated scenes.",2018,Journal of Visual Communication and Image Representation
NAVARRO2018257,Connecting the dots: Toward accountable machine-learning printer attribution methods,"Accountable machine learning, Digital forensics, Source printer attribution, Feature back-projection, Feature mapping, Feature importance","Digital forensics is rapidly evolving as a direct consequence of the adoption of machine-learning methods allied with ever-growing amounts of data. Despite the fact that these methods yield more consistent and accurate results, they may face adoption hindrances in practice if their produced results are absent in a human-interpretable form. In this paper, we exemplify how human-interpretable (a.k.a., accountable) extensions can enhance existing algorithms to aid human experts, by introducing a new method for the source printer attribution problem. We leverage the recently proposed Convolutional Texture Gradient Filter (CTGF) algorithm’s ability to capture local printing imperfections to introduce a new method that maps and highlights important attribution features directly onto the investigated printed document. Supported by Random Forest classifiers, we isolate and rank features that are pivotal for differentiating a printer from others, and back-project those features onto the investigated document, giving analysts further evidence about the attribution process.",2018,Journal of Visual Communication and Image Representation
JIAN201831,Integrating QDWD with pattern distinctness and local contrast for underwater saliency detection,"Underwater image, Saliency detection, QDWD, Pattern distinctness, Local contrast","In this paper, we propose a novel framework for underwater image saliency detection by exploiting Quaternionic Distance Based Weber Descriptor (QDWD), pattern distinctness, and local contrast. Our proposed algorithm incorporates quaternion number system and principal components analysis (PCA) simultaneously, so as to achieve superior performance. In our algorithm, QDWD, which was initially designed for detecting outliers in color images, is used to represent the directional cues in an underwater image. Then, PCA coordinate system is employed to compute pattern distinctness. Meanwhile, we utilize local contrast to further highlight salient regions and suppress background regions. Finally, by integrating QDWD, pattern distinctness, and local contrast, a reliable saliency map for underwater images can be computed and estimated. Experimental results, based on the publicly available OUC-VISION underwater image database, show that the proposed method can produce reliable and promising results, compared to other state-of-the-art saliency-detection models.",2018,Journal of Visual Communication and Image Representation
DONG2018171,Hyperspectral pansharpening based on guided filter and Gaussian filter,"Hyperspectral image, Panchromatic image, Image fusion, Guided filter","Hyperspectral pansharpening aims to integrate the panchromatic (PAN) and hyperspectral (HS) images into a single HS image with high spatial and high spectral resolution. This paper proposes a novel hyperspectral pansharpening method based on guided filter and gaussian filter. Most guided filter based researches extract the spatial details from the PAN image or the single band HS intensity component, and incorrect generation of the intensity component causes the spectral distortion. Different from the traditional guided filter based methods, the structure of the HS image is fully considered by the proposed method. We first use the high frequency layer of each band of the HS image as the guidance image of the guided filter. Then, the total spatial details are extracted from both the PAN image and the HS image. The total spatial details are finally injected into each band of the HS image low frequency layer to generate the fused image. Experiments demonstrate that the proposed method outperforms some state-of-the-art methods in terms of objective quality assessment and subjective visual effect.",2018,Journal of Visual Communication and Image Representation
SILVA201855,Making a long story short: A multi-importance fast-forwarding egocentric videos with the emphasis on relevant objects,"Semantic information, First-person video, Fast-forward, Egocentric stabilization","The emergence of low-cost high-quality personal wearable cameras combined with the increasing storage capacity of video-sharing websites have evoked a growing interest in first-person videos, since most videos are composed of long-running unedited streams which are usually tedious and unpleasant to watch. State-of-the-art semantic fast-forward methods currently face the challenge of providing an adequate balance between smoothness in visual flow and the emphasis on the relevant parts. In this work, we present the Multi-Importance Fast-Forward (MIFF), a fully automatic methodology to fast-forward egocentric videos facing these challenges. The dilemma of defining what is the semantic information of a video is addressed by a learning process based on the preferences of the user. Results show that the proposed method keeps over 3 times more semantic content than the state-of-the-art fast-forward. Finally, we discuss the need of a particular video stabilization technique for fast-forward egocentric videos1https://www.verlab.dcc.ufmg.br/semantic-hyperlapse/jvci2018/.1.",2018,Journal of Visual Communication and Image Representation
YANG2018245,Temporally enhanced image object proposals for online video object and action detections,"Video, Proposal, Online, Detection, Temporal","Despite the recent advances of image object proposals (IOPs) and video object proposals (VOPs), it still remains a challenge to apply them to online video object/action detection. To address this problem, we propose a novel form of image object proposals, Temporally Enhanced Image Object Proposals (TE-IOPs), for online video object/action detection. The proposed TE-IOPs augment the existing IOPs at every frame by their temporal dynamics in the past few frames. We develop a dynamic programming scheme to efficiently search for such TE-IOPs in an online manner. Compared with existing VOPs that cannot run online, our TE-IOPs can be used for online detection. Compared with IOPs, our TE-IOPs bring rich temporal dynamics with minor computational cost. Experiments on benchmark datasets validate the superior performance of the proposed TE-IOPs over existing IOPs and VOPs, in terms of both the proposal re-ranking and the application of online action detection.",2018,Journal of Visual Communication and Image Representation
HSU2018273,Robust cross-pose face recognition using landmark oriented depth warping,"Face recognition, Cross-pose, Facial landmarks, Depth warping, Sparse reconstruction, RTSM, PIE and Multi-PIE database","A novel approach exploiting facial landmarks and depth warping is proposed for robust cross-pose face recognition. Unlike the existing 3-D reconstruction based cross-pose recognition algorithms, the proposed algorithm utilizes the automatically identified extensive facial landmarks to replace the computationally expensive 3-D reconstruction procedure, by depth warping. The given face is thereby registered to the most similar 3-D reference model. When matching to a probe face image, the registered depth-warped faces in the gallery are rotated to align to the orientation of the probe image, and sparse regression is then used to identify the correct person. Further, to handle the more challenging cases with eyeglasses, we devise and employ an enhanced Regressive Tree Structured Model (RTSM) combined with inpainting procedure, prior to depth warping. The proposed robust cross-pose recognition (RCPR) algorithm is rigorously validated on PIE and Multi-PIE databases, and compared with state-of-the-art contemporary approaches to demonstrate its superior efficacy.",2018,Journal of Visual Communication and Image Representation
XU2018113,Saliency detection via bi-directional propagation,"Saliency detection, Bi-directional, Propagation","Recent saliency models rely on propagation to compute the saliency map. Previous propagation methods are single directional, where foreground propagation and background propagation are separate (e.g., only foreground propagation, or background propagation after foreground propagation). Different from the previous approaches, we propose a bi-directional propagation model (BIP) for saliency detection. The BIP model propagates from the labeled foreground superpixels and the labeled background superpixels to the unlabeled ones in the same iteration. A difficulty-based rule is adopted to manipulate the prorogation sequence, which considers both the distinctness of the superpixel to its neighboring ones and its connectivity to the labeled sets. The BIP model outperforms fourteen state-of-the-art saliency models on four challenging datasets, and largely enhances the propagation efficiency compared to single directional propagation models.",2018,Journal of Visual Communication and Image Representation
THONGKOR2018146,Digital watermarking for camera-captured images based on just noticeable distortion and Wiener filtering,"Digital image watermarking, Just noticeable distortion, Pixel value distortions, Geometric distortions","In this paper, we propose a digital image watermarking method for camera-captured images. In our proposed method, an image component of all image pixels is used for embedding an individual watermark bit in order to provide large amount of the embedded watermark. The watermark strength is adjusted in accordance with the modified just noticeable distortion. After the watermarked image is printed and then captured by a digital camera, the reliable watermark extraction is accomplished based on the techniques of reducing distortions introduced from the printing and camera-capturing processes, and predicting original image component from the watermarked image component. In the experiments, various types of pixel value distortions and geometric distortions are considered and explored. With the proposed method, the results show that the watermark can be invisibly embedded, and reliably extracted. We also demonstrate its robustness against various types of distortions from the printing and camera-capturing processes.",2018,Journal of Visual Communication and Image Representation
WANG201865,Super-resolution image reconstruction using surface fitting with hierarchical structure,"Super-resolution image reconstruction, Neighborhood expansion, Multi-surface fitting, Hierarchical structure, MAP estimation","We propose a super-resolution image reconstruction method using multi-source low resolution images. The proposed method includes a hierarchical structure that combines a neighborhood expansion process with the surface fitting technique. In the proposed method, a series of nested neighborhoods are created to collect LR pixels, and a purification algorithm is put forward to remove the outliers. Then we fit with a surface in each neighborhood to obtain a value at the location of estimated high resolution grid site. These values are pooled to a MAP frame to reconstruct high resolution pixels. Therefore, a reconstructed pixel is associated with the pixel correlation, pixel intensity and the spatial structure. Moreover, our method is non-iterative and does not suffer from convergence problem. Comparing with the state-of-the-art schemes, the proposed method provides superior effect and computational efficiency. Experimental results demonstrate the superiority of the proposed method in both visual fidelity and numerical measures.",2018,Journal of Visual Communication and Image Representation
WANG2017129,A chordiogram image descriptor using local edgels,"Visual place recognition, Loop closure detection, Chordiogram, Edge pixel, Dissimilarity measurement, Order statistics","Illumination variations result distant image representations of the same places, posing difficulty in image-based place recognition. We propose a shape-based global image descriptor and a matching method to address the problem. To describe a local image patch, a set of robust edge pixels is selected by thresholding a small proportion of pixels with large edge responses and represented by a shape descriptor which captures the local geometric features instead of image intensities. To alleviate the unbalanced distribution of edge pixels, the whole image is partitioned into regular patches and represented by a collection of local descriptors from individual patches. Instead of including the dissimilarity measurements of all patches in comparing two images, we propose to sum up a fraction of small measurements as a way to reject noisy patches. Experiments show that our global image descriptor supported by the proposed matching method achieves the state-of-the-art performance for visual place recognition.",2017,Journal of Visual Communication and Image Representation
YUE2017382,No reference image blurriness assessment with local binary patterns,"Blurriness/sharpness, Image quality assessment (IQA), No reference (NR), Local binary pattern (LBP)","In this paper, we put forward an effective and efficient no reference image blurriness assessment metric on the basis of local binary pattern (LBP) features. In this proposal, we reveal that part of the LBP histogram bins present monotonously with the degree of blurriness. The proposed method contains the following steps. Firstly, the LBP maps of an input image are extracted with multiple radiuses. And then, the frequency of pattern histogram is analyzed before part of bins are chosen as the features. In addition, we also take the entropy of these bins as another feature. Finally, we learn the extracted features to predict the image blurriness score. Validation of the proposed method is conducted on the blurred images of LIVE-II, CSIQ, TID2008, TID2013, LIVE3D IQA Phase I and LIVE3D IQA Phase II. Experimental results demonstrate that compared with the state-of-the-art image quality assessment (IQA) methods, the proposed algorithm has notable advantage in correlation with subjective perception and computational complexity.",2017,Journal of Visual Communication and Image Representation
LIU201747,Support vector machine active learning by Hessian regularization,"Active learning, Semi-supervised, Manifold regularization, Image segmentation, Activity recognition, Hessian","It is time-consuming and expensive to gather and label the growing multimedia data that is easily accessible with the prodigious development of Internet technology and digital sensors. Hence, it is essential to develop a technique that can efficiently be utilized for the large-scale multimedia data especially when labeled data is rare. Active learning is showing to be one useful approach that greedily chooses queries from unlabeled data to be labeled for further learning and then minimizes the estimated expected learning error. However, most active learning methods only take into account the labeled data in the training of the classifier. In this paper, we introduce a semi-supervised algorithm to learn the classifier and then perform active learning scheme on top of the semi-supervised scheme. Particularly, we employ Hessian regularization into support vector machine to boost the classifier. Hessian regularization exploits the potential geometry structure of data space (including labeled and unlabeled data) and then significantly leverages the performance in each round. To evaluate the proposed algorithm, we carefully conduct extensive experiments including image segmentation and human activity recognition on popular datasets respectively. The experimental results demonstrate that our method can achieve a better performance than the traditional active learning methods.",2017,Journal of Visual Communication and Image Representation
SHERLYALPHONSE2017459,A novel Monogenic Directional Pattern (MDP) and pseudo-Voigt kernel for facilitating the identification of facial emotions,"Directional pattern, ELM, Pseudo-Voigt, Monogenic","Facial expressions are the best way of communicating human emotions. This paper proposes a novel Monogenic Directional Pattern (MDP) for extracting features from the face. To reduce the time spent on choosing the best kernel, a novel pseudo-Voigt kernel is chosen as the common kernel for dimension reduction proposed as pseudo-Voigt kernel-based Generalized Discriminant Analysis (PVK-GDA). The pseudo-Voigt kernel-based Extreme Learning Machine (PVK-ELM) is used for better recognition of facial emotions. The efficiency of the approach is proved by experimenting with the Japanese Female Facial Expression (JAFFE), Cohn Kanade (CK+), Multimedia Understanding Group (MUG), Static Facial Expressions in the Wild (SFEW) and Oulu-Chinese Academy of Science, Institute of Automation (Oulu-CASIA) datasets. This approach achieves better classification accuracy of 96.7% for JAFFE, 99.4% for CK+, 98.6% for MUG, 35.6% for SFEW and 88% for Oulu-CASIA, which is certainly higher when compared to other techniques in the literature.",2017,Journal of Visual Communication and Image Representation
WANG2017332,Robust face anti-spoofing with depth information,"Face anti-spoofing, Depth information, Convolutional neural network","With the prevalence of face authentication applications, the prevention of malicious attack from fake faces such as photos or videos, i.e., face anti-spoofing, has attracted much attention recently. However, while an increasing number of works on the face anti-spoofing have been reported based on 2D RGB cameras, most of them cannot handle various attacking methods. In this paper we propose a robust representation jointly modeling 2D textual information and depth information for face anti-spoofing. The textual feature is learned from 2D facial image regions using a convolutional neural network (CNN), and the depth representation is extracted from images captured by a Kinect. A face in front of the camera is classified as live if it is categorized as live using both cues. We collected a face anti-spoofing experimental dataset with depth information, and reported extensive experimental results to validate the robustness of the proposed method.",2017,Journal of Visual Communication and Image Representation
WANG2017213,Large scale automatic image annotation based on convolutional neural network,"Deep learning, Automatic image annotation, Adaptive label, Multitasking, Convolutional neural network","Automatic image annotation is one of the most important challenges in computer vision, which is critical to many real-world researches and applications. In this paper, we focus on the issue of large scale image annotation with deep learning. Firstly, considering the existing image data, especially the network images, most of the labels of themselves are inaccurate or imprecise. We propose a Multitask Voting (MV) method, which can improve the accuracy of original annotation to a certain extent, thereby enhancing the training effect of the model. Secondly, the MV method can also achieve the adaptive label, whereas most existing methods pre-specify the number of tags to be selected. Additionally, based on convolutional neural network, a large scale image annotation model MVAIACNN is constructed. Finally, we evaluate the performance with experiments on the MIRFlickr25K and NUS-WIDE datasets, and compare with other methods, demonstrating the effectiveness of the MVAIACNN.",2017,Journal of Visual Communication and Image Representation
KAN2017104,SURF binarization and fast codebook construction for image retrieval,"SURF binarization, Two-step clustering algorithm, Scalable overlapping partition, Image retrieval, Object search","A new framework for image retrieval/object search is proposed based on the VLAD model and SURF descriptors to improve the codebook construction speed, the image matching accuracy, and the online retrieval speed and to reduce the data storage. First, SURF binarization and dimensionality reduction methods are proposed to convert a 64-dimensional SURF descriptor into an 8-dimensional descriptor. Second, a two-step clustering algorithm is proposed for codebook construction to significantly reduce the computational cost of clustering while maintaining the accuracy of the clustering results. Moreover, for object search, a scalable overlapping partition method is proposed to segment an image into 65 patches with different sizes so that the object can be matched quickly and efficiently. Finally, a feature fusion strategy is employed to compensate the performance degradation caused by the information loss of our proposed dimensionality reduction method. Experiments on the Holidays and Oxford datasets demonstrate the effectiveness and efficiency of the proposed algorithms.",2017,Journal of Visual Communication and Image Representation
RAHMAN2017433,A novel adaptive logic for dynamic adaptive streaming over HTTP,"HTTP-based video streaming, Quality of experience, Video rate adaptation algorithm, Video streaming scheme","In this paper, we propose an estimation method that estimates the throughput of upcoming video segments based on variations in the network throughput observed during the download of previous video segments. Then, we propose a rate-adaptive algorithm for Hypertext Transfer Protocol (HTTP) streaming. The proposed algorithm selects the quality of the video based on the estimated throughput and playback buffer occupancy. The proposed method selects high-quality video segments, while minimizing video quality changes and the risk of playback interruption, improving user’s experience. We evaluate the algorithm for single- and multi-user environments and demonstrate that it performs remarkably well under varying network conditions. Furthermore, we determine that it efficiently utilizes network resources to achieve a high video rate; competing HTTP clients achieve equitable video rates. We also confirm that variations in the playback buffer size and segment duration do not affect the performance of the proposed algorithm.",2017,Journal of Visual Communication and Image Representation
MARTINEZRACH2017274,Optimizing the image R/D coding performance by tuning quantization parameters,"Dead zone quantization, Image coding, Wavelet encoders, Rate distortion performance, Contrast Sensitivity Function, Quality assessment metrics","Uniform quantization schemas with dead zone are widely used in image and video codecs. The design of these quantizers affects to the final R/D performance, being two of the quantizer parameters the responsible for that variations: the dead zone size and the reconstruction point location inside each quantization step. In this work we tune the quantizer to obtain the optimum quantization parameters that provide the best R/D behavior for different quality metrics and rate ranges. Based on a representative image set, we provide the quantization parameters to encode general imagery, with a R/D performance close to the optimum one. The same study was done including the Contrast Sensitivity Function in the quantization stage. After an exhaustive experimental test, the results show that the estimated quantization parameters are able to provide bit rate savings up to 11% at low and moderate bit rates without additional computational cost.",2017,Journal of Visual Communication and Image Representation
ANIBROWNMARY2017225,Coral reef image classification employing Improved LDP for feature extraction,"Classification, Coral reef, Feature extraction, Euclidean distance, KNN, SVM, CLAHE, Contrast stretching","This paper presents a scheme for feature extraction that can be applied for classification of corals in submarine coral reef images. In coral reef image classification, texture features are extracted using the proposed Improved Local Derivative Pattern (ILDP). ILDP determines diagonal directional pattern features based on local derivative variations which can capture full information. For classification, three classifiers, namely Convolutional Neural Network (CNN), K-Nearest Neighbor (KNN) with four distance metrices, namely Euclidean distance, Manhattan distance, Canberra distance and Chi-Square distance, and Support Vector Machine (SVM) with three kernel functions, namely Polynomial, Radial basis function, Sigmoid kernel are used. The accuracy of the proposed method is compared with Local Binary pattern (LBP), Local Tetra Pattern (LTrP), Local Derivative Pattern (LDP) and Robust Local Ternary Pattern (RLTP) on five coral data sets and four texture data sets. Experimental results indicate that ILDP feature extraction method when tested with five coral data sets, namely EILAT, RSMAS, EILAT2, MLC2012 and SDMRI and four texture data sets, namely KTH-TIPS, UIUCTEX, CURET and LAVA achieves the highest overall classification accuracy, minimum execution time when compared to the other methods.",2017,Journal of Visual Communication and Image Representation
QURESHI2017177,A critical survey of state-of-the-art image inpainting quality assessment metrics,"Image inpainting, Image quality assessment, Inpainting quality, Inpainting databases, Image inpainting quality assessment, Survey","Image inpainting is the process of restoring missing pixels in digital images in a plausible way. Research in image inpainting has received considerable attention in different areas, including restoration of old and damaged documents, removal of undesirable objects, computational photography, retouching applications, etc. The challenge is that the recovery processes themselves introduce noticeable artifacts within and around the restored image regions. As an alternative to subjective evaluation by humans, a number of approaches have been introduced to quantify inpainting processes objectively. Unfortunately, existing objective metrics have their own strengths and weaknesses as they use different criteria. This paper provides a thorough insight into existing metrics related to image inpainting quality assessment, developed during the last few years. The paper provides, under a new framework, a comprehensive description of existing metrics, their strengths, their weaknesses, and a detailed performance analysis on real images from public image inpainting database. The paper also outlines future research directions and applications of inpainting and inpainting-related quality assessment measures.",2017,Journal of Visual Communication and Image Representation
CHEN2017283,Quaternion pseudo-Zernike moments combining both of RGB information and depth information for color image splicing detection,"Quaternion, Splicing detection, Pseudo-Zernike moment, Back-propagation neural network, Depth information","The quaternion representation (QR) used in current quaternion-based color image processing creates redundancy when representing a color image of three components by a quaternion matrix having four components. In this paper, both RGB and depth (RGB-D) information are considered to improve QR for efficiently representing RGB-D images. The improved QR fully utilizes the four-dimensional quaternion domain. Using this improved QR, firstly we define the new quaternion pseudo-Zernike moments (NQPZMs) and then propose an efficient computational algorithm for NQPZMs through the conventional pseudo-Zernike moments (PZMs). Finally, we propose an algorithm for color image splicing detection based on the NQPZMs and the quaternion back-propagation neural network (QBPNN). Experimental results on four public datasets (DVMM, CASIA v1.0 and v2.0, Wild Web) demonstrate that the proposed splicing detection algorithm can achieve almost 100% accuracy with the appropriate feature dimensionality and outperforms 14 existing algorithms. Moreover, the comparison of six color spaces (RGB, HSI, HSV, YCbCr, YUV, and YIQ) shows that the proposed algorithm using YCbCr color space has the overall best performance in splicing detection.",2017,Journal of Visual Communication and Image Representation
BOUDECHICHE201714,Distributed video coding based on vector quantization: Application to capsule endoscopy,"Distributed video coding, Wireless capsule endoscopy, Vector quantization, Side information, Image compression","We present in this paper a new distributed video coding (DVC) architecture for wireless capsule endoscopy. It is based on the state of the art DVC systems, but without using key frames. Instead, it uses an adapted vector quantization (VQ) with a searching complexity that is shifted to the decoder. VQ allows creating a good side information (SI) by exploiting the similarities in human anatomy. Thus, SI is created from a codebook (CB) rather than by motion compensated prediction. This approach decreases largely the complexity of the encoder, which codes only Wyner-Ziv frames, and allows a progressive decoding. The encoder of the proposed DVC generates only a simple hash that is used by the decoder to select the corresponding VQ codeword. The obtained experimental results show that rate-distortion results are better than those of JPEG, and show the possibility of using scalable coding to control the used rate and energy.",2017,Journal of Visual Communication and Image Representation
LI201738,Block linear discriminant analysis for visual tensor objects with frequency or time information,"Visual tensors, Discriminant analysis, Hyperspectral face recognition, Gait recognition, Between-class scatter, Within-class scatter","Recently, due to the advancement of acquisition techniques, visual tensor data have been accumulated in a great variety of engineering fields, e.g., biometrics, neuroscience, surveillance and remote sensing. How to analyze and learn with such tensor objects thus becomes an important and growing interest in machine learning community. In this paper, we propose a block linear discriminant analysis (BLDA) algorithm to extract features for visual tensor objects such as multichannel/hyperspectral face images or human gait videos. Taking the inherent characteristic of such tensor data into account, we unfold tensor objects according to their spatial information and frequency/time information, and represent them in a block matrix form. As a result, the block form between-class and within-class scatter matrices are constructed, and a related block eigen-decomposition is solved to extract features for classification. Comprehensive experiments have been carried out to test the effectiveness of the proposed method, and the results show that BLDA outperforms existing algorithms like DATER, 2DLDA, GTDA, UMLDA, STDA and MPCA for visual tensor object analysis.",2017,Journal of Visual Communication and Image Representation
FEZZA2017115,Using distortion and asymmetry determination for blind stereoscopic image quality assessment strategy,"Blind/NR image quality assessment, Stereoscopic images, Distortion classification, Asymmetric distortion, Weighting strategy","Predicting the perceived quality of stereoscopic 3D images is a challenging task, especially when the stereo-pair is asymmetrically distorted. Despite the considerable efforts to fix this issue, there is no commonly accepted metric. Most of the attempts consisted in developing full reference quality metrics, while very few efforts have been dedicated to blind/no-reference (NR) quality assessment of stereoscopic images. In this paper, we propose a blind/NR quality assessment strategy for stereoscopic images based on the identification of the distortion type in order to select the most efficient impairment measure in addition to the determination of whether a stereo-pair is symmetrically or asymmetrically distorted to account for the binocular fusion properties. Finally, the last step combines the two key information derived from previous steps and estimates the 3D image quality appropriately using different binocular combination strategies. Experimental results on four publicly available 3D image quality assessment databases showed that the proposed strategy reaches significant prediction consistency and accuracy when compared to state-of-the-art metrics.",2017,Journal of Visual Communication and Image Representation
BARNI2017153,Aligned and non-aligned double JPEG detection using convolutional neural networks,"Image forensics, Double JPEG detection, Double JPEG localization, Convolutional neural networks","Due to the wide diffusion of JPEG coding standard, the image forensic community has devoted significant attention to the development of double JPEG (DJPEG) compression detectors through the years. The ability of detecting whether an image has been compressed twice provides paramount information toward image authenticity assessment. Given the trend recently gained by convolutional neural networks (CNN) in many computer vision tasks, in this paper we propose to use CNNs for aligned and non-aligned double JPEG compression detection. In particular, we explore the capability of CNNs to capture DJPEG artifacts directly from images. Results show that the proposed CNN-based detectors achieve good performance even with small size images (i.e., 64×64), outperforming state-of-the-art solutions, especially in the non-aligned case. Besides, good results are also achieved in the commonly-recognized challenging case in which the first quality factor is larger than the second one.",2017,Journal of Visual Communication and Image Representation
FURNARI2017401,Next-active-object prediction from egocentric videos,"Egocentric vision, Forecasting, Object interaction, Next-active-object","Although First Person Vision systems can sense the environment from the user’s perspective, they are generally unable to predict his intentions and goals. Since human activities can be decomposed in terms of atomic actions and interactions with objects, intelligent wearable systems would benefit from the ability to anticipate user-object interactions. Even if this task is not trivial, the First Person Vision paradigm can provide important cues to address this challenge. We propose to exploit the dynamics of the scene to recognize next-active-objects before an object interaction begins. We train a classifier to discriminate trajectories leading to an object activation from all others and forecast next-active-objects by analyzing fixed-length trajectory segments within a temporal sliding window. The proposed method compares favorably with respect to several baselines on the Activity of Daily Living (ADL) egocentric dataset comprising 10 h of videos acquired by 20 subjects while performing unconstrained interactions with several objects.",2017,Journal of Visual Communication and Image Representation
WU201778,Image retrieval framework based on texton uniform descriptor and modified manifold ranking,"Image retrieval, Texton uniform descriptor, Modified manifold ranking, Landmark","Image representation and ranking are crucial parts in image retrieval. These two steps are independently constructed in most retrieval models, but the compatibility between descriptors and ranking algorithms play an important role. Inspired by human vision perception and manifold learning, we propose a novel image retrieval framework in this paper. We first propose an image representation called texton uniform descriptor, and then illustrate the preservation of the intrinsic manifold structure through visualizing the distribution of image representations on the two-dimensional manifold. This characteristic provides the foundation for subsequent manifold-based ranking. To further improve the efficiency in image retrieval, we propose modified manifold ranking (MMR) which aims at selecting small-scale images randomly as landmarks to propagate adjacent similarity among images iteratively. The extensive experiments in four public datasets demonstrate that our framework has better performance than other state-of-the-art methods in image retrieval.",2017,Journal of Visual Communication and Image Representation
SENGAR201789,Motion detection using block based bi-directional optical flow method,"Optical flow, Motion detection, Normalization, Block, Morphology","Detecting moving objects from video frame sequences has a lot of useful applications in computer vision. This proposed method of moving object detection first estimates the bi-directional optical flow fields between (i) the current frame and the previous frame and between (ii) the current frame and the next frame. The bi-directional optical flow field is then subjected to normalization and enhancement. Each normalized and enhanced optical flow field is then divided into non-overlapping blocks. The moving objects are finally detected in the form of binary blobs by examining the histogram based thresholded values of such optical flow field of each block as well as the optical flow field of the candidate flow value. Our technique has been conceptualized, implemented and tested on real video data sets with complex background environment. The experimental results and quantitative evaluation establish that our technique achieves effective and efficient results than other existing methods.",2017,Journal of Visual Communication and Image Representation
JING2017371,Novel “Squiral” (square spiral) architecture for fast image processing,"Square spiral (“squiral”) image processing (SIP), Spiral addressing scheme, Eye tremor, Non-overlapping convolution, Fast image processing","Fast image processing is a key element in achieving real-time image and video analysis. We propose a novel framework based on a square spiral (denoted as “squiral”) architecture to facilitate fast image processing. Unlike conventional image pixel addressing schemes, where the pixel indices are based on two-dimensional Cartesian coordinates, the spiral addressing scheme enables the image pixel indices to be stored in a one dimensional vector, thereby accelerating the subsequent processing. We refer to the new framework as “Squiral” Image Processing (SIP). Firstly we introduce the approach for SIP conversion that transforms a standard 2D image to a 1D vector according to the proposed “squiral” architecture. Secondly we propose a non-overlapping convolution technique for SIP-based convolution, in which the SIP addressing scheme is incorporated by simulating the phenomenon of eye tremor in the human visual system. Furthermore, we develop a strategy to extend the SIP framework to be multiscale. The performance of the proposed framework is evaluated by the application of SIP-based approaches to edge and corner detection. The results demonstrate the efficiency of the proposed SIP framework compared with standard 2D convolution.",2017,Journal of Visual Communication and Image Representation
DESHMUKH2017291,A novel approach for sharing multiple color images by employing Chinese Remainder Theorem,"Multi secret sharing scheme, Boolean XOR, Chinese Remainder Theorem, Greatest common divisor, Multiplicative inverse","Conventional approaches for encryption are unsuitable for simultaneously achieving reliability and confidentiality. Threshold-based secret sharing scheme deals with the problem of sharing a secret information into a group of n users and secret can be recovered only when a sufficient users come together, we can reconstruct a secret information from t, where t<n. There is a requirement to evolve a secure secret sharing scheme so that the reconstruction is possible only when all shares are available. In this paper, we propose a secure (n,n)-Multi Secret Sharing (MSS) scheme using Chinese Remainder Theorem (CRT). The proposed scheme shares secret information among n users and for recovery all n users are needed, if one of the user is absent then we could not reconstruct the secret information. The proposed scheme does not reveals the partial secret information, as the randomness in shares is more. The proposed scheme outperforms the existing techniques in terms of randomness and security.",2017,Journal of Visual Communication and Image Representation
SUN2017412,Vehicle counting in crowded scenes with multi-channel and multi-task convolutional neural networks,"Vehicle counting, Urban setting, Semantic feature, Regression, Classification","Vehicle counting in crowded urban setting plays a significant role in public security area. Most existing works on vehicle counting focused on video sequence. Though these techniques has achieved significant progress, it has a significant disadvantage: only moving vehicle could be counted. It is not realistic that vehicles are often stopped in most crowded cases, e.g. carpark and traffic-light intersections. To deal with this issue, in this paper, we propose a novel multi-channel and multi-task convolutional neural networks (CNN) to count vehicles from still images. More specially, we present a novel algorithm to produce illumination invariance image and combine it with original gray image as input channels, which could handle more details. And we deem vehicle counting as a local consistency deep regression problem, using a local label supervised deep CNN model to fit it. Moreover, we utilize surveillance camera view classification as a related task to improve the performance of vehicle counting task and the two tasks are trained end-to-end jointly. To evaluate the proposed model, we collect a real-work dataset for research and extensive experimental results show that the proposed method performs better than existing state-of-the-art methods.",2017,Journal of Visual Communication and Image Representation
GOUIFFES2017447,Color enhanced local binary patterns in covariance matrices descriptors (ELBCM),"Covariance matrices, Region descriptors, LBP, Image matching, Texture, Color, Object retrieval, Person re-identification","This paper proposes a new version of LBP and its inclusion into covariance region descriptors for image matching and recognition. Starting from the non-rotation invariant uniform LBP (called nriLBP), the pattern is described by the cosine and sine values of the angular portion defined by the ‘1’s. The use of this four-value vector leads to a better resilience of the feature to noise and small neighborhood rotations. Several color versions of this feature are proposed. For region description, these local features are included in covariance matrices, noted ELBCM for Enhanced-LBP Covariance Matrix. Experimental evaluations confirm the relevance of the proposed models on three databases designed for texture analysis, object retrieval and person re-identification. A study is also made on the impact of the colorspace included in the covariance descriptor and used for LBP definition. The experiments show that ELBCM has better recognition performance than the 12 other descriptors tested.",2017,Journal of Visual Communication and Image Representation
DUBEY2017141,Local SVD based NIR face retrieval,"Local features, Near-infrared face image, Face retrieval, Singular value decomposition, Local binary pattern","From last decade, local descriptor such as Local Binary Pattern (LBP) is accepted as a very prominent feature descriptor for characterizing the images such as faces. The performance of such descriptors depends upon the local relationship of the image. The local relationship of the image can be utilized in more discriminative and robust way after some preprocessing as compared to the original image. The preprocessed images in the form of 4 sub-bands (i.e. S, U, V, and D sub-bands) are obtained by applying the Singular Value Decomposition (SVD) over the original image. The local descriptors are computed over these sub-bands (mainly S sub-band) and termed as the SVD based local descriptors. The performance of four local descriptors over SVD sub-bands are tested for near-infrared face retrieval using PolyU-NIR and CASIA-NIR face databases, and compared with the results obtained using descriptors without SVD sub-band. The experimental results confirm the superiority of using S sub-band of SVD in terms of performance of the local descriptors over NIR face databases.",2017,Journal of Visual Communication and Image Representation
TANG2017204,An efficient and effective blind camera image quality metric via modeling quaternion wavelet coefficients,"Blind image quality evaluation, Camera image quality, Quaternion wavelet transform, Random forest","As an extension of Discrete and Complex Wavelet Transform, Quaternion Wavelet Transform (QWT) has attracted extensive attention in the past few years, because it can provide better analytic representation for 2D images. The QWT of an image consists of four parts, i.e., one magnitude part and three phase parts. The magnitude is nearly shift-invariant, which characterizes features at any spatial location, and the three phases represent the structure of these features. This indicates that QWT is more powerful in representing image structures, and thus is suitable for image quality evaluation. In this paper, an efficient and effective Camera Image Quality Metric (CIQM) is proposed based on QWT, which is utilized to describe the intrinsic structures of an image. For an image, it is first decomposed by QWT with three scales. Then, for each scale, the magnitude and entropy of the subband coefficients, and natural scene statistics of the third phase are calculated. The magnitude is utilized to describe the generalized spectral behavior, and the entropy is used to encode the generalized information of distortions. Since the third phase of QWT is considered to be texture feature, the natural scene statistics of the third phase of QWT is used to measure structure degradations in the proposed method. All these features reflect the self-similarity and independency of image content, which can effectively reflect image distortions. Finally, random forest is utilized to build the quality model. Experiments conducted on three camera image databases and two multiply distorted image databases have proved that CIQM outperforms the relevant state-of-the-art models for both authentically distorted images and multiply distorted images.",2017,Journal of Visual Communication and Image Representation
DANG20171,Learning location constrained pixel classifiers for image parsing,"Pedestrian parsing, Street-view scene parsing, Local learning, Spatial layout","When parsing images with regular spatial layout, the location of a pixel (x,y) can provide important prior for its semantic label. This paper proposes a technique to leverage both location and appearance information for pixel labeling. The proposed method utilizes the spatial layout of the image by building local pixel classifiers that are location constrained, i.e., trained with pixels from a local neighborhood region only. Our proposed local learning works well in different challenging image parsing problems, such as pedestrian parsing, street-view scene parsing and object segmentation, and outperforms existing results that rely on one unified pixel classifier. To better understand the behavior of our local classifier, we perform bias-variance analysis, and demonstrate that the proposed local classifier essentially performs spatial smoothness over the target estimator that uses appearance information and location, which explains why the local classifier is more discriminative but can still handle mis-alignment. Meanwhile, our theoretical and experimental studies suggest the importance of selecting an appropriate neighborhood size to perform location constrained learning, which can significantly influence the parsing results.",2017,Journal of Visual Communication and Image Representation
LI2017392,Graph-regularized CF with local coordinate for image representation,"Concept factorization, Graph regularization, Local coordinate constraint, Image representation","Concept factorization (CF) has been a powerful data representation method, which has been widely applied in image processing and document clustering. However, traditional CF cannot guarantee the decomposition results of CF to be sparse in theory and do not consider the geometric structure of the databases. In this paper, we propose a graph-regularized CF with local coordinate (LGCF) method, which enforces the learned coefficients to be sparse by using the local coordinate constraint meanwhile preserving the intrinsic geometric structure of the data space by incorporating graph regularization. An iterative optimization method is also proposed to solve the objective function of LGCF. By comparing with the state-of-the-arts algorithms (Kmeans, NMF, CF, LCCF, LCF), experimental results on four popular databases show that the proposed LGCF method has better performance in terms of average accuracy and mutual information.",2017,Journal of Visual Communication and Image Representation
SREENIVAS2017164,Improved image tamper localisation using chaotic maps and self-recovery,"Chaotic maps, Fragile watermarking, Image authentication, Self recovery, Tamper localisation","In this paper an image tamper localisation scheme is proposed in which authentication bits of a 2×2 image block are generated using the chaotic maps. Further the scheme is improved by including a self-recovery method to recover the tampered regions. To improve the quality of the recovered image, two different sets of restoration bits of a block are generated and each one is embedded into randomly selected distinct blocks. The proposed tamper detection scheme performs better than some of the recent schemes proposed by the researchers. The experimental results demonstrate the accuracy and fragility of the tamper detection scheme, and the efficacy of the recovery method.",2017,Journal of Visual Communication and Image Representation
MAGRI201757,Multiple structure recovery with T-linkage,"Multi-model fitting, Grouping, Segmentation","This work addresses the problem of robust fitting of geometric structures to noisy data corrupted by outliers. An extension of J-linkage (called T-linkage) is presented and elaborated. T-linkage improves the preference analysis implemented by J-linkage in term of performances and robustness, considering both the representation and the segmentation steps. A strategy to reject outliers and to estimate the inlier threshold is proposed, resulting in a versatile tool, suitable for multi-model fitting “in the wild”. Experiments demonstrate that our methods perform better than J-linkage on simulated data, and compare favorably with state-of-the-art methods on public domain real datasets.",2017,Journal of Visual Communication and Image Representation
HE2017303,Fast mode decision and PU size decision algorithm for intra depth coding in 3D-HEVC,"3D-HEVC, Mode decision, PU size decision, Fast algorithm","In 3D video extension of High-Efficiency-Video-Coding (3D-HEVC), intra depth coding involves huge computational complexity for the added depth modeling modes (DMMs) and the new complex processing flow. This paper proposes an algorithm including the fast mode and prediction unit (PU) size decisions to accelerate the intra depth coding. For the mode decision, after a modification of the processing flow, three strategies are adopted: (1) evaluation results for intra conventional modes (ICMs) are utilized to determine whether DMMs are skipped; (2) with a predicted direction from ICMs, a golden ratio method is adopted to simplify the DMMs searching; and (3) fast Planar mode decision is made by analyzing the relationship of DMMs and Planar mode. For the fast PU size decision, evaluation costs of ICMs and DMMs, with combination of some trained thresholds, are used to make decisions. Experimental results show the overall algorithm reduces 63.00% computational complexity, with 1.04% BD-rate increasing.",2017,Journal of Visual Communication and Image Representation
HOU2017243,"Combating highly imbalanced steganalysis with small training samples using feature selection,","Steganalysis, Class imbalance, Feature selection, Sampling, Learning algorithms","We consider a particular paradigm of steganalysis, namely, highly imbalanced steganalysis with small training samples, in which the cover images always significantly outnumber the stego ones. Researchers have rigorously studied sampling and learning algorithms as well as feature selection approaches to the class imbalance problem, but the research in the steganalysis domain is rare. This study provides a systematic comparison of eight feature selection metrics and of three types of methods developed for the imbalanced data classification problem in the steganalysis domain. Each metric is compared across three different classifiers and four steganalytic features. The efficiency of the metrics is evaluated to determine which performs best with minimal features selected. The performance of the three types of methods and their combinations is examined. Moreover, we also investigate the effect of feature dimensionality, sample number and imbalance degree on the performance of feature selection inresolving imbalanced image steganalysis.",2017,Journal of Visual Communication and Image Representation
ASLAN2017315,Exploring visual dictionaries: A model driven perspective,"Model-driven, Visual dictionary, Bag of Visual Words, Shape models, Primitive image structures, Image understanding, Object recognition, Scene classification","Good representative dictionaries is the most critical part of the BoVW: Bag of Visual Words scheme, used for such tasks as category identification. The paradigm of learning dictionaries from datasets is by far the most widely used approach and there exists a plethora of methods to this effect. Dictionary learning methods demand abundant data, and when the amount of training data is limited, the quality of dictionaries and consequently the performance of BoVW methods suffer. A much less explored path for creating visual dictionaries starts from the knowledge of primitives in appearance models and creates families of parametric shape models. In this work, we develop shape models starting from a small number of primitives and develop a visual dictionary using various nonlinear operations and nonlinear combinations. Compared with the existing model-driven schemes, our method is able to represent and characterize images in various image understanding applications with competitive, and often better performance.",2017,Journal of Visual Communication and Image Representation
SHU2017361,Speed up kernel dependence maximization for multi-label feature extraction,"Multi-label dimensionality reduction, Dependence maximization, Least squares, Hilbert-Schmidt independence criterion","Kernel dependence maximization for multi-label dimensionality reduction (kMDDM) has been proposed recently to cope with high-dimensional multi-label data. In order to produce discriminant projection vectors, kMDDM utilize the Hilbert-Schmidt independence criterion to capture the dependence between the feature description and the associated labels. However, the computation of kMDDM involves dense matrices eigen-decomposition that is known to be computationally expensive for large scale problems. In this paper, we reformulate the original kMDDM as a least-squares problem, so as to significantly lessen computational burden by utilizing the conjugate gradient algorithms. Further, appealing regularization techniques can be incorporated into the least-squares model to boost the generalization performance. Extensive experiments conducted on benchmark data collections verify the effectiveness of our proposed model.",2017,Journal of Visual Communication and Image Representation
YU2017192,A novel recurrent hybrid network for feature fusion in action recognition,"Deep learning, Action recognition, LSTM, CNNs, IDT","Action recognition in video is one of the most important and challenging tasks in computer vision. How to efficiently combine the spatial-temporal information to represent video plays a crucial role for action recognition. In this paper, a recurrent hybrid network architecture is designed for action recognition by fusing multi-source features: a two-stream CNNs for learning semantic features, a two-stream single-layer LSTM for learning long-term temporal feature, and an Improved Dense Trajectories (IDT) stream for learning short-term temporal motion feature. In order to mitigate the overfitting issue on small-scale dataset, a video data augmentation method is used to increase the amount of training data, as well as a two-step training strategy is adopted to train our recurrent hybrid network. Experiment results on two challenging datasets UCF-101 and HMDB-51 demonstrate that the proposed method can reach the state-of-the-art performance.",2017,Journal of Visual Communication and Image Representation
ZALIK2017420,Boolean operations on rasterized shapes represented by chain codes using space filling curves,"Chain codes, Space filling curves, Hilbert curve, Boolean operations","This paper introduces a new algorithm for Boolean operations on rasterized geometric shapes that are represented with chain codes. The algorithm works in three steps. Firstly, the chain code symbols are transformed in the Hilbert space, where the overlaid chain code symbols are recognised. After that, a suitable starting cell is determined. Finally, the walk-about through the sequence of the initial chain code symbols is performed to obtain the sequence of chain code symbols representing the shape of the required Boolean operation. The algorithm is demonstrated on Freeman chain code in four directions. The time and space complexity of the proposed algorithm is linear, which was proven theoretically and confirmed by experiments.",2017,Journal of Visual Communication and Image Representation
SAFAVI2017338,Cube-based perceptual weighted Kronecker Compressive Sensing: Can we avoid non-visible redundancies acquisition?,"Multidimensional signal, Kronecker Compressive Sensing, Weighted Compressive Sensing, Perceptual compressive sensing","Compressive sensing approach directly avoids the acquisition of statistical redundancies of a signal. However, perceptual redundancies of images and videos due to the human eye sensitivity are not considered so far. Besides, an effective sampling scheme is needed to multidimensional signal reconstruction using a low number of measurements to avoid all redundancies. In this paper, along with the Kronecker structure of the sampling matrix we design various weighting matrices based on the spatio-temporal contrast sensitivity function to avoid acquisition of non-visible redundancies. Moreover, inspired by the block-based compressive sensing, we divide a group of pictures in a video sequence into cubes. Hence, the size of measurement and sparsifying basis matrices are reduced and the reconstruction algorithm can be implemented in parallel. We further show that our simple linear sampling approach can be competitive with motion compensation method. Simulation results verify that our proposed method notably outperforms the other state-of-the-art methods.",2017,Journal of Visual Communication and Image Representation
HE2017351,Reversible data hiding using multi-pass pixel value ordering and prediction-error expansion,"Reversible data hiding, Multi-pass pixel value ordering, Prediction-error expansion, Optimal combined embedding","Pixel value ordering (PVO) prediction has become the most efficient method for high-fidelity reversible data hiding (RDH). In this approach, only the maximum and minimum of pixel block are predicted and modified to embed data and the preservation of pixel value order guarantees the reversibility. To achieve larger embedding capacity and superior performance, more blocks suitable for RDH are utilized in recent improved schemes. However, their performance is still unsatisfactory. In this paper, a novel RDH scheme is proposed by extending original PVO into multi-pass PVO embedding. Specially, the k largest or smallest pixels are taken as independent data bit carriers to fulfill k-pass PVO embedding. Although the pixel value order may change after data embedding, reversibility still can be guaranteed and image redundancy can be far better exploited. Moreover, embedding performance can be further enhanced by optimal combined embedding. Experimental results verify that the proposed scheme outperforms previous PVO-based schemes and some other state-of-the-art works.",2017,Journal of Visual Communication and Image Representation
HAN201727,Saliency detection for panoramic landscape images of outdoor scenes,"Saliency detection, Panoramic image, Wide fields of view, Background estimation, Saliency refinement","Saliency detection has been researched for conventional images with standard aspect ratios, however, it is a challenging problem for panoramic images with wide fields of view. In this paper, we propose a saliency detection algorithm for panoramic landscape images of outdoor scenes. We observe that a typical panoramic image includes several homogeneous background regions yielding horizontally elongated distributions, as well as multiple foreground objects with arbitrary locations. We first estimate the background of panoramic images by selecting homogeneous superpixels using geodesic similarity and analyzing their spatial distributions. Then we iteratively refine an initial saliency map derived from background estimation by computing the feature contrast only within local surrounding area whose range and shape are changed adaptively. Experimental results demonstrate that the proposed algorithm detects multiple salient objects faithfully while suppressing the background successfully, and it yields a significantly better performance of panorama saliency detection compared with the recent state-of-the-art techniques.",2017,Journal of Visual Communication and Image Representation
YAJAI2017257,Adaptive directional bounding box from RGB-D information for improving fall detection,"Fall detection, Comprehensive bounding box, Center of gravity, Aspect ratio, Kinect, Elderly care, Dynamic tracking, Stream data, Arbitrary movement",Fall detection for aging people is still a mainstream research focus for the current aging society. Tools that are simple and inexpensive but have high accuracy rates are needed. RGB-D information retrieved from a home entertainment system was used to detect falls using typical bounding boxes techniques. These techniques have limitations. This research introduced the Adaptive Directional Bounding Box that made use of a comprehensive bounding box and a dynamic state machine in a new way to detect falls. The proposed approach offered a way to track and analyze continuous data streams of the visual images to automatically predict a fall event prior to the fall state in a single-phase instead of the typical two-phases. This can significantly affect the survival or severe injury of the elderly. The proposed method can improve accuracy by 25.5% and the response time by 21.31% on average as compared to existing approaches.,2017,Journal of Visual Communication and Image Representation
MCDANIEL201832,Assessing the quality of domain ontologies: Metrics and an automated ranking system,"Domain ontology, Interoperability, Metrics, Ontology assessment, Ontology evaluation, Ranking, Ontology, Semiotics, Semiotic layers, Domain Ontology Ranking System","The ability of a user to select an appropriate, high-quality domain ontology from a set of available options would be most useful in knowledge engineering and other intelligent applications. This capability, however, requires good quality assessment metrics as well as automated support when there is a large number of ontologies from which to make a selection. This research analyzes existing metrics for domain ontology evaluation and extends them to derive a Layered Ontology Metrics Suite based on semiotic theory. The metrics are implemented in a Domain Ontology Ranking System (DoORS) prototype, the purpose of which is to search an ontology library for specific terms to retrieve candidate domain ontologies and then assess their quality and suitability based upon the suite of metrics. The prototype system is compared to existing approaches to automated ontology quality ranking to illustrate the usefulness of the research.",2018,Data & Knowledge Engineering
FURTADO201816,A branch and bound strategy for Fast Trajectory Similarity Measuring,"Movement data, GPS trajectory similarity, Fast Trajectory Similarity","The increasing use of GPS-enabled devices allowed the collection of huge volumes of movement data in the form of trajectories. An important research problem in trajectory data analysis is the similarity measurement. For most applications, a trajectory-to-trajectory comparison is needed, and therefore, scalability of trajectory similarity measures directly impact the viability to use these techniques. Most similarity measures adopt a dynamic programming implementation, which has a quadratic time complexity in all cases, computing the pair-wise distance for all trajectory points, thus limiting the scalability of these measures. In this article we present a new strategy which takes into account the distance properties in Euclidean spaces to reduce the number of pair-wise point comparison required to determine all the matching points of two trajectories. An extensive experimental evaluation over real GPS trajectory datasets demonstrates the pruning power over 85% in the number of distance computations required to determine the matchings, and a significant execution time speed-up of up to one order of magnitude over the dynamic programming approach.",2018,Data & Knowledge Engineering
NGUYEN2018129,A heuristics approach to mine behavioural data logs in mobile malware detection system,"Mobile security, Situational awareness, Anomaly detection, Incremental machine learning, Natural language processing, Scalable solution design","Nowadays, in the era of Internet of Things when everything is connected via the Internet, the number of mobile devices has risen exponentially up to billions around the world. In line with this increase, the volume of data generated is enormous and has attracted malefactors who do ill deeds to others. For hackers, one of the popular threads to mobile devices is to spread malware. These actions are very difficult to prevent because the application installation and configuration rights are set by owners, who usually have very low knowledge or do not care about the security. In this study, our aim is to improve security in the environment of mobile devices by proposing a novel system to detect malware intrusions automatically. Our solution is based on modelling user behaviours and applying the heuristic analysis approach to mobile logs generated during the device operation process. Although behaviours of individual users have a significant impact on the social cyber-security, to achieve the user awareness has still remained one of the major challenges today. For this task, there is proposed a light-weight semantic formalization in the form of physical and logical taxonomy for classifying the collected raw log data. Then a set of techniques is used, like sliding windows, lemmatization, feature selection, term weighting, and so on, to process data. Meanwhile, malware detection tasks are performed based on incremental machine learning mechanisms, because of the potential complexity of this tasks. The solution is developed in the manner to allow the scalability with several blocks that cover pre-processing raw collected logs from mobile devices, automatically creating datasets for machine learning methods, using the best selected model for detecting suspicious activity surrounding malware intrusions, and supporting decision making using a predictive risk factor. We experimented cautiously with the proposal and achieved test results confirm the effectiveness and feasibility of the proposed system in applying to the large-scale mobile environment.",2018,Data & Knowledge Engineering
BOICEA20181,Sampling strategies for extracting information from large data sets,"Sampling algorithms, Space complexity, Time complexity, Set operations, Data set cardinality, Time optimization","Getting information from large volumes of data is very expensive in terms of resources like CPU and memory, as well as computation time. The analysis of a small data set extracted from the original set is preferred. From this small set, called sample, approximate results can be obtained. The errors are acceptable given the reduced cost necessary for processing the data. Using sampling algorithms with small errors saves execution time and resources. This paper presents comparisons between sampling algorithms in order to determine which one performs better when taking into account set operations such as intersect, union and difference. The comparison focuses on the errors introduced by each algorithm for different sample sizes and on execution times.",2018,Data & Knowledge Engineering
CHARALAMPIDIS2018214,Semantic Web user interfaces – A model and a review,"SPARQL, Data structure, Data relation, Visualization, Exploration, Information retrieval, Agents, Zotero, EasyRDF","In the introduction of the Semantic Web vision, the software agents seek information, perform transactions and interact with physical devices. However, the Semantic Web is not yet fully implemented nor the software agents are yet capable for this critical mission. The access of the Semantic Web is still a task mainly intended for the humans. This access is through the user interfaces and is practiced mostly for information seeking tasks. The goal of this work is to create a review for the issues related to the user interfaces, with respect to their application in the access of the Semantic Web. Therefore we build a model and a web application, to abstract the interaction between the humans and the Semantic Web and investigate the features of the user interfaces as far as the information seeking in the Semantic Web is concerned. At first a study of related literature is performed, and in it are identified and analyzed those distinctive characteristics that a user interface needs to support. Then, it is conducted a field research in the World Wide Web, in order to discover and record Semantic Web's user interfaces. Based on the analysis of the reviewed literature, the model is devised, and the model's formalism is applied to the findings of the field research. After that, it is conducted an evaluation study and with the help of a dedicated application, comparative tables are outlined for reviewing user interfaces.",2018,Data & Knowledge Engineering
COMBI201894,A hybrid logic for XML reference constraints,"XML, DTD, Constraints, Hybrid logics","XML emerged as the (meta) mark-up language for representing, exchanging, and storing semistructured data. The structure of an XML document may be specified either through DTD (Document Type Definition) language or through the specific language XML Schema. While the expressiveness of XML Schema allows one to specify both the structure and constraints for XML documents, DTD does not allow the specification of integrity constraints for XML documents. On the other side, DTD has a very compact notation opposed to the complex notation and syntax of XML Schema. Thus, it becomes important to consider the issue of how to express further constraints on DTD-based XML documents, still retaining the simplicity and succinctness of DTDs. According to this scenario, in this paper we focus on a (as much as possible) simple logic, named XHyb, expressive enough to allow the specification of the most common integrity and reference constraints in XML documents. In particular, we focus on constraints on ID and IDREF(S) attributes, which are the common way of logically connecting parts of XML documents, besides the usual parent-child relationship of XML elements. Differently from other previously proposed hybrid logics, in XHyb IDREF(S) attributes are explicitly expressible by means of suitable syntactical constructors. Moreover, we propose a refinement of the usual graph representation of XML documents in order to represent XML documents in a formal and intuitive way without flatten accessibility through IDREF(S) to the usual parent-child relationship. Model checking algorithms are then proposed, to verify that a given XML document satisfies the considered constraints.",2018,Data & Knowledge Engineering
KLIEGR2018174,Antonyms are similar: Towards paradigmatic association approach to rating similarity in SimLex-999 and WordSim-353,"Word similarity, Word relatedness, WordSim353, SimLex-999","SimLex-999 is a widely used lexical resource for tracking progress in word similarity computation. It anchors similarity in synonymy, while other researchers such as Agirre et al. (2009) adopt broader similarity definition, involving also hyponymy and antonymy relations. Paradigmatic association covers synonymy, antonymy and co-hyponymy relations (Lapesa et al., 2014) largely overlapping with this broader similarity definition. Two words are paradigmatically associated if they can replace one another without affecting the grammaticality or acceptability of the sentence. Paradigmatic association can be elicited by asking for word interchangeability, which we hypothesize might be more natural than instructing raters with a list of relations to consider. To validate the proposed approach, we reannotated WordSim353 and SimLex-999 using two new guidelines: one explicitly qualifying antonymy as a similarity relation, the second one eliciting word interchangeability. As additional datasets we present a crowdsourced version of WordSim353 and a Czech version of SimLex-999. The paper also includes detailed analysis of lexical content of SimLex-999 and benchmark of thesaurus-based and distributional algorithms on multiple word similarity and relatedness datasets.",2018,Data & Knowledge Engineering
GOLPIRA2018116,A novel Multiple Attribute Decision Making approach based on interval data using U2P-Miner algorithm,"Supply chain, Supplier selection, MADM, Knowledge discovery in databases, Uncertainty, Pattern mining, Linear assignment method","This paper aims to introduce a technique for order of preference using pattern mining based on Decision Makers (DMs) level of risk aversion. However, the model is essentially defined on the problem of supplier selection, it can be used to deal with almost any similar decision making problem. This novel Multiple Attribute Decision Making (MADM) model takes the advantages of the U2P-Miner algorithm, the interval data weighting method, and the Linear Assignment Method (LAM). The key idea behind the method is to consider the attribute with more frequent patterns as the common attribute and to assign a smaller weight to it. Since, the model handles interval data as input, it can be guaranteed that the model uses the detailed information and, therefore, the resulting weight factors are more realistic. The DMs risk aversion level is also addressed in the model, which is necessary in real-life situations. Accordingly, the proposed decision making process depends directly on DMs attitude toward risk. It gives DM the opportunity to make a decision in two ways: 1) based on the specified risk aversion level, 2) based on an integrated approach using LAM. The linearity of the LAM, by itself, enhances the scalability of the model. Moreover, the necessity of providing pairwise comparison judgments is completely eliminated in the model and, therefore, the reliability of the decision making is enhanced. The effectiveness of the model is finally demonstrated through a numerical example while the broad comparative and sensitivity analysis further proves its validity and superiority.",2018,Data & Knowledge Engineering
ALSHARUEE2018194,Sentiment analysis: An automatic contextual analysis and ensemble clustering approach and comparison,"Text mining, Sentiment analysis, Unsupervised learning, Contextual analysis, Ensemble learning, k-means algorithm","Product reviews are one of the most important resources to determine public sentiment. The existing literature on review sentiment analysis mostly utilizes supervised models, which usually suffer from domain-dependency and require expensive manual labelling effort to provide training data. This article addresses these issues by describing a completely automatic and unsupervised approach to sentiment analysis. The method consists of two phases, which are contextual analysis and unsupervised ensemble learning. In the implementation of both phases, a sentiment lexicon, SentiWordNet, is deployed. Using effective contextual procedures and modifying the base learning component (the k-means algorithm) results in developing a successful approach to sentiment analysis which can overcome the domain-dependency and the labelling cost problems. The results show that the proposed nonrandom initialization of k-means yields a significant improvement compared to other algorithms. In terms of accuracy and performance, the proposed method is effective compared to supervised and unsupervised approaches. We also introduce new sentiment analysis problems relating to Australian airlines and home builders which could be potential benchmark problems in the sentiment analysis field. Our experiments on datasets from different domains show that contextual analysis and the ensemble phases improve the clustering performance in term of accuracy, stability and generalizability.",2018,Data & Knowledge Engineering
YAGO201848,ON-SMMILE: Ontology Network-based Student Model for MultIple Learning Environments,"Ontological engineering, Student modeling, Ontology network, Learning supervision, Semantic web","Currently, many educational researchers focus on the extraction of information about the learning progress to properly assist students. We present ON-SMMILE, a student-centered and flexible student model which is represented as an ontology network combining information related to (i) students and their knowledge state, (ii) assessments that rely on rubrics and different types of objectives, (iii) units of learning and (iv) information resources previously employed as support for the student model in intelligent virtual environment for training/instruction and here extended. The aim of this work is to design and build methodologically, throughout ontological engineering, the ON-SMMILE model to be used as support of future works closely linked to supervision of student's learning as competence-based recommender system. For this purpose, our model is designed as a set of ontological resources that have been extended, standardized, interrelated and adapted to be used in multiple learning environments. In this paper, we also analyze the available approaches based on instructional design which can be added to ontology network to build the proposed model. As a case study, a chemical experiment in a virtual environment and its instantiation are described in terms of ON-SMMILE.",2018,Data & Knowledge Engineering
SONG201868,"The landscape of smart aging: Topics, applications, and agenda","smart aging, Aged, Well-being, Self-care, Information communication technology","Smart aging is an emerging research topic that has a profound impact on society and well-being of aging population. To the best of our knowledge, there has been no systematic analysis of grasping what research has been conducted on smart aging. Thus, there is no discussion of major issues and future directions of smart aging. In this paper, we provide an overview of smart aging in three ways: 1) to synthesize the components of smart aging based on the comprehensive literature review, 2) to examine the range of topics extracted from 3760 web pages and 3) to analyze the research activities on smart aging by conducting a content analysis of 4500 web pages of the NIH funded organizations' websites related to smart aging. The results of the comprehensive literature review indicate that the discussions on smart aging in the scientific publications are by and large classified into the following three directions: Technologies, Aging Medical Care, and Behavior and Social. In addition, the major topics from search engine datasets, which echoes more general discussions from various different parties, are related to entertainment program and social media, along with medical science and innovation technologies, whereas the research activities of NIH funded organizations focused on cross-disciplinary research in Behavioral and Social science, and Medical Care.",2018,Data & Knowledge Engineering
MARAN2018152,Domain content querying using ontology-based context-awareness in information systems,"Ontology, Context-awareness, Information systems, Ubiquitous computing","Ubiquitous computing technologies have been applied in several areas. However, it still presents a number of challenges, both for the full implementation of technologies and for the integration with existing information systems. One of the main mismatches evidenced by recent works is how context-awareness, a widely used capability in ubiquitous computing and actual information systems with relational databases may be integrated to allow ubiquitous and traditional systems to query relational data sources without the necessity to modify the schema of the database. This paper presents an integration model relating context and domain information allowing relational data to be retrieved in context without the necessity to change the originally used relational queries. A set of linking rules and algorithms are formalized in a model and this model is implemented in a prototype. The evaluation of the model is performed by applying it in a case study in a Massive Open Online Course (MOOC) platform. The evaluation of the model by the application of it in a case study in a MOOC platform demonstrated the possibility to use an ontology frequently used in ubiquitous middleware as an extra filtering layer for information systems without the necessity to recreate queries or make a re-engineering in the relational database schema. The results of the queries after the application of the model showed an average decrease of 21% in returned tuples, which was evaluated as a significant reduce in tuple results.",2018,Data & Knowledge Engineering
AKL201812,A survey of exemplar-based texture synthesis methods,"Non-parametric synthesis, Exemplar, Synthetic texture, Objective analysis, Parametric synthesis, Regular patterns","Texture synthesis has become an important topic in image processing, with many fundamental applications in computer vision and image understanding. The purpose of this survey is to give an overview and classification of texture synthesis approaches. According to how they represent, analyze and synthesize textures, the methods are divided into three families; procedural synthesis, exemplar-based synthesis and model-based synthesis, while focusing on exemplar-based methods including most of the synthesis techniques. Finally, experimental evaluations on different textures show that non-parametric synthesis methods lead to the best results when dealing with regular structured textures while parametric algorithms are better for the synthesis of more irregular textures.",2018,Computer Vision and Image Understanding
LIMBERGER20181,Curvature-based spectral signatures for non-rigid shape retrieval,"Pattern recognition, Laplace equation, Information storage and retrieval, Geometric class field theory","The geometric properties of descriptors derived from the diffusion geometry family have many valuable properties for shape analysis. These descriptors, also known as diffusion distances, use the eigenvalues and eigenfunctions of the Laplace–Beltrami operator to construct invariant metrics about the shape. Although they are invariant to many transformations, non-rigid deformations still modify the shape spectrum. In this paper, we propose a shape descriptor framework based on a Lagrangian formulation of dynamics on the surface of the object. We show how our framework can be applied to non-rigid shape retrieval, once it benefits from the analysis and the automatic identification of shape joints, using a curvature-based scheme to identify these regions. We also propose modifications to the Improved Wave Kernel Signature in order to keep descriptors more stable against non-rigid deformations. We compare our spectral components with the classic ones and our spectral framework with state-of-the-art non-rigid signatures on traditional benchmarks, showing that our shape spectra is more stable and discriminative and clearly outperforms other descriptors in the SHREC’10, SHREC’11 and SHREC’17 benchmarks.",2018,Computer Vision and Image Understanding
SABOKROU201888,Deep-anomaly: Fully convolutional neural network for fast anomaly detection in crowded scenes,"Video anomaly detection, CNN, Transfer learning, Real-time processing","The detection of abnormal behaviour in crowded scenes has to deal with many challenges. This paper presents an efficient method for detection and localization of anomalies in videos. Using fully convolutional neural networks (FCNs) and temporal data, a pre-trained supervised FCN is transferred into an unsupervised FCN ensuring the detection of (global) anomalies in scenes. High performance in terms of speed and accuracy is achieved by investigating the cascaded detection as a result of reducing computation complexities. This FCN-based architecture addresses two main tasks, feature representation and cascaded outlier detection. Experimental results on two benchmarks suggest that the proposed method outperforms existing methods in terms of accuracy regarding detection and localization.",2018,Computer Vision and Image Understanding
WU201850,Direct pose estimation for planar objects,"Pose estimation, Pose tracking, Augmented reality","Estimating six degrees of freedom poses of a planar object from images is an important problem with numerous applications ranging from robotics to augmented reality. While the state-of-the-art Perspective-n-Point algorithms perform well in pose estimation, the success hinges on whether feature points can be extracted and matched correctly on target objects with rich texture. In this work, we propose a two-step robust direct method for six-dimensional pose estimation that performs accurately on both textured and textureless planar target objects. First, the pose of a planar target object with respect to a calibrated camera is approximately estimated by posing it as a template matching problem. Second, each object pose is refined and disambiguated using a dense alignment scheme. Extensive experiments on both synthetic and real datasets demonstrate that the proposed direct pose estimation algorithm performs favorably against state-of-the-art feature-based approaches in terms of robustness and accuracy under varying conditions. Furthermore, we show that the proposed dense alignment scheme can also be used for accurate pose tracking in video sequences.",2018,Computer Vision and Image Understanding
WU201825,Object tracking via Online Multiple Instance Learning with reliable components,"Object tracking, Online multiple instance learning, Reliable component","Visual object tracking is a challenging and essential research problem in the field of computer vision. Recent years, many Online Multiple Instance Learning (MIL) tracking methods have been proposed with promising experimental results. These methods train a discriminative classifier under the boosting framework. The weak classifiers are learned from parts of the object and all classifiers are updated while updating the appearance model. However, due to irregular shape of object or occlusions, some components are not on object and should not be learned. On the contrary, a discriminative weak classifier learned from these components will mislead the tracker to drift away. To overcome this problem, we propose a novel online MIL tracking approach by updating with reliable components (OMRC). It keeps both background and object templates while tracking. By comparing current tracking result with two templates, we can get whether the pixels belong to object. The components which have a higher rate of pixels belong to object than a predefined threshold are reliable components. Moreover, in order to represent images better, we use HOG features and Histogram features instead of the widely used Haar-like features and design a new online weak classifier learning method. Experiments are performed on two challenging datasets including OTB2015 and Temple Color. Experimental results demonstrate the robustness of our OMRC tracker and the effectiveness of each component in the OMRC tracker.",2018,Computer Vision and Image Understanding
ZAHEER2018107,Single-View Reconstruction using orthogonal line-pairs,"3D Reconstruction, Single-View Reconstruction, Multi-planar scenes, Orthogonal angles, Angle regularity, Urban environment","Multi-planar buildings and man-made structures are characterized by a profusion of parallel and orthogonal lines. In this paper, using orthogonal line-pairs as the primary feature, we describe an automatic algorithm to recover 3D structure of a multi-planar scene from a single image. First, we show how the presence of such regular angles can be used for 2D rectification of an image of a plane to a fronto-parallel view. Next, by exploiting this ability to rectify scene planes, we propose an automatic Single-View Reconstruction (SVR) method, assuming there are enough orthogonal line-pairs available on each plane. This angle regularity is only imposed on physically intersecting line-pairs, making it a local constraint. Furthermore, we also describe a novel algorithm to automatically segment planes within a scene, and discover their extents and adjacency relationships, using only orthogonal line-pairs. Unlike earlier literature, our approach does not make restrictive assumptions about the orientation of the planes or the camera view, and works for both indoor and outdoor scenes. Results are shown on challenging images which would be difficult to reconstruct for existing automatic SVR algorithms.",2018,Computer Vision and Image Understanding
GAY2018124,Factorization based structure from motion with object priors,"Structure from motion, Object detection, Affine camera, Probabilistic matrix factorization, Scene semantic","This paper presents an efficient framework to include the information of objects position in classical multi-view geometry problems for 3D reconstruction. In particular, we present two main contributions to Structure from Motion (SfM) using factorization methods for the affine camera case. First, we introduce a method based on factorization that extends the classical 3D point cloud reconstruction based on 2D point correspondences to objects using detection correspondences. In this case, objects are approximated as quadrics in 3D (or more specifically as ellipsoids) and therefore projected as conics in 2D onto the image plane. Therefore, instead of having 2D point to point correspondences, we solve a conic to conic correspondence problem in the setting of affine factorization methods. The solution to this problem provides a 3D location/occupancy of the object together with an affine camera calibration. This is shown to be a generalisation of the standard Tomasi and Kanade factorization method with rigid objects. Secondly, we use the estimated object locations/occupancies to robustly estimate the 3D point cloud from 2D point correspondences by constructing a prior that relates 2D points locations and the positions of the object ellipsoids in 3D. This is done by recasting the problem as a probabilistic matrix factorization where the priors are not generic but truly representative of the scene structure as a composition of objects. In particular we show that by using objects to points relations, we achieve compelling results with high rate of missing data and noisy 2D data, a common occurrence when dealing with man-made textureless objects.",2018,Computer Vision and Image Understanding
MURABITO201867,Top-down saliency detection driven by visual classification,"Visual attention, Image classification, Fully convolutional neural networks","This paper presents an approach for saliency detection able to emulate the integration of the top-down (task-controlled) and bottom-up (sensory information) processes involved in human visual attention. In particular, we first learn how to generate saliency when a specific visual task has to be accomplished. Afterwards, we investigate if and to what extent the learned saliency maps can support visual classification in nontrivial cases. To achieve this, we propose SalClassNet, a CNN framework consisting of two networks jointly trained: a) the first one computing top-down saliency maps from input images, and b) the second one exploiting the computed saliency maps for visual classification. To test our approach, we collected a dataset of eye-gaze maps, using a Tobii T60 eye tracker, by asking several subjects to look at images from the Stanford Dogs dataset, with the objective of distinguishing dog breeds. Performance analysis on our dataset and other saliency benchmarking datasets, such as POET, showed that SalClassNet outperforms state-of-the-art saliency detectors, such as SalNet and SALICON. Finally, we also analyzed the performance of SalClassNet in a fine-grained recognition task and found out that it yields enhanced classification accuracy compared to Inception and VGG-19 classifiers. The achieved results, thus, demonstrate that 1) conditioning saliency detectors with object classes reaches state-of-the-art performance, and 2) explicitly providing top-down saliency maps to visual classifiers enhances accuracy.",2018,Computer Vision and Image Understanding
LU201877,Lightweight convolutional neural networks for player detection and classification,"Player detection, Player classification, CNN, Team membership","Vision-based player detection and classification are important in sports applications. Accuracy, efficiency, and low memory consumption are desirable for real-time tasks such as intelligent broadcasts and event classification. In this paper, we present a convolutional neural network (CNN) that satisfies all these requirements. The network contains a three-branch proposal network and a four-cascade classification network. Our method first trains these cascaded networks from labeled image patches. Then, we efficiently apply the network to a whole image by using a dilation strategy in testing. We conducted experiments on soccer, basketball, ice hockey and pedestrian datasets. Experimental results demonstrate that our method can accurately detect players under challenging conditions. Compared with CNNs that are adapted from general object detection networks such as Faster-RCNN, our approach achieves state-of-the-art accuracy on three types of games (basketball, soccer and ice hockey) with 1000 × fewer parameters. The generality of our method is also demonstrated on a standard pedestrian detection dataset in which our method achieves competitive performance compared with state-of-the-art methods.",2018,Computer Vision and Image Understanding
GONZALEZBRIONES201898,A multi-agent system for the classification of gender and age from images,"Facial recognition, Automatic age estimation, Automatic gender estimation, Preprocessing of images, Multi-agent system","The automatic classification of human images on the basis of age range and gender can be used in audiovisual content adaptation for Smart TVs or marquee advertising. Knowledge about users is used by publishing agencies and departments regulating TV content; on the basis of this information (age, gender) they are able to provide content that suits the interests of users. To this end, the creation of a highly precise image pattern recognition system is necessary, this may be one of the greatest challenges faced by computer technology in the last decades. These recognition systems must apply different pattern recognition techniques, in order to distinct gender and age in the images. In this work, we propose a multi-agent system that integrates different techniques for the acquisition, preprocessing and processing of images for the classification of age and gender. The system has been tested in an office building. Thanks to the use of a multi-agent system which allows to apply different workflows simultaneously, the performance of different methods could be compared (each flow with a different configuration). Experimental results have confirmed that a good preprocessing stage is necessary if we want the classification methods to perform well (Fisherfaces, Eigenfaces, Local Binary Patterns, Multilayer perceptron). The Fisherfaces method has proved to be more effective than MLP and the training time was shorter. In terms of the classification of age, Fisherfaces offers the best results in comparison to the rest of the system’s classifiers. The use of filters has allowed to reduce dimensionality, as a result the workload was reduced, a great advantage in a system that performs classification in real time.",2018,Computer Vision and Image Understanding
IQBAL201837,A dual-source approach for 3D human pose estimation from single images,"3D human pose estimation, Motion capture, 3D reconstruction, Articulated pose estimation","In this work we address the challenging problem of 3D human pose estimation from single images. Recent approaches learn deep neural networks to regress 3D pose directly from images. One major challenge for such methods, however, is the collection of large amounts of training data. Particularly, collecting a large number of unconstrained images that are annotated with accurate 3D poses is impractical. We therefore propose to use two independent training sources. The first source consists of accurate 3D motion capture data, and the second source consists of unconstrained images with annotated 2D poses. To incorporate both sources, we propose a dual-source approach that combines 2D pose estimation with efficient 3D pose retrieval. To this end, we first convert the motion capture data into a normalized 2D pose space, and separately learn a 2D pose estimation model from the image data. During inference, we estimate the 2D pose and efficiently retrieve the nearest 3D poses. We then jointly estimate a mapping from the 3D pose space to the image and reconstruct the 3D pose. We provide a comprehensive evaluation of the proposed method and experimentally demonstrate the effectiveness of our approach, even when the skeleton structures of the two sources differ substantially.",2018,Computer Vision and Image Understanding
FLOREA2018220,Artistic movement recognition by consensus of boosted SVM based experts,"Randomized boosted SVMs, Multi-scale topography, Painting style recognition, Consensus of experts, Ensembles","In this work we aim to automatically recognize the artistic movement from a digitized image of a painting. Our approach uses a new system that resorts to descriptions induced by color structure histograms and by novel topographical features for texture assessment. The topographical descriptors accumulate information from the first and second local derivatives within four layers of finer representations. The classification is performed by two layers of ensembles. The first is an adapted boosted ensemble of support vector machines, which introduces further randomization over feature categories as a regularization. The training of the ensemble yields individual experts by isolating initially misclassified images and by correcting them in further stages of the process. The solution improves the performance by a second layer build upon the consensus of multiple local experts that analyze different parts of the images. The resulting performance compares favorably with classical solutions and manages to match the ones of modern deep learning frameworks.",2018,Journal of Visual Communication and Image Representation
SU2018234,Graph regularized low-rank tensor representation for feature selection,"Unsupervised feature selection, Low-rank tensor representation, Graph embedding, Subspace clustering","Recently, considerable efforts have been made in feature selection to improve the original feature subspace. In this paper, we proposed a graph regularized low-rank tensor representation (GRLTR) for feature selection. We jointly incorporated the low-rank representation and the graph embedding into a unified learning framework to preserve the intrinsic global low-dimension structure and local geometrical structure of data together. According to the wide presence of multidimensional data, our proposed framework is based on tensor, which can faithfully maintain the information. To improve the performance of specific clustering task, we employed the idea of embedded-based feature selection into our model for optimizing the feature representation and clustering result simultaneously. Experimental results on six available datasets suggest our proposed approach produces superior performances compared with several state-of-the-art methods.",2018,Journal of Visual Communication and Image Representation
LIU2018131,Content adaptive interpolation filters based on HEVC framework,"HEVC, Interpolation, Adaptive, Filter, Fractional samples","Motion compensation is the key technique to reduce temporal redundancy in video coding. Interpolation filters are adopted to generate the inter frame prediction for motion compensation with fractional pixel accuracy. In existing video coding standards such as H.264/AVC and HEVC, a set of predefined interpolation filters is adopted in motion compensation. However, predefined interpolation filters cannot adapt to the video content, which may compromise the coding efficiency. In this paper, a content adaptive interpolation scheme is proposed for motion compensation. In the proposed scheme, a set of adaptive interpolation filters is derived for each frame as additional interpolation filters to minimize the inter prediction difference. Rate-distortion optimization is employed to choose between the predefined interpolation filters and the derived adaptive interpolation filters to achieve the best coding performance at the low bit rates. The proposed scheme is implemented into the HM 12.1 software. Experimental results show that the proposed scheme achieves 5.13 percent, 3.42 percent and 4.07 percent bit rate saving on average compared with HEVC under the “low delay P”, the “low delay B” and the “random access” configurations respectively.",2018,Journal of Visual Communication and Image Representation
GAO2018305,3D object recognition based on pairwise Multi-view Convolutional Neural Networks,"3D object recognition, CNN, Multi-view, PMV-CNN, Pairwise, End-to-end","With the development of 3D sensors, it will be much easier for us to obtain 3D models, which is prevailing in our future daily life, but up to now, although many 3D object recognition algorithms have been proposed, there are some limitations, including the lack of training samples, hand-crafted feature representation, feature extraction and recognition separately. In this work, we propose a novel pairwise Multi-View Convolutional Neural Network for 3D Object Recognition (PMV-CNN for short), where automatic feature extraction and object recognition are put into a unify CNN architecture. Moreover, since the pairwise network architecture is utilized in PMV-CNN, thus, the requirement of the number of training samples in the original dataset is not severe. In addition, the latent complementary relationships from different views can be highly explored by view pooling. Large scale experiments demonstrate that the pairwise architecture is very useful when the number of labeled training samples is very small. Moreover, it also makes more robust feature extraction. Furthermore, since the end-to-end network architecture is employed in PMV-CNN, thus, the extracted feature is very suitable for 3D object recognition, whose performance is much better than that of hand-crafted features. In a word, the performance of our proposed method outperforms state-of-the-art methods.",2018,Journal of Visual Communication and Image Representation
OSZUST201815,No-reference image quality assessment with local features and high-order derivatives,"Image quality assessment, No-reference, Local features, Support vector regression","The perceptual quality of images is often affected by applied image processing techniques. Their evaluation requires tests which involve human subjects. However, in most cases, image quality assessment (IQA) should be automatic and reproducible. Therefore, in this paper, a novel no-reference IQA method is proposed. The method uses high-order derivatives to extract detailed structure deformation present in distorted images. Furthermore, it employs local features, considering that only some regions of an image carry interesting information. Then, statistics of local features are used by a support vector regression technique to provide an objective quality score. To improve the quality prediction, luminance and chrominance channels of the image are processed. Experimental results on six large-scale public IQA image datasets show that the proposed method outperforms the state-of-the-art hand-crafted and deep-learning techniques in terms of the visual quality prediction accuracy. Furthermore, the method is better than popular full-reference approaches (i.e., SSIM and PSNR).",2018,Journal of Visual Communication and Image Representation
YANG2018167,The spatial correlation problem of noise in imaging deblurring and its solution,"Spatial correlation coefficient, Noise probability distribution model, Colour interpolation, Colour space transformation, Correction algorithm, Image deblurring","We describe the spatial correlation problem of noise in colour digital images and analyse its cause. Pixel-correlated image processing procedures, such as CFA colour interpolation and colour space transformation, mainly lead to this problem. Considering this problem, we propose a new noise model based on a joint Gaussian probability distribution. Furthermore, we present an algorithm that makes the revised noise model fit the existing image deconvolution well. The parameters of our algorithm depend only on the image processing procedures of the imaging system. Finally, we apply the proposed algorithm to revise two typical image deconvolution methods and perform simulations and real-world experiments. Both the quantitative indicators and visual performance of the image deblurring results show that the revised deconvolution methods based on our noise model behave better in reducing the noise and ringing artefacts, thus improving the image quality compared with the methods that use the original noise model.",2018,Journal of Visual Communication and Image Representation
ZHANG20181,Robust visual tracking via multi-feature response maps fusion using a collaborative local-global layer visual model,"Collaborative visual model, Block color tracking, Correlation filter tracking, Response maps fusion, Online re-detection","This paper addresses the issue of robust visual tracking, in which an effective tracker based on multi-feature fusion under a collaborative local-global layer visual model is proposed. In the local layer, we implement a novel block tracker using structural local color histograms feature based on the foreground-background discrimination analysis approach. In the global layer we implement a complementary correlation filters-based tracker using HOG feature. Finally, the local and global trackers are linearly merged in the response maps level. We choose the different merging factors according to the reliability of each combined tracker, and when both of the combined trackers are unreliable, an online trained SVM detector is activated to re-detect the target. Experiments conducted on challenging sequences show that our final merged tracker achieves favorable tracking performance and outperforms several state-of-the-art trackers. Besides, performance of the implemented block tracker is evaluated by comparing with some relevant color histograms-based trackers.",2018,Journal of Visual Communication and Image Representation
RACHMADI2018265,Single image vehicle classification using pseudo long short-term memory classifier,"Pseudo-LSTM classifier, Vehicle classification, Deep convolutional network","In this paper, we propose a pseudo long short-term memory (LSTM) classifier for single image vehicle classification. The proposed pseudo-LSTM (P-LSTM) uses spatially divided images rather than time-series images. In other words, the proposed method considers the divided images to be time-series frames. The divided images are formed by cropping input images using two-level spatial pyramid region configuration. Parallel convolutional networks are used to extract the spatial pyramid features of the divided images. To explore the correlations between the spatial pyramid features, we attached an LSTM classifier to the end of the parallel convolutional network and treated each convolutional network as an independent timestamp. Although LSTM classifiers are typically used for time-dependent data, our experiments demonstrated that they can also be used for non-time-dependent data. We attached one fully connected layer to the end of the network to compute a final classification decision. Experiments on an MIO-TCD vehicle classification dataset show that our proposed classifier produces a high evaluation score and is comparable with several other state-of-the-art methods.",2018,Journal of Visual Communication and Image Representation
CHONG2018207,Discriminative kernel-based metric learning for face verification,"Face verification, Metric learning, Kernel machine, Discriminant analysis","This paper outlines a simplistic formulation for doublet constrained discriminative metric learning framework for face verification. The Mahalanobis distance metric of the framework is formulated by leveraging the within-class scatter matrix of the doublet and a quadratic kernel function. Unlike existing metric learning methods, the proposed framework admits efficient solution attributed to the convexity nature of the kernel machines. We demonstrate three realizations of the proposed framework based on the well-known kernel machine instances, namely Support Vector Machine, Kernel Ridge Regression and Least Squares Support Vector Machine. Due to wide availability of off-the-shelf kernel learner solvers, the proposed method can be easily trained and deployed. We evaluate the proposed discriminative kernel-based metric learning with two types of face verification setup: standard and unconstrained face verification through three benchmark datasets. The promising experimental results corroborate the feasibility and robustness of the proposed framework.",2018,Journal of Visual Communication and Image Representation
FAN2018182,A discriminative dynamic framework for facial expression recognition in video sequences,"Histogram of gradients, Facial expression, Feature extraction","Facial expression involves a dynamic process, leading to the variation of different facial components over time. Thus, dynamic descriptors are essential for recognising facial expressions. In this paper, we extend the spatial pyramid histogram of gradients to spatio-temporal domain to give 3-dimensional facial features. To enhance the spatial information, we divide the whole face region into a group of smaller local regions to extract local 3D features, and a weighting strategy based on fisher separation criterion is proposed to enhance the discrimination ability of local features. A multi-class classifier based on support vector machine is applied for recognising facial expressions. Experiments on the CK+ and MMI datasets using leave-one-out cross validation scheme show that the proposed framework perform better than using the descriptor of simple concatenation. Compared with state-of-the-art methods, the proposed framework demonstrates a superior performance.",2018,Journal of Visual Communication and Image Representation
LIU201873,Joint foveation-depth just-noticeable-difference model for virtual reality environment,"Just-noticeable-difference, Depth, Foveation, Stereoscopic images, Virtual reality environment","In this paper, we develop a joint foveation-depth just-noticeable-difference (FD-JND) model to quantify the perceptual redundancy of image in the VR display environment. The proposed FD-JND model is developed with considerations on the effects of both foveation and depth. More specifically, experiments for the VR environment on synthesized stimuli are conducted based on luminance masking and contrast masking and the FD-JND model is developed accordingly. Subjective quality discrimination experiments between the noise contaminated images and original ones validate favorableness of the proposed FD-JND model.",2018,Journal of Visual Communication and Image Representation
FEI2018139,An overview of face-related technologies,"Face recognition, Face enhancement, 3D face reconstruction, Deep learning","In recent years, information technology is developing continuously and set off a burst of artificial intelligence boom in the field of science. The development of advanced technologies such as unmanned driving and AI chips, is the extensive application of artificial intelligence. Face-related technologies have a wide range of applications because of intuitive results and good concealment. Since 3D face information can provide more comprehensive facial information than 2D face information, and it can solve many difficulties that cannot be solved in 2D face recognition. Therefore, more and more researchers have studied 3D face recognition in recent years. Under the new circumstances, the research on face are experiencing all kinds of challenges. With the tireless of many scientists, the new technology is also making a constant progress, and in the development of many technologies it still maintained its leading position. In this paper, we simply sort out the present development process of facial correlation technology, and the general evolution of this technology is outlined. Finally, the practical significance of this technology development is briefly discussed.",2018,Journal of Visual Communication and Image Representation
HAN2018287,View synthesis using foreground object extraction for disparity control and image inpainting,"Virtual view synthesis, DIBR, Disparity control, Exemplar-based inpainting, Foreground object extraction","Among the rapidly growing three-dimensional technologies, multiview displays have drawn great research interests in three-dimensional television due to their adaption to the motion parallax and wider viewing angles. However, multiview displays still suffer from dazzling discomfort on the border of viewing zones. Leveraging on the separability of scene via foreground segmentation, we propose a novel virtual view synthesis method for depth-image-based rendering to alleviate the discomfort. Foreground objects of interest are extracted to segment the whole image into multiple layers, which are further warped to the virtual viewpoint in order. To alleviate the visual discomfort, global disparity adjustments and local depth control are performed for specific objects in each layer. For the post-processing, we improve an exemplar-based inpainting algorithm to tackle the disoccluded areas. Experimental results demonstrate that our method achieves effective disparity control and generates high-quality virtual view images.",2018,Journal of Visual Communication and Image Representation
SHI2018256,Unsupervised multi-view feature extraction with dynamic graph learning,"Multi-view feature extraction, Intrinsic sample relations, Dynamic graph learning","Graph-based multi-view feature extraction has attracted much attention in literature. However, conventional solutions generally rely on a manually defined affinity graph matrix, which is hard to capture the intrinsic sample relations in multiple views. In addition, the graph construction and feature extraction are separated into two independent processes which may result in sub-optimal results. Furthermore, the raw data may contain adverse noises that reduces the reliability of the affinity matrix. In this paper, we propose a novel Unsupervised Multi-view Feature Extraction with Dynamic Graph Learning (UMFE-DGL) to solve these limitations. We devise a unified learning framework which simultaneously performs dynamic graph learning and the feature extraction. Dynamic graph learning adaptively captures the intrinsic multiple view-specific relations of samples. Feature extraction learns the projection matrix that could accordingly preserve the dynamically adjusted sample relations modelled by graph into the low-dimensional features. Experimental results on several public datasets demonstrate the superior performance of the proposed approach, compared with state-of-the-art techniques.",2018,Journal of Visual Communication and Image Representation
SUN201883,General-to-specific learning for facial attribute classification in the wild,"Facial attribute, Deep convolutional network, Joint learning, Task-aware learning","Recent studies have shown that facial attributes provide useful cues for a number of applications such as face verification. However, accurate facial attribute interpretation is still a formidable challenge in real life due to large head poses, occlusion and illumination variations. In this work, we propose a general-to-specific deep convolutional network architecture for predicting multiple attributes from a single image in the wild. First, we model the interdependencies among all attributes by joint learning them all. Second, task-aware learning is adopted to explore the disparity regarding each attribute. Finally, an attribute-aware face cropping scheme is proposed to extract more discriminative features from where a certain attribute naturally shows up. The proposed learning strategy ensures both robustness and performance of our model. Extensive experiments on two challenging publicly available datasets demonstrate the effectiveness of our architecture and the superiority to state-of-the-art alternatives.",2018,Journal of Visual Communication and Image Representation
WILLIEM201838,Cost aggregation benchmark for light field depth estimation,"Light field, Depth estimation, Cost aggregation, Weighted rank, Benchmark","Light field depth estimation has become a mature research topic and there are numerous algorithms introduced by various research groups. However, comprehensive and fair benchmark is difficult to apply because there are large step variances of the introduced algorithms. It is essential to analyze each step in the light field depth estimation so that it could help design better and more robust algorithms. Thus, a thorough analysis of cost aggregation is conducted in this paper to analyze the performance of various cost aggregation methods on light field depth estimation. A study on the parameter setting for each cost aggregation method is performed. Then, each cost aggregation with its optimal parameters is evaluated individually. Instead of using the standard rank system, this paper utilizes the weighted rank system based on the score difference on each criterion. Experimental results confirm that the guided-filter based method outperforms other methods in most evaluation criteria.",2018,Journal of Visual Communication and Image Representation
JIANG2018177,Analysis of security operation and maintenance system using privacy utility in media environment,"KVM, Safety, Operation and maintenance control, Intelligent management","At present, the power information room mostly adopts the analog KVM matrix, or adopts the digital KVM matrix, but there are various defects in the two methods. In order to solve the problem of traditional mode, this paper developed a new security operation and maintenance management system composed of 5 parts. It also has the advantages of traditional mode and overcomes the shortcomings of the traditional model. First, introduces the advantages and disadvantages of two kinds of traditional model, puts forward the necessity of improving; then, the security operation management system each part of the design, and set out to achieve its function; finally carries on the analysis of security. The results show that the security operation and maintenance management system improves the security of the system and helps the system to operate more intelligently and safely based on the guarantee of the required functions.",2018,Journal of Visual Communication and Image Representation
LI201892,Visual tracking via context-aware local sparse appearance model,"Visual tracking, Local sparse representation, Spatial-temporal context, Dictionary update","Most existing local sparse trackers are prone to drifting away as they do not make use of discriminative information of local patches. In this paper, we propose an effective context-aware local sparse appearance model to alleviate the drift problem caused by background clutter and occlusions. First, considering that different local patches should have different impacts on the likelihood computation, we present a novel Impact Allocation Strategy (IAS) with integration of the spatial-temporal context. Varying positive impact factors are adaptively assigned to different local patches based on their ability distinguishing the spatial context, which provides discriminative information to prevent the tracker from drifting. Furthermore, we exploit temporal context to introduce some historical information for more accurate locating. Second, we present a new patch-based dictionary update method being able to update each patch independently with the validation of effectiveness. On the one hand, we introduce sparsity concentration index to check whether the local patch to be updated is a valid local patch from the target object. On the other hand, spatial context is further employed to eliminate the effect of the background. Experimental results show the superiority and competitiveness of the proposed method on the benchmark data set compared to other state-of-the-art algorithms.",2018,Journal of Visual Communication and Image Representation
SHIJILA2018188,Moving object detection by low rank approximation and l1-TV regularization on RPCA framework,"Moving object detection, Low rank recovery, Background subtraction, Robust principle component analysis","The detection of moving objects and the subtraction of the scene background are significant tasks for intelligent video surveillance systems as it is one among the fundamental steps. Inspired by the challenging cases yet to be resolved in Moving Object Detection (MOD), a new formulation is done to detect moving objects from video sequences based on Robust Principal Component Analysis (RPCA) principle by adopting the regularization of Total Variation (TV) norm using a convergent convex optimization algorithm. While the nuclear norm exploits the low-rank property of background, the sparsity is enhanced by the l1-norm and the foreground spatial smoothness is explored by TV regularization. The goodness of this method lies in the reduced computational complexity, quickness and on the superiority acquired in quantitative evaluation based on F-measure, Recall and Precision with respect to the state of the art methods.",2018,Journal of Visual Communication and Image Representation
PANDA201852,A new Wronskian change detection model based codebook background subtraction for visual surveillance applications,"Visual surveillance, Moving object detection, Background subtraction, Dynamic backgrounds, Wronskian change detection model, Codebook model","Background subtraction (BS) is a popular approach for detecting moving objects in video sequences for visual surveillance applications. In this paper, a new multi-channel and multi-resolution Wronskian change detection model (MCMRWM) based codebook background subtraction is proposed for moving object detection in the presence of dynamic background conditio ns. In the prooed MCMRWM, the multi-channel information helps to reduce the false negative of the foreground object; and the multi-resolution data suppresses the background noise resulting in reduced false positives. The proposed algorithm considers the ratio between feature vectors of current frame to the background model or its reciprocal in an adaptive manner, depending on the l2 norm of the feature vector, which helps to detect the foreground object completely without any false negatives. Extensive experiments are carried out with challenging video sequences to show the efficacy of the proposed algorithm against state-of-the-art BS techniques.",2018,Journal of Visual Communication and Image Representation
HUNG2018144,Image up-sampling using deep cascaded neural networks in dual domains for images down-sampled in DCT domain,"DCT up-sampling, Interpolation, Super-resolution, Deep neural networks","Recent researches show that the high-frequency discrete cosine transform (DCT) coefficients can be estimated from low-frequency DCT coefficients by exploiting the spatial correlations. Hence, images coded by DCT such as JPEG/MJPEG/H.264, etc., can be down-sampled in DCT domain, where the high-frequency information can be accurately restored through image up-sampling. In this letter, we propose a novel deep neural network using the cascaded fully connected layers and convolution layers in dual domains (DCT and spatial domains), in order to restore high-frequency DCT coefficients from observed low-frequency DCT coefficients by exploiting the DCT inter-block and spatial correlations. In the proposed network, many recent techniques are adopted, including residual network in dual domains, batch normalization, denseNet, etc. Experimental results show that the proposed cascaded networks in dual domains significantly outperforms the state-of-the-art DCT up-sampling methods in terms of PSNR (0.63–2.57 dB gain), SSIM values, and subjective evaluations on standard image datasets Set5 and Set14.",2018,Journal of Visual Communication and Image Representation
JIANG2018201,Camera network analysis for visual surveillance in electric industrial context,"Camera network, Topology, Sparse, Visual surveillance","Society is rapidly accepting the use of a wide variety of cameras location and applications: site traffic monitoring, parking lot surveillance, car and smart space. The camera provides data every day in an analysis by an effective way. Recent advances in sensor technology manufacturing, communications and computing are stimulating. The development of new applications that can change the traditional vision system incorporating universal smart camera network was processed. This analysis of visual cues in multi camera networks makes wide applications ranging from smart home and office automation to large area surveillance and traffic surveillance. And dense Camera networks, most of which have large overlapping areas of cameras. In the view of good research, we focus on sparse camera networks. One sparse camera network using large area surveillance was developed. As few cameras as possible, most cameras do not overlap each other’s field of vision. This task is challenging. Lack of knowledge of topology network, the specific changes in appearance and movement track different opinions of the target, as well as difficulties understanding complex events in a network were observed. In this review, we present a comprehensive survey of recent studies. Results to solve the problem of topology learning, object appearance modeling and global activity understanding sparse camera network were determined. In addition, some of the current open research issues are discussed.",2018,Journal of Visual Communication and Image Representation
LIAN2018296,Attention guided U-Net for accurate iris segmentation,"Iris segmentation, U-Net, Attention","Iris segmentation is a critical step for improving the accuracy of iris recognition, as well as for medical concerns. Existing methods generally use whole eye images as input for network learning, which do not consider the geometric constrain that iris only occur in a specific area in the eye. As a result, such methods can be easily affected by irrelevant noisy pixels outside iris region. In order to address this problem, we propose the ATTention U-Net (ATT-UNet) which guides the model to learn more discriminative features for separating the iris and non-iris pixels. The ATT-UNet firstly regress a bounding box of the potential iris region and generated an attention mask. Then, the mask is used as a weighted function to merge with discriminative feature maps in the model, making segmentation model pay more attention to iris region. We implement our approach on UBIRIS.v2 and CASIA.IrisV4-distance, and achieve mean error rates of 0.76% and 0.38%, respectively. Experimental results show that our method achieves consistent improvement in both visible wavelength and near-infrared iris images with challenging scenery, and surpass other representative iris segmentation approaches.",2018,Journal of Visual Communication and Image Representation
YANG201827,Hybrid of extended locality-constrained linear coding and manifold ranking for salient object detection,"Salient object detection, Complex scene, Locality-constrained Linear Coding (LLC), Manifold ranking, Region classification, Region clustering","Recent years have witnessed great progress of salient object detection methods. However, due to the emerging complex scenes, two problems should be solved urgently: one is on the fast locating of the foreground while preserving the precision, and the other is about reducing the noise near the foreground boundary in saliency maps. In this paper, a hybrid method is proposed to ameliorate the above two issues. At first, to reduce the essential runtime of integrating the prior knowledge, a novel Prior Knowledge Learning based Region Classification (PKL-RC) method is proposed for classifying image regions and preliminarily locating foreground; furthermore, to generate more accurate saliency, a Locality-constrained Linear self-Coding based Region Clustering (LLsC-RC) model is proposed to improve the adjacency structure of the similarity graph for Manifold Ranking (MR). Experimental results demonstrate the effectiveness and superiority of the proposed method in both higher precision and better smoothness.",2018,Journal of Visual Communication and Image Representation
ZHANG2018150,Adaptive total variation-based spectral-spatial feature extraction of hyperspectral image,"Hyperspectral image classification, Principal component analysis, Adaptive total variation filtering, Extreme learning machine","In this paper, a simple yet quite useful hyperspectral images (HSI) classification method based on adaptive total variation filtering (ATVF) is proposed. The proposed method consists of the following steps: First, the spectral dimension of the HSI is reduced with principal component analysis (PCA). Then, ATVF is employed to extract image features which not only reduces the noise in the image, but also effectively exploits spatial–spectral information. Therefore, it can provide an improved representation. Finally, the efficient extreme learning machine (ELM) with a very simple structure is used for classification. This paper analyzes the influence of different parameters of the ATVF and ELM algorithm on the classification performance in detail. Experiments are performed on three hyperspectral urban data sets. By comparing with other HSI classification methods and other different feature extraction methods, the proposed method based on the ATVF algorithm shows outstanding performance in terms of classification accuracy and computational efficiency when compared with other hyperspectral classification methods.",2018,Journal of Visual Communication and Image Representation
TU2018160,Classification of hyperspectral images via weighted spatial correlation representation,"Hyperspectral image, Superpixel, Joint sparse representation, Correlation coefficient","Superpixel segmentation has been widely applied in hyperspectral image (HSI) classification. In this letter, a weighted spatial correlation representation (WSCR) method for HSI classification is proposed where an effective metric spatial correlation representation (SCR) that measures the correlation coefficient (CC) among different pixels in the superpixels is described, which fully utilizes the spatial information and structural features of superpixels. In addition, considering that the contribution of each SCR is different, the Gaussian weighted is considered. The proposed method includes the following steps: First, a superpixels image is obtained from HSI based on the entropy rate superpixel (ERS) algorithm. Second, the WSCRs for the training and test samples are calculated. Then, a joint sparse representation (JSR) classification is used to obtain the representation residuals of different pixels. Finally, the class label of each pixel is determined by the defined decision function that combines the WSCR and JSR. Experimental results obtained on two real HSI datasets demonstrate the superiority of the proposed methods compared to other widely used methods in terms of classification accuracy.",2018,Journal of Visual Communication and Image Representation
DEHNAVI2018106,Cost and power efficient FPGA based stereo vision system using directional graph transform,"FPGA, Stereo vision, Hardware architecture, Disparity map","3D information of an environment using stereo cameras is important information for navigation of intelligent systems. The cost, power, accuracy, and speed are four important parameters in these systems. In this article, an accurate, real-time, low-power and low-cost system is provided to extract disparity maps in a stereo vision, using FPGA hardware platform. First, a new transform based on directional graphs is proposed. Then, benefiting from this graph transform and cross-based matching method, disparity map is computed. By using optimized hardware for the proposed transform and algorithm, we have obtained an accurate, low-cost, low-power and fast stereo vision system. The proposed system is fully implemented on relatively low cost FPGA platform, XC7K160t, in order to operate as a Standalone system. This system uses 40 K registers, 31 K LUTs, 215 memory blocks, and 258 DSP blocks of this FPGA. The proposed system is tested and evaluated in Middlebury dataset. The results show that the proposed stereo system can process a HD quality video at 60 frames per second for 64 disparity levels with only 7.1% error in the final disparity map. The total power consumption of the proposed stereo vision core is about 1 W.",2018,Journal of Visual Communication and Image Representation
KANSO2018245,An efficient lossless secret sharing scheme for medical images,"Secret sharing, Secret image sharing, -threshold scheme, Chaos","Medical doctors use diagnostic imaging techniques such as X-rays, CT scans and MRI, for detecting diseases or narrowing down possible causes of pain. This often require sharing and transmitting medical images over public channels. In this work we adapt Shamir’s secret sharing paradigm to propose a novel lossless scheme for secure sharing of medical images. The proposed scheme takes advantage of the redundancy in typical medical images to reduce share sizes, and hence facilitate storing and sharing. To this end, we employ a customized run-length encoding method to compress the medical image. We conduct an extensive performance analysis on the proposed scheme, including a comparison with some existing Shamir-type secret image sharing schemes.",2018,Journal of Visual Communication and Image Representation
TONG2018116,"A new framework of action recognition with discriminative parts, spatio-temporal and causal interaction descriptors","Action recognition, Spectral clustering, Discriminative constraint, Action part, Spatio-temporal relationship, Causal relationship","To improve action recognition performance, a novel discriminative spectral clustering method is firstly proposed, by which the candidate parts with the internal trajectories being close in spatial position, consistent in appearance and similar in motion velocity are mined. Furthermore, the discriminative constraint is introduced to select discriminative parts. Meanwhile, by fully considering the local and global distributions of data, a new similarity matrix is constructed, which enhances clustering effect. Secondly, the spatio-temporal interaction descriptor and causal interaction descriptor are constructed respectively, which fully mine the spatio-temporal and implicit causal interactive relationships between parts. Finally, a new framework is proposed. By associating the discriminative parts, spatio-temporal and causal interaction descriptors together as the inputs of Latent Support Vector Machine (LSVM), the correlations between action categories and action parts as well as interaction descriptors are mined. Consequently, accuracy is enhanced. The extensive and adequate experiments demonstrate the effectiveness of the proposed method.",2018,Journal of Visual Communication and Image Representation
HU2018275,"Can a machine have two systems for recognition, like human beings?","Image annotation, Multi-labeling, Hierarchical tree structure, Feature-pool selection","Artificial Intelligence has attracted much of researchers’ attention in recent years. A question we always ask is: “Can machines replace human beings to some extent?” This paper aims to explore the knowledge learning for an image-annotation framework, which is an easy task for humans but a tough task for machines. This paper’s research is based on an assumption that machines have two systems of thinking, each of which handles the labels of images at different abstract levels. Based on this, a new hierarchical model for image annotation is introduced. We explore not only the relationships between the labels and the features used, but also the relationships between labels. More specifically, we divide labels into several hierarchies for efficient and accurate labeling, which are constructed using our Associative Memory Sharing method, proposed in this paper.",2018,Journal of Visual Communication and Image Representation
YANG201879,Video super-resolution based on spatial-temporal recurrent residual networks,"Spatial residue, Temporal residue, Video super-resolution, Inter-frame motion context, Intra-frame redundancy","In this paper, we propose a new video Super-Resolution (SR) method by jointly modeling intra-frame redundancy and inter-frame motion context in a unified deep network. Different from conventional methods, the proposed Spatial-Temporal Recurrent Residual Network (STR-ResNet) investigates both spatial and temporal residues, which are represented by the difference between a high resolution (HR) frame and its corresponding low resolution (LR) frame and the difference between adjacent HR frames, respectively. This spatial-temporal residual learning model is then utilized to connect the intra-frame and inter-frame redundancies within video sequences in a recurrent convolutional network and to predict HR temporal residues in the penultimate layer as guidance to benefit estimating the spatial residue for video SR. Extensive experiments have demonstrated that the proposed STR-ResNet is able to efficiently reconstruct videos with diversified contents and complex motions, which outperforms the existing video SR approaches and offers new state-of-the-art performances on benchmark datasets.",2018,Computer Vision and Image Understanding
OLIVEIRA2018172,A bi-directional evaluation-based approach for image retargeting quality assessment,"Image retargeting, Feature extraction, Keypoint detection, Quality assessment","Image retargeting is a technique that adjusts input images into arbitrary dimensions (rows and columns) and simultaneously preserves regions of interest. Assess the image quality under varying aspect ratio is significantly more challenging since it requires content matching in addition to semantic content analysis. In this work, we propose an objective quality assessment algorithm for image retargeting, called bi-directional importance map similarity (BIMS). The key step in our approach is to assess quality in image retargeting through some features in a bi-directional way, all in a feature fusion framework. The motivation behind employing bi-directional features is because the nature of them is useful to estimate pertinent locations where we can analyze whenever relevant content is missing or any visual distortion arises. Our proposal was assessed on a well-known state-of-the-art dataset in which human viewers provided their personal opinions on the perceptual quality. Due to the experimental results obtained, we consider the BIMS is a good choice for quality assessment of retargeted images.",2018,Computer Vision and Image Understanding
LI201864,Modified non-local means for super-resolution of hybrid videos,"Adaptive parameters, Hybrid video, Non-local means, Non-local self similarity, Super-resolution","Hybrid videos that contain periodic low-resolution (LR) frames and high-resolution (HR) guide frames are largely used for the consideration of bandwidth efficiency and the tradeoff between spatial and temporal resolution. Super-resolution (SR) algorithms are necessary to refine the LR frames, in which non-local means (NLM) is a promising algorithm. NLM replaces every pixel with a weighted average of its neighbors based on non-local self-similarity between pixels. However, the fixed decaying factor of NLM cannot satisfy regions of distinct characteristics in LR frames. The fixed neighborhood or the so-called searching window fails to balance the requirements of low computation and advanced video quality. In this paper, we propose novel criteria to choose the parameters adaptively. The decaying factor is defined by patch difference of a pixel and guarantees NLM to find relevant pixels. Two methods, namely a predefined method inspired by motion estimation and an exhaustive method by searching progressively enlarged neighborhood are proposed to determine the neighborhood size. Bilateral adjacent HR guide frames are used to handle the occlusion problem. We also analyze the defined patch difference on pixel-, frame-, and sequence-level and reveal its influence on the algorithm. The experimental results verify the validity of the proposed method.",2018,Computer Vision and Image Understanding
MONTEIRO2018104,Depth range accuracy for plenoptic cameras,"Standard plenoptic camera, Projection, Reconstruction, Depth range","Plenoptic cameras capture the directional information of the light distribution from a scene. This is accomplished by positioning a microlens array between the main lens and the sensor. This configuration obtains multiple projections for a point in the object space, which allows to retrieve the point’s depth on a single exposure. In recent years, several studies recover depth and shape from the lightfield data using several cues. Nonetheless, references regarding the depth capabilities of a standard plenoptic camera with different zoom and focus settings are scarce. In this work, we formalize a forward projection model and consider projection geometry cues to improve a metric reconstruction methodology for a calibrated standard plenoptic camera. The metric reconstruction methodology is used to evaluate the depth estimation accuracy under certain zoom and focus settings. The reconstruction is applied to new datasets captured for this purpose with objects placed at depths between 0.05 and 2.00 meters. The results indicate that these cameras are able to reconstruct accurately points within the depth range analyzed by appropriately choosing the zoom and focus depth settings. The zoom is a determinant factor on the reconstruction accuracy and the focus depth allows to determine the reconstruction depth range.",2018,Computer Vision and Image Understanding
BENZI201821,A bio-inspired synergistic virtual retina model for tone mapping,"Tone mapping, HDR, Retina, Photoreceptor adaptation, Contrast gain control, Synergistic model","Real-world radiance values span several orders of magnitudes which have to be processed by artificial systems in order to capture visual scenes with a high visual sensitivity. Interestingly, it has been found that similar processing happens in biological systems, starting at the retina level. So our motivation in this paper is to develop a new video tone mapping operator (TMO) based on a synergistic model of the retina. We start from the so-called Virtual Retina model, which has been developed in computational neuroscience. We show how to enrich this model with new features to use it as a TMO, such as color management, luminance adaptation at photoreceptor level and readout from a heterogeneous population activity. Our method works for video but can also be applied to static images (by repeating images in time). It has been carefully evaluated on standard benchmarks in the static case, giving comparable results to the state-of-the-art using default parameters, while offering user control for finer tuning. Results on HDR videos are also promising, specifically w.r.t. temporal luminance coherency. As a whole, this paper shows a promising way to address computational photography challenges by exploiting the current research in neuroscience about retina processing.",2018,Computer Vision and Image Understanding
SCHEDL201893,Optimized sampling for view interpolation in light fields using local dictionaries,"Light fields, Sampling, View interpolation, Superresolution, Compressed sensing",We present an angular superresolution method for light fields captured with a sparse camera array. Our method uses local dictionaries extracted from a sampling mask for upsampling a sparse light field to a dense light field by applying compressed sensing reconstruction. We derive optimal sampling masks by minimizing the coherence for representative global dictionaries. The desired output perspectives and the number of available cameras can be arbitrarily specified. We show that our method yields qualitative improvements compared to previous techniques.,2018,Computer Vision and Image Understanding
WEI2018132,Specular highlight reduction with known surface geometry,"Specular reflection, Diffuse reflection, 3D geometry, Robust PCA","The separation of reflection components is an important issue in computer graphics, computer vision, and image processing. This is a highly ill-posed problem since the number of unknowns to solve is much larger than the number of equations. We present a method to reduce the difficulty of this problem by assuming that surface geometry is known. A novel objective function based on robust principal component analysis is proposed to simultaneously separate specularities and estimate the position of light source. We develop an Augmented Lagrangian Multiplier based algorithm to solve the objective function efficiently and effectively. Experimental results on real-world and synthetic data demonstrate the effectiveness of our method.",2018,Computer Vision and Image Understanding
LI201837,Clustering based content and color adaptive tone mapping,"High dynamic range, Tone mapping, Clustering","By extracting image luminance channel and separating it into a base layer and a detail layer, the Retinex theory has been widely adopted for tone mapping to visualize high dynamic range (HDR) images on low dynamic range display devices. Many edge-preservation filtering techniques have been proposed to approximate the base layer for Retinex image decomposition; however, the associated tone mapping methods are prone to halo artifacts and false colors because filtering methods are limited in adapting the complex image local structures. We present a statistical clustering based tone mapping method which can more faithfully adapt image local content and colors. We decompose each color patch of the HDR image into three components, patch mean, color variation and color structure, and cluster the patches into a number of clusters. For each cluster, an adaptive subspace can be easily learned by principal component analysis, via which the patches are transformed into a more compact domain for effective tone mapping. Comparing with the popular edge-preservation filtering methods, the proposed clustering based method can better adapt to image local structures and colors by exploiting the image global redundancy. Our experimental results demonstrate that it can produce high-quality image with well-preserved local contrast and vivid color appearance. Furthermore, the proposed method can be extended to multi-scale for more faithful texture preservation, and off-line subspace learning for efficient implementation.",2018,Computer Vision and Image Understanding
ABEBE20183,Towards an automatic correction of over-exposure in photographs: Application to tone-mapping,"Image enhancement, Over-exposure correction, High dynamic range imaging, Tone-mapping","A common artifact in photographs is over-exposure due to bright scene features exceeding the abilities of the camera, and causing image areas to appear flat and lacking in detail. Although a wider luminance range could be captured with HDR techniques, this is often not possible, especially in moving scenes. To address this issue, we propose a novel solution for recovering lost details in clipped and over-exposed areas by taking advantage of channel cross-correlation in RGB images. To automate our approach we propose two improvements: (1) using the image white point, we adaptively estimate a clipping threshold value per image, and (2) to better understand the forms of over-exposure, for an optimal selection of parameters, we construct an image database focusing on over-exposed areas and automatically classify over-exposure as light sources, specular highlights or diffuse surfaces. We evaluate our solution using objective metrics and a subjective study based on an ITU standard protocol, showing that our correction leads to improved results compared to previous related techniques. We explore several potential applications of our method, including extending to video as well as using it as a preprocessing step prior to reverse tone mapping.",2018,Computer Vision and Image Understanding
LAGHRIB201850,Simultaneous deconvolution and denoising using a second order variational approach applied to image super resolution,"Multiframe super resolution, Bilateral TV filter, Bounded hessian space, Second order regularization, Relaxed function","The aim of a Super resolution (SR) technique is to construct a high-resolution image from a sequence of observed low-resolution ones of the same scene. One major roadblock of an SR reconstitution is removing noise and blur without destroying edges. We propose a novel multiframe image SR algorithm based on a convex combination of Bilateral Total Variation and a non-smooth second order variational regularization, using a controlled weighting parameter. We prove the existence of a minimizer of the proposed energy in the space of functions of bounded Hessian. The minimization of the convex functional is performed with a fast primal-dual algorithm. The simulation results and real experiments show the performance of the proposed algorithm in avoiding undesirable artifacts compared to other methods in the literature.",2018,Computer Vision and Image Understanding
EMBERTON2018145,Underwater image and video dehazing with pure haze region segmentation,"Dehazing, Image processing, Segmentation, Underwater, White balancing, Video processing","Underwater scenes captured by cameras are plagued with poor contrast and a spectral distortion, which are the result of the scattering and absorptive properties of water. In this paper we present a novel dehazing method that improves visibility in images and videos by detecting and segmenting image regions that contain only water. The colour of these regions, which we refer to as pure haze regions, is similar to the haze that is removed during the dehazing process. Moreover, we propose a semantic white balancing approach for illuminant estimation that uses the dominant colour of the water to address the spectral distortion present in underwater scenes. To validate the results of our method and compare them to those obtained with state-of-the-art approaches, we perform extensive subjective evaluation tests using images captured in a variety of water types and underwater videos captured onboard an underwater vehicle.",2018,Computer Vision and Image Understanding
GIACHETTI2018118,A novel framework for highlight reflectance transformation imaging,"Multi light image collections, Highlight reflectance transformation imaging, Photometric stereo, Image enhancement","We propose a novel pipeline and related software tools for processing the multi-light image collections (MLICs) acquired in different application contexts to obtain shape and appearance information of captured surfaces, as well as to derive compact relightable representations of them. Our pipeline extends the popular Highlight Reflectance Transformation Imaging (H-RTI) framework, which is widely used in the Cultural Heritage domain. We support, in particular, perspective camera modeling, per-pixel interpolated light direction estimation, as well as light normalization correcting vignetting and uneven non-directional illumination. Furthermore, we propose two novel easy-to-use software tools to simplify all processing steps. The tools, in addition to support easy processing and encoding of pixel data, implement a variety of visualizations, as well as multiple reflectance-model-fitting options. Experimental tests on synthetic and real-world MLICs demonstrate the usefulness of the novel algorithmic framework and the potential benefits of the proposed tools for end-user applications.",2018,Computer Vision and Image Understanding
WANG2018157,Blind image deblurring using elastic-net based rank prior,"Image deblurring, Non-local self-similarity, Kernel estimation","In this paper, we propose a new image prior for blind image deblurring. The proposed prior exploits similar patches of an image and it is based on an elastic-net regularization of singular values. We quantitatively verify that it favors clear images over blurred images. This property is able to facilitate the kernel estimation in the conventional maximum a posterior (MAP) framework. Based on this prior, we develop an efficient optimization method to solve the proposed model. The proposed method does not require any complex filtering strategies to select salient edges which are critical to the state-of-the-art deblurring algorithms. We also extend the prior to deal with non-uniform image deblurring problem. Quantitative and qualitative experimental evaluations demonstrate that the proposed algorithm performs favorably against the state-of-the-art deblurring methods.",2018,Computer Vision and Image Understanding
GUL201880,A multiple criteria credit rating approach utilizing social media data,"Credit rating, Cumulative belief degrees, Sentiment analysis, Social media, Web mining, Text mining","Credit rating is a process for building a classification system for credit lenders to characterize current or potential credit borrowers. By such a process, financial institutions classify borrowers for lending decision by evaluating their financial and/or nonfinancial performances. Recently, use of social media data has emerged an important source of information. Accordingly, social media data can be very useful in evaluating companies' credibility when financial or non-financial assessments are missing or unreliable as well as when credit analyzers' subjective perceptions manipulate the decision. In this study, a multiple criteria credit rating approach is proposed to determine companies' credibility level utilizing social media data as well as financial measures. Additionally, to strengthen the lender's interpretation and inference competency, ratings are represented with a risk distribution based on cumulative belief degrees. Sentiment analysis, a web mining and text classification method, is used to collect social media data on Twitter. Importance of criteria is revealed through pairwise comparisons. Companies' performance scores and ratings are obtained by a cumulative belief degree approach. The proposed approach is applied to 64 companies. Results indicate that social media provides valuable information to determine companies' creditability. However credit ratings tend to decrease when social media data is considered.",2018,Data & Knowledge Engineering
LYU201821,Privacy-preserving collaborative fuzzy clustering,"Participatory sensing, Collaborative learning, Clustering, Privacy-preserving, Randomisation","The proliferation of Internet of Things devices has contributed to the emergence of participatory sensing (PS), where multiple individuals collect and report their data to a third-party data mining cloud service for analysis. The need for the participants to collaborate with each other for this analysis gives rise to the concept of collaborative learning. However, the possibility of the cloud service being semi-honest poses a key challenge: preserving the participants' privacy. In this paper, we address this challenge with a two-stage scheme called RG+RP: in the first stage, each participant perturbs his/her data by passing the data through a nonlinear function called repeated Gompertz (RG); in the second stage, he/she then projects his/her perturbed data to a lower dimension in an (almost) distance-preserving manner, using a specific random projection (RP) matrix. The nonlinear RG function is designed to mitigate maximum a posteriori (MAP) estimation attacks, while random projection resists independent component analysis (ICA) attacks and ensures clustering accuracy. The proposed two-stage randomisation scheme is assessed in terms of its recovery resistance to MAP estimation attacks. Preliminary theoretical analysis as well as experimental results on synthetic and real-world datasets indicate that RG+RP has better recovery resistance to MAP estimation attacks than most state-of-the-art techniques. For clustering, fuzzy c-means (FCM) is used. Results using seven cluster validity indices, root mean squared error (RMSE) and accuracy ratio show that clustering results based on two-stage-perturbed data are comparable to the clustering results based on raw data — this confirms the utility of our privacy-preserving scheme when used with either FCM or HCM.",2018,Data & Knowledge Engineering
MARTINRODILLA2018177,"Assessing data analysis performance in research contexts: An experiment on accuracy, efficiency, productivity and researchers’ satisfaction","Data-analysis, Software-assistance, Data-analysis measurement, Data-analysis performance, Cognitive processes","Any knowledge generation process involves raw data comprehension, evaluation and inferential reasoning. These practices, common to different disciplines, are known as data analysis, and represent the most important set of activities in research contexts. Researchers use data analysis software methods and tools for generating new knowledge in their daily data analysis. In recent years, data analysis software has been incorporating explicit references in modelling of cognitive processes, in order to improve the assistance offered in data analysis tasks. However, data analysis software commercial suites are still resisting this inclusion, and there is little empirical work done in knowing more about how cognitive aspects inclusion in software helps researchers in analyzing data. In this paper, we evaluate the impact produced by the explicit inclusion of cognitive processes in the assistance logic of software tools design and development. We conducted an empirical experiment comparing data analysis performance using traditional software versus data analysis performance using software-assistance tools which incorporate cognitive processes in their design. The experiment is designed in terms of accuracy, efficiency, productivity and user satisfaction during the data analysis made by researchers. It allowed us to find some clear benefits of the cognitive inclusion in the software designed for research contexts, with statistically significant differences in terms of accuracy, productivity and researcher's satisfaction in support of this explicit inclusion, although some efficiency weaknesses are detected. We also discuss the implications of these results for the priority of cognitive inclusion in the software tools design for research contexts data analysis.",2018,Data & Knowledge Engineering
CHEN2018124,A cost-effective solution for blog search,"Blog search, Aspect model, EM algorithm, NGD, Machine learning","In recent years, blogging research has grown rapidly in social networks and the number of posts has continued to grow. An effective search method for these growing posts is to use a blog search engine to help bloggers quickly and accurately find the information they need. The blog search engine faces an important problem of the short query entered by the user like the general search engine. This problem makes it difficult for search engines to correctly define the nature of user queries. Relevant literature shows that many researchers have tried to solve this problem by using different semantic analysis models. However, these models are not suitable for big data environments such as search engines because they need significant computing time. In this paper, we propose a semantic analysis model with a dynamic judgment mechanism. According to the experimental results, our model can achieve a cost-effective solution in computing time and execution performance. That is, we can use a relatively small amount of computing time to achieve a near-optimal solution performance.",2018,Data & Knowledge Engineering
PAPANIKOLAOU201842,Hierarchical partitioning of the output space in multi-label data,"Knowledge discovery, Machine learning, Supervised learning, Text mining","Hierarchy Of Multi-label classifiERs (HOMER) is a multi-label learning algorithm that breaks the initial learning task to several, easier sub-tasks by first constructing a hierarchy of labels from a given label set and secondly employing a given base multi-label classifier (MLC) to the resulting sub-problems. The primary goal is to effectively address class imbalance and scalability issues that often arise in real-world multi-label classification problems. In this work, we present the general setup for a HOMER model and a simple extension of the algorithm that is suited for MLCs that output rankings. Furthermore, we provide a detailed analysis of the properties of the algorithm, both from an aspect of effectiveness and computational complexity. A secondary contribution involves the presentation of a balanced variant of the k means algorithm, which serves in the first step of the label hierarchy construction. We conduct extensive experiments on six real-world data sets, studying empirically HOMER's parameters and providing examples of instantiations of the algorithm with different clustering approaches and MLCs, The empirical results demonstrate a significant improvement over the given base MLC.",2018,Data & Knowledge Engineering
MEZNI2018100,A cloud services recommendation system based on Fuzzy Formal Concept Analysis,"Cloud computing, Recommender system, Cloud service recommendation, Collaborative filtering, Fuzzy Formal Concept Analysis","Cloud computing is an attractive paradigm which offers variant services on demand. Many available cloud services offer the same or similar functionalities, which made it challenging for cloud users to choose a suitable service that meets with their preferences. Existing service selection approaches were not enough to solve this challenge. That's why researchers went for recommendation approaches trying to find a solution. Cloud service recommendation has become an important technique for cloud services. It helps users decide whether a service satisfies their requirements or not. However, two main recommendation problems remain unsolved yet, data sparsity and cold start. In addition, existing solutions mostly tried to adapt techniques inherited from Web service and e-commerce domains. This approach is not always adequate due to many reasons such as the cloud architecture, the various service models, etc. To address the problems stated above, we propose a Collaborative Filtering based recommendation system for cloud services using Fuzzy Formal Concept Analysis (Fuzzy FCA). Fuzzy FCA has a solid mathematical foundation and it's based on the lattice theory. The lattice representation will give an explicit description of our cloud environment (users, services, ratings, etc.) and, then, extract the pertinent information from it (similar users to an active user, ratings of each similar user, top services, etc.) which will make the recommendations more suitable. Experimental results confirmed our expectations and proved the efficiency of such an approach.",2018,Data & Knowledge Engineering
BAYOUDHI2018138,How to Repair Inconsistency in OWL 2 DL Ontology Versions?,"OWL 2 DL ontology, Evolution, Inconsistency, A priori approach","Semantic modeling knowledge formalisms, such as ontologies, have to follow the continuous evolution and changes of knowledge. However, ontology changes should never affect its consistency. Ontology needs to remain in a consistent state along its whole engineering process. In the literature, most of approaches check/repair ontology inconsistencies in an a posteriori way. In this paper, an a priori inconsistency approach was proposed to generate consistent OWL 2 DL ontology versions. It relies on the OWL 2 DL change kits, which anticipate inconsistencies upon each change request on an ontology version. The proposed approach predicts potential inconsistencies, provides an a priori repair action and applies the required changes. Consistency rules were defined and used to check logical inconsistencies, but also syntactical invalidities and style issues. A protégé plugin was implemented to validate our approach.",2018,Data & Knowledge Engineering
XU2018205,Expert recommendation for trouble ticket routing,"Trouble ticket, Resolution recommendation, Sequence mining, Signature","A trouble ticket is an important information carrier in system maintenance, which records problem symptoms, the resolving process, and resolutions. A critical challenge for the ticket management system is how to quickly assign a proper expert to deal with trouble tickets and fix problems. Thousands of tickets bouncing among multiple experts before being fixed will consume limited system maintenance resources and may also violate the service level agreement (SLA). Thus, for an incoming ticket, an expert should be recommended as quickly as possible in order to reduce the processing delay. In this paper, to address the challenge in the expert assignment, we exploit an expert collaboration network model by combining expertise profiles and social profiles learned from problem descriptions and resolution sequences of the historical resolved tickets, and develop several two-stage expert recommendation algorithms to determine a resolver to solve the problem. To evaluate the effectiveness of expert recommendation algorithms, we conduct extensive experiments on a real ticket data set. The experimental results show that the proposed algorithms can effectively shorten the mean number of steps to resolve (MSTR) with a high recommendation precision, especially for the long routing sequences generated from manual assignments. The proposed model and algorithms have the potential of being used in a ticket routing recommendation engine to greatly reduce human intervention in the routing process.",2018,Data & Knowledge Engineering
DONG20181,Secure partial encryption with adversarial functional dependency constraints in the database-as-a-service model,"Database-as-a-service, Data outsourcing, Security, integrity, and protection, Database management, Management of integrity constraints","Cloud computing enables end-users to outsource their dataset and data management needs to a third-party service provider. One of the major security concerns of the outsourcing paradigm is how to protect sensitive information in the outsourced dataset. In some applications, only partial values are considered sensitive. In general, the sensitive information can be protected by encryption. However, data dependency constraints (together with the unencrypted data) in the outsourced data may serve as adversary knowledge and bring security vulnerabilities to the encrypted data. In this paper, we focus on functional dependency (FD), an important type of data dependency constraints, and study the security threats by the adversarial FDs. We design a practical scheme that can defend against the FD attack by encrypting a small amount of non-sensitive data (encryption overhead). We prove that finding the scheme that leads to the optimal encryption overhead is NP-complete, and design efficient heuristic algorithms, under the presence of one or multiple FDs. We design a secure query rewriting scheme that enables the service provider to answer various types of queries on the encrypted data with provable security guarantee. We extend our study to enforce security when there are conditional functional dependencies (CFDs) and data updates. We conduct an extensive set of experiments on two real-world datasets. The experiment results show that our heuristic approach brings small amounts of encryption overhead (at most 1% more than the optimal overhead), and enjoys a 10-time speedup compared with the optimal solution. Besides, our approach can reduce up to 90% of the encryption overhead of state-of-the-art solution.",2018,Data & Knowledge Engineering
LIU201861,Mechanisms to improve clustering uncertain data with UKmeans,"Uncertain data, Clustering, Centroid boundary","Uncertain data in Kmeans clustering, namely UKmeans, have been discussed in decade years. UKmeans clustering, however, has some difficulties of time performance and effectiveness because of the uncertainty of objects. In this study, we propose some modified UKmeans clustering mechanisms to improve the time performance and effectiveness, and to enable the clustering to be more complete. The main issues include (1) reducing the consideration of time performance in clustering, (2) increasing the effectiveness of clustering, and (3) considering the determination of the number of clusters. In time performance, we use simplified object expressions to reduce the time spent in comparing similarities. Regarding the effectiveness of clustering, we propose compounded factors including the distance, the overlapping of clusters and objects, and the cluster density as the clustering standard to determine similarity. In addition, to increase the effectiveness of clustering, we also propose the concept of a cluster boundary, which affects the belongingness of an object by the overlapping factor. Finally, we use the evaluating approach of the number of uncertain clusters to determine the appropriate the number of clusters. In the experiment, clustering results generated using strategies commonly used in processing uncertain data clustering in UKmeans clusters are compared. Our proposed model shows more favorable performance, higher effectiveness of clustering, and a more appropriate number of clusters compared to other models.",2018,Data & Knowledge Engineering
PEREZ2018159,Automatic query reformulations for feature location in a model-based family of software products,"Conceptual modeling, Information retrieval, Feature location, Query reformulation, Software maintenance and evolution, Families of software products","No maintenance activity can be completed without Feature Location (FL), which is finding the set of software artifacts that realize a particular functionally. Despite the importance of FL, the vast majority of work has been focused on retrieving code, whereas other software artifacts such as the models have been neglected. Furthermore, locating a piece of information from a query in a large repository is a challenging task as it requires knowledge of the vocabulary used in the software artifacts. This can be alleviated by automatically reformulating the query (adding or removing terms). In this paper, we test four existing query reformulation techniques, which perform the best for FL in code but have never been used for FL in models. Specifically, we test these techniques in two industrial domains: a model-based family of firmwares for induction hobs, and a model-based family of PLC software to control trains. We compare the results provided by our FL approach using the query and the reformulated queries by means of statistical analysis. Our results show that reformulated queries do not improve the performance in models, which could lead towards a new direction in the creation or reconsideration of these techniques to be applied in models.",2018,Data & Knowledge Engineering
LUO201746,Multi-focus image fusion using HOSVD and edge intensity,"Image fusion, Multi-focus, HOSVD, Edge intensity, Sigmoid function","The purpose of multi-focus image fusion is to integrate the partially focused images into one single image which is focused everywhere. To achieve this purpose, higher order singular value decomposition (HOSVD) and edge intensity (EDI) based multi-focus image fusion method is proposed. The main characteristics of the proposed method includes: 1. an effective and robust sharpness measure based on edge intensity is presented; 2. considering the fact that HOSVD is an effective data-driven decomposition technique and shows the outstanding ability in the representation of high-dimensional data, it is used to decompose multi-focus images; and 3. a multi-strategy fusion rule based on sigmoid function is used to fuse the decomposition coefficients. Furthermore, several experiments are conducted to verify the superiority of the proposed fusion framework in terms of visual and statistical analyses.",2017,Journal of Visual Communication and Image Representation
MOEINI201720,Facial expression recognition using dual dictionary learning,"Facial Expression Recognition, Dual dictionary learning, Sparse representation, Regression classification","In this paper, a novel method is proposed for Facial Expression Recognition (FER) using dictionary learning to learn both identity and expression dictionaries simultaneously. Accordingly, an automatic and comprehensive feature extraction method is proposed. The proposed method accommodates real-valued scores to a probability of what percent of the given Facial Expression (FE) is present in the input image. To this end, a dual dictionary learning method is proposed to learn both regression and feature dictionaries for FER. Then, two regression classification methods are proposed using a regression model formulated based on dictionary learning and two known classification methods including Sparse Representation Classification (SRC) and Collaborative Representation Classification (CRC). Convincing results are acquired for FER on the CK+, CK, MMI and JAFFE image databases compared to several state-of-the-arts. Also, promising results are obtained from evaluating the proposed method for generalization on other databases. The proposed method not only demonstrates excellent performance by obtaining high accuracy on all four databases but also outperforms other state-of-the-art approaches.",2017,Journal of Visual Communication and Image Representation
SAHU201777,SIFT based video watermarking resistant to temporal scaling,"Watermarking, Scale Invariant Feature Transform (SIFT), Feature points, Context coherency","In this paper, a blind video watermarking scheme is proposed which can resist temporal scaling such as frame dropping and frame rate adaptation due to scalable compression by exploiting the scale invariance property of the scale invariant feature transform (SIFT). A video scene can also be viewed from side plane where height is the number of rows in a video frame, width is the number of frames in the scene and depth is the number of columns in the frame. In this work, intensity values of selected embedding locations changed such that strong SIFT feature can be generated. SIFT features are extracted from side plane of the video. These newly generated SIFT features are used for watermark signal and are stored in the database for the authentication. A comprehensive set of experiments has been done to demonstrate the efficacy of the proposed scheme over the existing literature against temporal attacks.",2017,Journal of Visual Communication and Image Representation
ZHANG2017170,Fast depth map mode decision based on depth–texture correlation and edge classification for 3D-HEVC,"3D-HEVC, Depth map, Mode decision, Edge classification","The 3D extension of High Efficiency Video Coding (3D-HEVC) has been adopted as the emerging 3D video coding standard to support the multi-view video plus depth map (MVD) compression. In the joint model of 3D-HEVC design, the exhaustive mode decision is required to be checked all the possible prediction modes and coding levels to find the one with least rate distortion cost in depth map coding. Furthermore, new coding tools (such as depth-modeling mode (DMM) and segment-wise depth coding (SDC)) are exploited for the characteristics of depth map to improve the coding efficiency. These achieve the highest possible coding efficiency to code depth map, but also bring a significant computational complexity which limits 3D-HEVC from real-time applications. In this paper, we propose a fast depth map mode decision algorithm for 3D-HEVC by jointly using the correlation of depth map-texture video and the edge information of depth map. Since the depth map and texture video represent the same scene at the same time instant (they have the same motion characteristics), it is not efficient to use all the prediction modes and coding levels in depth map coding. Therefore, we can skip some specific prediction modes and depth coding levels rarely used in corresponding texture video. Meanwhile, the depth map is mainly characterized by sharp object edges and large areas of nearly constant regions. By fully exploiting these characteristics, we can skip some prediction modes which are rarely used in homogeneity regions based on the edge classification. Experimental results show that the proposed algorithm achieves considerable encoding time saving while maintaining almost the same rate-distortion (RD) performance as the original 3D-HEVC encoder.",2017,Journal of Visual Communication and Image Representation
XIAO20171,Separable reversible data hiding in encrypted image based on pixel value ordering and additive homomorphism,"Reversible data hiding, Encrypted image, Pixel value ordering, Additive homomorphism, Separable","This work proposes a separable reversible data hiding scheme in encrypted images based on pixel value ordering (PVO). After the original image is encrypted using homomorphism encryption by the content owner, the data hider embeds the secret data in encrypted domain. The PVO strategy realizes hiding data in each block. Additive homomorphism guarantees the performance of PVO in encrypted domain is close to that in plain domain. Besides, the homomorphism encryption does not cause data expansion, and the payload can be further improved. With the watermarked encrypted image, if the receiver has only the data hiding key, he can extract the additional data. If the receiver has only the encryption key, he can obtain a decrypted image similar to the original one. If the receiver has both the data hiding key and the encryption key, he can extract the additional data without any error and recover the original image losslessly.",2017,Journal of Visual Communication and Image Representation
ASGHAR2017122,"Transparent encryption with scalable video communication: Lower-latency, CABAC-based schemes","B-frames, Scalable video streaming, Reduced encryption, Selective encryption, Transparent encryption","Selective encryption masks all of the content without completely hiding it, as full encryption would do at a cost in encryption delay and increased bandwidth. Many commercial applications of video encryption do not even require selective encryption, because greater utility can be gained from transparent encryption, i.e. allowing prospective viewers to glimpse a reduced quality version of the content as a taster. Our lightweight selective encryption scheme when applied to scalable video coding is well suited to transparent encryption. The paper illustrates the gains in reducing delay and increased distortion arising from a transparent encryption that leaves reduced quality base layer in the clear. Reduced encryption of B-frames is a further step beyond transparent encryption in which the computational overhead reduction is traded against content security and limited distortion. This spectrum of video encryption possibilities is analyzed in this paper, though all of the schemes maintain decoder compatibility and add no bitrate overhead as a result of jointly encoding and encrypting the input video by virtue of carefully selecting the entropy coding parameters that are encrypted. The schemes are suitable both for H.264 and HEVC codecs, though demonstrated in the paper for H.264. Selected Content Adaptive Binary Arithmetic Coding (CABAC) parameters are encrypted by a lightweight Exclusive OR technique, which is chosen for practicality.",2017,Journal of Visual Communication and Image Representation
CHEN2017147,Exploring visual attention using random walks based eye tracking protocols,"Eye tracking, Visual attention, Fixation, Area of interest, Random walks","Identifying visual attention plays an important role in understanding human behavior and optimizing relevant multimedia applications. In this paper, we propose a visual attention identification method based on random walks. In the proposed method, fixations recorded by the eye tracker are partitioned into clusters where each cluster presents a particular area of interest (AOI). In each cluster, we estimate the transition probabilities of the fixations based on their point-to-point adjacency in their spatial positions. We obtain the initial coefficients for the fixations according to their density. We utilizing random walks to iteratively update the coefficients until their convergency. Finally, the center of the AOI is calculated according to the convergent coefficients of the fixations. Experimental results demonstrate that our proposed method which combines the fixations’ spatial and temporal relations, highlights the fixations of higher densities and eliminates the errors inside the cluster. It is more robust and accurate than traditional methods.",2017,Journal of Visual Communication and Image Representation
ADEYEMIEJEYE201795,"Packet loss visibility across SD, HD, 3D, and UHD video streams","Video streaming, Packet loss visibility, Objective MOS, Beyond HD","The trend towards video streaming with increased spatial resolutions and dimensions, SD, HD, 3D, and 4kUHD, even for portable devices has important implications for displayed video quality. There is an interplay between packetization, packet loss visibility, choice of codec, and viewing conditions, which implies that prior studies at lower resolutions may not be as relevant. This paper presents two sets of experiments, the one at a Variable BitRate (VBR) and the other at a Constant BitRate (CBR), which highlight different aspects of the interpretation. The latter experiments also compare and contrast encoding with either an H.264 or an High Efficiency Video Coding (HEVC) codec, with all results recorded as objective Mean Opinion Score (MOS). The video quality assessments will be of interest to those considering: the bitrates and expected quality in error-prone environments; or, in fact, whether to use a reliable transport protocol to prevent all errors, at a cost in jitter and latency, rather than tolerate low levels of packet errors.",2017,Journal of Visual Communication and Image Representation
ZHANG2017181,Robust corner detection using the eigenvector-based angle estimator,"Eigenvector, Angle estimation, Curvature, Corner detection, Repeatability, Localization error","Angle is an intuitive and important property for representing corners. This fact motivates us to present a novel angle-based corner detector, named Eigenvector-based Angle Estimator (EAE). EAE estimates the angle of each point in a contour via computing the eigenvectors of the covariance matrix of boundary points over a small Region of Support (RoS). Since EAE is sensitive to uniform scaling due to the fixed RoS, an enhanced version of EAE named Weighted EAE (WEAE) is proposed. WEAE achieves robustness to uniform scaling by weighting the boundary points using their distances from the target point. Experimental results demonstrate that EAE and WEAE can efficiently achieve promising performance in comparisons with several recent state-of-the-art approaches under two commonly used evaluation metrics, namely, Average Repeatability (AR) and Localization Error (LE).",2017,Journal of Visual Communication and Image Representation
AHMAD201762,Efficient object-based surveillance image search using spatial pooling of convolutional features,"Surveillance image search, Surveillance network, Features extraction, Convolutional features","Modern surveillance networks are large collections of computational sensor nodes, where each node can be programmed to capture, prioritize, segment salient objects, and transmit them to central repositories for indexing. Visual data from such networks grow exponentially and present many challenges concerning their transmission, storage, and retrieval. Searching for particular surveillance objects is a common but challenging task. In this paper, we present an efficient features extraction framework which utilizes an optimal subset of kernels from the first layer of a convolutional neural network pre-trained on ImageNet dataset for object-based surveillance image search. The input image is convolved with the set of kernels to generate feature maps, which are aggregated into a single feature map using a novel spatial maximal activator pooling approach. A low-dimensional feature vector is computed to represent surveillance objects. The proposed system provides improvements in both performance and efficiency over other similar approaches for surveillance datasets.",2017,Journal of Visual Communication and Image Representation
ZHUANG2017137,Image enhancement using divide-and-conquer strategy,"Image enhancement, Subspace decomposition, Gradient distribution specification, Weighted fusion","Existing enhancement methods tend to overlook the difference between image components of low-frequency and high-frequency. However, image low-frequency portions contain smooth areas occupied the majority of the image, while high-frequency components are sparser in the image. Meanwhile, the different importance of image low-frequency and high-frequency components cannot be precisely and effectively for image enhancement. Therefore, it is reasonable to deal with these components separately when designing enhancement algorithms with image subspaces. In this paper, we propose a novel divide-and-conquer strategy to decompose the observed image into four subspaces and enhance the images corresponding to each subspace individually. We employ the existing technique of gradient distribution specification for these enhancements, which has displayed promising results for image naturalization. We then reconstruct the full image using the weighted fusion of these four subspace images. Experimental results demonstrate the effectiveness of the proposed strategy in both image naturalization and details promotion.",2017,Journal of Visual Communication and Image Representation
LIM2017107,Contrast enhancement of noisy low-light images based on structure-texture-noise decomposition,"Image enhancement, Contrast enhancement, Structure-texture-noise decomposition, Noise removal, Denoising, Texture retrieval, Texture enhancement","A noisy low-light image enhancement algorithm based on structure-texture-noise (STN) decomposition is proposed in this work. We split an input image into structure, texture, and noise components, and enhance the structure and texture components separately. More specifically, we first enhance the contrast of the structure image, by extending a 2D-histogram-based image enhancement scheme based on the characteristics of low-light images. Then, we reconstruct the texture image by retrieving residual texture components from the noise image and enhance it by exploiting the perceptual response of the human visual system (HVS). Experimental results on both synthetic and real-world images demonstrate that the proposed STN algorithm sharpens the texture and enhances the contrast more effectively than conventional algorithms, while providing robust performance under various noise and illumination conditions.",2017,Journal of Visual Communication and Image Representation
XU201734,Tunable data hiding in partially encrypted H.264/AVC videos,"Data hiding, Encrypted domain, H.264/AVC, Context adaptive binary arithmetic coding (), substitution","An improved scheme of data hiding directly in partially encrypted H.264/AVC videos using CABAC bin-string substitution is proposed. The encryption of Luma prediction modes is designed in addition to residual encryption and motion vector encryption in order to significantly improve the structural deterioration. Both the bin-strings of abs_level and the bin-strings of abs_MVD are exploited for data hiding to provide a higher flexibility for users to select the tradeoff between hiding capacity and video quality. Since the data embedding is done in the encrypted domain, the proposed scheme preserves the confidentiality of video content. With an encrypted video containing the hidden data, the receiver can accomplish data extraction directly in encrypted domain using only the data-hiding key, or obtain a decrypted video similar to the original version using only the cryptographic key. Experimental results have demonstrated that the proposed scheme can achieve better scrambling performance and higher embedding capacity.",2017,Journal of Visual Communication and Image Representation
KO2017156,A ParaBoost stereoscopic image quality assessment (PBSIQA) system,"Stereoscopic images, Objective quality assessment, Machine learning, Decision fusion, Feature extraction, Image quality database","The problem of stereoscopic image quality assessment, which finds applications in 3D visual content delivery such as 3DTV, is investigated in this work. Specifically, we propose a new ParaBoost (parallel-boosting) stereoscopic image quality assessment (PBSIQA) system. The system consists of two stages. In the first stage, various distortions are classified into a few types, and individual quality scorers targeting at a specific distortion type are developed. These scorers offer complementary performance in face of a database consisting of heterogeneous distortion types. In the second stage, scores from multiple quality scorers are fused to achieve the best overall performance, where the fuser is designed based on the parallel boosting idea borrowed from machine learning. Extensive experimental results are conducted to compare the performance of the proposed PBSIQA system with those of existing stereo image quality assessment (SIQA) metrics. The developed quality metric can serve as an objective function to optimize the performance of a 3D content delivery system.",2017,Journal of Visual Communication and Image Representation
YOO201711,High-dimensional feature extraction using bit-plane decomposition of local binary patterns for robust face recognition,"Face recognition, Feature extraction, Local binary pattern, High-dimensional feature, Linear discriminant analysis, Bit-plane decomposition","Transforming an original image into a high-dimensional (HD) feature has been proven to be effective in classifying images. This paper presents a novel feature extraction method utilizing the HD feature space to improve the discriminative ability for face recognition. We observed that the local binary pattern can be decomposed into bit-planes, each of which has scale-specific directional information of the face image. Each bit-plane not only has the inherent local-structure of the face image but also has an illumination-robust characteristic. By concatenating all the decomposed bit-planes, we generate an HD feature vector with an improved discriminative ability. To reduce the computational complexity while preserving the incorporated local structural information, a supervised dimension reduction method, the orthogonal linear discriminant analysis, is applied to the HD feature vector. Extensive experimental results show that existing classifiers with the proposed feature outperform those with other conventional features under various illumination, pose, and expression variations.",2017,Journal of Visual Communication and Image Representation
DU201787,Two-dimensional discriminant analysis based on Schatten p-norm for image feature extraction,"Schatten -norm, Two-dimensional discriminant analysis, Feature extraction, Subspace learning, Image recognition","A Schatten p-norm-based two-dimensional principal component analysis (2DPCA-SP) method was proposed for image feature extraction in our previous work. As an unsupervised method, 2DPCA-SP ignores the label information of training samples, which is essential to classification tasks. In this paper, we propose a novel Schatten p-norm-based two-dimensional discriminant analysis (2DDA-SP) method for image feature extraction, which learns an optimal projection matrix by maximizing the difference of Schatten p-norm-based between-class dispersion and Schatten p-norm-based within-class dispersion in low-dimensional feature space. By using both the Schatten p-norm metric and the label information of training samples, 2DDA-SP not only can efficiently extract discriminative features, but is also robust to outliers. We also propose an efficient iterative algorithm to solve the optimization problem of 2DDA-SP with 0<p<1. Experimental results on several image databases show that 2DDA-SP with 0<p<1 is effective and robust for image feature extraction.",2017,Journal of Visual Communication and Image Representation
KUMAR2018171,Hierarchical uncorrelated multiview discriminant locality preserving projection for multiview facial expression recognition,Facial expression recognition,"Existing multi-view facial expression recognition algorithms are not fully capable of finding discriminative directions if the data exhibits multi-modal characteristics. This research moves toward addressing this issue in the context of multi-view facial expression recognition. For multi-modal data, local preserving projection (LPP) or local Fisher discriminant analysis (LFDA)-based approach is quite appropriate to find a discriminative space. Also, the classification performance can be enhanced by imposing uncorrelated constraint onto the discriminative space. So for multi-view (multi-modal) data, we proposed an uncorrelated multi-view discriminant locality preserving projection (UMvDLPP)-based approach to find an uncorrelated common discriminative space. Additionally, the proposed UMvDLPP is implemented in a hierarchical fashion (H-UMvDLPP) to obtain an optimal performance. Extensive experiments on BU3DFE dataset show that UMvDLPP performs slightly better than the existing methods. However, an improvement of approximately 3% as compared to the existing state-of-the-art multi-view learning-based approaches is achieved by our H-UMvDLPP. This improvement is due to the fact that the proposed method enhances the discrimination between the classes more effectively, and classifies expressions category-wise followed by classification of the basic expressions embedded in each of the subcategories (hierarchical approach).",2018,Journal of Visual Communication and Image Representation
SANCHEZ2018193,A reduced computational effort mode-level scheme for 3D-HEVC depth maps intra-frame prediction,"3D-HEVC, Intra-frame prediction, Depth maps, 3D video coding","To encode the depth maps efficiently, 3D-HEVC introduced three intra-frame prediction tools: (i) Depth Intra Skip (DIS), (ii) Depth Modeling Modes (DMMs), and (iii) Segment-wise DC Coding (SDC) that raise the encoding effort. Therefore, we analyzed the most time-consuming steps at the intra-frame prediction and proposed a model-level scheme for reducing the encoding time. The most time-consuming encoding steps were the DMM-1 wedgelet search and the Rate-Distortion (RD) list evaluation in Transform-Quantization and SDC flows. Consequently, we proposed a scheme composed of two solutions for speeding up the DMM-1 and one solution for reducing the RD-list size, accelerating the RD-list evaluation. The DMM-1 speeding up solutions use the information of neighbor-encoded blocks and the data contained in the border of the encoding block to accelerate the wedgelet search. The proposed scheme reduces 31.9% the encoding time with an impact of 0.272% in the Bjontegaard Delta-rate (BD-rate), surpassing the related works.",2018,Journal of Visual Communication and Image Representation
ZHU20181,Salient object detection via a local and global method based on deep residual network,"Salient object detection, Deep residual network, Local and global features","Salient object detection is a fundamental problem in both pattern recognition and image processing tasks. Previous salient object detection algorithms usually involve various features based on priors/assumptions about the properties of the objects. Inspired by the effectiveness of recently developed deep feature learning, we propose a novel Salient Object Detection via a Local and Global method based on Deep Residual Network model (SOD-LGDRN) for saliency computation. In particular, we train a deep residual network (ResNet-G) to measure the prominence of the salient object globally and extract multiple level local features via another deep residual network (ResNet-L) to capture the local property of the salient object. The final saliency map is obtained by combining the local-level and global-level saliency via Bayesian fusion. Quantitative and qualitative experiments on six benchmark datasets demonstrate that our SOD-LGDRN method outperforms eight state-of-the-art methods in the salient object detection.",2018,Journal of Visual Communication and Image Representation
IZADYYAZDANABADI201810,"Convolutional neural networks: Ensemble modeling, fine-tuning and unsupervised semantic localization for neurosurgical CLE images","Neural network, Unsupervised localization, Ensemble modeling, Brain tumor, Confocal laser endomicroscopy, Surgical vision","Confocal laser endomicroscopy (CLE) is an advanced optical fluorescence technology undergoing assessment for applications in brain tumor surgery. Many of the CLE images can be distorted and interpreted as nondiagnostic. However, just one neat CLE image might suffice for intraoperative diagnosis of the tumor. While manual examination of thousands of nondiagnostic images during surgery would be impractical, this creates an opportunity for a model to select diagnostic images for the pathologists or surgeons review. In this study, we sought to develop a deep learning model to automatically detect the diagnostic images. We explored the effect of training regimes and ensemble modeling and localized histological features from diagnostic CLE images. The developed model could achieve promising agreement with the ground truth. With the speed and precision of the proposed method, it has potential to be integrated into the operative workflow in the brain tumor surgery.",2018,Journal of Visual Communication and Image Representation
SANTOS201821,Lossless coding of light field images based on minimum-rate predictors,"Image coding, Lossless compression, Light field coding","Recent developments in light field acquisition and computational photography are driving new research efforts on light field encoding methods, capable of exploiting the specific features of this type of visual data. This paper presents a research study of lossless light field image compression, using Minimum-Rate Predictors (MRP) and mainstream image and video encoders. The research is focused on three light field representation formats: lenslet images, stack of sub-aperture images and epipolar images. The main contributions of this work are the ‘Spiral-blackend’ serialization method and the use of MRP for the lossless compression of light fields with joint encoding of RGB data. The results show that the lenslet format yields lower compression efficiencies than other formats. Furthermore, it is demonstrated that the MRP algorithm consistently outperforms HEVC-RExt, JPEG2000, JPEG-LS and CALIC when light fields are represented by either a stack of sub-aperture or epipolar images.",2018,Journal of Visual Communication and Image Representation
LEMOAN201831,Towards exploiting change blindness for image processing,"Perception, Visual awareness, Visual attention, Change blindness, Salience, Image quality","Change blindness is a type of visual masking which affects our ability to notice changes introduced in visual stimuli (e.g. change in the colour or position of an object). In this paper, we propose to use it as a means to identify image attributes that are less important than others. We propose a model of visual awareness based on low-level saliency detection and image inpainting, which identifies textured regions within images that are the most prone to change blindness. Results from a user study demonstrate that our model can generate alternative versions of natural scenes which, while noticeably different, have the same visual quality as the original. We show an example of practical application in image compression.",2018,Journal of Visual Communication and Image Representation
BAI2018123,Image quality assessment in first-person videos,"First-person videos, Local Visual Information (LVI), Mutual reference, Image quality assessment, Pseudo-reference","First-person videos (FPVs) or egocentric videos provide a huge amount of data for visual lifelogs. The quality assessment of frames in FPVs serves as an important tool, feature or evaluation baseline for not only structuring but also analyzing lifelogs. To develop a frame-quality measure for FPVs, we introduce a new strategy for image quality estimation, called mutual reference (MR), which uses one or more pseudo-reference images to evaluate a test image. We then propose a MR quality estimator, called Local Visual Information (LVI), that primarily measures the relative blur between two images. To apply the MR strategy to FPVs, we propose a mutual reference frame quality assessment for FPVs (MRFQAFPV) framework which incorporates LVI. Our results, using both real and synthetic distortions and objective and subjective tests, demonstrate both methods perform better than existing NR QEs at measuring the quality of frames in FPVs.",2018,Journal of Visual Communication and Image Representation
RETA201839,Color uniformity descriptor: An efficient contextual color representation for image indexing and retrieval,"Image retrieval, Image representation, Contextual features, Color uniformity descriptor, Lab color space","Color is a rich source of visual information for the effective characterization of image content. The recognition of texture or shape elements in images is strongly associated with the analysis of the image color layout. This paper presents a contextual color descriptor designed especially to be applied to CBIR tasks in heterogeneous image databases. The proposed color uniformity descriptor (CUD) clusters perceptually similar image color regions according to the uniformity analysis of their neighbor pixels. CUD produces vast color image details with a thin histogram, whilst preserving the balance between uniqueness and robustness. CUD is computationally efficient and can achieve high precision and throughput rates when used in CBIR. Experimental results show that CUD performs comparably against local features and multiple features state-of-the-art approaches that require more complex data manipulation. Results demonstrate that CUD provides strong image discrimination even in the presence of significant content variation.",2018,Journal of Visual Communication and Image Representation
KANG201880,Rician denoising and deblurring using sparse representation prior and nonconvex total variation,"Rician denoising, Deblurring, Sparse representation, Dictionary learning, Nonconvex total variation, Penalty method, Alternating minimization method","We propose a sparse representation based model to restore an image corrupted by blurring and Rician noise. Our model is composed of a nonconvex data-fidelity term and two regularization terms involving a sparse representation prior and a nonconvex total variation. The sparse representation prior, using image patches, provides restored images with well-preserved repeated patterns and small details, whereas the non-convex total variation enables the preservation of edges. Moreover, the regularization terms are mutually complementary in removing artifacts. To realize our nonconvex model, we adopt the penalty method and the alternating minimization method. The K-SVD algorithm is utilized for learning dictionaries. Numerical experiments demonstrate that the proposed model is superior to state-of-the-art models, in terms of visual quality and certain image quality measurements.",2018,Journal of Visual Communication and Image Representation
ZHOU2018100,Targeted attack and security enhancement on texture synthesis based steganography,"Texture image, Steganalysis, Texture synthesis, Steganography","We describe an effective and efficient strategy building steganography detector for patch synthesis based steganography, one case of which is reversible texture synthesis based steganography method proposed by Wu et al. (2015). By exploiting the observation that steganography destroys optimization of matching extent between the synthetic patch and optimal candidate patch, we reconstruct the two patches from an overlapped region to extract the existence of optimality, which are distinct between cover and stego images, to form features. Support vector machine (SVM) is implemented for classification. Meanwhile, a variant of Wu et al.’s steganographic method is proposed with reinforced security, by padding redundant regions carrying no message around the periphery of the synthesized image and generating additional candidate patches to increase capacity. Experiments demonstrate that the modified algorithm offers not only better resistance against the state-of-the-art steganalysis methods and steganalytic attack we developed, but also a larger embedding capacity.",2018,Journal of Visual Communication and Image Representation
WANG2018213,Joint feature selection and graph regularization for modality-dependent cross-modal retrieval,"Cross-modal retrieval, Feature selection, Subspace learning, Graph regularization","Most existing cross-modal retrieval methods ignore the discriminative semantics embedded in multi-modal data and the unique characteristics of different sub-retrieval tasks. To address the problem, we propose a novel approach in this paper, which is named Joint Feature selection and Graph regularization for Modality-dependent cross-modal retrieval (JFGM). The key idea of JFGM is learning modality-dependent subspaces for different sub-retrieval tasks while simultaneously preserving the semantic consistency of multi-modal data. Specifically, besides to the shared subspace learning between different modalities, a linear regression term is introduced to further correlate the discovered modality-dependent subspace with the explicit semantic space. Furthermore, a multi-model graph regularization term is formulated to preserve the inter-modality and intra-modality semantic consistency. In order to avoid over-fitting problems and select the discriminative features, l2,1-norm is imposed on the projection matrices. Experimental results on several publicly available datasets demonstrate the superiority of the proposed method compared with several state-of-the-art approaches.",2018,Journal of Visual Communication and Image Representation
GHOSH201863,Chaotic firefly algorithm-based fuzzy C-means algorithm for segmentation of brain tissues in magnetic resonance images,"FCM, FAFCM, En-FAOFCM, Bias field, Spatial information, Total variation, PVE, Tanimoto coefficient and dice similarity","Image segmentation with clustering approach is widely used in biomedical application. Accurate brain Magnetic Resonance (MR) image segmentation is a challenging task due to the complex anatomical structure of brain tissues in addition to the existence of intensity inhomogeneity, partial volume effects and noise. In this study, a spatial modified bias corrected FCM algorithm is applied to brain MRI for the purpose of segmentation into White Matter (WM), Gray Matter (GM) and Cerebrospinal fluid (CSF) in MR images. So to overcome the uncertainty caused by the above effects, a modified Fuzzy C-Means (m-FCM) algorithm for MR brain image segmentation is presented in this paper. Also FCM suffers from initialization sensitivity, to overcome this we have used chaos theory based firefly algorithm. This paper presents a novel application of FCM clustering by using Firefly algorithm with a chaotic map to initialize the population of fireflies and tune the absorption coefficient (λ), for increasing the global search mobility. This algorithm is called chaotic firefly integrated Fuzzy C-means (C-FAFCM) algorithm, which embeds chaos map in the Firefly Algorithm. The proposed technique is applied to several simulated and real T1-weighted for normal magnetic resonance brain images, taken from IBSR and BrainWeb database. The algorithm is realized by incorporating the spatial neighborhood information into the standard FCM algorithm and modifying the membership weighting of each cluster by regularizing it by Total Variation (TV) denoising. The experimental results on both simulated and real brain MRI datasets demonstrate that our proposed method (C-FAFCM) has satisfactory outputs in comparison with some other state of the art, based on FCM and non FCM based algorithms.",2018,Journal of Visual Communication and Image Representation
WU201851,Saliency propagation with perceptual cues and background-excluded seeds,"Saliency detection, Perceptual cue, Graph-based framework, Label propagation, Seed, Background probability","Graph-based methods have shown their potentialities for saliency detection. In this paper, a graph-based framework is proposed for saliency detection, which incorporates perceptual cues into the framework and uses the background-excluded seeds to propagate saliency. Firstly, a graph is constructed by two perceptual cues, including proximity and similarity. Secondly, probable background nodes are generated by a novel background probability measure and used to pick out reliable seeds. Then a label propagation model is developed to diffuse saliency based on these reliable seeds. Lastly, another perceptual cue called rareness is integrated into a cost function to optimize the propagation result. Results on four datasets demonstrate that the proposed method achieves superior performance against fifteen state-of-the-art methods in terms of different evaluation metrics.",2018,Journal of Visual Communication and Image Representation
WANG2018108,Region-based rate control for 3D-HEVC based texture video coding,"3D-HEVC, Rate control, Bit allocation, Bit starvation, Retained bit earnings, R-λ model","Bit starvation resulted from inefficient rate control of 3D video coding deteriorates visual quality of synthesized views. Most region based rate control schemes allocate higher bitrate to regions of interest (ROIs), but bits may be still consumed by early coded units. This paper avoids reducing coding bits in high-cost regions of 3D-HEVC. Instead of ROIs that are determined by humans, high-cost regions sensitive to bit starvation are detected. Region-level bit allocation is achieved by curve fitting of coding statistics, and recursive Taylor expansion (RTE) based bit allocation is adopted to optimally estimates the target bitrate and the QP related λ of LCUs in each region. Based on retained earnings in economics, bits are reserved for LCUs that are sensitive to distortions. Experimental results show that the proposed scheme outperforms both the R-λ model and RTE model in bitrate accuracy with similar R-D performance.",2018,Journal of Visual Communication and Image Representation
IAKOVIDOU2018155,Content-aware detection of JPEG grid inconsistencies for intuitive image forensics,"Image forensics, JPEG artifacts, Forgery localization, Splicing","The paper proposes a novel method for detecting indicators of image forgery by locating grid alignment abnormalities in JPEG compressed image bitmaps. The method evaluates multiple grid positions with respect to a fitting function, and areas of lower contribution are identified as grid discontinuities and possibly tampered areas. An image segmentation step is introduced to differentiate between discontinuities produced by tampering and those that are attributed to image content, making the output maps easier to interpret by suppressing non-relevant activations. Our evaluations, on both synthetically produced datasets and real world tampering cases against seven methods from the literature, highlight the effectiveness of the proposed method in its ability to produce output maps that are clear and readable, and which can achieve successful detections on cases where other algorithms fail.",2018,Journal of Visual Communication and Image Representation
KE2018133,A multilevel reversible data hiding scheme in encrypted domain based on LWE,"Information security, Reversible data hiding, Multilevel embedding, Public key cryptography, Learning with Error","This paper proposes a multilevel reversible data hiding scheme in encrypted domain by utilizing the controllable redundancy of learning with error public key cryptography. Messages can be embedded into multilevel sub-regions of ciphertext by quantifying the encrypted domain and recoding its redundancy. We recode redundancy based on the characteristics of cipher’s distribution. Extraction and decryption processes are separated by dividing the encrypted domain into multilevel sub-regions and introducing different quantification standards. Original plaintext can be losslessly recovered from the marked ciphertext by using the decryption key; with a specific level data-hiding key, only the message hiding in the corresponding level can be extracted, while plaintext and other messages remain secret. We provide theoretical analysis and experimental results on the feasibility, reversibility, and security of the proposed scheme. The capacity and encryption blow up factor are discussed. The experimental results demonstrate the maximum embedding rate can exceed 0.3000 bpb of ciphertext.",2018,Journal of Visual Communication and Image Representation
ZHENG2018145,A novel distortion criterion of rate-distortion optimization for depth map coding,"Three dimensional video (3DV), Multiview video plus depth (MVD), Rate-distortion optimization, Virtual view distortion, 3D-HEVC","In 3D video coding systems, depth maps are not displayed to the viewers, but provide the geometric information to generate virtual views. To ensure the quality of virtual views, the rate-distortion optimization (RDO) in depth map coding adopts the virtual view distortion as the distortion item. The virtual view distortion comes from the reconstructed color video distortion and depth distortion. It is usually recognized that the virtual view distortion caused by reconstructed color video distortion is independent of that in depth map coding. Preliminary experiments reveal that the virtual view distortion in depth map coding is also influenced by the reconstructed color video distortion. Therefore, we proposed a novel distortion criterion of depth map coding in which the reconstructed color video distortion is modeled and joins into the virtual view distortion calculation. Correspondingly, the associated Lagrange multiplier is also proposed. Experimental results demonstrate that the method by integrating the proposed distortion criterion into RDO for depth map coding can achieve an average 12.72% bitrate saving compared with SSD based RDO method and can also lead a bitrate reduction (0.64%) compared with the existing distortion estimation method in the current 3D-HEVC reference software. With the associated Lagrange multiplier, the proposed distortion criterion can achieve 12.98% bitrate saving compared with SSD based RDO method on average.",2018,Journal of Visual Communication and Image Representation
VAZQUEZCORRAL2018204,Spatial gamut mapping among non-inclusive gamuts,"Gamut mapping, Gamut extension, Gamut reduction, Color coherence","Gamut mapping transforms the color gamut of an image to that of a target device. Two cases are usually considered: gamut reduction (target gamut smaller than source gamut), and gamut extension (target gamut larger than the source gamut). Less attention is devoted to the more general case, when neither gamut is fully included in the other. In this work we unify and expand two recent methods for gamut extension and reduction, so as to simultaneously perform both forms of gamut mapping in different regions of the same image without introducing color artifacts or halos. We demonstrate the usefulness of this approach for the traditional gamut mapping problem, and also how the proposed method can be used to adapt the color palette of an image so that it is closer to that of a given reference image. Results are compared with the state-of-the-art and validated through user tests and objective metrics.",2018,Journal of Visual Communication and Image Representation
LI2018182,Face spoofing detection with local binary pattern network,"Face spoofing detection, Deep learning, Local binary pattern","Nowadays, face biometric based access control systems are becoming ubiquitous in our daily life while they are still vulnerable to spoofing attacks. So developing robust and reliable methods to prevent such frauds is unavoidable. As deep learning techniques have achieved satisfactory performances in computer vision, they have also been applied to face spoofing detection. However, the numerous parameters in these deep learning based detection methods cannot be updated to optimum due to limited data. Local Binary Pattern (LBP), effective features for face recognition, have been employed in face spoofing detection and obtained promising results. Considering the similarities between LBP extraction and convolutional neural network (CNN) that the former can be accomplished by using fixed convolutional filters, we propose a novel end-to-end learnable LBP network for face spoofing detection. Our network can significantly reduce the number of network parameters by combing learnable convolutional layers with fixed-parameter LBP layers that are comprised of sparse binary filters and derivable simulated gate functions. Compared with existing deep leaning based detection methods, the parameters in our fully connected layers are up to 64x savings. Conducting extensive experiments on two standard spoofing databases, i.e., Relay-Attack and CASIA-FA, our proposed LBP network substantially outperforms the state-of-the-art methods.",2018,Journal of Visual Communication and Image Representation
ZHU201861,HCLR: A hybrid clustering and low-rank regularization-based method for photon-limited image restoration,"Image restoration, Low rank, Poisson denoising, Newton’s method","A photon-limited image can be represented as a pixel matrix limited by the relatively small number of collected photons. The image can also be seen as being contaminated by Poisson noise because the total number of photons follows the Poisson distribution. Through exploitation of the inherent properties of observation combined with application of a denoising method, an image can be significantly restored. In this paper, a hybrid clustering and low-rank regularization-based model (HCLR) is proposed based on the essential features of patch clustering and noise. An efficient Newton-type method is designed to optimize this biconvex problem. Experimental results demonstrate that HCLR achieves competitive denoising performance, especially for high noise levels, compared with state-of-the-art Poisson denoising algorithms.",2018,Journal of Visual Communication and Image Representation
ZHANG2018253,Input-output finite-region stability and stabilization for discrete the 2-D Roesser model,"Two-dimensional Roesser model, Input-output finite region stability, Controllers of state feedback","Image information is usually propagated along horizontal and vertical directions, and it is usually modeled as two-dimensional (2-D) Roesser systems. For Roesser systems, stability ensures it’s normal operation, and it is regarded as a key issue. However, note that the mentioned stability above ignores the running conditions of the system in a finite-region, which probably destroy the system’ normal operation before the system reaches a steady state. In this paper, many attentions are focused on the classical discrete 2-D Roesser model, and output signal is analyzed in detail on some finite region. This issue is formulated as input-out finite-domain stability (I-O FRS) and it can effectively analyze output signals' transient behavior of discrete 2D Roesser model. First, for discrete 2-D Roesser model, I-O FRS concept is established under considering the effect of exogenous disturbance set W. In particular, when exogenous disturbances W are regarded as W2 and W∞, sufficient I-O FRS criteria are formulated respectively, which are described as linear matrix inequality (LMIs) conditions. Subsequently, by designing state feedback controller, I-O finite-region stabilization is realized also under exogenous disturbances W2 and W∞, and compact LMIs criteria are proposed accordingly. Finally, ranges of examples are described for supporting the correctness of research results.",2018,Journal of Visual Communication and Image Representation
SHI2018118,Visual comparison based on linear regression model and linear discriminant analysis,"Visual comparison, LDA, Linear regression, SVM, Pairwise relative attributes","Visual comparison is that given two images, we can predict which one exhibits a particular visual attribute more than the other. The existing relative attribute methods rely on ranking SVM functions to conduct visual comparison; however, the ranking SVM functions are sensitive to the support vectors. When there are rarely effective samples, the performance of the ranking SVM model will be greatly discounted. To address this issue, we propose the pairwise relative attribute method for visual comparison by training the Linear Regression Model (LRM), which can be formulated by learning a mapping function between a vector-formed feature input with pairwise image difference and a scalar-valued output. In addition, we propose a novel feature reduction method based on the Linear Discriminant Analysis (LDA) in order to obtain a low dimensional and discriminant feature. Experimental results on the three databases of UT-Zap50K-1, OSR and PubFig demonstrate the advantages of the proposed method.",2018,Journal of Visual Communication and Image Representation
JIAN20181,Saliency detection based on directional patches extraction and principal local color contrast,"Saliency detection, Wavelet frame transform, Principal local color contrast, Directional patches","Saliency detection has become an active topic in both computer vision and multimedia fields. In this paper, we propose a novel computational model for saliency detection by integrating the holistic center-directional map with the principal local color contrast (PLCC) map. In the proposed framework, perceptual directional patches are firstly detected based on discrete wavelet frame transform (DWFT) and sparsity criterion, then the center of the spatial distribution of the extracted directional patches are utilized to locate the salient object in an image. Meanwhile, we proposed an efficient local color contrast method, called principal local color contrast (PLCC), to compute the color contrast between the salient object and the image background, which is sufficient to highlight and separate salient objects from complex background while dramatically reduce the computational cost. Finally, by incorporating the complementary visual cues of the global center-directional map with the PLCC map, a final compounded saliency map can be generated. Extensive experiments performed on three publicly available image databases, verify that the proposed scheme is able to achieve satisfactory results compared to other state-of-the-art saliency-detection algorithms.",2018,Journal of Visual Communication and Image Representation
VISHWAKARMA201848,An optimized non-subsampled shearlet transform-based image fusion using Hessian features and unsharp masking,"Image fusion, Kaiser window, Optimized NSST, Canny edge detector, Hessian features, Unsharp masking","Existing image fusion approaches are not so efficient to seize significant edges, texture and fine features of the source images due to ineffective and non-adaptive fusion structure. Also for objective evaluation of fusion algorithms, there is a need of a metric to measure source image features which are preserved in the fused image. To address these issues, an optimized non-subsampled shearlet transform (NSST) is developed, which is applied to decompose the source images into low- and high frequency bands. The low frequency bands are fused using proposed descriptor obtained from superposition of scale multiplied Canny edge detector features and Hessian features. The high frequency bands are fused using unsharp masking based fusion rule. Moreover, a metric QE is formulated on the basis of Karhunen-Loeve transform (KLT). The information of image pixel variance for both source and fused images can be measured by using the proposed metric QE, and it gives an indication of the amount of variance information transferred from the source images to the fused image. Both subjective and objective analysis show the efficacy of the proposed fusion structure and the metric QE.",2018,Journal of Visual Communication and Image Representation
ZHANG2018163,Geometric discriminative deep features for traffic image analysis,"Deep features, Traffic image analysis","Traffic image analysis is an important application in intelligent transportation. For local features’ robustness to image variances, such as scale changes and occlusions, they are widely used in image classification. However, how to integrate these local features for modeling traffic images optimally is still a crucial challenge. In this paper, a novel deep learning method, geometric discriminative feature fusion (GDFF), is proposed to tackle this problem. First, we use a variety of data sets to train the general convolutional neural network (CNN), which is used to extract the features of the training and test set after deep level. Deep architecture makes it possible for people to learn more abstract and internal features that are robust to changes in viewpoint and illumination. It can fuse image geometric related local features, such as local regions’ RGB histograms, into high level discriminative features, which can be used for better classifying complex scene images. Our framework’s central task is to build a structural kernel, called discriminative topological kernel. Firstly, we segment the traffic images into several regions and use a region connected graph (RCG) to model regions location relationships. We use frequent sub graph mining algorithm to mine all frequent sub structures (topologies) occurs in all training RCGs. And a selection algorithm is designed to select the k qualified topologies from the entire mined frequent topologies. We call these selected topologies geometric feature fusers, which are both high discriminative and low redundant structures in all training RCGs. Finally, given a pair of RCGs and to each geometric fuser, we extract all pairs of sub graphs sharing the same topology and calculate distance between them. All k distances are accumulated for the final kernel. The experimental result demonstrates the effectiveness of our method.",2018,Journal of Visual Communication and Image Representation
CHEN2018272,Reversible data hiding in encrypted images with private-key homomorphism and public-key homomorphism,"Reversible data hiding, Encrypted images, Lossless recovery, Homomorphic encryption","This paper proposes two reversible data hiding schemes in encrypted images that provide lossless recovery of directly decrypted images. The modified homomorphic encryption is introduced to encrypt the original image so that the private-key homomorphism and public-key homomorphism are both available. To embed secret message into encrypted image, a part of encrypted pixels are replaced with new ciphertexts by homomorphic property. Finally, the original image and embedded secret message can be restored by direct decryption. Optimal visual quality is obtained by the proposed schemes, since the directly decrypted pixel value is equal to the original pixel value. And the embedding rate is further improved. In addition, the proposed schemes are suitable for compressed multimedia, which extends the application scenarios. Experimental results are presented to demonstrate the effectiveness and superiority of the proposed schemes.",2018,Journal of Visual Communication and Image Representation
TIAN2018212,A multi-order derivative feature-based quality assessment model for light field image,"Light field image, Image quality assessment, Multi-order derivative feature","This paper presents an image quality assessment (IQA) model exploring the multi-order derivative feature, called Multi-order Derivative Feature-based Model (MDFM), for evaluating the perceptual quality of light field image (LFI). In our approach, for the input reference and distorted LFIs, the multi-order derivative features are extracted by using the discrete derivative filter to represent the image details in different degrees. Then, the similarities of the extracted derivative features are measured independently. Finally, the weight map is established through the maximum value of the second-order derivative feature of reference and distorted LFIs, which is further utilized to pool the similarity map for generating the final score. Extensive simulation results have demonstrated that the proposed MDFM is more consistent with the perception of the HVS on the evaluation of LFI than the classical and state-of-the-art IQA methods.",2018,Journal of Visual Communication and Image Representation
ZHOU201869,A novel hypergraph matching algorithm based on tensor refining,"Hypergraph matching, Probabilistic, Tensor refining","Hypergraph matching utilizes high order constraints rather than unary or pairwise ones, which aims to establish a more reliable correspondence between two sets of image features. Although many hypergraph matching methods have been put forward over the past decade, it remains a challenging problem to be solved due to its combinatorial nature. Most of these methods are based on tensor marginalization, where tensor entries representing joint probabilities of the assignment are fixed during the iterations meanwhile the individual assignment probabilities evolving. This will cause some incomplete information which may hurt the matching performance. Addressing this issue, we propose a novel hypergraph matching algorithm based on tensor refining, accompanied with an alternative adjustment method to accelerate the convergence. We make a comparison between the proposed approach and several outstanding matching algorithms on three commonly used benchmarks. The experimental results validate the superiority of our method on both matching accuracy and robustness against noise and deformation.",2018,Journal of Visual Communication and Image Representation
WU2018107,Efficient VR Video Representation and Quality Assessment,"Virtual reality, Cinematic VR, Immersive media, Video coding, Quality assessment","VR video is increasingly popular due to the recent advances in VR technology and hardware. The bulky size of VR video, however, impose new challenges in its storage and processing. In this paper, we focus on the research problems of VR video representation and objective quality assessment. Distinct from traditional 2D video, a VR video is displayed and represented in a form of spherical surface. For encoding purpose, a VR video frame needs to be projected to a 2D flat plane. Existing projection methods usually lead to much redundancy or significant violation in the correlation of neighbor pixels, which are not encoding friendly or are creating visible edge artifacts. To alleviate these problems, we propose in this paper our Quadrangle Affine Square Projection (QASP). QASP is a novel representation for VR video frames, which can reduce the redundant pixels over the traditional projections. In particular, all the inner pixels in QASP remain connected, i.e. the correlations between neighbors pixels are well maintained, which is a desirable feature for video encoding and edge-artifact-free viewing experience. Besides, we also investigated in predicting the optimal rotation angle for QASP frames for higher encoding efficiency. In addition to VR video representation, we also investigate in this paper accurate objective quality measurement for VR video. The traditional video quality measurements, e.g. PSNR, are not suitable to measure the quality of VR videos since they will take the redundant pixels into account. In this paper, we propose a new quality measurement for VR videos, named as Resized-PSNR (R-PSNR). With R-PSNR, only the “meaningful” pixels are considered for quality measurement while the redundant pixels are discarded. To evaluate QASP and R-PSNR, experiments are conducted based on standard VR video sequences. The experimental results show that the proposed projection method achieves noticeable improvement over traditional methods, and the proposed quality assessment method outperforms the traditional measurements in terms of consistency with subjective evaluation.",2018,Journal of Visual Communication and Image Representation
WANG2018262,Asymmetric filtering-based dense convolutional neural network for person re-identification combined with Joint Bayesian and re-ranking,"Person re-identification, Joint Bayesian, Deep convolutional neural networks, Multimodal features","Person re-identification aims at matching individuals across multiple camera views under surveillance systems. The major challenges lie in the lack of spatial and temporal cues, which makes it difficult to cope with large variations of lighting conditions, viewing angles, body poses and occlusions. How to extract multimodal features including facial features, physical features, behavioral features, color features, etc is still a fundamental problem in person re-identification. In this paper, we propose a novel Convolutional Neural Network, called Asymmetric Filtering-based Dense Convolutional Neural Network (AF D-CNN) to learn powerful features, which can extract different levels’ features and take advantage of identity information. Moreover, instead of using typical metric learning methods, we obtain the ranking lists by merging Joint Bayesian and re-ranking techniques which do not need dimensionality reduction. Finally, extensive experiments show that our proposed architecture performs well on four popular benchmark datasets (CUHK01, CUHK03, Market-1501, DukeMTMC-reID).",2018,Journal of Visual Communication and Image Representation
LIU201899,Panoramic visual tracking based on adaptive mechanism,"Panoramic vision, Target tracking, Particle filtering, Feature fusion, Adaption","Panoramic visual tracking has high application value in many situations, but its visual distortion is likely to cause low tracking robustness or loss of target. This paper presents a panoramic visual tracking method based on adaptive feature fusion method, the size of the trapezoidal frame is calibrated with target moving in the method, and the linear model of trapezoidal frame parameters is fitted, then according to the model trapezoidal area of target extracted, and are modified to target trapezoidal region through the affine transformation; Based on filter tracking framework, the fusion of color and shape information is as the main characteristics of the target tracking, and Bayesian fusion recursive formula is used for calculating the particle weights. The experimental results show that the proposed algorithm is better than the existing methods in tracking precision and anti occlusion, and effectively improves the robustness of panoramic visual tracking.",2018,Journal of Visual Communication and Image Representation
LIU2018218,Disparity tuning guided stereoscopic saliency detection for eye fixation prediction,"Stereoscopic saliency, Disparity tuning, Diffusion-based saliency","The development of emerging 3D display brings increasing attention of stereoscopic techniques such as quality assessment, re-targeting, and compression of 3D image, that require new saliency detection methods to deal with stereoscopic data. In this paper, we present a disparity tuning guided stereoscopic saliency (DTSS) model which apply the disparity tuning mechanism of visual cortical neurons into visual attention modeling. First, we investigate the rationality of converting features from physical quantity into perception quantity before computing saliency. Second, we discuss the biological principles that depth affects visual attention and consider both absolute and relative depth tuning mechanisms to model visual attention. Then, we propose a diffusion saliency feature combining depth and RGB features. Specifically, we use RGB contrast as primitive labels to diffuse a saliency map for depth map and using depth contrast as primitive labels to diffuse a saliency map for RGB image. Finally, an adaptively weighted fusion method is proposed for the integration of feature maps. Experiments demonstrate that the proposed model performs well against to the state-of-art methods on the task of 3D eye fixation prediction.",2018,Journal of Visual Communication and Image Representation
WANG2018228,Facial expression video analysis for depression detection in Chinese patients,"Depression detection, Facial expression, Video processing, Eye movement, Feature extraction","Emotional state analysis of facial expression is an important research content of emotion recognition. At the same time, in the medical field, the auxiliary early screening tools for depression are also urgently needed by clinics. Whether there are differences in facial expression changes between depressive patients and normal people in the same situation, and whether the characteristics can be obtained and recognized from the video images of depressive patients, so as to help doctors detect and diagnose potential depressive patients early are the contents of this study. In this paper, we introduce the videos collection process of depression patients and control group at Shandong Mental Health Center in China. The key facial features are extracted from the collected facial videos by person specific active appearance model. On the basis of locating facial features, we classified depression with the movement changes of eyes, eyebrows and corners of mouth by support vector machine. The results show that these features are effective for automatic classification of depression patients.",2018,Journal of Visual Communication and Image Representation
JIGUANG201834,A robust enhancement system based on observer-backstepping controller,"Robustness, Adaptive function, Observer","A large mount of data is indispensable in deep learning. The learning results can be different because of the noise or contaminated tags. So in this paper, a controller design method is proposed to reduce the influence due to noise or damaged label. Our method is based on backstepping control method and observer. In our work, an adaptive function is designed to eliminate the influence of the unmodelable part of the system because of the contaminated tags. For the noise, the observer is used to accurately estimated and effectively compensated. Experimental results show the effectiveness of our method. Our modified system has good performance and can accurately response the input training data in the case of the unmodelable part of the system and the external noise.",2018,Journal of Visual Communication and Image Representation
PAN201876,HDR video quality assessment: Perceptual evaluation of compressed HDR video,"High dynamic range (HDR), Subjective quality assessment, Video compression","Compared with standard dynamic range (SDR) video, the high dynamic range (HDR) video can provide us significantly enhanced viewing experience. In particular, compared to SDR video, the HDR video has better contrast and preserves more details for the same scene. With the rapid development of HDR video compression technology, there is a lack of trusted quality measure of HDR video compression. In order to facilitate the future development of objective HDR quality assessment, we build a HDR video quality assessment database, in which the bitstream is created by compressing a series of HDR video sequences. In the compression, the quantization parameters (QP) are set to 12 levels according to the configuration of the codec. The subjective quality of each bitstream is rated by 22 viewers. It is revealed that the subject viewers have arrived at a reasonable agreement on the subjective quality of different QP levels. This paper presents the results of subjective quality assessment of HDR compressed video, which also exhibits that there is significant room to further improve the objective HDR video quality assessment algorithms.",2018,Journal of Visual Communication and Image Representation
JIAN2018202,Saliency detection based on background seeds by object proposals and extended random walk,"Saliency detection, Object proposals, Background seeds, Extended random walk","Recently, many graph-based algorithms are applied in the research of saliency detection, which use the border of an image as a background query. This frequently leads to undesired errors and retrieval outputs when the boundaries of the salient objects concerned touch, or connect with, the image’s border. In this paper, a novel bottom-up saliency-detection algorithm is proposed to tackle and overcome the above issue. First, we utilize object proposals to collect the background seeds reliably. Then, the Extended Random Walk (ERW) algorithm is adopted to propagate the prior background labels to the rest of the pixels in an image. Finally, we refine the saliency map by taking both the textural and structure-information into consideration simultaneously. Experiments on publicly available data sets show that our proposed method achieves competitive results against the state-of-the-art approaches.",2018,Journal of Visual Communication and Image Representation
HUANG2018172,Pedestrian tracking by learning deep features,"Pedestrian tracking, Convolutional neural networks, Optical flow","Pedestrian tracking technique is now widely used in many intelligent systems, such as video surveillance, security regions. But many methods suffer from illumination, human posture or human appendant. With the development of Convolutional Neural Networks (CNNs), deep feature can be learned. In this paper, training images will be divided into subregions to reduce the influence of human appendant, such as bags. The remain regions are almost fixed regions. Then these fixed regions will be fed into our CNNs for learning deep features. In order to copy with different sizes of training images, an arbitrarily-sized pooling layer is developed in our CNN architecture. Then, these deeply-learned feature vector can be used in pedestrian recognition. In our work, optical flow is used for pedestrian tracking. Experimental results show our proposed method can achieve pedestrian tracking effectively.",2018,Journal of Visual Communication and Image Representation
WANG2018234,Deep intensity guidance based compression artifacts reduction for depth map,"Convolutional neural network, Compression artifacts reduction, JPEG compression, Depth map","In this paper, we propose an deep intensity guidance based compression artifacts reduction model (denoted as DIG-Net) for depth map. The proposed DIG-Net model can learn an end-to-end mapping from the color image and distorted depth map to the uncompressed depth map. To eliminate undesired artifacts such as discontinuities around object boundary, the proposed model is with three branches, which extracts the high frequency information from color image and depth maps as priors. Based on the modified edge preserving loss function, the deep multi-scale guidance information are learned and fused in the model to make the edge of depth map sharper. Experimental results show the effectiveness and superiority of our proposed model compared with the state-of-the-art methods.",2018,Journal of Visual Communication and Image Representation
DONG201828,Cross-modal hashing based on category structure preserving,"Cross-modal retrieval, Supervised hashing, Category-specific structure preserving","Cross-modal hashing has made a great development in cross-modal retrieval since its vital reduction in computational cost and storage. Generally, projections for each modality that map heterogeneous data into a common space are used to bridge the gap between different modalities. However, category-specific distributions are usually be ignored during the projection. To address this issue, we propose a novel cross-modal hashing, termed as Category Structure Preserving Hashing (CSPH), for cross-modal retrieval. In CSPH, category-specific distribution is preserved by a structure-preserving regularization term during the hash learning. Compared with existing methods, CSPH not only preserves the local structure of each category, but also generates more stable hash codes with less time for training. Extensive experiments conducted on three benchmark datasets, and the experimental results demonstrate the superiority of CSPH under various cross-modal scenarios.",2018,Journal of Visual Communication and Image Representation
WANG2018152,Learning multi-denoising autoencoding priors for image super-resolution,"Single image super-resolution, Denoising autoencoder, Multi-denoising autoencoding priors, Alternative iteration","Inspired by the application of denoising autoencoding priors (DAEP) to image restoration tasks, we propose a single image super-resolution (SISR) method via introducing multi-denoising autoencoding priors (MDAEP). On the basis of the naive DAEP, the proposed MDAEP integrates multi-DAEPs from different noisy inputs into the iterative restoration process. The combined strategy avails to alleviate the instability of the denoising autoencoders, and thus to avoid falling into local solutions. Furthermore, compared with the existing SISR methods based on end-to-end mapping, MDAEP is only trained once and applied to different magnification factors, but also can effectively preserve high-frequency information and reduce ringing effects of the reconstructed images. Both quantitative and qualitative assessments of the benchmark datasets show that the ability and the stability of the network are improved effectively. The proposed method performs better than the state-of-the-art algorithms including the basic DAEP, in terms of PSNRs and visual comparisons.",2018,Journal of Visual Communication and Image Representation
KABIRIRAD201839,"A (t,n)-multi secret image sharing scheme based on Boolean operations","-secret image sharing scheme, Multi-secret image sharing, Boolean operations, Security","In (t,n)-multi secret image sharing (MSIS) schemes, a number of secret images are shared among n users so that participation of at least t of them is needed to recover the shared images. Due to the high volume of images and computing complexity of secret sharing schemes, recent Boolean-based approaches are highly desirable. Unfortunately, to the best of our knowledge, existing literature on Boolean-based MSIS schemes only supports two cases: (2,n) and (n,n). In (n,n)-schemes, we lose fault tolerancy such that in the absence of even one share, secret images can not be recovered. On the other hand, (2,n)-MSIS seems to be quite restrictive for the wide range of applications that might occur in practice. It is therefore a challenging problem to propose a Boolean-based (t,n)-MSIS for t≠2,n. The aim of this paper is to solve this problem. We further provide formal proofs of security as well as comparison with existing literature.",2018,Journal of Visual Communication and Image Representation
MAHMOUDPOUR2018125,Reduced-reference quality assessment of multiply-distorted images based on structural and uncertainty information degradation,"Image quality, Multiply-distortion types, Shearlet transform, Entropy analysis, Support vector regression, Privileged information","The majority of existing objective Image Quality Assessment (IQA) methods are designed for evaluation of images corrupted by single distortion types. However, images may be degraded with multiple distortions during processing stages. In this paper, we propose a reduced-reference IQA algorithm to predict the quality of multiply-distorted images. An image is first decomposed into predicted and disorderly portions based on the internal generative mechanism theory. The structural information is captured from the predicted image by using a shearlet representation and Rényi directional entropy is deployed to measure the disorderly information changes. Finally, we introduce the application of a framework namely Learning Using Privileged Information (LUPI) to build a quality model and obtain quality scores. During training, the LUPI framework utilizes a set of additional privileged data to learn an improved quality model. Experimental results on multiply-distorted image datasets (MLIVE and MDID2015) confirm the effectiveness of the proposed IQA model.",2018,Journal of Visual Communication and Image Representation
ZHANG2018192,"Sparsity induced prototype learning via ℓp,1-norm grouping","Prototype, Subset selection, -norm, Sparse learning, Video summarization","Prototype learning aims to eliminate redundancy of large-scale data by selecting an informative subset. It is at the center of visual data analysis and processing. However, due to intrinsic structures among sample groups, the learnt prototypes are generally less representative and diversified. To alleviate this issue, we develop in this paper a structurally regularized model via ℓp,1-norm grouping, in which both the intra-group and inter-group structures of source data in object-space are rationally exploited. Thus, while the learnt representative prototypes are prone to distribute in different groups at the inter-group level, the grouping constraint via ℓp,1-norm will enforce the greatest diversity for intra-group prototypes. Considering the convexity in the formulated model, an alternative re-weighting solver is presented to efficiently solve the proposed optimization problem. Experimental results on video summarization, scene categorization and handwriting recognition demonstrate that the proposed method is considerably superior to the state-of-the-art methods in prototype learning.",2018,Journal of Visual Communication and Image Representation
HU2018176,Anti-occlusion tracking algorithm of video target based on prediction and re-matching strategy,"Anti-occlusion, Mean Shift algorithm, Kalman filter, Normalized cross correlation matching","Accurately locating the video target in the process of occlusion and recurrence will be very important for effective follow-up of the target. For the problem of poor applicability of Mean Shift and its improved algorithm when the target is heavily occluded, this paper proposes an anti-occlusion video target tracking algorithm based on prediction and re-matching strategy. Firstly, dynamically combining the Mean Shift algorithm with the Kalman filter, this paper achieves stable tracking of un-occluded target. Secondly, when the target is occluded, Kalman filter is combined with the target prior information to predict the position of the occluded target. Finally, in the recurrence process of occluded targets, the target is re-matched through the normalized cross-correlation method to obtain target optimal position, and then the target can be quickly and accurately located. The simulation results show that the proposed method has strong anti-occlusion and reliability tracking in the video target tracking process.",2018,Journal of Visual Communication and Image Representation
CHANG2018138,An uniformizing method of MR image intensity transformation,"MR images, Intensity value, Distribution uniformization","The scanner-dependent variations effect fluctuation of intensities of MR images, even under the fixed condition of key parameters: the scanner, the patient, the body region and the type of MRI protocol. The inherent variation causes the lack of a standard and quantifiable interpretation of image intensities. Moreover, the unbalanced distribution of intensity values lowers accuracy and sensitivity of automatic analysis and segmentation based on MR images. As such, we proposed a uniformizing method to make the distribution even while ensuring that similar intensities of MR images reflect the same tissue after processed. Our experiments based on the 3D brain tumor MR images proved that this method can significantly improve labeling and segmentation accuracy as compared to conventional preprocessed methods.",2018,Journal of Visual Communication and Image Representation
LIU2018243,Low-rank regularized multi-view inverse-covariance estimation for visual sentiment distribution prediction,"Image sentiment, Label distribution learning, Structured sparsity, Low-rank","With the increasing tendency of using images to express opinions and share experiences, sentiment analysis of visual content has aroused considerable attention interests in the past few years. Traditional sentiment analysis methods mainly focus on predicting the most dominant sentiment category of images while neglecting the sentiment ambiguity problem restricted by various factors such as environment, subjectivity, and cultural background. To tackle this problem, visual sentiment distribution prediction has been put forward to characterize images by distributions over a set of sentiment labels instead of a single distinct label or multiple distinct labels. Nevertheless, existing approaches usually separate feature embedding and distribution prediction. In this paper, we propose a novel supervised visual sentiment distribution prediction model, termed as low-rank regularized multi-view inverse-covariance estimation, in which feature embedding and distribution prediction are jointly performed. Specifically, our proposed model contains two main components: multi-view embedding and inverse-covariance estimation terms. The multi-view embedding term is restricted by low-rank constraints to seek the lowest-rank representation of samples. The inverse-covariance estimation term is restricted by structured sparsity regularization to learn a more reasonable distribution prediction model. We develop an alternative heuristic optimization algorithm to solve the objective function of the proposed model. Experiment results performed on three publicly available datasets demonstrate the effectiveness of our proposed scheme compared with state-of-the-art algorithms.",2018,Journal of Visual Communication and Image Representation
PAN201812,Graph regularized multiview marginal discriminant projection,"Marginal discriminant projection, Graph Laplacian, Manifold regularization, Multiview learning, Dimensionality reduction, Hyperspectral images classification","Multi-view data has become commonplace in today's computer vision applications, for the same object can be sampled through various viewpoints or by different instruments. The large discrepancy between distinct even heterogenous views bring the challenge of handling multi-view data. To obtain intrinsic common representation shared by all views, this paper proposes a novel multi-view algorithm called Multiview Marginal Discriminant Projection (MMDP), which is a supervised dimensionality reduction method for searching latent common subspace across multiple views. MMDP takes both inter-view and intra-view discriminant information into account and can preserve the global geometric structure and local discriminant structure of data manifold. Furthermore, the performance of MMDP is improved via imposing graph embedding as a regularization term to give a penalization of the local data geometric structure violation, which is called Graph regularized Multiview Marginal Discriminant Projection (GMMDP). The extensive experimental results on face recognition tasks demonstrate the effectiveness and robustness of MMDP and GMMDP. Finally, this paper excavates a new application scenario of multi-view learning and introduce it including the proposed GMMDP into solving hyperspectral image classification (HIC) problem, which leads to a satisfactory result.",2018,Journal of Visual Communication and Image Representation
LI201891,Community detection for multi-layer social network based on local random walk,"Multi-layer social network, Local community detection, Trust, Multi-layer local random walk","With the fast development of information network, the scale of social network has become very significant, and it has become more difficult to obtain the information of entire network. In addition, because current mining method for complicated network community utilizes the information of node link or property, which cannot effectively detect the community with dense member links and highly similar properties. As a result, most current algorithms are impractical for online social network with large scale, and we propose a community detection algorithm for multi-layer social network based on local random walk (MRLCD); this algorithm determines the core node based on the repeatability of multi-layer nodes. It expands from a core node, has local random walk in multi-layer network, identifies and controls the random walk scope of node based on the intra-layer and interlayer trust. During the walk process, the clustering coefficient of nodes to be combined is comprehensively compared to further complete a local community search, and the optimal local community search is obtained through multiple iterations. Finally, the multi-layer modularity is used as the indicator for measurement and evaluation of algorithm performance, and its performance is compared with other network clustering algorithms such as GL, LART and PMM through four actual multi-layer network datasets. The MRLCD algorithm can autonomously explore the local community structure of given node, and effectively improve the stability and accuracy for local community detection in multi-layer social network.",2018,Journal of Visual Communication and Image Representation
LI2018183,Extraction of PRNU noise from partly decoded video,"Forensics, Smartphone, Camera, Sensor noise, PRNU","This paper presents an algorithm for extracting PRNU noise from video files taken by a smartphone camera. We consider video because they are quite prevalent in our life, but are not often involved in the existing research works. Unlike most prior arts tending to extract PRNU noise from completely decompressed video frames, our proposed algorithm leaves out some procedures in the video decoding process to reduce the computational complexity. Besides, we design a maximum-likelihood-estimation algorithm for extracting PRNU noise from partly decoded video frames, and analyze the algorithm’s suitability as well in theory. Experimental results further prove the validity and effectiveness of the proposed algorithm.",2018,Journal of Visual Communication and Image Representation
WEN201884,Edge detection with feature re-extraction deep convolutional neural network,"Edge detection, Feature re-extract, Deep convolutional neural network, Generalization ability","In this paper, we propose an edge detector based on feature re-extraction (FRE) of a deep convolutional neural network to effectively utilize features extracted from each stage, and design a new loss function. The proposed detector is mainly composed of three modules: backbone, side-output, and feature fusion. The backbone module provides preliminary feature extraction; the side-output module makes network architecture more robustly map features from different stages of the backbone network to edge-pixel space by applying residual learning, and the feature fusion module generates the edge map. Generalization ability on the same distribution is verified using the BSDS500 dataset, achieving optimal dataset scale (ODS) F-score = 0.804. Cross-distribution generalization ability is verified on the NYUDv2 dataset, achieving ODS F-score = 0.701. In addition, we find that freezing backbone network can significantly speed up training process, without much overall accuracy loss (ODS F-score of 0.791 after 5.4k iterations).",2018,Journal of Visual Communication and Image Representation
CAI201823,Can modified minimax win in Pearl’s game?,"Minimax algorithm, Modified Minimax algorithm, Pearl’s game","Minimax algorithm is widely used for adversarial searching. It is commonly believed that searching depth and winning chance has a positive correlation, but Dana S. Nau pointed out in his 1982 research that in Pearl’s game, pathology occurs. Minimax shows a decrease of winning chance as searching depth increases. Our research proposes a possible way to fix the pathology by taking the opponent’s strategy into consideration in some specific cases. The experiment proves that the accumulation of incorrect predictions at least partially causes the pathology. Our modified version of Minimax successfully overcomes the pathology and continues to present the power of Minimax in Pearl’s game.",2018,Journal of Visual Communication and Image Representation
BEZZINE2018283,Sparse optimization of non separable vector lifting scheme for stereo image coding,"Stereo images, Adaptive coding, Vector lifting scheme, Non separable transform, Optimization","One of the potential 3D imaging techniques relies on the use of stereoscopic systems. The great interest in these systems has resulted in huge amount of data which needs to be compressed for storage and transmission purposes. In this context, vector lifting scheme has been found to be an efficient approach for stereo image coding. For instance, the coding performance depends on the design of the involved lifting operators referred to as prediction and update filters. For this reason, while a non separable vector lifting structure is retained, we investigate different techniques for optimizing sparse criteria to design the filters used with both views. More precisely, an independent full optimization algorithm as well as a joint algorithm will be developed and studied. Simulations performed on different stereo images demonstrate the effectiveness of the proposed sparse optimization algorithms in terms of quality of reconstruction and bitrate saving.",2018,Journal of Visual Communication and Image Representation
PRIBYL2017130,Absolute pose estimation from line correspondences using direct linear transformation,"Camera pose estimation, Perspective-n-Line, Line correspondences, Direct linear transformation","This work is concerned with camera pose estimation from correspondences of 3D/2D lines, i. e. with the Perspective-n-Line (PnL) problem. We focus on large line sets, which can be efficiently solved by methods using linear formulation of PnL. We propose a novel method “DLT-Combined-Lines” based on the Direct Linear Transformation (DLT) algorithm, which benefits from a new combination of two existing DLT methods for pose estimation. The method represents 2D structure by lines, and 3D structure by both points and lines. The redundant 3D information reduces the minimum required line correspondences to 5. A cornerstone of the method is a combined projection matrix estimated by the DLT algorithm. It contains multiple estimates of camera rotation and translation, which can be recovered after enforcing constraints of the matrix. Multiplicity of the estimates is exploited to improve the accuracy of the proposed method. For large line sets (10 and more), the method is comparable to the state-of-the-art in accuracy of orientation estimation. It achieves state-of-the-art accuracy in estimation of camera position and it yields the smallest reprojection error under strong image noise. The method achieves top-3 results on real world data. The proposed method is also highly computationally effective, estimating the pose of 1000 lines in 12 ms on a desktop computer.",2017,Computer Vision and Image Understanding
SULTANI201777,Automatic action annotation in weakly labeled videos,"Weakly supervised, Action annotation, Generalized maximum clique graph","Manual spatio-temporal annotation of human actions in videos is laborious, requires several annotators and contains human biases. In this paper, we present a weakly supervised approach to automatically obtain spatio-temporal annotations of an actor in action videos. We first obtain a large number of action proposals in each video. To capture a few most representative action proposals in each video and evade processing thousands of them, we rank them using optical flow and saliency in a 3D-MRF based framework and select a few proposals using MAP based proposal subset selection method. We demonstrate that this ranking preserves the high quality action proposals. Several such proposals are generated for each video of the same action. Our next challenge is to iteratively select one proposal from each video so that all proposals are globally consistent. We formulate this as Generalized Maximum Clique Graph problem using shape, global and fine-grained similarity of proposals across the videos. The output of our method is the most action representative proposals from each video. Our method can also annotate multiple instances of the same action in a video. We have validated our approach on three challenging action datasets: UCF-Sport, sub-JHMDB and THUMOS13 and have obtained promising results compared to several baseline methods. Moreover, action detection experiments using annotations obtained by our method and several baselines demonstrate the superiority of our approach.",2017,Computer Vision and Image Understanding
JAMPOUR201729,Face inpainting based on high-level facial attributes,"Face inpainting, Face analysis, Facial attributes","We introduce a novel data-driven approach for face inpainting, which makes use of the observable region of an occluded face as well as its inferred high-level facial attributes, namely gender, ethnicity, and expression. Based on the intuition that the realism of a face inpainting result depends significantly on its overall consistency with respect to these high-level attributes, our approach selects a guidance face that matches the targeted attributes and utilizes it together with the observable input face regions to inpaint the missing areas. These two sources of information are balanced using an adaptive optimization, and the inpainting is performed on the intrinsic image layers instead of the RGB color space to handle the illumination differences between the target face and the guidance face to further enhance the resulting visual quality. Our experiments demonstrate that this approach is effective in inpainting facial components such as the mouth or the eyes that could be partially or completely occluded in the input face. A perceptual study shows that our approach generates more natural facial appearances by accounting for high-level facial attributes.",2017,Computer Vision and Image Understanding
LI201799,Predictive RANSAC: Effective model fitting and tracking approach under heavy noise and outliers,"Robust estimation, Outlier removal, RANSAC, Kalman filtering","In this paper, we introduce a robust and efficient algorithm, Predictive RANSAC, to fit and track a model in the presence of a large number of outlier measurements and heavy noise. Our algorithm works in two stages. In the model fitting stage, the algorithm first ranks the measurements from most likely to be inliers to least likely. It searches for the best model fit from the top-ranked to the lower-ranked measurements using a similar, but more effective, procedure to the RANSAC algorithm. In the model tracking stage, we use a Kalman filter to predict the location of the model and generate the confidence interval using the prediction error. To update the Kalman filter, the fitting process begins again with an initial guess using the Kalman filter prediction result and searches for inliers in the confidence interval. We also estimate the parameter of the Kalman filter such as noise covariance using the fitting algorithm and a Gaussian-Uniform mixture model. In this way, the two components work together to improve overall performance. To show the performance of the Predictive RANSAC algorithm, we compare our approach with previous algorithms based on RANSAC frameworks over several synthetic data sets and real world data sets, which include road mark fitting, homography estimation and multiple target tracking. The Predictive RANSAC algorithm shows better results in estimation accuracy, and consumes significantly less computational power.",2017,Computer Vision and Image Understanding
SULTANI201742,Unsupervised action proposal ranking through proposal recombination,"Action proposal ranking, Action recognition, Unsupervised method","Recently, action proposal methods have played an important role in action recognition tasks, as they reduce the search space dramatically. Most unsupervised action proposal methods tend to generate hundreds of action proposals which include many noisy, inconsistent, and unranked action proposals, while supervised action proposal methods take advantage of predefined object detectors (e.g., human detector) to refine and score the action proposals, but they require thousands of manual annotations to train. Given the action proposals in a video, the goal of the proposed work is to generate a few better action proposals that are ranked properly. In our approach, we first divide action proposal into sub-proposal and then use Dynamic Programming based graph optimization scheme to select the optimal combinations of sub-proposals from different proposals and assign each new proposal a score. We propose a new unsupervised image-based actionness detector that leverages web images and employs it as one of the node scores in our graph formulation. Moreover, we capture motion information by estimating the number of motion contours within each action proposal patch. The proposed method is an unsupervised method that neither needs bounding box annotations nor video level labels, which is desirable with the current explosion of large-scale action datasets. Our approach is generic and does not depend on a specific action proposal method. We evaluate our approach on several publicly available trimmed and untrimmed datasets and obtain better performance compared to several proposal ranking methods. In addition, we demonstrate that properly ranked proposals produce significantly better action detection as compared to state-of-the-art proposal based methods.",2017,Computer Vision and Image Understanding
YUN201765,Riemannian manifold-valued part-based features and geodesic-induced kernel machine for activity classification dedicated to assisted living,"Activity of daily living, Human activity classification, Fall detection, Assisted living, Riemannian manifolds, Geodesic distance, Covariance matrix, Kernel machines","In this paper, we address the problem of classifying human activities that are typical in a daily living environment from videos. We propose a novel method based on Riemannian manifolds that uses a tree structure of two layers, where nodes in each tree branch are on a Riemannian manifold. Each node corresponds to different part-based covariance features, and induces a geodesic-based kernel machine for classification. In the first layer, activities are classified according to the dynamics of body pose and the movement of hands or arms. Activities with similar body pose and motion but different human-object interaction are coarsely classified into the same category. In the second layer, the coarsely classified activities are further fine classified, according to the appearance of local image patches at hands in key frames. This is based on the observation that interacting objects as discriminative cues are likely to be attached to hands. The main novelties of this paper include: (i) Motion of body parts for each video activity is characterized by global features. More specifically, the features are distances between each pair of key points and the orientations of lines that connect them; (ii) Human-object interaction is described by local features. That is, the appearance of local regions around hands in key frames, where key frames are selected using the proximity of hands to other key points; (iii) Classification of human activities is formulated by a geodesic distance-induced kernel machine. This is done by exploiting pairwise geodesics on Riemannian manifolds under the log-Euclidean metric. Experiments were conducted on 2 video datasets. The first dataset, made on our university campus, contains 8 activities with a total number of 943 videos. The second dataset is from a publicly available dataset, containing 7 activity classes and a total of 224 videos. Our test results on the first video dataset have shown high classification accuracy (average 94.27%), and small false alarm rate (average 0.80%). For the second video dataset, test results from the proposed method are compared with 6 existing methods. The proposed method has outperformed all these existing methods. Discussions are given on the impact of detected skeleton points from Kinect on the performance of activity classification.",2017,Computer Vision and Image Understanding
YOUSSEF201720,Shot boundary detection via adaptive low rank and svd-updating,"Shot boundary, Low rank, Frobenius norm, SVD-updating","Usually considered as the first step in content-based video retrieval, shot boundary detection (SBD) is crucial to subsequent high-level applications like video summarization. The paper proposes an accurate video shot boundary detection method based on singular value decomposition (SVD), through the use of different mathematical theorems and interpretations. In our contribution, adaptive feature extraction is performed using the Frobenius norm of low rank approximation matrices. Each frame will be mapped into k˜-dimensional vector in the singular space according to each segment. The classification of continuity values is then achieved via double thresholding technique for detecting the hard cuts. For gradual transitions detection, the folding-in technique, known as SVD-updating, is used for the first time in video shot boundary detection. This allows for accurate detection in reduced computational time, as it is no longer necessary to recalculate the whole SVD decomposition for segment correction. Experimental results on four different datasets, including the TRECVid 2001, 2002 and 2005 SBD tasks, show the effectiveness of our detector, which outperforms recent related methods in detecting both hard and gradual transitions.",2017,Computer Vision and Image Understanding
MISHKIN201711,Systematic evaluation of convolution neural network advances on the Imagenet,"CNN, Benchmark, Non-linearity, Pooling, ImageNet","The paper systematically studies the impact of a range of recent advances in convolution neural network (CNN) architectures and learning methods on the object categorization (ILSVRC) problem. The evaluation tests the influence of the following choices of the architecture: non-linearity (ReLU, ELU, maxout, compatability with batch normalization), pooling variants (stochastic, max, average, mixed), network width, classifier design (convolutional, fully-connected, SPP), image pre-processing, and of learning parameters: learning rate, batch size, cleanliness of the data, etc. The performance gains of the proposed modifications are first tested individually and then in combination. The sum of individual gains is greater than the observed improvement when all modifications are introduced, but the “deficit” is small suggesting independence of their benefits. We show that the use of 128 × 128 pixel images is sufficient to make qualitative conclusions about optimal network structure that hold for the full size Caffe and VGG nets. The results are obtained an order of magnitude faster than with the standard 224 pixel images.",2017,Computer Vision and Image Understanding
ZHANG201751,Salient object detection based on super-pixel clustering and unified low-rank representation,"Salient object detection, Laplacian sparse subspace clustering, Unified low-rank representation, Primitive saliency dictionary construction, Super-pixel cluster","In this paper, we present a novel salient object detection method, efficiently combining Laplacian sparse subspace clustering (LSSC) and unified low-rank representation (ULRR). Unlike traditional low-rank matrix recovery (LRMR) based saliency detection methods which mainly extract saliency from pixels or super-pixels, our method advocates the saliency detection on the super-pixel clusters generated by LSSC. By doing so, our method succeeds in extracting large-size salient objects from cluttered backgrounds, against the detection of small-size salient objects from simple backgrounds obtained by most existing work. The entire algorithm is carried out in two stages: region clustering and cluster saliency detection. In the first stage, the input image is segmented into many super-pixels, and on top of it, they are further grouped into different clusters by using LSSC. Each cluster contains multiple super-pixels having similar features (e.g., colors and intensities), and may correspond to a part of a salient object in the foreground or a local region in the background. In the second stage, we formulate the saliency detection of each super-pixel cluster as a unified low-rankness and sparsity pursuit problem using a ULRR model, which integrates a Laplacian regularization term with respect to the sparse error matrix into the traditional low-rank representation (LRR) model. The whole model is based on a sensible cluster-consistency assumption that the spatially adjacent super-pixels within the same cluster should have similar saliency values, similar representation coefficients as well as similar reconstruction errors. In addition, we construct a primitive dictionary for the ULRR model in terms of the local-global color contrast of each super-pixel. On top of it, a global saliency measure covering the representation coefficients and a local saliency measure considering the sparse reconstruction errors are jointly employed to define the final saliency measure. Comprehensive experiments over diverse publicly available benchmark data sets demonstrate the validity of the proposed method.",2017,Computer Vision and Image Understanding
SANTANACEDRES20171,Automatic correction of perspective and optical distortions,"Lens distortion, Vanishing points, Perspective correction","Perspective and optical (lens) distortions are aberrations of very different nature that can simultaneously affect an image. Perspective distortion is caused by the position of the camera, especially when it is too close to the scene. Optical distortion is a lens aberration which causes straight lines in the scene to be projected onto the image as distorted lines. Standard methods to correct perspective distortion are based on the estimation of the vanishing points, which can fail if lens distortion is significant. In this paper, we introduce a new method which addresses both problems in a single framework. First we estimate a lens distortion model by extracting a collection of distorted lines in the image. These distorted lines are afterward rectified by means of the lens distortion model and used to estimate the vanishing points. Finally, the vanishing points are used to correct the perspective distortion. We present a variety of experiments to show the reliability of the proposed method.",2017,Computer Vision and Image Understanding
ASAD2017114,SPORE: Staged Probabilistic Regression for Hand Orientation Inference,"Hand orientation, Regression, Probabilistic, Hand pose","Learning the global hand orientation from 2D monocular images is a challenging task, as the projected hand shape is affected by a number of variations. These include inter-person hand shape and size variations, intra-person pose and style variations and self-occlusion due to varying hand orientation. Given a hand orientation dataset containing these variations, a single regressor proves to be limited for learning the mapping of hand silhouette images onto the orientation angles. We address this by proposing a staged probabilistic regressor (SPORE) which consists of multiple expert regressors, each one learning a subset of variations from the dataset. Inspired by Boosting, the novelty of our method comes from the staged probabilistic learning, where each stage consists of training and adding an expert regressor to the intermediate ensemble of expert regressors. Unlike Boosting, we marginalize the posterior prediction probabilities from each expert regressor by learning a marginalization weights regressor, where the weights are extracted during training using a Kullback–Leibler divergence-based optimization. We extend and evaluate our proposed framework for inferring hand orientation and pose simultaneously. In comparison to the state-of-the-art of hand orientation inference, multi-layered Random Forest marginalization and Boosting, our proposed method proves to be more accurate. Moreover, experimental results reveal that simultaneously learning hand orientation and pose from 2D monocular images significantly improves the pose classification performance.",2017,Computer Vision and Image Understanding
SOCHOR201787,Traffic surveillance camera calibration by 3D model bounding box alignment for accurate vehicle speed measurement,"Speed measurement, Camera calibration, Fully automatic, Traffic surveillance, Bounding box alignment, Vanishing point detection","In this paper, we focus on fully automatic traffic surveillance camera calibration, which we use for speed measurement of passing vehicles. We improve over a recent state-of-the-art camera calibration method for traffic surveillance based on two detected vanishing points. More importantly, we propose a novel automatic scene scale inference method. The method is based on matching bounding boxes of rendered 3D models of vehicles with detected bounding boxes in the image. The proposed method can be used from arbitrary viewpoints, since it has no constraints on camera placement. We evaluate our method on the recent comprehensive dataset for speed measurement BrnoCompSpeed. Experiments show that our automatic camera calibration method by detection of two vanishing points reduces error by 50% (mean distance ratio error reduced from 0.18 to 0.09) compared to the previous state-of-the-art method. We also show that our scene scale inference method is more precise, outperforming both state-of-the-art automatic calibration method for speed measurement (error reduction by 86 % – 7.98 km/h to 1.10 km/h) and manual calibration (error reduction by 19 % – 1.35 km/h to 1.10 km/h). We also present qualitative results of the proposed automatic camera calibration method on video sequences obtained from real surveillance cameras in various places, and under different lighting conditions (night, dawn, day).",2017,Computer Vision and Image Understanding
LU2017145,Indoor localization via multi-view images and videos,"Vision-based localization, Multi-task learning, Self-Similarity matrix","Indoor localization systems are applicable to labyrinth-like environments where mobile and robotic operators require precise direction and location. Existing indoor localization systems require additional equipment, such as WiFi receivers and distributed beacons to capture the necessary information to accurately calculate direction and location. Image-based localization is mostly used in outdoor environments to compensate for the deficiency of weak GPS signals in large building areas. This paper presents a new indoor localization method that significantly reduces the dependency of external hardware resource by utilizing multiple-view configuration. The proposed algorithm initially extracts the self-similarity matrix features to represent the video that captures the user’s spatio-temporal information. We then perform the image and video retrieval based on the trained multi-task classifiers to determine scene location and orientation. Our method generates accurate location and orientation estimation.",2017,Computer Vision and Image Understanding
ZACH201847,Generalized fusion moves for continuous label optimization,"Energy minimization, Markov random fields, Convex relaxations, Low-level vision","Energy-minimization methods are ubiquitous in computer vision and related fields. Low-level computer vision problems are typically defined on regular pixel lattices and seek to assign discrete or continuous values (or both) to each pixel such that a combined data term and a spatial smoothness prior are minimized. In this work we propose to minimize difficult, non-convex energies over continuous unknowns by repeated generalized fusion moves. In contrast to standard fusion moves, the fusion step jointly optimizes over binary and continuous sets of variables representing label ranges. Further, each fusion step can optimize over additional continuous unknowns appearing in the energy. We demonstrate the general method on a variational-inspired stereo approach, and optionally optimize over radiometric changes between the images as well.",2018,Computer Vision and Image Understanding
CEVIKALP20182,Large-scale image retrieval using transductive support vector machines,"Image retrieval, Hashing, Transductive support vector machines, Semi-supervised learning, Ramp loss","In this paper, we propose a new method for large-scale image retrieval by using binary hierarchical trees and transductive support vector machines (TSVMs). We create multiple hierarchical trees based on the separability of the visual object classes, and TSVM classifier is used to find the hyperplane that best separates both the labeled and unlabeled data samples at each node of the binary hierarchical trees (BHTs). Then the separating hyperplanes returned by TSVM are used to create binary codes or to reduce the dimension. We propose a novel TSVM method that is more robust to the noisy labels by interchanging the classical Hinge loss with the robust Ramp loss. Stochastic gradient based solver is used to learn TSVM classifier to ensure that the method scales well with large-scale data sets. The proposed method significantly improves the Euclidean distance metric and achieves comparable results to the state-of-the-art on CIFAR10 and MNIST data sets, and significantly outperforms the state-of-the-art hashing methods on more challenging ImageCLEF 2013, NUS-WIDE, and CIFAR100 data sets.",2018,Computer Vision and Image Understanding
VAKHITOV201813,Set2Model networks: Learning discriminatively to learn generative models,"Learning-to-learn, Deep learning, Internet-based computer vision, Image retrieval, Gaussian mixture model, ImageNet","We present a new “learning-to-learn”-type approach that enables rapid learning of concepts from small-to-medium sized training sets and is primarily designed for web-initialized image retrieval. At the core of our approach is a deep architecture (a Set2Model network) that maps sets of examples to simple generative probabilistic models such as Gaussians or mixtures of Gaussians in the space of high-dimensional descriptors. The parameters of the embedding into the descriptor space are trained in the end-to-end fashion in the meta-learning stage using a set of training learning problems. The main technical novelty of our approach is the derivation of the backprop process through the mixture model fitting, which makes the likelihood of the resulting models differentiable with respect to the positions of the input descriptors. While the meta-learning process for a Set2Model network is discriminative, a trained Set2Model network performs generative learning of generative models in the descriptor space, which facilitates learning in the cases when no negative examples are available, and whenever the concept being learned is polysemous or represented by noisy training sets. Among other experiments, we demonstrate that these properties allow Set2Model networks to pick visual concepts from the raw outputs of Internet image search engines better than a set of strong baselines.",2018,Computer Vision and Image Understanding
WIENTAPPER201857,"A universal, closed-form approach for absolute pose problems","Absolute pose, Perspective-n-point problem, Perspective-n-line problem, Absolute orientation, Gröbner basis, 3D registration","We propose a general approach for absolute pose problems including the well known perspective-n-point (PnP) problem, its generalized variant (GPnP) with and without scale, and the pose from 2D line correspondences (PnL). These have received a tremendous attention in the computer vision community during the last decades. However, it was only recently that efficient, globally optimal, closed-form solutions have been proposed, which can handle arbitrary numbers of correspondences including minimal configurations as well as over-constrained cases with linear complexity. We follow the general scheme by eliminating the linear parameters first, which results in a least squares error function that only depends on the non-linear rotation and a small symmetric coefficient matrix of fixed size. Then, in a second step the rotation is solved with algorithms which are derived using methods from algebraic geometry such as the Gröbner basis method. We propose a unified formulation based on a representation with orthogonal complements which allows to combine different types of constraints elegantly in one single framework. We show that with our unified formulation existing polynomial solvers can be interchangeably applied to problem instances other than those they were originally proposed for. It becomes possible to compare them on various registrations problems with respect to accuracy, numerical stability, and computational speed. Our compression procedure not only preserves linear complexity, it is even faster than previous formulations. For the second step we also derive an own algebraic equation solver, which can additionally handle the registration from 3D point-to-point correspondences, where other rotation solvers fail. Finally, we also present a marker-based SLAM approach with automatic registration to a target coordinate system based on partial and distributed reference information. It represents an application example that goes beyond classical camera pose estimation from image measurements and also serves for evaluation on real data.",2018,Computer Vision and Image Understanding
ZHANG201886,Cascade residuals guided nonlinear dictionary learning,"Sparse coding, Dictionary learning","In this paper, we aim to extend dictionary learning onto hierarchical image representations in a principled way. To achieve dictionary atoms capture additional information from extended receptive fields and attain improved descriptive capacity, we present a two-pass multi-resolution cascade framework for dictionary learning and sparse coding. This cascade method allows collaborative reconstructions at different resolutions using only the same dimensional dictionary atoms. The jointly learned dictionary comprises atoms that adapt to the information available at the coarsest layer, where the support of atoms reaches a maximum range, and the residual images, where the supplementary details refine progressively a reconstruction objective. The residual at a layer is computed by the difference between the aggregated reconstructions of the previous layers and the downsampled original image at that layer. Our method generates flexible and accurate representations using only a small number of coefficients. It is computationally efficient since it encodes the image at the coarsest resolution while yielding very sparse residuals. Our extensive experiments on multiple image coding, denoising, inpainting and artifact removal tasks demonstrate that our method provides superior results.",2018,Computer Vision and Image Understanding
ADITYA201833,Image Understanding using vision and reasoning through Scene Description Graph,"Image Understanding, Commonsense Reasoning, Vision, Reasoning","Two of the fundamental tasks in image understanding using text are caption generation and visual question answering (Antol et al., 2015; Xiong et al., 2016). This work presents an intermediate knowledge structure that can be used for both tasks to obtain increased interpretability. We call this knowledge structure Scene Description Graph (SDG), as it is a directed labeled graph, representing objects, actions, regions, as well as their attributes, along with inferred concepts and semantic (from KM-Ontology (Clark et al., 2004)), ontological (i.e. superclass, hasProperty), and spatial relations. Thereby a general architecture is proposed in which a system can represent both the content and underlying concepts of an image using an SDG. The architecture is implemented using generic visual recognition techniques and commonsense reasoning to extract graphs from images. The utility of the generated SDGs is demonstrated in the applications of image captioning, image retrieval, and through examples in visual question answering. The experiments in this work show that the extracted graphs capture syntactic and semantic content of images with reasonable accuracy.",2018,Computer Vision and Image Understanding
RUPPRECHT201824,Learning without prejudice: Avoiding bias in webly-supervised action recognition,"Action recognition, Webly-supervised learning","Webly-supervised learning has recently emerged as an alternative paradigm to traditional supervised learning based on large-scale datasets with manual annotations. The key idea is that models such as CNNs can be learned from the noisy visual data available on the web. In this work we aim to exploit web data for video understanding tasks such as action recognition and detection. One of the main problems in webly-supervised learning is cleaning the noisy labeled data from the web. The state-of-the-art paradigm relies on training a first classifier on noisy data that is then used to clean the remaining dataset. Our key insight is that this procedure biases the second classifier towards samples that the first one understands. Here we train two independent CNNs, a RGB network on web images and video frames and a second network using temporal information from optical flow. We show that training the networks independently is vastly superior to selecting the frames for the flow classifier by using our RGB network. Moreover, we show benefits in enriching the training set with different data sources from heterogeneous public web databases. We demonstrate that our framework outperforms all other webly-supervised methods on two public benchmarks, UCF-101 and Thumos’14.",2018,Computer Vision and Image Understanding
CHUNG201876,Learning to lip read words by watching videos,"Lip reading, Lip synchronisation, Active speaker detection, Large vocabulary, Dataset","Our aim is to recognise the words being spoken by a talking face, given only the video but not the audio. Existing works in this area have focussed on trying to recognise a small number of utterances in controlled environments (e.g. digits and alphabets), partially due to the shortage of suitable datasets. We make three novel contributions: first, we develop a pipeline for fully automated data collection from TV broadcasts. With this we have generated a dataset with over a million word instances, spoken by over a thousand different people; second, we develop a two-stream convolutional neural network that learns a joint embedding between the sound and the mouth motions from unlabelled data. We apply this network to the tasks of audio-to-video synchronisation and active speaker detection; third, we train convolutional and recurrent networks that are able to effectively learn and recognize hundreds of words from this large-scale dataset. In lip reading and in speaker detection, we demonstrate results that exceed the current state-of-the-art on public benchmark datasets.",2018,Computer Vision and Image Understanding
HUANG201721,Store classification using Text-Exemplar-Similarity and Hypotheses-Weighted-CNN,"Store classification, Deep convolutional network, Hypotheses-weighted CNN, Image classification, Text-Exemplar-Similarity","Store classification is a challenging task due to the large variation of view, scale, illumination and occlusion. To efficiently distinguish different stores, we introduce two features: Text-Exemplar-Similarity and Hypotheses-Weighted-CNN. For the first feature, the similarity with the discriminative characters is used to represent the text information. For the second feature, we first generate a set of object hypotheses. Then, we introduce two priors: edge boundary and repeatness prior to give a higher weight to the hypotheses enclosing the object. After the generation of two features, a simple and efficient optimization method is used to find the best weight for each feature. Extensive experiments are evaluated to verify the superiority of the proposed method. We built a new 9-class store dataset composed of photos and images from the internet. The experiments show that our method is nearly 10% higher than the state-of-art methods.",2017,Journal of Visual Communication and Image Representation
TIAN201750,Automatic image annotation based on Gaussian mixture model considering cross-modal correlations,"Automatic image annotation, Gaussian mixture model, RPEM, Semantic correlation, Max-bisection, Image retrieval","Automatic image annotation has been an active topic of research in the field of computer vision and pattern recognition for decades. In this paper, we present a new method for automatic image annotation based on Gaussian mixture model (GMM) considering cross-modal correlations. To be specific, we first employ GMM fitted by the rival penalized expectation-maximization (RPEM) algorithm to estimate the posterior probabilities of each annotation keyword. Next, a label similarity graph is constructed by a weighted linear combination of label similarity and visual similarity by seamlessly integrating the information from both image low level visual features and high level semantic concepts together, which can effectively avoid the phenomenon that different images with the same candidate annotations would obtain the same refinement results. Followed by the rank-two relaxation heuristics over the built label similarity graph is applied to further mine the correlation of the candidate annotations so as to capture the refining annotation results, which plays a crucial role in the semantic based image retrieval. The main contributions of this work can be summarized as follows: (1) Exploiting GMM that is trained by the RPEM algorithm to capture the initial semantic annotations of images. (2) The label similarity graph is constructed by a weighted linear combination of label similarity and visual similarity of images associated with the corresponding labels. (3) Refining the candidate set of annotations generated by the GMM through solving the max-bisection based on the rank-two relaxation algorithm over the weighted label graph. Compared to the current competitive model SGMM-RW, we can achieve significant improvements of 4% and 5% in precision, 6% and 9% in recall on the Corel5k and Mirflickr25k, respectively.",2017,Journal of Visual Communication and Image Representation
MA201729,Manifold-ranking embedded order preserving hashing for image semantic retrieval,"Manifold ranking, Hashing, Image semantic retrieval","Due to the storage and computational efficiency of hashing technology, it has proven a valuable tool for large scale similarity search. In many cases, the large scale data in real-world lie near some (unknown) low-dimensional and non-linear manifold. Moreover, Manifold Ranking approach can preserve the global topological structure of the data set more effectively than Euclidean Distance-based Ranking approach, which fails to preserve the semantic relevance degree. However, most existing hashing methods ignore the global topological structure of the data set. The key issue is how to incorporate the global topological structure of data set into learning effective hashing function. In this paper, we propose a novel unsupervised hashing approach, namely Manifold-Ranking Embedded Order Preserving Hashing (MREOPH). A manifold ranking loss is introduced to solve the issue of global topological structure preserving. An order preserving loss is introduced to ensure the consistency between manifold ranking and hamming ranking. A hypercubic quantization loss is introduced to learn discrete binary codes. The information theoretic regularization term is taken into consideration for preserving desirable properties of hash codes. Finally, we integrate them in a joint optimization framework for minimizing the information loss in each processing. Experimental results on three datasets for semantic search clearly demonstrate the effectiveness of the proposed method.",2017,Journal of Visual Communication and Image Representation
TARIQ2017198,Spatial/temporal motion consistency based MERGE mode early decision for HEVC,"Fast MERGE mode prediction, High Efficiency Video Coding (HEVC), Image coding, Video coding, Inter mode decision, Fast mode decision, Merge candidates, Sum of absolute difference, SAD","A framework for the early decision of MERGE mode (EDM) is proposed to overcome the brute force inter mode decision for the coding unit (CU) in High Efficiency Video Coding (HEVC). Firstly, the prediction-results of merge candidates (MrgCands) in previous and current frame are modeled to identify smooth/single-motion regions for EDM. Secondly, the RD-cost based statistical model is proposed for EDM since MERGE is selected 98.20% on average when 2N×2N and MERGE produce similar RD-cost. Finally, a model is proposed that obtains the SAD values for the prediction units (PU) of modes using the motion-estimation of 2N×2N and performs EDM based on the comparison of these SAD values. Experimental results demonstrate that an average 46.75% coding time can be saved, while the Bjøntegaard delta bit rate (BDBR) increase is only 1.79%. In addition, an average of 68.54% complexity reduction is achieved with 1.79% BDBR increase for conference video sequences.",2017,Journal of Visual Communication and Image Representation
HU2017106,Massive parallelization of approximate nearest neighbor search on KD-tree for high-dimensional image descriptor matching,"KD-tree, Approximate nearest neighbor search, Parallel algorithm, GPU, CUDA, Image descriptor matching","To overcome the high computing cost associated with high-dimensional digital image descriptor matching, this paper presents a massively parallel approximate nearest neighbor search (ANNS) on K-dimensional tree (KD-tree) on the modern massively parallel architectures (MPA). The proposed algorithm is of comparable quality to traditional sequential counterpart on central processing unit (CPU). However, it achieves a high speedup factor of 121 when applied to high-dimensional real-world image descriptor datasets. The algorithm is also studied for factors that impact its performance to obtain the optimal runtime configurations for various datasets. The performance of the proposed parallel ANNS algorithm is also verified on typical 3D image matching scenarios. With the classical local image descriptor signature of histograms of orientations (SHOT), the parallel image descriptor matching can achieve speedup of up to 128. Our implementation will potentially benefit realtime image descriptor matching in high dimensions.",2017,Journal of Visual Communication and Image Representation
ACHARYA2017156,Efficient fuzzy composite predictive scheme for effectual 2-D up-sampling of images for multimedia applications,"Up-scaling, Interpolation, De-blurring, Local variance, Laplacian, Fuzzy logic, Fuzzy inference system","In this paper, a highly nonlinear, fuzzy logic based, composite scheme is proposed by combining a pre-processing and a post-processing operation to efficiently restore high frequency (HF) and very high frequency (VHF) details in an up-scaled image. The blurring in case of an up-sampled image is caused by the degradation of HF and VHF image details that correspond to fine details and edge regions during the up-sampling process. The degradation of HF and VHF image details is more significant than that of the flat and slowly varying regions. In order to resolve this problem effectively, a fuzzy composite scheme is developed which is based on the inverse modeling approach of HF degradation. During the pre-processing operation, the VHF components of an image are boosted up using recursive Laplacian of Laplacian (LOL) operator prior to image up-scaling. Subsequent to the image up-scaling, a fuzzy local adaptive Laplacian post-processing scheme is used which enhances the HF image details more than the low frequency image details based on local statistics in the up-scaled image. The HF restoration performance of the fuzzy based composite scheme is enhanced by improving its nonlinearity through the variations of different parameters of the fuzzy inference system (FIS) such as slope, width and the number of input-, and output membership functions. The effective fusion of pre-processing and post-processing operations makes the proposed scheme much effective to tackle the non-uniform blurring than the standalone pre-processing and post-processing techniques. Experimental results reveal that the proposed composite scheme gives much less blurring in comparison to the standalone schemes and performs better than most of the widely used interpolation schemes in terms of objective and subjective measures.",2017,Journal of Visual Communication and Image Representation
LI201761,Joint image compression and encryption based on order-8 alternating transforms,"Image encryption, Orthogonal transforms, Security analysis, JPEG standard","In this paper, we propose a novel joint image compression and encryption scheme based on JPEG standard. We realize image encryption at JPEG’s transformation stage. Instead of only using 8×8 discrete cosine transform (DCT) for transformation, we generate new orthogonal transforms by embedding an extra rotation angle of π to different stages’ butterflies in 8×8 DCT’s flow-graph, and then apply them alternatively for transformation according to a predefined secret key. By carefully controlling the number of rotation angles embedded, the quality control of encrypted images can also be achieved. The encryption algorithm is further enhanced by performing block permutation before the entropy encoding stage. Extensive experiments have been conducted to show the good protection and compression performance of our encryption schemes. Finally, a detailed security analysis is provided to show the encryption schemes’ resistance to various cryptanalysis methods, such as brute-force attack, key sensitivity analysis, replacement attack and statistical attack.",2017,Journal of Visual Communication and Image Representation
LEE2017148,Novel video stabilization for real-time optical character recognition applications,"Video stabilization, Optical character recognition, Real-time","This paper presents a novel video stabilization algorithm for real-time optical character recognition (OCR) applications. The proposed method generates output frames in order to stabilize the position of a target word that will be recognized by the OCR application. Unlike in conventional algorithms, in the proposed algorithm, a causal low pass filter is not applied to the trajectory of the target word for reducing the high frequency component of camera motion. The proposed algorithm directly calculates the stable position of the word using two forces: the force used to pull the target word to the center of an output frame and a back force used to return the center of an output frame to the center of an input frame. Hence, the proposed algorithm significantly minimizes the time take to respond to sudden camera movement. Although the proposed method may not outperform state-of-the-art video stabilization in terms of video stability, the proposed technique is much more appropriate for real-time OCR applications than the conventional techniques in terms of accuracy, computational cost, processing delay, and the time taken to respond to sudden camera movement. Simulation results prove the superiority of the proposed method over conventional techniques for real-time OCR applications.",2017,Journal of Visual Communication and Image Representation
LI20171,Robust object tracking based on adaptive templates matching via the fusion of multiple features,"Visual tracking, Feature fusion, Double templates matching, Timed motion history image","Moving object tracking under complex scenes remains to be a challenging problem because the appearance of a target object can be drastically changed due to several factors, such as occlusions, illumination, pose, scale change and deformation. This study proposes an adaptive multi–feature fusion strategy, in which the target appearance is modeled based on timed motion history image with HSV color histogram features and edge orientation histogram features. The variances based on the similarities between the candidate patches and the target templates are used for adaptively adjusting the weight of each feature. Double templates matching, including online and offline template matching, is adopted to locate the target object in the next frame. Experimental evaluations on challenging sequences demonstrate the accuracy and robustness of the proposed algorithm in comparison with several state-of-the-art algorithms.",2017,Journal of Visual Communication and Image Representation
HU2017116,An image coding scheme using parallel compressive sensing for simultaneous compression-encryption applications,"Compressive sensing, Cryptography, Image compression, Image encryption, Parallel processing","Recently, using compressive sensing (CS) as a cryptosystem has drawn attention due to its compressibility and low-complexity during the sampling process. However, when applying such cryptosystem to images, how to protect the privacy of the image while keeping efficiency becomes a challenge. In this paper, we propose a novel image coding scheme that achieves combined compression and encryption under a parallel compressive sensing framework, where both the CS sampling and the CS reconstruction are performed in parallel. In this way, the efficiency can be guaranteed. On the other hand, for security, the resistance to chosen plaintext attack (CPA) is realized with the help of the cooperation between a nonlinear chaotic sensing matrix construction process and a counter mode operation. Furthermore, the defect of energy information leakage in CS-based cryptosystem is also overcome by a diffusion procedure. Experimental and analysis results show the scheme achieves effectiveness, efficiency and high security simultaneously.",2017,Journal of Visual Communication and Image Representation
UNDE2017187,Block compressive sensing: Individual and joint reconstruction of correlated images,"Compressive sensing, Joint sparsity model, Joint reconstruction, Correlation model","Compressive sensing provides simultaneous sensing and compression of data. Block compressive sensing (BCS) of images has gained a prominence in recent years due to low encoding complexity. In this paper, we propose the reconstruction algorithm for BCS framework based on iterative re-weighted l1 norm minimization. In the proposed algorithm, the desired signal sparsity is achieved using l1 norm minimization while Wiener filtering is incorporated as the smoothing operator. We also propose block based joint reconstruction algorithm for correlated images and video frames. The correlation is captured through the joint sparsity model by minimizing the objective function which promotes the common sparsity structure. The performance of proposed algorithms is tested on different stereo images and video data. Our analysis shows that the proposed individual reconstruction algorithm gives good compression performance as compared to existing schemes. Extensive analysis on correlated images demonstrates that the proposed joint reconstruction algorithm outperforms individual reconstruction algorithms.",2017,Journal of Visual Communication and Image Representation
SAINI2017128,Multiwavelet transform based license plate detection,"License plate detection, Multiwavelet transform, Hilbert-Huang transform","The presented framework uses the localization concept of multiwavelet transform and empirical mode decomposition (EMD) to locate number plate from vehicle. Multiwavelet transform is similar to wavelet transform but unlike wavelet, it simultaneously provides orthogonality, symmetry, short-support and vanishing moment. Multiwavelet is used to decompose the image and EMD helps to find the actual wave crest from the projected information provided by multiwavelet transform. The effectiveness of the proposed algorithm is improvised using pre- and post-processing steps which include image enhancement and skew correction respectively. Proposed algorithm has also been tested on single and double line number plate. The performance of the proposed algorithm has been tested on various countries’ number plates like Croatia, Austria, France, India and Greece, and in various conditions like shadow, dirt and blurry. Proposed algorithm has detected number plate with high accuracy and in relatively less time.",2017,Journal of Visual Communication and Image Representation
YE201772,Iterative optimization for frame-by-frame object pose tracking,"Object detection, Frame-by-frame tracking, Pose estimation, Iterative optimization, Probabilistic voting","Joint object tracking and pose estimation is an important issue in Augmented Reality (AR), interactive systems, and robotic systems. Many studies are based on object detection methods that only focus on the reliability of the features. Other methods combine object detection with frame-by-frame tracking using the temporal redundancy in the video. However, in some mixed methods, the interval between consecutive detection frames is usually too short to take the full advantage of the frame-by-frame tracking, or there is no appropriate switching mechanism between detection and tracking. In this paper, an iterative optimization tracking method is proposed to alleviate the deviations of the tracking points and prolong the interval, and thus speed up the pose estimation process. Moreover, an adaptive detection interval algorithm is developed, which can make the switch between detection and frame-by-frame tracking automatically according to the quality of frames so as to improve the accuracy in a tough tracking environment. Experimental results on the benchmark dataset manifest that the proposed algorithms, as an independent part, can be combined with some inter-frame tracking methods for optimization.",2017,Journal of Visual Communication and Image Representation
DONEVSKI201740,Colorimetrically accurate gray component replacement using the additive model,"Gray component replacement, Printing process model, Ink optimization, Radial basis functions","In four color printing, gray component replacement (GCR) is a method of replacing the achromatic component of a mixture of chromatic inks by a corresponding amount of the achromatic ink. Simple approaches to GCR lead to unacceptable color shifts. In this paper, the method using multiple processing steps is proposed. The novelty of the proposed method is augmentation of masking equations, which allows finding solutions for a pre-set amount of the black ink. The method performance was evaluated and compared with state of the art commercial solution. The experiments have shown that the proposed model is on average capable of achieving 40–55% ink savings with median colorimetric difference of less than 0.3, thus preserving the visual appearance of images.",2017,Journal of Visual Communication and Image Representation
HAO2017139,Fast L1 regularized iterative forward backward splitting with adaptive parameter selection for image restoration,"regularization, Regularization parameter, Splitting methods, Image restoration",We consider the L1 regularized iterative forward backward splitting (IFBS) algorithm for image restoration. The main aim of the paper is to develop a fast and adaptive method with an automatic selection of regularization parameter. The regularization parameter is updated in each iteration without requiring the initial value of the parameter. We establish analytically monotonicity results of the adaptive parameter. Such an algorithm corresponds to solving an adaptive iterative thresholding process. Experimental results demonstrate that the adaptive parameter method is efficient and provide competitive performance.,2017,Journal of Visual Communication and Image Representation
MOHAMMADI2017214,Region based Image Steganalysis using Artificial Bee Colony,"Image steganalysis, Artificial Bee Colony (ABC), Swarm intelligent, Feature selection, Information hiding","Steganalysis is the art and skill of discriminating stego images from cover images. Image steganalysis algorithms can be divided into two broad categories, specific and universal. In this paper, a novel universal image steganalysis algorithm is proposed which is called RISAB, Region based Image Steganalysis using Artificial Bee colony. The goal of the proposed method is to realize a sub-image from stego and cover images through ABC with respect to density according to the cover, stego and difference images. In our method, we look for the best sub-image, which contains the highest density with respect to the changed embedding pixels. Furthermore, after selecting the best sub-image, we extract the features, which have been selected by IFAB, Image steganalysis based on Feature selection using Artificial Bee colony. At the end, both selected features by IFAB and extracted features by RISAB are combined. As a result, a feature vector is generated which improves accuracy of steganalysis. Experimental results show that our proposed method outperforms other approaches.",2017,Journal of Visual Communication and Image Representation
CAO2017236,No embedding: A novel image cryptosystem for meaningful encryption,"Image encryption, Privacy protection, Compressive sensing, Coupled dictionary learning, Image cryptosystem","In this paper, we propose a novel image cryptosystem, which enables to encrypt the secret images with a smaller-size cover image. Compared with the existing meaningful encryption methods, our cryptosystem has three advantages: (1) non-embedding encryption, i.e., there isn’t any data embedding into the cover image during the encryption process. (2) Our cryptosystem can simultaneously encrypt multiple secret images with one cover image, which greatly improves the security of secret images. (3) Our cryptosystem can accomplish not only the meaningful encryption, but also the meaningless encryption. Thus, people don’t switch encryption methods when meeting different encryption requirements. Our scheme leverages the popular coupled dictionary learning and compressive sensing techniques to accomplish the whole task. Specifically, we use the coupled dictionaries to build connection between the cover image and the secret image, and apply the compressive sensing to decrypt the secret image. To demonstrate the effectiveness of the proposed cryptosystem, a series of experiments are conducted. Experimental results on gray images and colorful RGB images verify its superiority.",2017,Journal of Visual Communication and Image Representation
AKINLAR201782,ColorED: Color edge and segment detection by Edge Drawing (ED),"Color edge detection, Edge Drawing (ED), Vector gradient operators, Compass, Edge segment validation, Helmholtz principle","We extend our recent edge and segment detector, Edge Drawing (GrayED), to detect edge segments in color images. Edge Drawing for color images, named ColorED, takes in a color image, and outputs a set of edge segments, each a contiguous, 1-pixel wide chain of pixels. Detected edge segments are then passed through an ‘a contrario’ validation step due to the Helmholtz principle to eliminate perceptually invalid detections. We quantitatively evaluate ColorED with different colorspaces and vector gradient operators within the precision-recall framework of the widely-used Berkeley Segmentation Dataset and Benchmark (BSDS300), and compare its results with those of GrayED and a color version of the Canny edge detector named ColorCanny. We conclude that color edge detection is in general superior to grayscale edge detection, and that ColorED with edge segment validation (ColorEDV) greatly outperforms GrayED, ColorED, and ColorCanny, producing an F-score of 0.6593 with DiZenzo and 0.6747 with the Compass operator while taking an average time of 31.5ms for BSDS300.",2017,Journal of Visual Communication and Image Representation
MEKHALFI201795,Fast indoor scene description for blind people with multiresolution random projections,"Assistive technologies, Coarse scene description, Multiobject recognition, Multiresolution processing, Random projection, Visually impaired people","Object recognition forms a substantial need for blind and visually impaired individuals. This paper proposes a new multiobject recognition framework. It consists of coarsely checking the presence of multiple objects in a portable camera-grabbed image at a considered indoor site. The outcome is a list of objects that likely appear in the indoor scene. Such description is meant to uplift the conscience of the blind person in order to better sense his/her surroundings. The method consists of a library containing (i) a bunch of images represented by means of the Random Projections (RP) technique and (ii) their respective list of objects, both prepared offline. Thus, given an online shot image, its RP representation is generated and matched to the RP patterns of library images. It thus inherits the objects of the closest image from the library. Extensive experiments returned promising recognition accuracies and a processing lapse of real-time standard.",2017,Journal of Visual Communication and Image Representation
ZHU2017229,Integration of semantic and visual hashing for image retrieval,"Image retrieval, Semantic similarity, Visual structure, Hashing code","With the rapid proliferation of large-scale web images, recent years have witnessed more and more images labeled with user-provided tags, which leads to considerable effort made on hashing based image retrieval in huge databases. Current research efforts focus mostly on learning semantic hashing functions which design compact binary codes to map semantically similar images into similar codes; however the visual similarity is not well explored for constructing semantic hashing functions. Here a novel approach is proposed to learn hashing functions that preserve semantic and visual similarity between images. Specifically, semantic hashing codes are first learned by leveraging the similarity between textual structure and visual structure; then, the maximum entropy principle is exploited to achieve compact binary codes; finally, the function decay principle is introduced to remove noisy visual attributes. Experimental results conducted on a widely-used image dataset demonstrate the superior performance of the proposed method over the examined state-of-the-art techniques.",2017,Journal of Visual Communication and Image Representation
KUEHNE201778,Weakly supervised learning of actions from transcripts,"Weak learning, Action recognition, Action classification, Temporal segmentation","We present an approach for weakly supervised learning of human actions from video transcriptions. Our system is based on the idea that, given a sequence of input data and a transcript, i.e. a list of the order the actions occur in the video, it is possible to infer the actions within the video stream and to learn the related action models without the need for any frame-based annotation. Starting from the transcript information at hand, we split the given data sequences uniformly based on the number of expected actions. We then learn action models for each class by maximizing the probability that the training video sequences are generated by the action models given the sequence order as defined by the transcripts. The learned model can be used to temporally segment an unseen video with or without transcript. Additionally, the inferred segments can be used as a starting point to train high-level fully supervised models. We evaluate our approach on four distinct activity datasets, namely Hollywood Extended, MPII Cooking, Breakfast and CRIM13. It shows that the proposed system is able to align the scripted actions with the video data, that the learned models localize and classify actions in the datasets, and that they outperform any current state-of-the-art approach for aligning transcripts with video data.",2017,Computer Vision and Image Understanding
TAMAAZOUSTI201741,Vision-language integration using constrained local semantic features,"Image classification, Image retrieval, Bi-modal classification, Semantic features, Concept-based sparsification, Constrained local regions, Vision-language integration, Common latent space, Pure concept space","This paper tackles two recent promising issues in the field of computer vision, namely “the integration of linguistic and visual information” and “the use of semantic features to represent the image content”. Semantic features represent images according to some visual concepts that are detected into the image by a set of base classifiers. Recent works exhibit competitive performances in image classification and retrieval using such features. We propose to rely on this type of image descriptions to facilitate its integration with linguistic data. More precisely, the contribution of this paper is threefold. First, we propose to automatically determine the most useful dimensions of a semantic representation according to the actual image content. Hence, it results into a level of sparsity for the semantic features that is adapted to each image independently. Our model takes into account both the confidence on each base classifier and the global amount of information of the semantic signature, defined in the Shannon sense. This contribution is further extended to better reflect the detection of a visual concept at a local scale. Second, we introduce a new strategy to learn an efficient mid-level representation by CNNs that boosts the performance of semantic signatures. Last, we propose several schemes to integrate a visual representation based on semantic features with some linguistic piece of information, leading to the nesting of linguistic information at two levels of the visual features. Experimental validation is conducted on four benchmarks (VOC 2007, VOC 2012, Nus-Wide and MIT Indoor) for classification, three of them for retrieval and two of them for bi-modal classification. The proposed semantic feature achieves state-of-the-art performances on three classification benchmarks and all retrieval ones. Regarding our vision-language integration method, it achieves state-of-the-art performances in bi-modal classification.",2017,Computer Vision and Image Understanding
WU201721,Visual question answering: A survey of methods and datasets,"Visual question answering, Natural language processing, Knowledge bases, Recurrent neural networks","Visual Question Answering (VQA) is a challenging task that has received increasing attention from both the computer vision and the natural language processing communities. Given an image and a question in natural language, it requires reasoning over visual elements of the image and general knowledge to infer the correct answer. In the first part of this survey, we examine the state of the art by comparing modern approaches to the problem. We classify methods by their mechanism to connect the visual and textual modalities. In particular, we examine the common approach of combining convolutional and recurrent neural networks to map images and questions to a common feature space. We also discuss memory-augmented and modular architectures that interface with structured knowledge bases. In the second part of this survey, we review the datasets available for training and evaluating VQA systems. The various datatsets contain questions at different levels of complexity, which require different capabilities and types of reasoning. We examine in depth the question/answer pairs from the Visual Genome project, and evaluate the relevance of the structured annotations of images with scene graphs for VQA. Finally, we discuss promising future directions for the field, in particular the connection to structured knowledge bases and the use of natural language processing models.",2017,Computer Vision and Image Understanding
CHRISTIE2017101,Resolving vision and language ambiguities together: Joint segmentation & prepositional attachment resolution in captioned scenes,"Semantic segmentation, Prepositional phrase ambiguity resolution","We present an approach to simultaneously perform semantic segmentation and prepositional phrase attachment resolution for captioned images. Some ambiguities in language cannot be resolved without simultaneously reasoning about an associated image. If we consider the sentence “I shot an elephant in my pajamas”, looking at language alone (and not using common sense), it is unclear if it is the person or the elephant wearing the pajamas or both. Our approach produces a diverse set of plausible hypotheses for both semantic segmentation and prepositional phrase attachment resolution that are then jointly re-ranked to select the most consistent pair. We show that our semantic segmentation and prepositional phrase attachment resolution modules have complementary strengths, and that joint reasoning produces more accurate results than any module operating in isolation. Multiple hypotheses are also shown to be crucial to improved multiple-module reasoning. Our vision and language approach significantly outperforms the Stanford Parser (De Marneffe et al., 2006) by 17.91% (28.69% relative) and 12.83% (25.28% relative) in two different experiments. We also make small improvements over DeepLab-CRF (Chen et al., 2015).",2017,Computer Vision and Image Understanding
NIAN2017126,Learning explicit video attributes from mid-level representation for video captioning,"Mid-level video representation, Video attributes learning, Video caption, Sequence-to-sequence learning","Recent works on video captioning mainly learn the map from low-level visual features to language description directly without explicitly representing the high-level semantic video concepts (e.g. objects, actions in the annotated sentences). To bridge the semantic gap, in this paper, addressing it, we propose a novel video attribute representation learning algorithm for video concept understanding and utilize the learned explicit video attribute representation to improve video captioning performance. To achieve it, firstly, inspired by the success of spectrogram in audio processing, a novel mid-level video representation named “video response map” (VRM) is proposed, by which the frame sequence could be represented by a single image representation. Therefore, the video attributes representation learning could be converted to a well-studied multi-label image classification problem. Then in the captions prediction step, the learned video attributes feature is integrated with the single frame feature to improve previous sequence-to-sequence language generation model by adjusting the LSTM (Long-Short Term Memory) input units. The proposed video captioning framework could both handle variable frame inputs and utilize high-level semantic video attribute features. Experimental results on video captioning tasks show that the proposed method, utilizing only RGB frames as input without extra video or text training data, could achieve competitive performance with state-of-the-art methods. Furthermore, the extensive experimental evaluations on the UCF-101 action classification benchmark well demonstrate the representation capability of the proposed VRM.",2017,Computer Vision and Image Understanding
LUO201767,Simple to complex cross-modal learning to rank,"Cross-modal retrieval, Learning to rank, Self-paced learning, Diversity regularization","The heterogeneity-gap between different modalities brings a significant challenge to multimedia information retrieval. Some studies formalize the cross-modal retrieval tasks as a ranking problem and learn a shared multi-modal embedding space to measure the cross-modality similarity. However, previous methods often establish the shared embedding space based on linear mapping functions which might not be sophisticated enough to reveal more complicated inter-modal correspondences. Additionally, current studies assume that the rankings are of equal importance, and thus all rankings are used simultaneously, or a small number of rankings are selected randomly to train the embedding space at each iteration. Such strategies, however, always suffer from outliers as well as reduced generalization capability due to their lack of insightful understanding of procedure of human cognition. In this paper, we involve the self-paced learning theory with diversity into the cross-modal learning to rank and learn an optimal multi-modal embedding space based on non-linear mapping functions. This strategy enhances the model’s robustness to outliers and achieves better generalization via training the model gradually from easy rankings by diverse queries to more complex ones. An efficient alternative algorithm is exploited to solve the proposed challenging problem with fast convergence in practice. Extensive experimental results on several benchmark datasets indicate that the proposed method achieves significant improvements over the state-of-the-arts in this literature.",2017,Computer Vision and Image Understanding
KAFLE20173,"Visual question answering: Datasets, algorithms, and future challenges","Image understanding, Natural language processing, Vision and language","Visual Question Answering (VQA) is a recent problem in computer vision and natural language processing that has garnered a large amount of interest from the deep learning, computer vision, and natural language processing communities. In VQA, an algorithm needs to answer text-based questions about images. Since the release of the first VQA dataset in 2014, additional datasets have been released and many algorithms have been proposed. In this review, we critically examine the current state of VQA in terms of problem formulation, existing datasets, evaluation metrics, and algorithms. In particular, we discuss the limitations of current datasets with regard to their ability to properly train and assess VQA algorithms. We then exhaustively review existing algorithms for VQA. Finally, we discuss possible future directions for VQA and image understanding research.",2017,Computer Vision and Image Understanding
LIU2017113,Hierarchical & multimodal video captioning: Discovering and transferring multimodal knowledge for vision to language,"Video to text, Semantic discovery, Multi-modal fusion, Deep learning","Recently, video captioning has achieved significant progress through the advances of Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs). Given a video, deep learning approach is applied to encode the visual information and generate the corresponding caption. However, this direct visual to textual translation ignores the rich intermediate description, such as objects, scenes, actions, etc. In this paper, we proposed to discover and integrate the rich and primeval external knowledge (i.e., frame-based image caption) to benefit the video caption task. We propose a Hierarchical & Multimodal Video Caption (HMVC) model to jointly learn the dynamics within both visual and textual modalities for video caption task, which infers an arbitrary length sentence according to the input video with arbitrary number of frames. Specifically, we argue that the module for latent semantic discovery transfers external knowledge to generate complex and helpful complementary cues. We comprehensively evaluate the HMVC model on the Microsoft Video Description Corpus (MSVD), the MPII Movie Description Dataset (MPII-MD), and the novel dataset for 2016 MSR Video to Text challenge (MSR-VTT), and have attained a competitive performance. In addition, we evaluate the generalization properties of the proposed model by fine-tuning and evaluating the model on different datasets. To the best of our knowledge, this is the first time such analysis has been applied for the video caption task.",2017,Computer Vision and Image Understanding
LIU201758,Recognizing semantic correlation in image-text weibo via feature space mapping,"Recognizing semantic correlation, Image-text weibo, Textual-linguistic features, Visual features, Social features, Feature space mapping","Recent years have witnessed the fast development of social media platforms, such as Twitter, Sina Weibo, and Wechat. Practically, the textual weibos are frequently uploaded with images, namely image-text weibos in this paper. To gain the deep insights into the semantics of the image-text weibos, this paper explores the semantic correlation between the image and text. The semantic correlation recognition approach based on feature space mapping and support vector machine has been developed, due to the heterogeneity and incomparability of image, text, and social multi-source information in image-text weibos. Our model firstly extracts three types of features, namely, textual-linguistic, visual, and social features. It then uses the genetic algorithm to project the features from the different feature spaces to the unified one. At last, the semantic correlation recognition model based on support vector machine is constructed in the unified feature space. The experimental results show that the accuracy of our recognition model for semantic correlation between image and text in image-text weibo, with feature space mapping and support vector machine using the three types of multi-source features, achieves a significant performance compared to the traditional model only based on support vector machine.",2017,Computer Vision and Image Understanding
DAS201790,Human Attention in Visual Question Answering: Do Humans and Deep Networks Look at the Same Regions?,"Visual Question Answering, Attention","We conduct large-scale studies on ‘human attention’ in Visual Question Answering (VQA) to understand where humans choose to look to answer questions about images. We design and test multiple game-inspired novel attention-annotation interfaces that require the subject to sharpen regions of a blurred image to answer a question. Thus, we introduce the VQA-HAT (Human ATtention) dataset. We evaluate attention maps generated by state-of-the-art VQA models against human attention both qualitatively (via visualizations) and quantitatively (via rank-order correlation). Our experiments show that current attention models in VQA do not seem to be looking at the same regions as humans. Finally, we train VQA models with explicit attention supervision, and find that it improves VQA performance.",2017,Computer Vision and Image Understanding
PRATONDO20171,Integrating machine learning with region-based active contour models in medical image segmentation,"Machine learning, Active contour, Medical images, Segmentation","Region-based active contour models are effective in segmenting images with poorly defined boundaries but often fail when applied to images containing intensity inhomogeneity. The traditional models utilize pixel intensity and are very sensitive to parameter tuning. On the other hand, machine learning algorithms are highly effective in handling inhomogeneities but often result in noise from misclassified pixels. In addition, there is no objective function. We propose a framework which integrates machine learning with a region-based active contour model. Classification probability scores from machine learning algorithm, which are regularized using a non-linear function, are used to replace the pixel intensity values during energy minimization. In our experiments, we integrate the k-nearest neighbours and the support vector machine with the Chan-Vese method and compare the results obtained with the traditional methods of Chan-Vese and Li et al. The proposed framework gives better accuracy and less sensitive to parameter tuning.",2017,Journal of Visual Communication and Image Representation
OK201761,HDR tone mapping algorithm based on difference compression with adaptive reference values,"High dynamic range image, Tone mapping operator, Objective quality assessment, Perceptual quality, Difference compression","Tone mapping remains a challenging problem since tone mapping operators need to produce high perceptual quality under all conditions. In this paper, we propose a new local tone mapping method based on difference compression with adaptive reference values, which can effectively reproduce the details of bright and shadow regions. We also use a global tone mapping method and blend the output images produced by the global and local methods based on objective quality metrics. To quantitatively measure output images, we developed a new objective quality metric for the tone mapped images. The proposed detailness metric measures detail loss in the bright and shadow regions, and shows good correlations with subjective quality. We combined this metric with the recently proposed tone mapped image quality index (TMQI) that may not sufficiently reflect the amount of local detail loss. The experiments show that the proposed algorithm provides better perceptual quality than existing methods.",2017,Journal of Visual Communication and Image Representation
CHEN201777,Rough mode cost–based fast intra coding for high-efficiency video coding,"High-efficiency video coding (HEVC), Fast intra coding, Coding unit (CU), Intra mode decision, Rough mode decision, Transform unit (TU)","The quadtree-based coding unit (CU) and transform unit (TU) structure, as well as various prediction units (PUs) of HEVC, considerably increase encoding complexity in intra coding and inter coding. This paper proposes a rough mode cost (RMC)-based algorithm for accelerating CU/TU depth decisions and PU mode decisions in HEVC intra coding. For CU depth decisions, RMC values are used for the fast determination of CU partition. In the case of PU mode decisions, modes with higher RMCs are removed from the candidate list to reduce the number of test modes. For TU depth decisions, the TU partition of the mode with the least RMC is used to determine the TU partitions of remaining modes. The proposed TU partitioning method demonstrates superior performance to the default method in reference software. The proposed algorithm can reduce encoding time by approximately 51% on average, with a 0.69% increase in the Bjøntegaard-Delta (BD) rate.",2017,Journal of Visual Communication and Image Representation
HATI2017212,An image texture insensitive method for saliency detection,"Saliency, Texture suppression, Total variation, Sparse segmentation, Relevance feedback, Image matting","We propose a texture insensitive, region based image saliency detection algorithm, having excellent detection and localization properties, to obtain salient objects. We use a total variation based regularizer to suppress textures from the image and to make the method invariant to textural variations in the scene. This leads to an image that contains piecewise constant gray valued regions. This texture-free image is sparsely segmented into a small number of regions using the expectation maximization algorithm assuming a Gaussian mixture model. We compute three different saliency measures for every region using its intensity and spatial features. We adopt a relevance feedback mechanism to obtain weights for combining the three saliency measures and obtain the final saliency map. Next we input the thresholded saliency map to an image matting technique and extract the salient objects from the image with exact boundaries. Experimental comparisons with existing saliency detection algorithms demonstrate the superiority of the proposed technique.",2017,Journal of Visual Communication and Image Representation
CHEN201741,Virtual view quality assessment based on shift compensation and visual masking effect,"Depth image based rendering, Multiview video plus depth, Visual masking effect, Virtual viewpoint quality assessment","Depth image based rendering technology is essential for free viewpoint video systems. Because of the compression of depth images and limitations of rendering algorithms, various types of distortion might occur in the virtual viewpoints and cannot effectively be evaluated by traditional two-dimensional assessment methods. Hence, this paper proposes a method for virtual viewpoint quality assessment using the visual masking effect. First, shift is compensated for the distorted virtual viewpoint and then the compensated virtual viewpoint is objectively assessed. Next, according to human visual characteristics such as texture, magnitude, and distribution masking, the corresponding visual sensitivity map and visual masks are extracted. Finally, the visual masking and all factors are pooled to create the final quality score. As verified by the experimental results, the method proposed in this paper corresponds with the characteristics of human vision and can serve as a more effective method for assessing the quality of virtual viewpoints.",2017,Journal of Visual Communication and Image Representation
CUI201730,A nonconvex nonsmooth regularization method with structure tensor total variation,"Nonconvex nonsmooth regularization, Structure tensor, Image restoration and reconstruction, Alternating minimization methods","In this paper, a novel regularization method for image restoration and reconstruction is introduced which is accomplished by adopting a nonconvex nonsmooth penalty that depends on the eigenvalues of structure tensor of the underlying image. At first, an alternating minimization scheme is developed in which the problem can be decomposed into three subproblems, two of them are convex and the remaining one is smooth. Then, the convergence of the sequence which generate by the alternating minimization algorithm is proved. Finally, the efficient performance of the proposed method is demonstrated through experimental results for both grayscale and vector-value images.",2017,Journal of Visual Communication and Image Representation
YAO2017152,Guided filtering based color image reversible data hiding,"Color image, Reversible data hiding, Guided filtering predictor, Payload partition, Adaptive prediction-error expansion","In this paper, a color-image-dedicated reversible data hiding (RDH) algorithm is proposed to improve embedding performance by applying a guided filtering predictor and an adaptive prediction-error expansion (PEE) scheme. PEE-based RDH methods can be mainly separated into two stages for each channel embedding, i.e., pixel prediction and prediction-error histogram (PEH) modification. In our work, the inter-channel correlation is exploited at all stages of prediction and modification. Specifically, for predicting the pixels in the current channel with the guidance of pixels from other channels, a linear transform model from reference channels to the current channel is established and its coefficients are determined by the Laplacian minimization criterion. Then, to modify the PEH, an adaptive PEE embedding scheme is conducted by seeking the optimal parameters of the embedding bins and the complexity threshold to minimize distortion. The experimental results demonstrate the proposed method has better performance than the state-of-the-art, color-image RDH methods.",2017,Journal of Visual Communication and Image Representation
XU2017164,A privacy-preserving content-based image retrieval method in cloud environment,"Privacy-preserving, Image retrieval, Secure search, Orthogonal decomposition","In order to protect data privacy, image with sensitive or private information needs to be encrypted before being outsourced to a cloud service provider. However, this causes difficulties in image retrieval and data management. A privacy-preserving content-based image retrieval method based on orthogonal decomposition is proposed in the paper. The image is divided into two different components, for which encryption and feature extraction are executed separately. As a result, cloud server can extract features from an encrypted image directly and compare them with the features of the queried images, so that users can thus obtain the image. Different from other methods, the proposed method has no special requirements to encryption algorithms, which makes it more universal and can be applied in different scenarios. Experimental results prove that the proposed method can achieve better security and better retrieval performance.",2017,Journal of Visual Communication and Image Representation
WANG2017185,Spectral-spatial adaptive and well-balanced flow-based anisotropic diffusion for multispectral image denoising,"Multispectral images, Anisotropic diffusion, Spectral-spatial adaptive, Image denoising, Partial differential equation","Anisotropic diffusion can provide better compromise between noise reduction and edge preservation. In multispectral images, there exist different spatial local structures in the same band. Therefore, the levels of smoothing of anisotropic diffusion process should conform to both of image spectral and spatial features. In this paper, we present an effective denoising algorithm by integrating the spectral-spatial adaptive mechanism into a well-balanced flow (WBF) based anisotropic diffusion model, in which an adjustable weighted function is introduced to perform the appropriate levels of smoothing and enhancing according to different feature scales. Moreover, we make the fidelity term in the model to be adaptive by replacing the original noisy signal with the last evolution of the smoothed image. Consequently, the proposed algorithm can better control the diffusion behavior than traditional multispectral diffusion-based algorithms. The experimental results verify that our algorithm can improve visual quality of the image and obtain better quality indices.",2017,Journal of Visual Communication and Image Representation
KARIMI2017108,Quality assessment of retargeted images by salient region deformity analysis,"Image quality assessment, Image retargeting, Geometrical distortions, Homogeneity of deformities, Saliency preservation","Displaying images on different devices, requires resizing of the media. Traditional image resizing methods result in quality degradation. Content-aware retargeting algorithms aim to resize images for displaying them on a new device with the goal of preserving important contents of the image. Quality assessment of retargeted images can be employed to choose among outputs of different retargeting methods or help the optimization of such methods. In this paper we propose a learning based quality assessment method for retargeted images. An optical flow algorithm is used to find the correspondence between regions in the scaled and retargeted images. Three groups of features are defined to cover different aspects of distortions that are important to human observers. Area related features are used to detect how the areas of salient regions are retained and how much geometrical deformities are produced in the image. Also, to better assess the retargeted image we introduce features to show how well the aspect ratios of objects are retained. More importantly, we introduce the concept of measuring the homogeneity of distribution of deformities throughout the image. Experimental results demonstrate that our quality estimation method has better correlation with subjective scores and outperforms existing methods.",2017,Journal of Visual Communication and Image Representation
HUANG2017173,No-reference pixel based video quality assessment for HEVC decoded video,"HEVC analysis, No-reference, Video quality assessment, Machine learning, Elastic net","This paper proposes a No-Reference (NR) Video Quality Assessment (VQA) method for videos subject to the distortion given by the High Efficiency Video Coding (HEVC) scheme. The assessment is performed without access to the bitstream. The proposed analysis is based on the transform coefficients estimated from the decoded video pixels, which is used to estimate the level of quantization. The information from this analysis is exploited to assess the video quality. HEVC transform coefficients are modeled with a joint-Cauchy probability density function in the proposed method. To generate VQA features the quantization step used in the Intra coding is estimated. We map the obtained HEVC features using an Elastic Net to predict subjective video quality scores, Mean Opinion Scores (MOS). The performance is verified on a dataset consisting of HEVC coded 4K UHD (resolution equal to 3840×2160) video sequences at different bitrates and spanning a wide range of content. The results show that the quality scores computed by the proposed method are highly correlated with the mean subjective assessments.",2017,Journal of Visual Communication and Image Representation
GUO201750,Hierarchical content importance-based video quality assessment for HEVC encoded videos transmitted over LTE networks,"Content type, High efficiency video coding (HEVC), Long term evolution (LTE) network, Mean opinion score (MOS), Neural network, Quality of experience (QoE), Video quality assessment (VQA)","To improve the accuracy of assessment, many previous works take into account the video content. However, these previous works just only consider the video content, but do not consider the location and importance of the degraded content. Thus, this paper takes into account not only the video content, but also the location and importance of the degraded content, and proposes a hierarchical content importance-based video quality assessment. Firstly, we propose to use the hierarchical content importance-based frame degradation rate (HFDR) metric to quantify the importance of degraded content hierarchically. Secondly, we propose to use the intra random access point (IRAP) loss rate (ILR) metric to quantify the impact of IRAP. Finally, the proposed HFDR metric and ILR metric are subsequently used to develop an objective video quality assessment model. The experimental results show that the predicted mean opinion score (MOS) of the proposed method highly correlates with the actual MOS.",2017,Journal of Visual Communication and Image Representation
LUO2017138,Interactive image segmentation based on samples reconstruction and FLDA,"FLDA, Interactive segmentation, Sample reconstruction, Superpixel, Multi-classification, Dictionary building","Existing interactive image segmentation methods heavily rely on manual input, i.e. a sufficient quantity and correct locations of labels. In this paper, we propose a new interactive segmentation algorithm which aims to reduce human intervention and to generate high-quality segmentation results. In contrast to most energy minimizing based segmentation methods, the segmentation is cast as multi-classification in our proposed method. First, the input image is segmented into superpixels by using different methods. Then we build a dictionary consisting of all obtained superpixels and reconstruct samples represented by certain labeled superpixels. Finally, we learn a discriminative projection matrix through Fishers linear discriminant analysis (FLDA) algorithm, which learns a discriminative subspace for classification. The unlabeled superpixels are grouped into foreground or background, via calculating their minimal norm. Our method can capture long range grouping cues and reduce the sensitivity with respect to input label quantity and location of labels, by the combination of superpixels and discriminative dictionary. Extensive experiments are conducted both on MSRC and another challenging database in order to demonstrate the effectiveness of the proposed method. Quantitative and qualitative results show that our method is competitive to the state-of-the-art performance.",2017,Journal of Visual Communication and Image Representation
LEE201798,Dual learning based compression noise reduction in the texture domain,"Compression noise, Learning-based denoising, Dual learning, Texture domain","Compression noise reduction is similar to the super-resolution problem in terms of the restoration of lost high-frequency information. Because learning-based approaches have proven successful in the past in terms of addressing the super-resolution problem, we focus on a learning-based technique for compressed image denoising. In this process, it is important to search for the exact prior in a training set. The proposed method utilizes two different databases (i.e., a noisy and a denoised database), which work together in a complementary way. The denoised images from the dual databases are combined into a final denoised one. Additionally, the input noisy image is decomposed into structure and texture components, and only the latter is denoised because most noise tends to exist within the texture component. Experimental results show that the proposed method can reduce compression noise while reconstructing the original information that was lost in the compression process, especially for texture regions.",2017,Journal of Visual Communication and Image Representation
DONG201721,A two-stage learning approach to face recognition,"Collaborative representation, Collaborative coefficient, Face recognition, Small sample size","This paper introduces the Collaborative Representation (CR) techniques to small sample size conditions, and propose a Two-Stage learning approach to face recognition based on Collaborative Representation (TSCR). Based on the assumption that the same class samples should lie in the same subspace, we first use the unlabeled samples as dictionary atoms to construct each labeled sample, and obtain the collaborative coefficients by CR. The unlabeled sample with the largest collaborative coefficient is assigned the same class label as the reconstructed labeled sample, and is added to the labeled data set. This process is repeated until about half of the unlabeled samples are labeled and added to the labeled dataset. After that, we employ the original CR approach to classify the left unlabeled samples based on the newly labeled dataset. Experimental results demonstrate that the proposed TSCR is effective on face recognition.",2017,Journal of Visual Communication and Image Representation
LIN2017127,Key-frame-based depth propagation for semi-automatic stereoscopic video conversion,"2D-to-3D stereo video conversion, Depth propagation, Key-frame, Error correction, Depth image based rendering (DIBR)","In this paper, we propose a key-frame-based bi-directional depth propagation algorithm for semi-automatic 2D-to-3D stereoscopic video conversion. First, key-frames are identified from each video shot based on color motion-compensation errors to prevent high-motion content between any pair of consecutive key frames. Depths for key-frames are manually assigned or rendered by popular computer tools, and then bi-directionally propagated to non-key-frames there between. Our depth propagation algorithm is featured of a multi-pass error correcting procedure for each frame to prevent depth artifacts from being further propagated to adjacent frames. Our proposed algorithm is advantageous in solving the background occlusion/dis-occlusion problem that degrades the performances of traditional depth propagation algorithms. Experimental results show that our scheme is capable of achieving better results against three prior algorithms in view of the qualities of the estimated depth map (e.g., dis-occluded background and object boundaries) and the synthesized stereo views.",2017,Journal of Visual Communication and Image Representation
WEN2017119,A weighted full-reference image quality assessment based on visual saliency,"Visual saliency computation, Weighted image quality assessment, Human visual system","In full reference image quality assessment (IQA), the images without distortion are usually employed as reference, while the structures in both reference images and distorted images are ignored and all pixels are equally treated. In addition, the role of human visual system (HVS) is not taken account into subjective IQA metric. In this paper, a weighted full-reference image quality metric is proposed, where a weight imposed on each pixel indicates its importance in IQA. Furthermore, the weights can be estimated via visual saliency computation, which can approximate the subjective IQA via exploiting the HVS. In the experiments, the proposed metric is compared with several objective IQA metrics on LIVE release 2 and TID 2008 database. The results demonstrate that SROCC and PLCC of the proposed metric are 0.9647 and 0.9721, respectively,which are higher than other methods and it only takes 427.5s, which is lower than that of most other methods.",2017,Journal of Visual Communication and Image Representation
MASOUMI2017198,Spectral shape classification: A deep learning approach,"Deep learning, Spectral graph wavelet, Bag-of-features, Classification","In this paper, we propose a deep learning approach to 3D shape classification using spectral graph wavelets and the bag-of-features paradigm. In order to capture both the local and global geometry of a 3D shape, we present a three-step feature description strategy. Local descriptors are first extracted via the spectral graph wavelet transform having the Mexican hat wavelet as a generating kernel. Then, mid-level features are obtained by embedding local descriptors into the visual vocabulary space using the soft-assignment coding step of the bag-of-features model. A global descriptor is subsequently constructed by aggregating mid-level features weighted by a geodesic exponential kernel, resulting in a matrix representation that describes the frequency of appearance of nearby codewords in the vocabulary. Experimental results on two standard 3D shape benchmarks demonstrate the much better performance of the proposed approach in comparison with state-of-the-art methods.",2017,Journal of Visual Communication and Image Representation
RAHIMZADEHARASHLOO201789,Dynamic texture representation using a deep multi-scale convolutional network,"Dynamic texture, Multilayer convolutional architectures, PCA, Multi-scale analysis","This work addresses dynamic texture representation and recognition via a convolutional multilayer architecture. The proposed method considers an image sequence as a concatenation of spatial images along the time axis as well as spatio-temporal images along both horizontal and vertical axes of an image sequence and uses multilayer convolutional operations to describe each plane. The filters used are learned via principal component analysis (PCA) on each of the three orthogonal planes of an image sequence. A particularly advantageous attribute of the technique is the unsupervised training procedure of the proposed network. An inter-database evaluation has been performed to investigate the generalisation capability of the proposed approach. Moreover, a multi-scale extension of the proposed architecture is presented to capture texture details at multiple resolutions. Through extensive evaluations on different databases, it is shown that the proposed PCA-based network on three orthogonal planes (PCANet-TOP) yields very discriminative features for dynamic texture classification.",2017,Journal of Visual Communication and Image Representation
METTES2017182,Water detection through spatio-temporal invariant descriptors,"Water detection, Spatio-temporal descriptors, Fourier analysis, Invariants, Markov random fields","In this work, we aim to segment and detect water in videos. Water detection is beneficial for appllications such as video search, outdoor surveillance, and systems such as unmanned ground vehicles and unmanned aerial vehicles. The specific problem, however, is less discussed compared to general texture recognition. Here, we analyze several motion properties of water. First, we describe a video pre-processing step, to increase invariance against water reflections and water colours. Second, we investigate the temporal and spatial properties of water and derive corresponding local descriptors. The descriptors are used to locally classify the presence of water and a binary water detection mask is generated through spatio-temporal Markov Random Field regularization of the local classifications. Third, we introduce the Video Water Database, containing several hours of water and non-water videos, to validate our algorithm. Experimental evaluation on the Video Water Database and the DynTex database indicates the effectiveness of the proposed algorithm, outperforming multiple algorithms for dynamic texture recognition and material recognition.",2017,Computer Vision and Image Understanding
JAVARAN201716,Non-blind image deconvolution using a regularization based on re-blurring process,"Non-blind image deconvolution, Image prior, Regularization, Optimization, Re-blurring","Image deconvolution is an ill-posed problem that requires a regularization term to solve. The most common forms of image priors used as the regularization term in image deconvolution tend to produce smoothed (slightly blurry) images, hence don’t well reconstruct image details. In this paper, a new image prior is introduced. This prior is used as a regularization term to model the non-blind image deconvolution problem. The complete regularization term consists of two parts: one that penalizes non-sparsity of the gradient, and the other that penalizes the blurriness in the image. The resulting regularization term favors sharp images over blurry ones. It means that the minimum of this term corresponds to the true sharp solution. The minimization problem is non-convex and we propose a scheme based on half-quadratic regularization. We demonstrate the efficiency of the proposed method by performing several quantitative and qualitative comparisons with the existing non-blind image deconvolution methods for deblurring artificial and real blurred images. The experimental results show that the proposed method tends to well reconstruct image details whilst suppresses noise. In addition, the reconstructed images have a higher PSNR and a lower blurriness value compared to those in the existing methods.",2017,Computer Vision and Image Understanding
DENG2017127,Unsupervised object region proposals for RGB-D indoor scenes,"Object segmentation, RGB-D, Sensor fusion","In this paper, we present a novel unsupervised framework for automatically generating bottom up class independent object candidates for detection and recognition in cluttered indoor environments. Utilizing raw depth map from active sensors such as Kinect, we propose a novel plane segmentation algorithm for dividing an indoor scene into predominant planar regions and non-planar regions. Based on this partition, we are able to effectively predict object locations and their spatial extensions. Our approach automatically generates object proposals considering five different aspects: Non-planar Regions (NPR), Planar Regions (PR), Detected Planes (DP), Merged Detected Planes (MDP) and Hierarchical Clustering (HC) of 3D point clouds. Object region proposals include both bounding boxes and instance segments. Our approach achieves very competitive results and is even able to outperform supervised state-of-the-art algorithms on the challenging NYU-v2 RGB-Depth dataset. In addition, we apply our approach to the most recently released large scale RGB-Depth dataset from Princeton University – “SUN RGBD”, which utilizes four different depth sensors. Its consistent performance demonstrates a general applicability of our approach.",2017,Computer Vision and Image Understanding
KAKADIARIS2017137,3D-2D face recognition with pose and illumination normalization,"Face and gesture recognition, Biometrics, Physically-based modeling, 3D-2D face recognition, Illumination normalization, Model-based face recognition, 3D-2D model fitting, Object recognition, Computer vision","In this paper, we propose a 3D-2D framework for face recognition that is more practical than 3D-3D, yet more accurate than 2D-2D. For 3D-2D face recognition, the gallery data comprises of 3D shape and 2D texture data and the probes are arbitrary 2D images. A 3D-2D system (UR2D) is presented that is based on a 3D deformable face model that allows registration of 3D and 2D data, face alignment, and normalization of pose and illumination. During enrollment, subject-specific 3D models are constructed using 3D+2D data. For recognition, 2D images are represented in a normalized image space using the gallery 3D models and landmark-based 3D-2D projection estimation. A method for bidirectional relighting is applied for non-linear, local illumination normalization between probe and gallery textures, and a global orientation-based correlation metric is used for pairwise similarity scoring. The generated, personalized, pose- and light- normalized signatures can be used for one-to-one verification or one-to-many identification. Results for 3D-2D face recognition on the UHDB11 3D-2D database with 2D images under large illumination and pose variations support our hypothesis that, in challenging datasets, 3D-2D outperforms 2D-2D and decreases the performance gap against 3D-3D face recognition. Evaluations on FRGC v2.0 3D-2D data with frontal facial images, demonstrate that the method can generalize to databases with different and diverse illumination conditions.",2017,Computer Vision and Image Understanding
BETANCOURT201773,Left/right hand segmentation in egocentric videos,"Hand-segmentation, Hand-identification, Egocentric vision, First person vision","Wearable cameras allow people to record their daily activities from a user-centered (First Person Vision) perspective. Due to their favorable location, wearable cameras frequently capture the hands of the user, and may thus represent a promising user-machine interaction tool for different applications. Existent First Person Vision methods handle hand segmentation as a background-foreground problem, ignoring two important facts: i) hands are not a single “skin-like” moving element, but a pair of interacting cooperative entities, ii) close hand interactions may lead to hand-to-hand occlusions and, as a consequence, create a single hand-like segment. These facts complicate a proper understanding of hand movements and interactions. Our approach extends traditional background-foreground strategies, by including a hand-identification step (left-right) based on a Maxwell distribution of angle and position. Hand-to-hand occlusions are addressed by exploiting temporal superpixels. The experimental results show that, in addition to a reliable left/right hand-segmentation, our approach considerably improves the traditional background-foreground hand-segmentation.",2017,Computer Vision and Image Understanding
PHAM201735,Pair-wisely optimized clustering tree for feature indexing,"Feature indexing, Fast nearest neighbour search, Clustering tree, Hierarchical Voronoi diagram","This paper presents a new approach for indexing real feature vectors in high dimensional space. The proposed approach is developed based on Pair-wisely Optimized Clustering tree (POC-tree) that exploits the benefit of hierarchical clustering and Voronoi decomposition. The POC-tree maximizes the separation space of every pair of clusters at each level of decomposition, making a compact representation of the underlying data. Searching in the POC-tree is efficiently driven by the bandwidth search strategy. A single POC-tree can be used to create effective index of data for both exact and approximate nearest neighbour search. We also present a new method to combine multiple weak POC-trees for boosting the search performance for specific datasets in very high dimensional space. Extensive experiments have been conducted to evaluate the proposed approach in which it outperforms the state-of-the-art methods for all the datasets used in our experiments.",2017,Computer Vision and Image Understanding
NAIEL201794,Online multi-object tracking via robust collaborative model and sample selection,"Multi-object tracking, Particle filter, Collaborative model, Sample selection, Sparse representation","The past decade has witnessed significant progress in object detection and tracking in videos. In this paper, we present a collaborative model between a pre-trained object detector and a number of single-object online trackers within the particle filtering framework. For each frame, we construct an association between detections and trackers, and treat each detected image region as a key sample, for online update, if it is associated to a tracker. We present a motion model that incorporates the associated detections with object dynamics. Furthermore, we propose an effective sample selection scheme to update the appearance model of each tracker. We use discriminative and generative appearance models for the likelihood function and data association, respectively. Experimental results show that the proposed scheme generally outperforms state-of-the-art methods.",2017,Computer Vision and Image Understanding
PEREZYUS2017192,Stairs detection with odometry-aided traversal from a wearable RGB-D camera,"Stair detection, Visually impaired, RGB-D, Visual odometry, Wearable computing","Stairs are one of the most common structures present in human-made scenarios, but also one of the most dangerous for those with vision problems. In this work we propose a complete method to detect, locate and parametrise stairs with a wearable RGB-D camera. Our algorithm uses the depth data to determine if the horizontal planes in the scene are valid steps of a staircase judging their dimensions and relative positions. As a result we obtain a scaled model of the staircase with the spatial location and orientation with respect to the subject. The visual odometry is also estimated to continuously recover the current position and orientation of the user while moving. This enhances the system giving the ability to come back to previously detected features and providing location awareness of the user during the climb. Simultaneously, the detection of the staircase during the traversal is used to correct the drift of the visual odometry. A comparison of results of the stair detection with other state-of-the-art algorithms was performed using public dataset. Additional experiments have also been carried out, recording our own natural scenes with a chest-mounted RGB-D camera in indoor scenarios. The algorithm is robust enough to work in real-time and even under partial occlusions of the stair.",2017,Computer Vision and Image Understanding
LEO20171,Computer vision for assistive technologies,"Computer vision, Assistive technologies","In the last decades there has been a tremendous increase in demand for Assistive Technologies (AT) useful to overcome functional limitations of individuals and to improve their quality of life. As a consequence, different research papers addressing the development of assistive technologies have appeared into the literature pushing the need to organize and categorize them taking into account the application assistive aims. Several surveys address the categorization problem for works concerning a specific need, hence giving the overview on the state of the art technologies supporting the related function for the individual. Unfortunately, this “user-need oriented” way of categorization considers each technology as a whole and then a deep and critical explanation of the technical knowledge used to build the operative tasks as well as a discussion on their cross-contextual applicability is completely missing making thus existing surveys unlikely to be technically inspiring for functional improvements and to explore new technological frontiers. To overcome this critical drawback, in this paper an original “task oriented” way to categorize the state of the art of the AT works has been introduced: it relies on the split of the final assistive goals into tasks that are then used as pointers to the works in literature in which each of them has been used as a component. In particular this paper concentrates on a set of cross-application Computer Vision tasks that are set as the pivots to establish a categorization of the AT already used to assist some of the user’s needs. For each task the paper analyzes the Computer Vision algorithms recently involved in the development of AT and, finally, it tries to catch a glimpse of the possible paths in the short and medium term that could allow a real improvement of the assistive outcomes. The potential impact on the assessment of AT considering users, medical, economical and social perspective is also addressed.",2017,Computer Vision and Image Understanding
KEROLA2017108,Cross-view human action recognition from depth maps using spectral graph sequences,"Human action recognition, Depth cameras, Spectral graph theory, Graph signal processing, Graph wavelets, Wavelet transform","We present a method for view-invariant action recognition from depth cameras based on graph signal processing techniques. Our framework leverages a novel graph representation of an action as a temporal sequence of graphs, onto which we apply a spectral graph wavelet transform for creating our feature descriptor. We evaluate two view-invariant graph types: skeleton-based and keypoint-based. The skeleton-based descriptor captures the spatial pose of the subject, whereas the keypoint-based is able to capture complementary information about human-object interaction and the shape of the point cloud. We investigate the effectiveness of our method by experiments on five publicly available datasets. By the graph structure, our method captures the temporal interaction between depth map interest points and achieves a 19.8% increase in performance compared to state-of-the-art results for cross-view action recognition, and competing results for frontal-view action recognition and human-object interaction. Namely, our method results in 90.8% accuracy on the cross-view N-UCLA Multiview Action3D dataset and 91.4% accuracy on the challenging MSRAction3D dataset in the cross-subject setting. For human-object interaction, our method achieves 72.3% accuracy on the Online RGBD Action dataset. We also achieve 96.0% and 98.8% accuracy on the MSRActionPairs3D and UCF-Kinect datasets, respectively.",2017,Computer Vision and Image Understanding
BABAEE2017166,"Combined segmentation, reconstruction, and tracking of multiple targets in multi-view video sequences","Superpixels, Segmentation, Reconstruction, Tracking, Hypergraph","Tracking of multiple targets in a crowded environment using tracking by detection algorithms has been investigated thoroughly. Although these techniques are quite successful, they suffer from the loss of much detailed information about targets in detection boxes, which is highly desirable in many applications like activity recognition. To address this problem, we propose an approach that tracks superpixels instead of detection boxes in multi-view video sequences. Specifically, we first extract superpixels from detection boxes and then associate them within each detection box, over several views and time steps that lead to a combined segmentation, reconstruction, and tracking of superpixels. We construct a flow graph and incorporate both visual and geometric cues in a global optimization framework to minimize its cost. Hence, we simultaneously achieve segmentation, reconstruction and tracking of targets in video. Experimental results confirm that the proposed approach outperforms state-of-the-art techniques for tracking while achieving comparable results in segmentation.",2017,Computer Vision and Image Understanding
LAI2017152,Efficient guided hypothesis generation for multi-structure epipolar geometry estimation,"Epipolar geometry estimation, Multiple structures, Guided sampling, Joint feature distributions","We propose an Efficient Guided Hypothesis Generation (EGHG) method for multi-structure epipolar geometry estimation. Based on the Markov Chain Monte Carlo process, EGHG combines two guided sampling strategies: a global sampling strategy and a local sampling strategy. The global sampling strategy, guided by using both spatial sampling probabilities and keypoint matching scores, rapidly obtains promising solutions. The spatial sampling probabilities are computed by using a normalized exponential loss function. The local sampling strategy, guided by using both Joint Feature Distributions (JFDs) and keypoint matching scores, efficiently achieves accurate solutions. In the local sampling strategy, EGHG updates a set of current best hypothesis candidates on the fly, and then computes JFDs between the input data and these candidates. Experimental results on public real image pairs show that EGHG significantly outperforms several state-of-the-art sampling methods on multi-structure data.",2017,Computer Vision and Image Understanding
SVENSSON201764,Segmentation of clusters by template rotation expectation maximization,"Segmentation, Generative model, Expectation maximization, Template matching","To solve the task of segmenting clusters of nearly identical objects we here present the template rotation expectation maximization (TREM) approach which is based on a generative model. We explore both a general purpose optimization approach for maximizing the log-likelihood and a modification of the standard expectation maximization (EM) algorithm. The general purpose approach is strict template matching, while TREM allows for a more deformable model. As benchmarking we compare TREM with standard EM for a two dimensional Gaussian mixture model (GMM) as well as direct maximization of the log-likelihood using general purpose optimization. We find that the EM based algorithms, TREM and standard GMM, are faster than the general purpose optimizer algorithms without any loss of segmentation accuracy. When applying TREM and GMM to a synthetic data set consisting of pairs of almost parallel objects we find that the TREM is better at segmenting those than an unconstrained GMM. Finally we demonstrate that this advantage for TREM over GMM gives significant improvement in segmentation of microscopy images of the motile unicellular alga Seminavis robusta.",2017,Computer Vision and Image Understanding
STEIN201782,Recognising complex activities with histograms of relative tracklets,"Activity recognition, Relative tracklets, Sensor fusion, Food preparation","One approach to the recognition of complex human activities is to use feature descriptors that encode visual interactions by describing properties of local visual features with respect to trajectories of tracked objects. We explore an example of such an approach in which dense tracklets are described relative to multiple reference trajectories, providing a rich representation of complex interactions between objects of which only a subset can be tracked. Specifically, we report experiments in which reference trajectories are provided by tracking inertial sensors in a food preparation scenario. Additionally, we provide baseline results for HOG, HOF and MBH, and combine these features with others for multi-modal recognition. The proposed histograms of relative tracklets (RETLETS) showed better activity recognition performance than dense tracklets, HOG, HOF, MBH, or their combination. Our comparative evaluation of features from accelerometers and video highlighted a performance gap between visual and accelerometer-based motion features and showed a substantial performance gain when combining features from these sensor modalities. A considerable further performance gain was observed in combination with RETLETS and reference tracklet features.",2017,Computer Vision and Image Understanding
VERMA201748,A support vector approach for cross-modal search of images and texts,"Image search, Image description, Cross-media analysis","Building bilateral semantic associations between images and texts is among the fundamental problems in computer vision. In this paper, we study two complementary cross-modal prediction tasks: (i) predicting text(s) given a query image (“Im2Text”), and (ii) predicting image(s) given a piece of text (“Text2Im”). We make no assumption on the specific form of text; i.e., it could be either a set of labels, phrases, or even captions. We pose both these tasks in a retrieval framework. For Im2Text, given a query image, our goal is to retrieve a ranked list of semantically relevant texts from an independent text-corpus (i.e., texts with no corresponding images). Similarly, for Text2Im, given a query text, we aim to retrieve a ranked list of semantically relevant images from a collection of unannotated images (i.e., images without any associated textual meta-data). We propose a novel Structural SVM based unified framework for these two tasks, and show how it can be efficiently trained and tested. Using a variety of loss functions, extensive experiments are conducted on three popular datasets (two medium-scale datasets containing few thousands of samples, and one web-scale dataset containing one million samples). Experiments demonstrate that our framework gives promising results compared to competing baseline cross-modal search techniques, thus confirming its efficacy.",2017,Computer Vision and Image Understanding
ALVES201760,Ultimate levelings,"Residual morphological operator, Ultimate attribute openings, Ultimate grain filters, Levelings, Component trees, Tree of shapes","This work presents a new class of residual operators called ultimate levelings which are powerful image operators based on numerical residues. Within a multi-scale framework, these operators analyze a given image under a series of levelings. Thus, contrasted objects can be detected if a relevant residue is generated when they are filtered out by one of these levelings. Our approach consists of, firstly, (i) representing the input image as a morphological tree; then, (ii) showing that a certain operation on this tree results in a leveling operator; and finally (iii) demonstrating that a sequential application of this operation on the tree is able to produce a family of levelings that satisfies scale-space properties. Besides, other contributions of this paper include: (i) the statement of properties of ultimate levelings, (ii) the presentation of an efficient algorithm for their computation, (iii) the provision of strategies for choosing families of primitives, (iv) the presentation of strategies for filtering undesirable residues, and (v) the provision of some illustrative examples of application of ultimate levelings. Furthermore, ultimate levelings are computationally efficient and their performance evaluations are comparable to the state of art methods for filtering and image segmentation.",2017,Computer Vision and Image Understanding
ASTROM201743,A geometric approach for color image regularization,"Image analysis, Color image restoration, Vectorial total variation, Double-opponent space, Split-Bregman, Non-convex regularization","We present a new vectorial total variation method that addresses the problem of color consistent image filtering. Our approach is inspired from the double-opponent cell representation in the human visual cortex. Existing methods of vectorial total variation regularizers have insufficient (or no) coupling between the color channels and thus may introduce color artifacts. We address this problem by introducing a novel coupling between the color channels related to a pullback-metric from the opponent space to the data (RGB color) space. Our energy is a non-convex, non-smooth higher-order vectorial total variation approach and promotes color consistent image filtering via a coupling term. For a convex variant, we show well-posedness and existence of a solution in the space of vectorial bounded variation. For the higher-order scheme we employ a half-quadratic strategy, which model the non-convex energy terms as the infimum of a sequence of quadratic functions. In experiments, we elaborate on traditional image restoration applications of inpainting, deblurring and denoising. Regarding the latter, we consider two noise scenarios i) intensity and chromaticity (the color representation of the double-opponent space) are corrupted by uniform noise and ii) only the chromaticity is corrupted with noise. In the latter case, we demonstrate state of the art restoration quality with respect to structure coherence and color consistency.",2017,Computer Vision and Image Understanding
JIANG201717,Image dehazing using adaptive bi-channel priors on superpixels,"Image restoration, Dehazing, Dark channel prior, Bright channel prior, Superpixels","Recently, a number of image dehazing methods are developed based on dark channel prior which is simple yet effective. In order to compensate for any failure on the use of dark channel prior in white regions and bright channel prior in black regions, an image dehazing method using a novel adaptive bi-channel priors on superpixels is presented in this paper. In the proposed method, a haze image is converted to the hue, saturation, and value space, and the linearly transformed thresholds on saturation and value are used to detect any white and black pixels. Using superpixels as local regions, the local transmission and atmospheric light values are estimated more reliably and efficiently by combining the dark and bright channel priors (bi-channel priors). Furthermore, adaptive bi-channel priors are developed to rectify any incorrect estimations on transmission and atmospheric light values for white and black pixels that fail to satisfy the assumptions of the bi-channel priors. After applying our dehazing method, the white and black pixels on the restored image are with excellent fidelity. Experimental results demonstrate that our proposed method performs better for restoring images in terms of both quality and execution speed than the current state-of-the-art dehazing methods.",2017,Computer Vision and Image Understanding
ESSA201797,Automatic segmentation of cross-sectional coronary arterial images,"IVUS, OCT, Graph cut, Image segmentation, Shape prior.","We present a novel approach to segment coronary cross-sectional images acquired using catheterization imaging techniques, i.e. intra-vascular ultrasound (IVUS) and optical coherence tomography (OCT). The proposed approach combines cross-sectional segmentation with longitudinal tracking in order to tackle various forms of imaging artifacts and to achieve consistent segmentation. A node-weighted directed graph is constructed on two consecutive cross-sectional frames with embedded shape constraints within individual cross-sections or frames and between consecutive frames. The intra-frame constraints are derived from a set of training samples and are embedded in both graph construction and its cost function. The inter-frame constraints are imposed by tracking the borders of interest across multiple frames. The coronary images are transformed from Cartesian coordinates to polar coordinates. Graph partition can then be formulated as searching an optimal interface in the node-weighted directed graph without user initialization. It also allows efficient parametrization of the border using radial basis function (RBF) and thus reduces the tracking of a large number of border points to a very few RBF centers. Moreover, we carry out supervised column-wise tissue classification in order to automatically optimize the feature selection. Instead of empirically assigning weights to different feature detectors, we dynamically and automatically adapt those weighting depending on the tissue compositions in each individual column of pixels. The proposed approach is applied to IVUS and OCT images. Both qualitative and quantitative results show superior performance of the proposed method compared to a number of alternative segmentation techniques.",2017,Computer Vision and Image Understanding
CHENG201775,A new primal-dual algorithm for multilabel graph-cuts problems with approximate moves,"MRF-MAP inference, Primal-dual, Graph-cuts, Preflow algorithm","Graph-cuts based move making algorithms have been intensively studied. Previous methods uniformly rely on max-flow/min-cut solutions for move-making, and have achieved generally good performance on a variety of applications. Early research suggests that path-augmenting algorithms such as BK tend to perform well on grid-structured graphs. Unlike conventional graph-cuts methods, our algorithm does not require the exact max-flow/min-cut solution for update. Instead, any cut/flow of a subproblem can be used for primal/dual update, which allows the max-flow solver to stop at any time during execution. Thanks to the dynamicity of our approach, the energy convergence rate can be improved by several times in our experiments on GPU.",2017,Computer Vision and Image Understanding
ZHU201733,Atmospheric light estimation in hazy images based on color-plane model,"Dehaze, Single image, Air light estimation, Model","In this paper, a novel air light recovery method based on color-plane model is proposed. The method aims to improve the robustness of air light estimation for single image dehazing applications. Traditional methods estimating air light rely on user input or dense haze region. It is unstable when dense haze region is not included. The methods based on the color-line model and haze-line model achieve significant improvements on air light estimation without identifying dense haze regions. However, both of the models are lack of generality. Therefore, we propose the color-plane model which combines the color-line model and haze-line model. It is motivated by the fact that colors with a common direction widely exist and tend to stay together in natural images. These colors spread on color-plane after being blended with haze, which indicates the orientation of the air light. An algorithm based on region growing is designed to extract potential color-plane in haze images. RANSAC is employed to estimate the air light orientation. The magnitude is estimated based on the assumption that the intensities of several bright pixels in different depth ranges should be similar. A novel algorithm based on energy minimization is proposed to estimate depth ranges. Experimental results show that the proposed method performs better than state-of-the-art methods.",2017,Computer Vision and Image Understanding
QUAN201785,Spatiotemporal lacunarity spectrum for dynamic texture classification,"Dynamic textures, Lacunarity analysis, Local binary patterns, Video classification","Dynamic texture (DT) in videos is the combination of texture patterns with motion pat-terns, and DT recognition is a key step in many vision-related applications. Owing to the additional challenges arising from the characterization on temporal organizations of texture elements, the recognition on DTs is more dif?cult than that on static textures. In this paper, a DT descriptor for classi?cation is constructed, which examines the stationary irregularities of spatial and temporal distributions of local binary patterns in DT slices and encodes the irregularities by lacunarity-based features. The proposed descriptor has strong robustness to monotonic illumination changes and modest viewpoint changes, as well as strong discriminability in classification. In comparison with histogram-based methods, our approach is capable of encoding spatio-temporal details on the distribution of DT patterns. It also encodes additional details on the layout of DT patterns that recent fractal-based methods ignore. The proposed descriptor was applied to DT classification, and the experimental results show its power on several benchmark datasets.",2017,Computer Vision and Image Understanding
GUO20181,Research on case retrieval of Bayesian network under big data,"Case retrieval, Big data, BN model, Hadoop platform","Although case retrieval of Bayesian network has greatly promoted the application of CBR technique in engineering fields, it is facing huge challenges with the arrival of the era of big data. First, huge computation task of BN learning caused by big data seriously hampers the efficiency of case retrieval; Second, with the increasing data size, the accuracy of case retrieval becomes poorer and poorer because existing methods of improving probability learning become unfit for new situation. Aiming at the first problem, this paper proposes Within-Cross algorithm to assign computation task to improve the result of parallel data processing and gain better efficiency of case retrieval. For the second problem, this paper proposes a new method called Weighted Index Coefficient of Dirichlet Distribution (WICDD) algorithm, which first measures the influence of different factors on probability learning and then gives a weight to each super parameter of Dirichlet Distribution to adjust the result of probability learning. Thus with WICDD algorithm, the effect of probability learning is greatly improved, which then further enhances the accuracy of case retrieval. Finally, lots of experiments are executed to validate the effectiveness of the proposed method.",2018,Data & Knowledge Engineering
SHAO201892,Mining range associations for classification and characterization,"Classification, Characterization, Numerical ranges, Classification association rule mining","In this paper, we propose a method that is able to derive rules involving range associations from numerical attributes, and to use such rules to build comprehensible classification and characterization (data summary) models. Our approach follows the classification association rule mining paradigm, where rules are generated in a way similar to association rule mining, but search is guided by rule consequents. This allows many credible rules, not just some dominant rules, to be mined from the data to build models. In so doing, we propose several sub-range analysis and rule formation heuristics to deal with numerical attributes. Our experiments show that our method is able to derive range-based rules that offer both accurate classification and comprehensible characterization for numerical data.",2018,Data & Knowledge Engineering
HUNG201852,INSiGHT: A system to detect violent extremist radicalization trajectories in dynamic graphs,"Graph pattern matching, Pattern matching trajectories, Investigative graph search, Radicalization, Violent extremists","The number and lethality of violent extremist plots motivated by the Salafi-jihadist ideology have been growing for nearly the last decade in many parts of the world including both the U.S and Western Europe. While detecting the radicalization of violent extremists is a key component in preventing future terrorist attacks, it remains a significant challenge to law enforcement due to the issues of both scale and dynamics. We propose the development of a radicalization trend detection system as a risk assessment assistance technology that relies on data mined from public data and government databases for individuals who exhibit risk indicators for extremist violence, and enables law enforcement to monitor those individuals at the scope and scale that is lawful, and accounts for the dynamic indicative behaviors of the individuals and their associates rigorously and automatically. We frame our approach to monitoring the radicalization pattern of behaviors as a unique dynamic graph pattern matching problem, and develop a technology called INSiGHT (Investigative Search for Graph-Trajectories) to help identify individuals or small groups with conforming subgraphs to a radicalization query pattern, and follow the match trajectories over time. This paper presents the overall INSiGHT architecture and is aimed at assisting law enforcement and intelligence agencies in monitoring and screening for those individuals whose behaviors indicate a significant risk for violence, and allow for the better prioritization of limited investigative resources. We demonstrated the performance of INSiGHT on a variety of datasets, to include small synthetic radicalization-specific datasets and a real behavioral dataset of time-stamped radicalization indicators of recent U.S. violent extremists.",2018,Data & Knowledge Engineering
LUAN201841,Experimental identification of hard data sets for classification and feature selection methods with insights on method selection,"Classification methods, Feature selection methods, Hard data sets, Method ranking, Performance comparison, Classification, Mining methods and algorithms","The paper reports an experimentally identified list of benchmark data sets that are hard for representative classification and feature selection methods. This was done after systematically evaluating a total of 48 combinations of methods, involving eight state-of-the-art classification algorithms and six commonly used feature selection methods, on 129 data sets from the UCI repository (some data sets with known high classification accuracy were excluded). In this paper, a data set for classification is called hard if none of the 48 combinations can achieve an AUC over 0.8 and none of them can achieve an F-Measure value over 0.8; it is called easy otherwise. A total of 15 out of the 129 data sets were found to be hard in that sense. This paper also compares the performance of different methods, and it produces rankings of classification methods, separately on the hard data sets and on the easy data sets. This paper is the first to rank methods separately for hard data sets and for easy data sets. It turns out that the classifier rankings resulting from our experiments are somehow different from those in the literature and hence they offer new insights on method selection. It should be noted that the Random Forest method remains to be the best in all groups of experiments.",2018,Data & Knowledge Engineering
LI201871,Approximate top-K answering under uncertain schema mappings,"Database integration, Uncertain schema mappings, Top- query, Histogram-based approximation","Data integration techniques provide a communication bridge between isolated sources and offer a platform for information exchange. When the schemas of heterogeneous data sources map to the centralized schema in a mediated data integration system or a source schema maps to a target schema in a peer-to-peer system, multiple schema mappings may exist due to the ambiguities in the attribute matching. The obscure schema mappings lead to the uncertainty in query answering, and frequently people are only interested in retrieving the best k answers (top-k) with the biggest probabilities. Retrieving the top-k answers efficiently has become a research issue. For uncertain queries, two semantics, by-table and by-tuple, have been developed to capture top-k answers based on the schema mapping probabilities. However, although the existing algorithms support certain features to capture the accurate top-k answers and avoid accessing all data from sources, they cannot effectively reduce the number of processed tuples in most cases. In this paper, new algorithms based on the histogram approximation and heuristic are proposed to efficiently identify the top-k answers for the data integration systems under uncertain schema mappings. In the experiments, the Histogram algorithm in the by-table semantics and the expected approach in the by-tuple semantics are shown to significantly reduce the number of processed tuples while maintaining high accuracy with the estimated probabilistic confidence.",2018,Data & Knowledge Engineering
SANCHEZFERRERES201825,Aligning textual and model-based process descriptions,"Business process management, Process models, Natural language processing, Alignments","Process model descriptions are an ubiquitous source of information that exists in any organization. To reach different types of stakeholders, distinct descriptions are often kept, so that process understandability is boosted with respect to individual capabilities. While the use of distinct representations allows more stakeholders to interpret process information, it also poses a considerable challenge: to keep different process descriptions aligned. In this paper, a novel technique to align process models and textual descriptions is proposed. The technique is grounded on projecting knowledge extracted from these two representations into a uniform representation that is amenable for comparison. It applies a tailored linguistic analysis of each description, so that the important information is considered when aligning description’ elements. Compared to existing approaches that address this use case, our technique provides more comprehensive alignments, which encompass process model activities, events and gateways. Furthermore, the technique, which has been implemented into the platform nlp4bpm.cs.upc.edu, shows promising results based on experiments with real-world data.",2018,Data & Knowledge Engineering
BENAVIDES2018107,An ontology-based approach to knowledge representation for Computer-Aided Control System Design,"Conceptual modeling, Data and knowledge visualization, Ontologies, Computer-Aided Control System Design","Different approaches have been used in order to represent and build control engineering concepts for the computer. Software applications for these fields are becoming more and more demanding each day, and new representation schemas are continuously being developed. This paper describes a study of the use of knowledge models represented in ontologies for building Computer Aided Control Systems Design (CACSD) tools. The use of this approach allows the construction of formal conceptual structures that can be stated independently of any software application and be used in many different ones. In order to show the advantages of this approach, an ontology and an application have been built for the domain of design of lead/lag controllers with the root locus method, presenting the results and benefits found.",2018,Data & Knowledge Engineering
CHEN201814,Leveraging social media news to predict stock index movement using RNN-boost,"Recurrent neural networks, Adaboost, Time series prediction, Online social networks","News from traditional media has been used to facilitate the prediction of stock movement for a long time. However, in recent times, online social networks (OSN) have played an increasing significant role as a platform for information sharing. News content posted on these OSN provides very useful insight about public moods. In this paper, we carefully select official accounts from China’s largest online social networks — Sina Weibo and analyze the news content crawled from these accounts by extracting sentiment features and Latent Dirichlet allocation (LDA) features. We then input these features together with technical indicators into a novel hybrid model called RNN-boost to predict the stock volatility in the Chinese stock market. The Shanghai-Shenzhen 300 Stock Index (HS300) is the use case for this research. Experimental results show that our model outperforms other prevalent methods and can achieve a good prediction performance.",2018,Data & Knowledge Engineering
ROYER2017115,"COnfusion REduction (CORE) algorithm for local descriptors, floating-point and binary cases","Keypoints filtering, Computer vision, Feature matching, Kernel density estimator","In this paper, we propose a generic pre-filtering method of point descriptors which addresses the confusion problem due to repetitive patterns. This confusion often leads to wrong descriptor matches and prevents further processes such as object recognition, image indexation, super-resolution or stereo-vision. Our method sorts keypoints by their unicity without taking into account any visual element but the feature vectors’s statistical properties thanks to a kernel density estimation approach. Both binary descriptors and floating point based descriptors are studied, regardless of their dimensions. Even if highly reduced in number, results show that keypoints subsets extracted are still relevant and our algorithm can be combined with classical post-processing methods.",2017,Computer Vision and Image Understanding
MAHMOUDABADI201717,Detecting sudden moving objects in a series of digital images with different exposure times,"Moving object, High dynamic range, HDR, Ghost artifact, HOG, SVD","This paper presents an algorithm to detect sudden objects appearing within a set of digital images obtained at different exposures to create a high dynamic range (HDR) image. While some previous work has focused on detecting moving objects within a scene, the majority cannot handle exposure variability. The few techniques developed specifically for HDR images track moving objects that have smaller movements within a scene compared to an abrupt object that appears and disappears quickly. Further, the algorithm advances existing methods because it does not require: 1) robust estimation of a camera response function, 2) supervision of objects in the scene such as explicit object detection and tracking, and 3) selection of a reference image. In this approach, every image in the set is first partitioned into equal size patches. Next, the properties (e.g., histograms of oriented gradients, HOG) of values within the window of the same patch are compared between the images to identify differences. Finally, a statistical classifier is developed to recognize significant differences between patch descriptors and identify patches containing sudden objects. This statistical classifier makes it possible to define confidence levels for categorizing patches into a moving object or not. A sensitivity analysis indicated that the best performance occurs when using four or six digital images. However, the optimal patch size is dependent on the size of the moving object to be detected. Hence, a mechanism is introduced to estimate the range of reasonable patch sizes given an image.",2017,Computer Vision and Image Understanding
HAN201785,Space-time representation of people based on 3D skeletal data: A review,"Human representation, Skeleton data, 3D visual perception, Space-time features, Survey","Spatiotemporal human representation based on 3D visual perception data is a rapidly growing research area. Representations can be broadly categorized into two groups, depending on whether they use RGB-D information or 3D skeleton data. Recently, skeleton-based human representations have been intensively studied and kept attracting an increasing attention, due to their robustness to variations of viewpoint, human body scale and motion speed as well as the realtime, online performance. This paper presents a comprehensive survey of existing space-time representations of people based on 3D skeletal data, and provides an informative categorization and analysis of these methods from the perspectives, including information modality, representation encoding, structure and transition, and feature engineering. We also provide a brief overview of skeleton acquisition devices and construction methods, enlist a number of benchmark datasets with skeleton data, and discuss potential future research directions.",2017,Computer Vision and Image Understanding
QUACH2017126,Non-convex online robust PCA: Enhance sparsity via ℓp-norm minimization,"Robust principal component analysis, Low-rank minimization, Sparse minimization, Non-convex optimization","Compressive sensing, matrix rank optimization and Robust PCA-based matrix decomposition have an increasing number of non-convex approaches for optimizing the ideal ℓ0-norm sparsity. This paper presents a novel online non-convex ℓp-norm based Robust PCA (OLP-RPCA) approach, where 0 < p < 1. OLP-RPCA is developed from the offline version LP-RPCA. Our LP-RPCA method uses a new objective function in the Alternating Direction Method of Multipliers (ADMM) framework to efficiently solve the Robust PCA problem. More importantly, our OLP-RPCA method can achieve real-time performance on large-scale data without parallelizing or implementing on a graphics processing unit. We mathematically and empirically show that the computational complexity of our OLP-RPCA algorithm is linear in both the sample dimension and the number of samples. The proposed approaches are evaluated in various applications including Gaussian/non-Gaussian image denoising, face modeling, real-time background subtraction and video inpainting and compared against numerous state-of-the-art low-rank minimization methods to demonstrate the robustness of our algorithms.",2017,Computer Vision and Image Understanding
WANG201731,Specularity removal: A global energy minimization approach based on polarization imaging,"Specularity removal, Polarization, Diffuse, Separation, Energy minimization","Concentration of light energy in images causes strong highlights (specular reflection), and challenges the robustness of a large variety of vision algorithms, such as feature extraction and object detection. Many algorithms indeed assume perfect diffuse surfaces and ignore the specular reflections; specularity removal may thus be a preprocessing step to improve the accuracy of such algorithms. Regarding specularity removal, traditional color-based methods generate severe color distortions and local patch-based algorithms do not integrate long range information, which may result in artifacts. In this paper, we present a new image specularity removal method which is based on polarization imaging through global energy minimization. Polarization images provide complementary information and reduce color distortions. By minimizing a global energy function, our algorithm properly takes into account the long range cue and produces accurate and stable results. Compared to other polarization-based methods of the literature, our method obtains encouraging results, both in terms of accuracy and robustness.",2017,Computer Vision and Image Understanding
DAHI2017141,An edge-based method for effective abandoned luggage detection in complex surveillance videos,"Video surveillance, Object detection, Background subtraction, Abandoned object, Clustering algorithm, Static object","Abandoned objects detection is one of the most challenging tasks in intelligent video surveillance systems. In this paper we present a new method for detecting abandoned objects (AO) using edges instead of pixel intensities. Our main focus, is on reducing false alarms, while keeping a high positives detection rate. Based on edge information, the proposed method reduces errors rate considerably compared to pixel intensities based approaches. At first, static edges are detected by applying a temporal accumulation step using the foreground edges mask resulting from the edge-based background subtraction model. Then, edges clustering is applied on the obtained stable edges mask, using edges’ position and stability in time to delineate the object bounding box. Finally, an efficient classification approach, relying on edges’ position, orientation, and staticness based scores, is applied on the AO candidates. The proposed approach has been validated on several challenging benchmarks, and is compared to other works of the literature. The results shows that our method reduce false alarms rates greatly, while keeping a good detection accuracy of true positives.",2017,Computer Vision and Image Understanding
KWON201762,Leveraging observation uncertainty for robust visual tracking,"Object tracking, Background subtraction, Intrinsic image, Saliency detection","In this paper, the accuracy of visual tracking is enhanced by leveraging a novel measure for observation quality. We measure observation quality with mutual information, then look at the interval covered by that mutual information. As observation uncertainty the interval length is proposed. The best observation is considered the one that both maximizes the observation quality and minimizes the observation uncertainty. We show that searching for the best observation in these terms amounts to preprocessing the image by subtracting the background, detecting salient regions, and rendering the image illumination-invariant. These preprocessing steps are very fast and can precede any existing tracker. In experiments it is shown that the performance of several trackers can be substantially boosted when they run on our preprocessed images, rather than the raw input for which they were intended. In all cases the version with preprocessing significantly outperforms the original tracker’s performance.",2017,Computer Vision and Image Understanding
BAGHERI2017106,Locality regularized group sparse coding for action recognition,"Bag of words, Feature encoding, Locality constrained coding, Group sparse coding, Alternating direction method of multipliers, Action recognition","Bag of visual words (BoVW) models are widely utilized in image/ video representation and recognition. The cornerstone of these models is the encoding stage, in which local features are decomposed over a codebook in order to obtain a representation of features. In this paper, we propose a new encoding algorithm by jointly encoding the set of local descriptors of each sample and considering the locality structure of descriptors. The proposed method takes advantages of locality coding such as its stability and robustness to noise in descriptors, as well as the strengths of the group coding strategy by taking into account the potential relation among descriptors of a sample. To efficiently implement our proposed method, we consider the Alternating Direction Method of Multipliers (ADMM) framework, which results in quadratic complexity in the problem size. The method is employed for a challenging classification problem: action recognition by depth cameras. Experimental results demonstrate the outperformance of our methodology compared to the state-of-the-art on the considered datasets.",2017,Computer Vision and Image Understanding
MANFREDI201740,Segmentation models diversity for object proposals,"Segmentation, Supervised learning, Object proposals","In this paper we present a segmentation proposal method which employs a box-hypotheses generation step followed by a lightweight segmentation strategy. Inspired by interactive segmentation, for each automatically placed bounding-box we compute a precise segmentation mask. We introduce diversity in segmentation strategies enhancing a generic model performance exploiting class-independent regional appearance features. Foreground probability scores are learned from groups of objects with peculiar characteristics to specialize segmentation models. We demonstrate results comparable to the state-of-the-art on PASCAL VOC 2012 and a further improvement by merging our proposals with those of a recent solution. The ability to generalize to unseen object categories is demonstrated on Microsoft COCO 2014.",2017,Computer Vision and Image Understanding
GILBERT201772,Image and video mining through online learning,"Action recognition, Data mining, Real-time, Learning, Spatio-temporal, Clustering","Within the field of image and video recognition, the traditional approach is a dataset split into fixed training and test partitions. However, the labelling of the training set is time-consuming, especially as datasets grow in size and complexity. Furthermore, this approach is not applicable to the home user, who wants to intuitively group their media without tirelessly labelling the content. Consequently, we propose a solution similar in nature to an active learning paradigm, where a small subset of media is labelled as semantically belonging to the same class, and machine learning is then used to pull this and other related content together in the feature space. Our interactive approach is able to iteratively cluster classes of images and video. We reformulate it in an online learning framework and demonstrate competitive performance to batch learning approaches using only a fraction of the labelled data. Our approach is based around the concept of an image signature which, unlike a standard bag of words model, can express co-occurrence statistics as well as symbol frequency. We efficiently compute metric distances between signatures despite their inherent high dimensionality and provide discriminative feature selection, to allow common and distinctive elements to be identified from a small set of user labelled examples. These elements are then accentuated in the image signature to increase similarity between examples and pull correct classes together. By repeating this process in an online learning framework, the accuracy of similarity increases dramatically despite labelling only a few training examples. To demonstrate that the approach is agnostic to media type and features used, we evaluate on three image datasets (15 scene, Caltech101 and FG-NET), a mixed text and image dataset (ImageTag), a dataset used in active learning (Iris) and on three action recognition datasets (UCF11, KTH and Hollywood2). On the UCF11 video dataset, the accuracy is 86.7% despite using only 90 labelled examples from a dataset of over 1200 videos, instead of the standard 1122 training videos. The approach is both scalable and efficient, with a single iteration over the full UCF11 dataset of around 1200 videos taking approximately 1 min on a standard desktop machine.",2017,Computer Vision and Image Understanding
CHI201749,Enhancing textural differences using wavelet-based texture characteristics morphological component analysis: A preprocessing method for improving image segmentation,"Texture difference enhancement, Segmentation improvement, Morphological component analysis, Wavelet-based dictionary, Dual-tree complex wavelet transform","In a recent paper, a method called “texture characteristic based morphological component analysis” (TC-MCA) has been proposed to enhance the performances of texture-based image segmentation algorithms: (1) TC-MCA separates texture into multiple pairs of components each representing a different visual characteristic of the texture; (2) then the TC-MCA algorithm manipulates each component and recombines them to produce the enhanced image where textures are more different, so that the texture-based segmentation is improved. This paper proposes a novel method outperforming TC-MCA by: (1) applying dictionaries based on dual-tree complex wavelet transform (DTCWT) to decompose the image into components representing different visual characteristics of texture, and (2) manipulating the dual-tree complex wavelet coefficients of the texture components to enhance each texture component’s own property and producing an texture-difference-enhanced image by recombining the enhanced components. The wavelet-based texture characteristic morphological component analysis (WT-TC-MCA) is applied as the preprocessing step to some state-of-the-art texture-based segmentation algorithms and compared with other texture enhancing methods, including the TC-MCA, with respect to the accuracy, precision-recall curves of the segmentation results. Experiments demonstrate that our method produces better textural difference enhancement effects and improves texture-based segmentation more than the comparators.",2017,Computer Vision and Image Understanding
MA20171,Learning a no-reference quality metric for single-image super-resolution,"Image quality assessment, No-reference metric, Single-image super-resolution","Numerous single-image super-resolution algorithms have been proposed in the literature, but few studies address the problem of performance evaluation based on visual perception. While most super-resolution images are evaluated by full-reference metrics, the effectiveness is not clear and the required ground-truth images are not always available in practice. To address these problems, we conduct human subject studies using a large set of super-resolution images and propose a no-reference metric learned from visual perceptual scores. Specifically, we design three types of low-level statistical features in both spatial and frequency domains to quantify super-resolved artifacts, and learn a two-stage regression model to predict the quality scores of super-resolution images without referring to ground-truth images. Extensive experimental results show that the proposed metric is effective and efficient to assess the quality of super-resolution images based on human perception.",2017,Computer Vision and Image Understanding
YANG2017133,Rotational contour signatures for both real-valued and binary feature representations of 3D local shape,"Local shape descriptor, Rotation, Contour signature, Binary representation, Feature matching","This paper presents a rotational contour signatures (RCS) method for both real-valued and binary descriptions of 3D local shape. RCS comprises several signatures that characterize the 2D contour information derived from 3D-to-2D projection of the local point cloud. The inspiration of our encoding technique comes from that when viewing towards an object, its contour is an effective and robust cue for representing its shape. In order to achieve a comprehensive geometry encoding, the local surface is continually rotated in a predefined local reference frame (LRF) so that multi-view information is obtained. A peculiar trait of our RCS method is its seamless extension to binary representations to accelerate feature matching and reduce storage consumption. Specifically, we resort to three techniques, i.e., thresholding, quantization and geometrical binary encoding, to generate RCS binary strings. In contrast to 2D image area, there are quite rare 3D binary descriptors yet in 3D computer vision. We deploy experiments on three standard datasets including shape retrieval, 3D object recognition and 2.5D point cloud view matching scenarios with a rigorous comparison with six state-of-the-art descriptors. The comparative outcomes confirm numerous merits of our RCS method, e.g., highly discriminative, compact, computational efficient and robust to many nuisances including noise, mesh resolution variation, clutter and occlusion. We also show the versatility of RCS in matching of both LiDAR and Kinect point clouds.",2017,Computer Vision and Image Understanding
FANG201757,Online hash tracking with spatio-temporal saliency auxiliary,"Visual tracking, Spatio-temporal saliency, Online hash-code learning, Minimum barrier distance","In this paper, we propose an online hashing tracking method with a further exploitation of spatio-temporal saliency for template sampling. Specifically, spatio-temporal saliency is firstly explored to make the sampled templates contain true object templates as much as possible. Then, different from the previous batch modes for hashing, the hashing function in this work is online learned by new pairs of collected templates received sequentially, in which the relationship between the positive templates and negative templates can be appropriately preserved that is more useful for visual tracking. With the hash coding for templates, the between-frame matching can be efficiently conducted. Besides, this work further builds a positive template pool as a memory buffer for object depiction, in which representative truly positive target templates are gathered and utilized to restrain the degradation of the appearance model due to the error accommodation in online hashing. Extensive experiments demonstrate that our tracker performs favorably against the state-of-the-art ones.",2017,Computer Vision and Image Understanding
CHEN20171,Survey: How good are the current advances in image set based face identification? – Experiments on three popular benchmarks with a naïve approach,"Face identification, Modelling, Performance","The recent proposed approaches on image set based face identification always follow a four-stage pipeline: face detection – face image representation – face image set modelling – identification; with face image set modelling being the additional step in this pipeline compared to that of the conventional image based face identification. As the research community moves forward, the performance in the area of image set based face identification have been slightly improved; however, the algorithms, mainly concentrated on the stages of face image set modelling and identification, have become dramatically complex. This paper shows that on the three most commonly used benchmarks, namely Honda/UCSD, CMU-MoBo and YouTube Celebrities datasets, a naïve Euclidean distance based approach can perform at least as good as, if not better than, the state-of-the-art algorithms. This leads to the question: how far has the current research tapped into the modelling of image face sets for the identification purpose?",2017,Computer Vision and Image Understanding
THEOLOGOU2017148,Part-based 3D object retrieval via multi-label optimization,"3D object retrieval, 3D mesh segmentation, Part-based representation","This paper deals with the problem of 3D object retrieval using a part-based representation. The premise in this context is that similar objects will consist of similar parts. A part-based representation is proposed, where each object is segmented, and represented as a labeled graph, with nodes corresponding to parts, and edges connecting adjacent parts. The calculation of the distance between two segmented objects is formulated as a multi-label optimization problem, taking into account the aforementioned graphs. The proposed method achieves comparable performance to the state-of-the-art on several datasets, while it has a clear advantage in the case of articulated objects.",2017,Computer Vision and Image Understanding
KIM2017114,Multi-view face recognition from single RGBD models of the faces,"Face recognition, Depth cameras, Manifold representations, Multi-view face recognition, RGBD models, Deep convolutional neural networks, Deep learning","This work takes important steps towards solving the following problem of current interest: Assuming that each individual in a population can be modeled by a single frontal RGBD face image, is it possible to carry out face recognition for such a population using multiple 2D images captured from arbitrary viewpoints? Although the general problem as stated above is extremely challenging, it encompasses subproblems that can be addressed today. The subproblems addressed in this work relate to: (1) Generating a large set of viewpoint dependent face images from a single RGBD frontal image for each individual; (2) using hierarchical approaches based on view-partitioned subspaces to represent the training data; and (3) based on these hierarchical approaches, using a weighted voting algorithm to integrate the evidence collected from multiple images of the same face as recorded from different viewpoints. We evaluate our methods on three datasets: a dataset of 10 people that we created and two publicly available datasets which include a total of 48 people. In addition to providing important insights into the nature of this problem, our results show that we are able to successfully recognize faces with accuracies of 95% or higher, outperforming existing state-of-the-art face recognition approaches based on deep convolutional neural networks.",2017,Computer Vision and Image Understanding
ATKINSON2017158,Polarisation photometric stereo,"Polarisation, Photometric stereo, 3D Reconstruction","This paper concerns a novel approach to fuse two-source photometric stereo (PS) data with polarisation information for complete surface normal recovery for smooth or slightly rough surfaces. PS is a well-established method but is limited in application by its need for three or more well-spaced and known illumination sources and Lambertian reflectance. Polarisation methods are less studied but have shown promise for smooth surfaces under highly controlled capture conditions. However, such methods suffer from inherent ambiguities and the depolarising effects of surface roughness. The method presented in this paper goes some way to overcome these limitations by fusing the most reliable information from PS and polarisation. PS is used with only two sources to deduce a constrained mapping of the surface normal at each point onto a 2D plane. Phase information from polarisation is used to deduce a mapping onto a different plane. The paper then shows how the full surface normal can be obtained from the two mappings. The method is tested on a range of real-world images to demonstrate the advantages over standalone applications of PS or polarisation methods.",2017,Computer Vision and Image Understanding
TACHOS201773,Mining discriminative descriptors for goal-based activity detection,"Activity detection, Goal-based, Activity localization, Discriminative descriptors","Human activity detection from video that is recorded continuously over time has been gaining increasing attention due to its use in applications like security monitoring, smart homes and assisted living setups. The analysis of continuous videos for the detection of specific activities, called Activities of Interest (AoI) in this work, is particularly challenging, as the start and end times of the AoI are unknown, while the AoI themselves feature large anthropometric variations, making their recognition more difficult. Continuously recorded videos also contain periods of inactivity, or activities that are not in the set of AoI, further complicating the problem of detection. This work attempts to overcome these challenges by introducing the concepts of (1) discriminative descriptors, (2) a goal for the AoI, represented by the most discriminative descriptors, (3) a novel, goal-based framework for activity detection and recognition in video. We represent AoI goals by descriptors found to be the most discriminative, as defined by a function of their correlation distance from the majority of the data, rather than by semantics or parametric modeling. This ensures flexibility, as activities in video feature many variations which cannot always be adequately represented by model-based approaches. Temporal detection of AoI is based on the distance of the test data from the AoI goals, which is shown to provide accurate results. Activity recognition takes place by applying SVM classification on the detected AoI, and the results are compared with the state-of-the-art on publicly available real world and benchmark research datasets.",2017,Computer Vision and Image Understanding
JIA201787,Multiple metric learning with query adaptive weights and multi-task re-weighting for person re-identification,"Person re-identification, Multiple metric learning, Multi-task learning, Query adaptive weighting","Metric learning has been widely studied in person re-identification (re-id). However, most existing metric learning methods only learn one holistic Mahalanobis distance metric for the concatenated high dimensional feature. This single metric learning strategy cannot handle complex nonlinear data structure and may easily encounter overfitting. Besides, feature concatenation is incapable of exploring the discriminant capability of different features and low dimensional features tend to be dominated by high dimensional ones. Motivated by these problems, we propose a multiple metric learning method for the re-id problem, where individual sub-metrics are separately learned for each feature type and the final metric is formed as weighted sum of the sub-metrics. The sub-metrics are learned with the Cross-view Quadratic Discriminant Analysis (XQDA) algorithm and the weights to each sub-metric are assigned in a two-step procedure. First, the importance of each feature type is estimated according to its discriminative power, which is measured in a query adaptive manner as related to the partial Area Under Curve (pAUC) scores. Then, the weights of all feature types are learned simultaneously with a maximum-margin based multi-task structural SVM learning framework, in order to make sure that relevant gallery images are ranked before irrelevant ones within all feature spaces. Finally, the sub-metrics are integrated with the learned weights in an ensemble model, generating a sophisticated distance metric. Experiments on the challenging i-LIDS, VIPeR, CAVIAR and 3DPeS datasets demonstrate the effectiveness of the proposed method.",2017,Computer Vision and Image Understanding
DAFNI201736,Detecting moving regions in CrowdCam images,"Motion detection, CrowdCam, Epipolar geometry","We address the novel problem of detecting dynamic regions in CrowdCam images – a set of still images captured by a group of people. These regions capture the most interesting parts of the scene, and detecting them plays an important role in the analysis of visual data. Our method is based on the observation that matching static points must satisfy the epipolar geometry constraints, but computing exact matches is challenging. Instead, we compute the probability that a pixel has a match, not necessarily the correct one, along the corresponding epipolar line. The complement of this probability is not necessarily the probability of a dynamic point because of occlusions, noise, and matching errors. Therefore, information from all pairs of images is aggregated to obtain a high quality dynamic probability map, per image. Experiments on challenging datasets demonstrate the effectiveness of the algorithm on a broad range of settings; no prior knowledge about the scene, the camera characteristics or the camera locations is required.",2017,Computer Vision and Image Understanding
ORAMASM2017100,Context-based object viewpoint estimation: A 2D relational approach,"Context, Viewpoint estimation, Relational learning, Collective classification, Cautious inference","The task of object viewpoint estimation has been a challenge since the early days of computer vision. To estimate the viewpoint (or pose) of an object, people have mostly looked at object intrinsic features, such as shape or appearance. Surprisingly, informative features provided by other, extrinsic elements in the scene, have so far mostly been ignored. At the same time, contextual cues have been proven to be of great benefit for related tasks such as object detection or action recognition. In this paper, we explore how information from other objects in the scene can be exploited for viewpoint estimation. In particular, we look at object configurations by following a relational neighbor-based approach for reasoning about object relations. We show that, starting from noisy object detections and viewpoint estimates, exploiting the estimated viewpoint and location of other objects in the scene can lead to improved object viewpoint predictions. Experiments on the KITTI dataset demonstrate that object configurations can indeed be used as a complementary cue to appearance-based viewpoint estimation. Our analysis reveals that the proposed context-based method can improve object viewpoint estimation by reducing specific types of viewpoint estimation errors commonly made by methods that only consider local information. Moreover, considering contextual information produces superior performance in scenes where a high number of object instances occur. Finally, our results suggest that, following a cautious relational neighbor formulation brings improvements over its aggressive counterpart for the task of object viewpoint estimation.",2017,Computer Vision and Image Understanding
PATEL201724,Evaluation of periocular features for kinship verification in the wild,"Periocular, Kinship verification, Local binary patterns, Pattern classification, Metric learning","Kinship verification is receiving increasing attention among computer vision researchers due to interesting applications ranging from family album management to searching missing family members. Existing approaches have focused on using face images to decode kinship information. In contrast, this paper explores the effectiveness of periocular region in verifying kinship from images captured in the wild. Further, we also propose a block-based neighborhood repulsed metric learning (BNRML) framework, an extension of NRML, to yield more discriminative power. The proposed method learns multiple local distance metrics from different blocks of the images represented by local ternary patterns. Moreover, to contemplate diversity in discrimination power of different blocks, weighted score-level fusion scheme is used to obtain a similarity score of image pair. Extensive experiments on KinFaceW-I and KinFaceW-II datasets demonstrated the potential of periocular features for kinship verification. Furthermore, the fusion of periocular and face traits under BNRML framework provided highly competitive results as compared to state-of-the-art methods.",2017,Computer Vision and Image Understanding
SEIBOLD201745,Model-based motion blur estimation for the improvement of motion tracking,"Motion blur, Multi-frame deconvolution, Motion tracking","Video tracking is an important task in many automated or semi-automated applications, like cinematic post production, surveillance or traffic monitoring. Most established video tracking methods fail or lead to an inaccurate estimate when motion blur occurs in the video, as they assume, that the object appears constantly sharp in the video. In this paper, we present a novel motion tracking method with explicit modeling of motion blur, estimating the continuous motion of a rigid 3-D object with known geometry in a monocular video as well as the sharp object texture. Instead of treating motion blur as a potential source of errors, we take advantage of it and consider motion blur as an additional information source, providing information about the motion of the tracked object during the exposure. In an analysis-by-synthesis approach we explicitly model the effects of motion blur reconstructing the captured frames, in order to accomplish a more accurate estimation. We design our algorithm to be capable to run in parallel on the GPU using the common rendering pipeline and considering each frame individually to handle also long videos. We tested our approach on both synthetic and real videos. In both cases, we achieve significant improvements of accuracy and reductions of frame reconstruction error compared to the estimated motion of a rigid body tracker, without motion blur handling.",2017,Computer Vision and Image Understanding
PARISOT201774,Scene-specific classifier for effective and efficient team sport players detection from a single calibrated camera,"Detection, Scene-specific classifier, Online training, Random ferns, Sports analysis","This paper considers the detection of players in team sport scenes observed with a still or motion-compensated camera. Background-subtracted foreground masks provide easy-to-compute primary cues to identify the vertical silhouettes of moving players in the scene. However, they are shown to be too noisy to achieve reliable detections when only a single viewpoint is available, as often desired for reduced deployment cost. To circumvent this problem, our paper investigates visual classification to identify the true positives among the candidates detected by the foreground mask. It proposes an original approach to automatically adapt the classifier to the game at hand, making the classifier scene-specific for improved accuracy. Since this adaptation implies the use of potentially corrupted labels to train the classifier, a semi-naive Bayesian classifier that combines random sets of binary tests is considered as a robust alternative to boosted classification solutions. In final, our validations on two publicly released datasets prove that our proposed combination of visual and temporal cues supports accurate and reliable players’ detection in team sport scenes observed from a single viewpoint.",2017,Computer Vision and Image Understanding
DRORY2017116,Automated detection and tracking of slalom paddlers from broadcast image sequences using cascade classifiers and discriminative correlation filters,"Detection, Tracking, Cascade classification, Discriminative correlation filter, Multi-class SVM, Canoe Kayak Slalom, Shot transition, Sports biomechanics, Performance analysis","This paper addresses the problem of automatic detection and tracking of slalom paddlers through a long sequence of sports broadcast images comprised of persistent view changes. In this context, the task of visual object tracking is particularly challenging due to frequent shot transitions (i.e. camera switches), which violate the fundamental spatial continuity assumption used by most of the state-of-the-art object tracking algorithms. The problem is further compounded by significant variations in object location, shape and appearance in typical sports scenarios where the athletes often move rapidly. To overcome these challenges, we propose a Periodically Prior Regularised Discriminative Correlation Filters (PPRDCF) framework, which exploits recent successful Discriminative Correlation Filters (DCF) with a periodic regularisation by a prior that constitutes a rich discriminative cascade classifier. The PPRDCF framework reduces the corruption of positive samples during online learning of the correlation filters by negative training samples. Our framework detects rapid shot transitions to reinitialise the tracker. It successfully recovers the tracker when the location, view or scale of the object changes or the tracker drifts from the object. The PPRDCF also provides the race context by detection of the ordered course obstacles and their spatial relations to the paddler. Our framework robustly outputs the evidence base pre-requisite to derived race kinematics for analysis of performance. Experiments are performed on task-specific dataset containing Canoe/Kayak Slalom race image sequences with successful results obtained.",2017,Computer Vision and Image Understanding
RENO2017164,A technology platform for automatic high-level tennis game analysis,"Synchronized cameras platform, Ball and player tracking, Trajectory analysis, Semantic interaction interpretation","Sports video research is a popular topic that has been applied to many prominent sports for a large spectrum of applications. In this paper we introduce a technology platform which has been developed for the tennis context, able to extract action sequences and provide support to coaches for players performance analysis during training and official matches. The system consists of an hardware architecture, devised to acquire data in the tennis context and for the specific domain requirements, and a number of processing modules which are able to track both the ball and the players, to extract semantic information from their interactions and automatically annotate video sequences. The aim of this paper is to demonstrate that the proposed combination of hardware and software modules is able to extract 3D ball trajectories robust enough to evaluate ball changes of direction recognizing serves, strokes and bounces. Starting from these information, a finite state machine based decision process can be employed to evaluate the score of each action of the game. The entire platform has been tested in real experiments during both training sessions and matches, and results show that automatic annotation of key events along with 3D positions and scores can be used to support coaches in the extraction of valuable information about players intentions and behaviours.",2017,Computer Vision and Image Understanding
SETTI201747,The S-Hock dataset: A new benchmark for spectator crowd analysis,"Spectator monitoring, Crowd analysis, Spectator crowd","Although crowd analysis is a classical and extensively studied problem for the computer vision community, the vast majority of the works in the literature assume a single type of crowd, while the sociological literature classifies a number of different typologies, each one with their own distinctive traits. In this paper we focus on a particular kind of crowd referred in sociology as spectator crowd, which consists a number of people that are “interested in watching something specific that they came to see” Berlonghi (1995). This is the typical social formation that attends entertainment events like sport matches, concerts, movies, etc. In this work we present a novel dataset, the Spectators Hockey (S-Hock), containing almost 30 hours of videos recorded at an ice hockey rink during the Winter Universiade “Trentino2013”. On these data we provide a massive annotation, focusing on the spectators at different levels of detail: from high level features describing which team a person supports and if he/she knows his/her neighbors; to a lower level, where we consider standard pose information as well as atomic actions like applauding, jumping, etc. We also provide annotations for the game field, which allows us to analyze the relationship between the crowd behavior and the events of the match. Eventually we provide more than 100 million of annotations, that can be used for many different tasks spanning from standard applications, like people counting and head pose estimation, to higher level tasks, like excitement estimation and automatic summarization. We provide protocols and baseline results for all of these applications, encouraging further research in these field.",2017,Computer Vision and Image Understanding
MANAFIFARD201719,A survey on player tracking in soccer videos,"Soccer, Playfield, Player, Detection, Labeling, Appearance, Tracking, Occlusion, Evaluation","There is a growth of demand for automatically analyzing soccer matches and tactics. Since players are the focus of attentions in soccer matches, player tracking is a fundamental element in most soccer video analysis. The aim of player tracking is to extract the trajectories of players, and its input is provided through some preprocessing steps including playfield detection, player detection, player labeling, occlusion handling and player appearance modeling. Soccer player tracking is a complex and challenging task due to difficulties such as blur, illumination change and heavy occlusions. This paper presents the state-of-the-art in preprocessing and processing methods for soccer player tracking. We categorize different approaches, analyze their strengths and weaknesses, review evaluation criteria and conclude future research directions.",2017,Computer Vision and Image Understanding
THOMAS20173,Computer vision for sports: Current applications and research topics,"Player tracking, Ball tracking, Sports analysis","The world of sports intrinsically involves fast and accurate motion that is not only challenging for competitors to master, but can be difficult for coaches and trainers to analyze, and for audiences to follow. The nature of most sports means that monitoring by the use of sensors or other devices fixed to players or equipment is generally not possible. This provides a rich set of opportunities for the application of computer vision techniques to help the competitors, coaches and audience. This paper discusses a selection of current commercial applications that use computer vision for sports analysis, and highlights some of the topics that are currently being addressed in the research community. A summary of on-line datasets to support research in this area is included.",2017,Computer Vision and Image Understanding
KASIRI2017143,Fine-grained action recognition of boxing punches from depth imagery,"Fine-grained action recognition, Sports analytics, Boxing-punch classification, Body part detection","Competitive sporting environments demand reliable statistics on an athlete’s performance to measure an athlete’s actions during competition, and to differentiate between the fine-grained actions performed. This is especially true for combat sports such as boxing where the variations observed between the main punching actions are subtle, making automatic classification of movements extremely difficult. This paper presents a robust framework for the automatic classification of a boxer’s punches. Overhead depth imagery is employed to alleviate challenges associated with occlusions, and robust body-part tracking is developed for the noisy time-of-flight sensors. Punch recognition is addressed through multi-class Support Vector Machine (SVM) and Random Forest classifiers using combinations of features. A coarse-to-fine hierarchical SVM classifier is presented in this paper based on prior knowledge of boxing punches. This framework has been applied to boxing image sequences taken at the Australian Institute of Sport with 14 elite boxers. Results demonstrate the effectiveness of the action recognition method, with the hierarchical SVM classifier yielding a 97.3% accuracy improving on the recent state-of-the-art action recognition systems.",2017,Computer Vision and Image Understanding
CHEN201759,Where should cameras look at soccer games: Improving smoothness using the overlapped hidden Markov model,"Camera planning, Camera calibration, Hidden Markov model, Soccer games","Automatic camera planning for sports has been a long term goal in computer vision and machine learning. In this paper, we study camera planning for soccer games using pan, tilt and zoom (PTZ) cameras. Two important problems have been addressed. First, we propose the Overlapped Hidden Markov Model (OHMM) method which effectively optimizes the camera trajectory in overlapped local windows. The OHMM method significantly improves the smoothness of the camera planning by optimizing the camera trajectory in the temporal space, resulting in much more natural camera movements present in real broadcasts. We also propose CalibMe which is a highly automatic camera calibration method for soccer games. CalibMe enables users to collect large amounts of training data for learning algorithms. The precision of CalibMe is evaluated on a motion blur affected sequence and outperforms several strong existing methods. The performance of the OHMM method is extensively evaluated on both synthetic and real data. It outperforms the state-of-the-art algorithms in terms of smoothness without sacrificing accuracy.",2017,Computer Vision and Image Understanding
REILY2017154,Real-time gymnast detection and performance analysis with a portable 3D camera,"Depth image segmentation, Human activity recognition, Sports analysis, Gymnastics","Sports analysis is a useful application of technology, providing value to athletes, coaches, and sports fans by producing quantitative evaluations of performance. To address this field in the context of men’s gymnastics, we introduce a system that utilizes a Microsoft Kinect 2 camera to automatically evaluate the performance of a gymnast on the pommel horse apparatus, specifically in regards to the consistency of the gymnast’s timing and body angle. The Kinect’s ability to determine the depth at each pixel provides information not available to typical sports analysis approaches based solely on RGB data. Our approach consists of a three stage pipeline that automatically identifies a depth of interest, localizes the gymnast, detects when the gymnast is performing a certain routine, and finally provides an analysis of that routine. We demonstrate that each stage of the pipeline produces effective results: our depth of interest approach identifies the gymnast 97.8% of the time and removes over 60% of extraneous data; our activity recognition approach is highly efficient and identifies ‘spinning’ by the gymnast with 94.8% accuracy; and our performance analysis method evaluates the gymnast’s timing with accuracy only limited by the frame rate of the Kinect. Additionally, we validate our system and the proposed methods with a real-world online application, used by actual gymnastics coaches and viewed as a highly effective training tool.",2017,Computer Vision and Image Understanding
TURCHINI2017128,Understanding and localizing activities from correspondences of clustered trajectories,"Action recognition, Action localization, Sport analytics","We present an approach for human activity recognition based on trajectory grouping. Our representation allows to perform partial matching between videos obtaining a robust similarity measure. This approach is extremely useful in sport videos where multiple entities are involved in the activities. Many existing works perform person detection, tracking and often require camera calibration in order to extract motion and imagery of every player and object in the scene. In this work we overcome this limitations and propose an approach that exploits the spatio-temporal structure of a video, grouping local spatio-temporal features unsupervisedly. Our robust representation allows to measure video similarity making correspondences among arbitrary patterns. We show how our clusters can be used to generate frame-wise action proposals. We exploit proposals to improve our representation further for localization and recognition. We test our method on sport specific and generic activity dataset reporting results above the existing state-of-the-art.",2017,Computer Vision and Image Understanding
MORIMITSU201789,Exploring structure for long-term tracking of multiple objects in sports videos,"Multi-object tracking, Structural information, Particle filter, Graph","In this paper, we propose a novel approach for exploiting structural relations to track multiple objects that may undergo long-term occlusion and abrupt motion. We use a model-free approach that relies only on annotations given in the first frame of the video to track all the objects online, i.e. without knowledge from future frames. We initialize a probabilistic Attributed Relational Graph (ARG) from the first frame, which is incrementally updated along the video. Instead of using the structural information only to evaluate the scene, the proposed approach considers it to generate new tracking hypotheses. In this way, our method is capable of generating relevant object candidates that are used to improve or recover the track of lost objects. The proposed method is evaluated on several videos of table tennis, volleyball, and on the ACASVA dataset. The results show that our approach is very robust, flexible and able to outperform other state-of-the-art methods in sports videos that present structural patterns.",2017,Computer Vision and Image Understanding
KHAN201790,Disclosure risk reduction for generalized linear model output in a remote analysis system,"Confidentiality protection, Data utility, Efficiency loss, Generalized linear model, Perturbation, Remote analysis","Remote analysis systems allow analysts to obtain statistical results without providing direct access to confidential data stored in a secure server system. An attacking analyst could send queries to a remote server to obtain outputs of statistical analyses and use those outputs for a disclosure attack. Statistical disclosure control (SDC) methods are used to modify remote analysis system (RAS) outputs in the protection of confidential information. Confidentiality protection through perturbation is one of the most commonly adopted SDC methods. In the case of generalized linear modelling, random noise is added to the estimated coefficients or to the associated estimating equation prior to getting estimates. This inflates the variances of estimators, and some efficiency and utility of estimators are lost. Thus the application of any perturbation based SDC method could result in an inefficient estimator, with the danger of producing worthless inferences. To date, little attention has been given to systematically controlling the disclosure risk and utility in SDC methods for RAS. In this paper, we develop a framework for the perturbation of estimating equations that enables an RAS to release modified generalized linear model output in such a way that the disclosure risk is not only reduced but also a good utility is maintained. Finally, we present some empirical results demonstrating the application of our framework for obtaining estimates from perturbed estimating equations of binary and count response models.",2017,Data & Knowledge Engineering
KIM201739,Maximal object+: An acyclic semantic structure on the universal relation model,"Maximal object+, Semantic structure, Universal relation, USQL, Data models, Database semantics","The universal relation model allows us to find the results on a virtual relation that joins all the relations in a relational database if the user specifies only selection and projection conditions. It automatically finds actual relations in which the selection and projection conditions are performed and possible join paths among the relations using the database schema. When there are cycles in the database schema graph, however, the universal relation model may lose some results since it adds an unintentional condition to the interpretation of a query. Here, the unintentional condition is an equality condition that intersects multiple query interpretations by different join paths, and thus, it returns only part of the results that the user intends. This paper proposes a new semantic structure, maximal object+, that completely removes cycles in a universal relation. A maximal object+ is a largest acyclic connected component in the database schema graph where the entire set of relations in the component has the lossless join property. Here, the important point is that a maximal object+ allows only the lossless join property indicated by functional dependencies excluding the lossless join property indicated by only multivalued dependencies. To show the advantage of a maximal object+, we compare the effectiveness of the query processing method based on maximal object+ with that of the existing query processing method based on the maximal object by performing experiments on the synthetic and real datasets. As a result, we show that our method significantly outperforms the one based on the maximal object in terms of mean recall when a cycle exists in a maximal object while maintaining comparable efficiency. Specifically, our method improves the mean recall by up to 8.15 times for the dataset whose schema involves cycles.",2017,Data & Knowledge Engineering
VELAMPALLI2017103,Graph based knowledge discovery using MapReduce and SUBDUE algorithm,"Analytics, Big data, Conceptual graph, Graph mining, HDFS, MapReduce, Resumes, Skill, SUBDUE","Knowledge Discovery is the process of extracting useful and hidden information. Extracting knowledge from data represented in the form of graphs is emerging in this new generation. Graphs are used to model and solve many real world problems. In this work, we aim to show how skills data from resumes is modelled into a variant of graph data structure called conceptual graph using MapReduce programming model. Resumes are taken as data source because they are the ones containing skill-sets of candidates. Initial storage and pre-processing is done in a big data framework using Hadoop Distributed File System (HDFS ) and MapReduce. SUB Structure Discovery Using Examples (SUBDUE), a popular graph mining algorithm is used for retrieving common skill-sets. The results obtained from real-world dataset of resumes clearly demonstrate the potential of graph mining algorithms in skill set analytics. Proposed approach is able to extract common skill-sets. Common skill-set extraction is useful for course curriculum designers as well as job seekers.",2017,Data & Knowledge Engineering
BALA2017114,A Fine‐Grained Distribution Approach for ETL Processes in Big Data Environments,"Data Warehousing, ETL, Parallel and Distributed Processing, Big Data, MapReduce","Among the so-called “4Vs” (volume, velocity, variety, and veracity) that characterize the complexity of Big Data, this paper focuses on the issue of “Volume” in order to ensure good performance for Extracting-Transforming-Loading (ETL) processes. In this study, we propose a new fine-grained parallelization/distribution approach for populating the Data Warehouse (DW). Unlike prior approaches that distribute the ETL only at coarse-grained level of processing, our approach provides different ways of parallelization/distribution both at process, functionality and elementary functions levels. In our approach, an ETL process is described in terms of its core functionalities which can run on a cluster of computers according to the MapReduce (MR) paradigm. The novel approach allows thereby the distribution of the ETL process at three levels: the “process” level for coarse-grained distribution and the “functionality” and “elementary functions” levels for fine-grained distribution. Our performance analysis reveals that employing 25 to 38 parallel tasks enables the novel approach to speed up the ETL process by up to 33% with the improvement rate being linear.",2017,Data & Knowledge Engineering
LEOPOLD201722,Ensuring the canonicity of process models,"Conceptual modeling, Business process, Canonical representation, Non-canonicity patterns, Pattern refactoring","Process models play an important role for specifying requirements of business-related software. However, the usefulness of process models is highly dependent on their quality. Recognizing this, researches have proposed various techniques for the automated quality assurance of process models. A considerable shortcoming of these techniques is the assumption that each activity label consistently refers to a single stream of action. If, however, activities textually describe control flow related aspects such as decisions or conditions, the analysis results of these tools are distorted. Due to the ambiguity that is associated with this misuse of natural language, also humans struggle with drawing valid conclusions from such inconsistently specified activities. In this paper, we therefore introduce the notion of canonicity to prevent the mixing of natural language and modeling language. We identify and formalize non-canonical patterns, which we then use to define automated techniques for detecting and refactoring activities that do not comply with it. We evaluated these techniques by the help of four process model collections from industry, which confirmed the applicability and accuracy of these techniques.",2017,Data & Knowledge Engineering
MANAA201758,Ontology-based modeling and querying of trajectory data,"Ontology, OWL-DL formalism, Semantic modeling, Trajectory","With the evolution of location-sensing devices and associated technologies, mobility data driven scientific discovery approaches became an important paradigm for advanced computing performed in various central areas i.e., Internet of things and social networks. Under this paradigm, trajectory data is considered as a core revealing details of instantaneous behaviors piloted by mobile entities. This forms the need of modeling of such behaviors and the understanding of them, and actually, gave rise to different modeling approaches using either conceptual modeling or ontologies. Modeling and querying of trajectory data are still challenging because of their structural and semantic heterogeneities, and due to the complexity of establishing choices about the domain’ consensual knowledge. Ontologies are promising solutions for the above two problems seeing that they are intended to reduce structural heterogeneity among sources and to specify the semantics of concepts in an unambiguous way. In this paper, we propose a framework for a semantics oriented modeling and querying of trajectory data. We present an ontology-based trajectory pivot model that covers common structures encountered in trajectories associated with links to application and geographic modules. We validate our proposal through a case study dealing with human movement activity.",2017,Data & Knowledge Engineering
TURAN20171,Secure logical schema and decomposition algorithm for proactive context dependent attribute based inference control,"Inference control, Secure logical schema, Database decomposition, Database granularity, Sensitive data protection","Inference problem has always been an important and challenging topic of data privacy in databases. In relational databases, the traditional solution to this problem was to define views on relational schemas to restrict the subset of attributes and operations available to the users in order to prevent unwanted inferences. This method is a form of decomposition strategy, which mainly concentrates on the granularity of the accessible fields to the users, to prevent sensitive information inference. Nowadays, due to increasing data sharing among parties, the possibility of constructing complex indirect methods to obtain sensitive data has also increased. Therefore, we need to not only consider security threats due to direct access to sensitive data but also address indirect inference channels using functional and probabilistic dependencies (e.g., deducing gender of an individual from his/her name) while creating security views. In this paper, we propose a proactive and decomposition based inference control strategy for relational databases to prevent direct or indirect inference of private data. We introduce a new kind of context dependent attribute policy rule, which is named as security dependent set, as a set of attributes whose association should not be inferred. Then, we define a logical schema decomposition algorithm that prevents inference among attributes in security dependent set. The decomposition algorithm takes both functional and probabilistic dependencies into consideration in order to prevent all kinds of known inferences of relations among the attributes of security dependent sets. We prove that our proposed decomposition algorithm generates a secure logical schema that complies with the given security dependent set constraints. Since our proposed technique is purely proactive, it does not require any prior knowledge about executed queries and do not need to modify any submitted queries. It can also be embedded into any relational database management system without changing anything in the underlying system. We empirically compare our proposed method with the state of art reactive methods. Our extensive experimental analysis, conducted using TPC-H11TPC-H is an ad-hoc decision support benchmark of Transaction Processing Performance Council. benchmark scheme, shows the effectives our proposed approach.",2017,Data & Knowledge Engineering
ZHU201773,A natural language interface to a graph-based bibliographic information retrieval system,"Information retrieval, Natural language interface, Graph database, Data and knowledge visualization, Digital libraries","With the ever-increasing volume of scientific literature, there is a need for a natural language interface to bibliographic information retrieval systems to retrieve relevant information effectively. In this paper, we propose one such interface, NLI-GIBIR, which allows users to search for a variety of bibliographic data through natural language. NLI-GIBIR makes use of a novel framework applicable to graph-based bibliographic information retrieval systems in general. This framework incorporates algorithms/heuristics for interpreting and analyzing natural language bibliographic queries via a series of text- and linguistic-based techniques, including tokenization, named entity recognition, and syntactic analysis. We find that our framework, as implemented in NLI-GIBIR, can effectively represent and address complex bibliographic information needs. Thus, the contributions of this paper are as follows: First, to our knowledge, it is the first attempt to propose a natural language interface for graph-based bibliographic information retrieval. Second, we propose a novel customized natural language processing framework that integrates a few original algorithms/heuristics for interpreting and analyzing bibliographic queries. Third, we show that the proposed framework and natural language interface provide a practical solution for building real-world bibliographic information retrieval systems. Our experimental results show that the presented system can correctly answer 39 out of 40 example natural language queries with varying lengths and complexities.",2017,Data & Knowledge Engineering
FITSCHEN201724,Removal of curtaining effects by a variational model with directional forward differences,"Image processing, Convex analysis, Variational method, FIB tomography, Curtaining effect, Directional differences","Focused ion beam (FIB) tomography provides high resolution volumetric images on a micro scale. However, due to the physical acquisition process the resulting images are often corrupted by a so-called curtaining or waterfall effect. In this paper, a new convex variational model for removing such effects is proposed. More precisely, an infimal convolution model is applied to split the corrupted 3D image into the clean image and two types of corruptions, namely a striped part and a laminar one. In order to accomplish the decomposition we exploit the fact that the single parts have certain spatial structures, which are penalized by different first and second order differences. By doing so, our approach generalizes discrete unidirectional total variational (TV) approaches. A minimizer of the proposed model is computed by well-known primal dual techniques. Numerical examples show the very good performance of our new method for artificial as well as real-world data. Besides FIB tomography, we have also successfully applied our technique for the removal of pure stripes in Moderate Resolution Imaging Spectroradiometer (MODIS) data.",2017,Computer Vision and Image Understanding
KIM2017106,Dual soft assignment clustering algorithm for human action video clustering,"Dual assignment clustering, Unsupervised learning, Optimization, Human activity recognition","Dual assignment clustering (DAC) has been recently proposed in computer vision, shown to yield improved accuracy for action clustering tasks. The key idea of DAC is to consider another view (different from the original features) for the same set of samples, and to exploit the statistical correlation between cluster assignments in two views. However, the existing optimization is heuristic, mainly due to the difficulty in combinatorial optimization for hard cluster assignment. In this paper, we introduce a novel DAC optimization algorithm based on a probabilistic (soft) treatment, where the proposed objective function incorporates both the goodness of clustering in each view and the correlation between two views in a more principled and theoretically sound fashion. We also propose a lower-bound maximization technique that not only admits fast per-iteration solutions but also guarantees convergence to a local optimum. The superiority of the proposed approach to the existing methods is demonstrated for several activity video datasets.",2017,Computer Vision and Image Understanding
KREJOV2017124,Guided optimisation through classification and regression for hand pose estimation,"Hand pose estimation, Human computer interaction, Hand tracking, Finger tracking, Model optimisation, Random decision forest, Discriminative learning, Regression","This paper presents an approach to hand pose estimation that combines discriminative and model-based methods to leverage the advantages of both. Randomised Decision Forests are trained using real data to provide fast coarse segmentation of the hand. The segmentation then forms the basis of constraints applied in model fitting, using an efficient projected Gauss–Seidel solver, which enforces temporal continuity and kinematic limitations. However, when fitting a generic model to multiple users with varying hand shape, there is likely to be residual errors between the model and their hand. Also, local minima can lead to failures in tracking that are difficult to recover from. Therefore, we introduce an error regression stage that learns to correct these instances of optimisation failure. The approach provides improved accuracy over the current state of the art methods, through the inclusion of temporal cohesion and by learning to correct from failure cases. Using discriminative learning, our approach performs guided optimisation, greatly reducing model fitting complexity and radically improves efficiency. This allows tracking to be performed at over 40 frames per second using a single CPU thread.",2017,Computer Vision and Image Understanding
WANG201743,Object co-segmentation via weakly supervised data fusion,"Computer vision, Image segmentation, Object detection, Weakly supervised clustering, Data fusion","Object co-segmentation aims to simultaneously segment common regions of interest from multiple images. It is of great importance to image classification, object recognition and image retrieval. One way to extract similar objects shared by multiple images is to construct a correlation function between image regions. In this paper, object co-segmentation is addressed based on weakly supervised data fusion. First, we integrate the image boundary information into weakly supervised clustering by adopting an efficient image segmentation algorithm with proved convergence. Feature learning as well as clustering are also incorporated into the proposed algorithm to establish a unified framework so that an optimal feature subspace with clustering-oriented methods is provided. Second, the shared object from multiple images is regarded as the procedure to search objects from heterogeneous data sources, which is formalized as data fusion problems. Using data fusion techniques, we present a novel method to evaluate the similarity between images, which facilitates the use of similar objects from multiple images. Finally, the two proposed object segmentation and co-segmentation algorithms are verified through publicly available datasets MSRA1000 and iCoseg. Experiments demonstrate that both algorithms are capable to achieve superior or comparable performance over the compared state-of-the-art segmentation methods in all tested datasets.",2017,Computer Vision and Image Understanding
SHUKLA201783,A new composite multi-constrained differential-radon warping approach for digital video affine motion stabilization,"Motion estimation, Video stabilization, Integral projection, Radon transform, Dynamic time warping","This paper presents a new projection based affine motion stabilizer framework for video stabilization using differential-Radon (DRadon) curve warping. Extending the translational domain of classical projection based algorithms towards affine stabilization, multiple angular curves obtained with Radon or rotated images have recently been explored for combined rotation and zoom estimation. Radon provides efficient projection extraction, but use of integral intensity under local variation degrades the desired motion accuracy. DRadon works on derivative of each angular slice to incorporate shape based matching for better projection alignment. Based on human perception of inter-frame tilt in unsteady camera recordings, the proposed angular DRadon curve estimation is confined to angular search space of [−20ο, 20ο] with the angular increment of 0.1ο. Out of complete set of angular DRadon curves of reference frame, five key-angular slices are selected and correlated with their corresponding neighbourhood in target DRadon for inter-frame tilt estimation. Best matched key slices of reference and target DRadon are warped using a novel multi-constrained approach and the extracted warping vectors are further processed for translation and zoom estimation. A vector-slope algorithm based on relative stretching/contraction between the DRadon-projections is used for camera zoom estimation. Combining the estimated motion parameters, an affine transformation is developed for inter-frame stabilization. Comparative performance using motion accuracy and frame stability is evaluated over different categories of real-world videos.",2017,Computer Vision and Image Understanding
BRANCATI201733,Human skin detection through correlation rules between the YCb and YCr subspaces based on dynamic color clustering,"Skin detection, color space, Pixel based method, Pixel classification, Dynamic color clustering, Correlation rules","This paper presents a novel rule-based skin detection method that works in the YCbCr color space. The method is based on correlation rules that evaluate the combinations of chrominance values to identify the skin pixels in the YCb and YCr subspaces. The correlation rules depend on the shape and size of dynamically generated skin color clusters, which are computed on a statistical basis in the YCb and YCr subspaces for each single image, and represent the areas that include most of the candidate skin pixels. Comparisons with six well-known rule-based methods in literature carried out on four publicly available databases show that the proposed method outperforms the others in terms of quantitative performance evaluation parameters. Moreover, the qualitative analysis shows that the method achieves satisfactory results also in critical scenarios, including severe variations in illumination conditions.",2017,Computer Vision and Image Understanding
CHEN2017113,A new framework with multiple tasks for detecting and locating pain events in video,"Pain event detection, Pain event locating, P-HOG, HOG-TOP, Probabilistic fusion, Multiple kernel fusion","Automatically detecting and locating pain events in video is an important task in medical assessment. It is a challenging problem in facial expression analysis due to spontaneous faces, head movements and pose variations. In this paper, we explore the role of facial information at various time scales (frame, segment and sequence) and propose a new framework for pain event detection and locating in video. We introduce a feature-level fusion method for pain event detection and a multiple-task fusion method for locating pain events, respectively. Both spatial and spatial–temporal features are utilized in our study. At first, we employ the histogram of oriented gradients (HOG) of fiducial points (P-HOG) to extract spatial features from each video frame and train an SVM as a frame-based pain event detector. Secondly, HOG from Three Orthogonal Planes (named as HOG-TOP) is used to characterize the dynamic textures of a video segment, a segment-based classifier (SVM) is then trained for segment-level detection. We further apply a max pooling strategy to obtain the global P-HOG and HOG-TOP to represent the whole video sequence and a multiple kernel fusion is employed to find an optimal feature-level fusion. An SVM with multiple kernels is trained to perform sequence-level (pain event) detection. Finally, an effective probabilistic fusion method is proposed to integrate the detection results of the three different tasks (frame-level, segment-level and sequence-level detection) to locate pain events in video. Extensive experiments conducted on the UNBC-McMaster Shoulder Pain database show that our proposed method outperforms other state-of-the-art methods both in pain event detection and locating in video. Our sequence-level event detection method has also been applied to facial expression recognition in video with good results.",2017,Computer Vision and Image Understanding
ARGYRIOU201770,Frequency domain subpixel registration using HOG phase correlation,"Phase correlation, Registration in frequency domain, Subpixel, Fourier, Histogram of oriented gradients","We present a novel frequency-domain image registration technique, which employs histograms of oriented gradients providing subpixel estimates. Our method involves image filtering using dense Histogram of oriented gradients (HOG), which provides an advanced representation of the images coping with real-world registration problems such as non-overlapping regions and small deformations. The proposed representation retains the orientation information and the corresponding weights in a multi-dimensional representation. Furthermore, due to the overlapping local contrast normalization characteristic of HOG, the proposed histogram of oriented gradients - phase correlation (HOG-PC) method improves significantly the estimated motion parameters in small size blocks. Experiments using sequences with and without ground truth including both global and local/multiple motions demonstrate that the proposed method outperforms the state-of-the-art in frequency-domain motion estimation, in the shape of phase correlation, in terms of subpixel accuracy and motion compensation prediction for a range of test material, block sizes and motion scenarios.",2017,Computer Vision and Image Understanding
CHO2017150,Single image 3D human pose estimation using a procrustean normal distribution mixture model and model transformation,"Human pose estimation, 3D Shape recovery, 3D Human pose estimation, 3D Reconstruction","3D human pose estimation from a single image is an important problem in computer vision with a number of applications, including action recognition and scene understanding. However, it is still challenging due to its ill-posedness and complex non-rigid shape variations of a human body. In this paper, we use the Procrustean normal distribution mixture model as a 3D shape prior and propose a model transformation method for adjusting limb lengths of the 3D shape prior model, by which the proposed method can be applied to a novel test image. Inaccuracies of 2D part detections are handled by selecting from a diverse set of 2D pose candidates considering both the 2D part model and 3D shape model. Experimental results show that the proposed method performs favorably compared with existing methods, despite inaccuracies of 2D part detections and 3D shape ambiguities.",2017,Computer Vision and Image Understanding
IDREES20171,The THUMOS challenge on action recognition for videos “in the wild”,"Action recognition, Action detection, Action localization, Untrimmed videos, THUMOS, Dataset, Benchmark, UCF101","Automatically recognizing and localizing wide ranges of human actions are crucial for video understanding. Towards this goal, the THUMOS challenge was introduced in 2013 to serve as a benchmark for action recognition. Until then, video action recognition, including THUMOS challenge, had focused primarily on the classification of pre-segmented (i.e., trimmed) videos, which is an artificial task. In THUMOS 2014, we elevated action recognition to a more practical level by introducing temporally untrimmed videos. These also include ‘background videos’ which share similar scenes and backgrounds as action videos, but are devoid of the specific actions. The three editions of the challenge organized in 2013–2015 have made THUMOS a common benchmark for action classification and detection and the annual challenge is widely attended by teams from around the world. In this paper we describe the THUMOS benchmark in detail and give an overview of data collection and annotation procedures. We present the evaluation protocols used to quantify results in the two THUMOS tasks of action classification and temporal action detection. We also present results of submissions to the THUMOS 2015 challenge and review the participating approaches. Additionally, we include a comprehensive empirical study evaluating the differences in action recognition between trimmed and untrimmed videos, and how well methods trained on trimmed videos generalize to untrimmed videos. We conclude by proposing several directions and improvements for future THUMOS challenges.",2017,Computer Vision and Image Understanding
PANDEY2017162,Accurate vessel segmentation using maximum entropy incorporating line detection and phase-preserving denoising,"Line detection, Phase-preserving denoising, Morphological operation, Maximum entropy, Retinal image segmentation","The retinal images with lesions, exudates, non-uniformed illuminations and pathological artifacts have intrinsic problems such as the absence of thin vessels and false vessels detection. To solve these problems, we propose a novel algorithm which involves separation of background images to minimize the influence of noise, non-uniformed illuminations and lesions. We develop two different strategies to segment thin and thick blood vessels. Thin blood vessels are identified by taking benefits of local phase-preserving denoising, line detection, local normalization and maximum entropy thresholding. To remove noise and preserve detailed blood vessels information, phase-preserving denoising technique is used. The technology takes an advantage of log-Gabor wavelet responses in the complex domain to preserve the phase information of the image. Thick vessels are extracted and binarized via maximum entropy thresholding. The performance of the proposed algorithm is tested on four popular databases (DRIVE, STARE, CHASE_ DB1, HRF). The results demonstrate that the proposed segmentation process is automatic, accurate and computationally efficient.",2017,Computer Vision and Image Understanding
DIMICCOLI201755,SR-clustering: Semantic regularized clustering for egocentric photo streams segmentation,"Temporal segmentation, Egocentric vision, Photo streams clustering","While wearable cameras are becoming increasingly popular, locating relevant information in large unstructured collections of egocentric images is still a tedious and time consuming process. This paper addresses the problem of organizing egocentric photo streams acquired by a wearable camera into semantically meaningful segments, hence making an important step towards the goal of automatically annotating these photos for browsing and retrieval. In the proposed method, first, contextual and semantic information is extracted for each image by employing a Convolutional Neural Networks approach. Later, a vocabulary of concepts is defined in a semantic space by relying on linguistic information. Finally, by exploiting the temporal coherence of concepts in photo streams, images which share contextual and semantic attributes are grouped together. The resulting temporal segmentation is particularly suited for further analysis, ranging from event recognition to semantic indexing and summarization. Experimental results over egocentric set of nearly 31,000 images, show the prominence of the proposed approach over state-of-the-art methods.",2017,Computer Vision and Image Understanding
BARROS2017139,A dynamic gesture recognition and prediction system using the convexity approach,"Gesture recognition, Computer vision, Features extraction, Gesture prediction","Several researchers around the world have studied gesture recognition, but most of the recent techniques fall in the curse of dimensionality and are not useful in real time environment. This study proposes a system for dynamic gesture recognition and prediction using an innovative feature extraction technique, called the Convexity Approach. The proposed method generates a smaller feature vector to describe the hand shape with a minimal amount of data. For dynamic gesture recognition and prediction, the system implements two independent modules based on Hidden Markov Models and Dynamic Time Warping. Two experiments, one for gesture recognition and another for prediction, are executed in two different datasets, the RPPDI Dynamic Gestures Dataset and the Cambridge Hand Data, and the results are showed and discussed.",2017,Computer Vision and Image Understanding
LI2017173,"Simultaneous tumor segmentation, image restoration, and blur kernel estimation in PET using multiple regularizations","Image restoration, Tumor segmentation, Blur kernel estimation, Variational method, TV regularization, regularization","Accurate tumor segmentation from PET images is crucial in many radiation oncology applications. Among others, partial volume effect (PVE) is recognized as one of the most important factors degrading imaging quality and segmentation accuracy in PET. Taking into account that image restoration and tumor segmentation are tightly coupled and can promote each other, we proposed a variational method to solve both problems simultaneously in this study. The proposed method integrated total variation (TV) semi-blind de-convolution and Mumford–Shah segmentation with multiple regularizations. Unlike many existing energy minimization methods using either TV or L2 regularization, the proposed method employed TV regularization over tumor edges to preserve edge information, and L2 regularization inside tumor regions to preserve the smooth change of the metabolic uptake in a PET image. The blur kernel was modeled as anisotropic Gaussian to address the resolution difference in transverse and axial directions commonly seen in a clinic PET scanner. The energy functional was rephrased using the Γ-convergence approximation and was iteratively optimized using the alternating minimization (AM) algorithm. The performance of the proposed method was validated on a physical phantom and two clinic datasets with non-Hodgkin's lymphoma and esophageal cancer, respectively. Experimental results demonstrated that the proposed method had high performance for simultaneous image restoration, tumor segmentation and scanner blur kernel estimation. Particularly, the recovery coefficients (RC) of the restored images of the proposed method in the phantom study were close to 1, indicating an efficient recovery of the original blurred images; for segmentation the proposed method achieved average dice similarity indexes (DSIs) of 0.79 and 0.80 for two clinic datasets, respectively; and the relative errors of the estimated blur kernel widths were less than 19% in the transversal direction and 7% in the axial direction.",2017,Computer Vision and Image Understanding
CHEN201716,Using 3D face priors for depth recovery,"Depth recovery, Image restoration, Face model","For repairing inaccurate depth measurements from commodity RGB-D sensors, existing depth recovery methods primarily rely on low-level and rigid prior information. However, as the depth quality deteriorates, the recovered depth maps become increasingly unreliable, especially for non-rigid objects. Thus, additional high-level and non-rigid information is needed to improve the recovery quality. Taking as a starting point the human face that is the primary prior available in many high-level tasks, in this paper, we incorporate face priors into the depth recovery process. In particular, we propose a joint optimization framework that consists of two main steps: transforming the face model for better alignment and applying face priors for improved depth recovery. Face priors from both sparse and dense 3D face models are studied. By comparing with the baseline method on benchmark datasets, we demonstrate that the proposed method can achieve up to 23.8% improvement in depth recovery with more accurate face registrations, bringing inspirations to both non-rigid object modeling and analysis.",2017,Journal of Visual Communication and Image Representation
LEE201766,Combining self-learning based super-resolution with denoising for noisy images,"Self-learning, Image super-resolution, PCA, Denoising, Noisy image","In this paper, we propose a new learning based joint Super-Resolution (SR) and denoising algorithm for noisy images. The individual processing of denoising and SR when super-resolving a noisy image has drawbacks such as noise amplification, blurring and SR performance reduction. In the proposed joint method, principal component analysis (PCA) based denoising is closely combined with a self-learning SR framework in order to minimize the SR visual quality degradation caused by noise. Experimental results show that the joint method achieves an SR image quality improvement in terms of noise and blurring, when compared with the state-of-the-art joint method and sequential combinations of individual denoising and SR.",2017,Journal of Visual Communication and Image Representation
YOONCHOI20171,Fast super-resolution algorithm using rotation-invariant ELBP classifier and hierarchical pattern matching,"Reconstruction, Super-resolution, Classification, FIR filters, Up-scaling, Hierarchical addressing","This paper proposes a fast super-resolution (SR) algorithm using content-adaptive two-dimensional (2D) finite impulse response (FIR) filters based on a rotation-invariant classifier. The proposed algorithm consists of a learning stage and an inference stage. In the learning stage, we cluster a sufficient number of low-resolution (LR) and high-resolution (HR) patch pairs into a specific number of groups using the rotation-invariant classifier, and choose a specific number of dominant clusters. Then, we compute the optimal 2D FIR filter(s) to synthesize a high-quality HR patch from an LR patch per cluster, and finally store the patch-adaptive 2D FIR filters in a dictionary. Also, we present a smart hierarchical addressing method for effective dictionary exploration in the inference stage. In the inference stage, the ELBP of each input LR patch is extracted in the same way as the learning stage, and the best matched FIR filter(s) to the input LR patch is found from the dictionary by the hierarchical addressing. Finally, we synthesize the HR patch by using the optimal 2D FIR filter. The experimental results show that the proposed algorithm produces better HR images than the existing SR methods, while providing fast running time.",2017,Journal of Visual Communication and Image Representation
XIONG2017268,A two-stage convolutional sparse prior model for image restoration,"Image deblurring, CS-MRI, Fields-of-Experts, Convolutional sparse coding, Multi-view features prior, Alternating direction method of multipliers","Image restoration (IR) from noisy, blurred or/and incomplete observed measurement is one of the important tasks in image processing community. Image prior is of utmost importance for recovering a high quality image. In this paper, we present a two-stage convolutional sparse prior model for efficient image restoration. The multi-view features prior is first obtained by convolving the image with the Fields-of-Experts (FoE) filters and then the resulting multi-view features are represented by convolutional sparse coding (CSC) prior. By taking advantage of the convolutional filters, the proposed two-stage model inherits the strengths of multi-view features and CSC priors. The assembled multi-view features contain high-frequency, redundancy, and large range of feature orientations, which are favor to be represented by CSC and consequently for better image recovery. Augmented Lagrangian and alternating direction method of multipliers are employed to decouple the nonlinear optimization problem in order to iteratively approach the optimum solution. The results of various experiments on image deblurring and compressed sensing magnetic resonance imaging (CS-MRI) reconstruction consistently demonstrate that the proposed algorithm efficiently recovers image and presents advantages over the current leading restoration approaches.",2017,Journal of Visual Communication and Image Representation
JIANG2017356,Internet cross-media retrieval based on deep learning,"Cross-media retrieval, Deep learning, Feature extracting, Multimedia information","With the development of Internet, multimedia information such as image and video is widely used. Therefore, how to find the required multimedia data quickly and accurately in a large number of resources, has become a research focus in the field of information process. In this paper, we propose a real time internet cross-media retrieval method based on deep learning. As an innovation, we have made full improvement in feature extracting and distance detection. After getting a large amount of image feature vectors, we sort the elements in the vector according to their contribution and then eliminate unnecessary features. Experiments show that our method can achieve high precision in image-text cross media retrieval, using less retrieval time. This method has a great application space in the field of cross media retrieval.",2017,Journal of Visual Communication and Image Representation
GUO2017491,Improved marching tetrahedra algorithm based on hierarchical signed distance field and multi-scale depth map fusion for 3D reconstruction,"3D reconstruction, Surface reconstruction, Depth map fusion, Hierarchical signed distance field, Feature matching","3D reconstruction systems are promoted by developments of both computer hardware and computing technologies. They still remain problems like high expense, low efficiency and inaccuracy. Especially for large-scale scenes, lack of full use of multi-scale depth information will cause blurring and irreal reconstruction results. To solve this problem, we construct the structure of hierarchical signed distance field (H-SDF) and design an improved marching tetrahedra algorithm for multi-scale depth map fusion. In addition, to improve efficiency, we also propose a two-phase search strategy in image feature matching: the bag-of-features model (BOF) is adopted in a coarse search to narrow search scope and then the SIFT descriptor is used in exact matching to pick reconstruction image points. Experiment results indicate that coarse search makes matching time shorter; using the H-SDF to fuse multi-scale depth maps, and isosurface extraction with improved marching tetrahedra algorithm can improve visual effect.",2017,Journal of Visual Communication and Image Representation
XIA2017110,Combining multi-layer integration algorithm with background prior and label propagation for saliency detection,"Corner, Objectness, Energy function, Integration algorithm, Multi-layer","In this paper, we propose a novel approach to automatically detect salient regions in an image. Firstly, some corner superpixels serve as the background labels and the saliency of other superpixels are determined by ranking their similarities to the background labels based on ranking algorithm. Subsequently, we further employ an objectness measure to pick out and propagate foreground labels. Furthermore, an integration algorithm is devised to fuse both background-based saliency map and foreground-based saliency map, meanwhile an original energy function is acted as refinement before integration. Finally, results from multiscale saliency maps are integrated to further improve the detection performance. Our experimental results on five benchmark datasets demonstrate the effectiveness of the proposed method. Our method produces more accurate saliency maps with better precision-recall curve, higher F-measure and lower mean absolute error than other 13 state-of-the-arts approaches on ASD, SED, ECSSD, iCoSeg and PASCAL-S datasets.",2017,Journal of Visual Communication and Image Representation
TANG2017254,Rate control for non-uniform video in HEVC,"Rate control, HEVC, R-Q, Bit allocation","Rate control plays an important role in video coding, and most of the existing rate control schemes are based on the assumption that the video contents are uniform. However, for non-uniform video applications, such as screen content videos and movies, previous rate control schemes may cause severe quality degradation, since the bit allocation strategy is improper and the rate-quantization (R-Q) model parameters may extremely inaccurate. In this paper, firstly an adaptive bit allocation algorithm is proposed for the newest video coding standard high efficiency video coding (HEVC), next a key frame detection method is presented, and finally an accurate intra R-Q model, a model parameter adjusting strategy and a bit feedback strategy are developed for the scene change frame. Experimental results show that the proposed rate control method could achieve more accurate bitrates and better rate-distortion (R-D) performance than previous rate control methods.",2017,Journal of Visual Communication and Image Representation
CHEN2017329,Sum-of-gradient based fast intra coding in 3D-HEVC for depth map sequence (SOG-FDIC),"3D-HEVC, MVD, Intra prediction, Low complexity","As the latest video coding standard for multi-view plus depth video, 3D-HEVC yields high coding efficiency but at the cost of heavy computational complexity. To reduce the computational complexity, a fast intra coding algorithm based on sum-of-gradient criterion for depth map coding in 3D-HEVC, named SOG-FDIC, is proposed in this paper. Based on the observation that DMM modes and smaller partitioning sizes are rarely used in flat region, sum of gradient is presented to determine whether the current block belongs to the flat region so as to skip unnecessary checking of DMMs and smaller partitioning sizes. Experimental results show that the proposed algorithm can save about 21.8% coding time while keeping almost the same coding efficiency and the reconstructed video quality of depth maps and synthesized views, compared with the original 3D-HEVC. Moreover, it has been verified that the proposed method outperforms the state-of-the-art methods.",2017,Journal of Visual Communication and Image Representation
WANG201777,Efficient local and global contour detection based on superpixels,"Contour detection, Segmentation, Superpixels, Saliency object segmentation","In this paper, two contour detection methods, inspired from gPb framework, are introduced and applied to saliency object segmentation. To improve the computational efficiency of gPb method, superpixels are introduced into the computational processes of both mPb and sPb. Specifically, for mPb, only the pixels within a given distance from the boundaries of superpixels are considered. For sPb, graph is constructed from superpixels and some selected pixels. Experiments on a public available BSDS500 image dataset show that higher efficiency could be achieved by the proposed local contour detection method, mPbSP, than mPb while with competitive results. Besides, compared with state-of-the-art methods, better results could be produced by the proposed global contour detection method, gPbSP, when a relatively small distance is considered. Moreover, experiments on PASCAL VOC2012 training segmentation dataset show that competitive results of saliency object segmentation could also be produced by the proposed methods with much less time.",2017,Journal of Visual Communication and Image Representation
LIU2017169,Image contrast enhancement based on intensity expansion-compression,"Contrast enhancement, Information content, Expansion-compression","In most image based applications, input images of high information content are required to ensure that satisfactory performances can be obtained from subsequent processes. Manipulating the intensity distribution is one of the popular methods that have been widely employed. However, this conventional procedure often generates undesirable artifacts and causes reductions in the information content. An approach based on expanding and compressing the intensity dynamic range is here proposed. By expanding the intensity according to the polarity of local edges, an intermediate image of continuous intensity spectrum is obtained. Then, by compressing this image to the allowed intensity dynamic range, an increase in information content is ensured. The combination of edge guided expansion with compression also enables the preservation of fine details contained in the input image. Experimental results show that the proposed method outperforms other approaches, which are based on histogram divisions and clippings, in terms of image contrast enhancement.",2017,Journal of Visual Communication and Image Representation
NIE2017375,Multimedia venue semantic modeling based on multimodal data,"Location-based, Multimedia modeling, Graph clustering, Image description","A huge amount of text and multimedia (images and videos) data concerning venues is constantly being generated. To model the semantics of these venues, it is essential to analyze both text and multimedia user-generated content (UGC) in an integral manner. This task, however, is difficult for location-based social networks (LBSNs) because their text and multimedia UGCs tend to be uncorrelated. In this paper, we propose a novel multimedia location topic modeling approach to address this problem. We first utilize Recurrent Convolutional Networks to build the correlation between multimedia UGCs and text. Then, a graph model is structured according to these correlations. Next, we employ a graph clustering method to detect the latent multimedia topics for each venue. Based on the obtained venue semantics, we propose techniques to model multimedia location topics and perform semantic-based location summarization, venue prediction and image description. Extensive experiments are conducted on a cross-platform dataset, and the promising results demonstrate the superiority of the proposed method.",2017,Journal of Visual Communication and Image Representation
JIANG2017419,Combining passive visual cameras and active IMU sensors for persistent pedestrian tracking,"Persistent pedestrian tracking, Visual object tracking, IMU tracking, Dead reckoning","Vision based pedestrian tracking becomes a hard problem when long-term/heavy occlusion happens or pedestrian temporarily moves out of the visual field. In this paper, a novel persistent pedestrian tracking system is presented which combines visual signal from surveillance cameras and sensor signals from Inertial Measurement Unit (IMU) carried by pedestrians themselves. IMU tracking performs Dead Reckoning (DR) approach utilizing accelerometer, gyroscope and magnetometer. IMU tracking has nothing to do with visual occlusion, so it keeps working even when pedestrians are visually occluded. Meanwhile, visual tracking assists in calibrating IMU to avoid the bias drift during DR. The experimental results show that the IMU and visual tracking are complementary to each other and their combination performs robust pedestrian tracking in many challenging scenarios.",2017,Journal of Visual Communication and Image Representation
SU2017480,Hierarchical image resampling detection based on blind deconvolution,"Image forensics, Image resampling detection, Blind deconvolution","Resampling detection is a helpful tool in multimedia forensics; however, it is a challenge task in cases with compression and noisy. In this paper, by modeling the recovery of edited images using an inverse filtering process, we propose a novel resampling detection framework based on blind deconvolution. Different interpolation types in the resampling process can be distinguished by our algorithm, which is significant for practical forensics scenarios. Furthermore, in contrast to traditional resampling detection algorithms, our method can effectively avoid interference caused by JPEG block artifacts. As the experimental results show, our method is more robust than other state-of-the-art approaches in the case of strong JPEG compression and substantial Gaussian noise.",2017,Journal of Visual Communication and Image Representation
TANG2017310,Semi-supervised learning on large-scale geotagged photos for situation recognition,"Evolving situations, Semi-supervised learning, New label discovery, -norm, Capped norm, Outlier elimination","Photos are becoming spontaneous, objective, and universal sources of information. This paper explores evolving situation recognition using photo streams coming from disparate sources combined with the advances of deep learning. Using visual concepts in photos together with space and time information, we formulate the situation detection into a semi-supervised learning framework and propose new graph-based models to solve the problem. To extend the method for unknown situations, we introduce a soft label method that enables the traditional semi-supervised learning framework to accurately predict predefined labels as well as effectively form new clusters. To overcome the noisy data which degrades graph quality, leading to poor recognition results, we take advantage of two kinds of noise-robust norms which can eliminate the adverse effects of outliers in visual concepts and improve the accuracy of situation recognition. Finally, we demonstrate the idea and the effectiveness of the proposed models on Yahoo Flickr Creative Commons 100 Million.",2017,Journal of Visual Communication and Image Representation
LIN2017238,3D saliency detection based on background detection,"3D saliency detection, Background detection, Envisioned background, Polynomial fitting, Salient region","Unlike 2D saliency detection, 3D saliency detection can consider the effects of depth and binocular parallax. In this paper, we propose a 3D saliency detection approach based on background detection via depth information. With the aid of the synergism between a color image and the corresponding depth map, our approach can detect the distant background and surfaces with gradual changes in depth. We then use the detected background to predict the potential characteristics of the background regions that are occluded by foreground objects through polynomial fitting; this step imitates the human imagination/envisioning process. Finally, a saliency map is obtained based on the contrast between the foreground objects and the potential background. We compare our approach with 14 state-of-the-art saliency detection methods on three publicly available databases. The proposed model demonstrates good performance and succeeds in detecting and removing backgrounds and surfaces of gradually varying depth on all tested databases.",2017,Journal of Visual Communication and Image Representation
ZENG2017386,Multimedia annotation via semi-supervised shared-subspace feature selection,"Semi-supervised learning, Feature selection, Multi-label learning, Web page annotation, Image annotation","With the rapid development of social network and computer technologies, we always confront with high-dimensional multimedia data. It is time-consuming and unrealistic to organize such a large amount of data. Most existing methods are not appropriate for large-scale data due to their dependence of Laplacian matrix on training data. Normally, a given multimedia sample is usually associated with multiple labels, which are inherently correlated to each other. Although traditional methods could solve this problem by translating it into several single-label problems, they ignore the correlation among different labels. In this paper, we propose a novel semi-supervised feature selection method and apply it to the multimedia annotation. Both labeled and unlabeled samples are sufficiently utilized without the need of graph construction, and the shared information between multiple labels is simultaneously uncovered. We apply the proposed algorithm to both web page and image annotation. Experimental results demonstrate the effectiveness of our method.",2017,Journal of Visual Communication and Image Representation
DAI2017340,A generic denoising framework via guided principal component analysis,"Image denoising, Principal component analysis, Back projection","Though existing state-of-the-art denoising algorithms, such as BM3D, LPG-PCA and DDF, obtain remarkable results, these methods are not good at preserving details at high noise levels, sometimes even introducing non-existent artifacts. To improve the performance of these denoising methods at high noise levels, a generic denoising framework is proposed in this paper, which is based on guided principle component analysis (GPCA). The propose framework can be split into two stages. First, we use statistic test to generate an initial denoised image through back projection, where the statistical test can detect the significantly relevant information between the denoised image and the corresponding residual image. Second, similar image patches are collected to form different patch groups, and local basis are learned from each patch group by principle component analysis. Experimental results on natural images, contaminated with Gaussian and non-Gaussian noise, verify the effectiveness of the proposed framework.",2017,Journal of Visual Communication and Image Representation
CUI2017367,Hybrid textual-visual relevance learning for content-based image retrieval,"Content-based image retrieval, Tag completion, Semantics modeling, Rank aggregation, Sparse linear method","Learning effective relevance measures plays a crucial role in improving the performance of content-based image retrieval (CBIR) systems. Despite extensive research efforts for decades, how to discover and incorporate semantic information of images still poses a formidable challenge to real-world CBIR systems. In this paper, we propose a novel hybrid textual-visual relevance learning method, which mines textual relevance from image tags and combines textual relevance and visual relevance for CBIR. To alleviate the sparsity and unreliability of tags, we first perform tag completion to fill the missing tags as well as correct noisy tags of images. Then, we capture users’ semantic cognition to images by representing each image as a probability distribution over the permutations of tags. Finally, instead of early fusion, a ranking aggregation strategy is adopted to sew up textual relevance and visual relevance seamlessly. Extensive experiments on two benchmark datasets well verified the promise of our approach.",2017,Journal of Visual Communication and Image Representation
KALILOU201743,Non-texture image inpainting using histogram of oriented gradients,"Image inpainting, Histogram of oriented gradients, Dominant orientation, Local gradients","This paper presents a novel and efficient algorithm for non-texture inpainting of images based on using the dominant orientation of local gradients. It first introduces the concept of a new matrix called orientation matrix and then uses it for faster and better inpainting. The process of propagating information is carried out by using a new formulation which leads to much more efficient computations than the previous methods. The gain is both in terms of computational complexity and visual quality. The promising results in contexts of text, scratch, and block loss inpainting demonstrate the effectiveness of the proposed method.",2017,Journal of Visual Communication and Image Representation
FERRARA2017159,Wide-angle and long-range real time pose estimation: A comparison between monocular and stereo vision systems,"Vision systems, Visual tracking, Target detection, Monocular vision system, Stereo vision systems, Pose estimation","In this work, a comparison of the performances of a stereo and a monocular vision system for the 3D pose estimation of a planar target in very challenging conditions is presented. In particular, the systems have been designed to detect in real time a target moving with a maximum speed of 1m/s, in a range of distances from 0.5 to 4m from the cameras, with an accuracy of less than 1cm (referred to the estimation of the real world coordinates) and with a field of view of 80deg. A theoretical evaluation and experimental results to assess the performance of the proposed systems are presented. Our analysis demonstrates the good accuracy in terms of target position estimation of the presented approaches not only for close range applications, but also for mid-to-long range ones.",2017,Journal of Visual Communication and Image Representation
WEI2017292,Contour segment grouping for object detection,"Shape-based object detection, Contour grouping, Depth-first search","In this paper, we propose a novel framework for object detection and recognition in cluttered images, given a single hand-drawn example as model. Compared with previous work, our contribution is threefold. (1) Three preprocessing procedures are proposed to reduce the number of irrelevant edge fragments that are often generated during edge detection in cluttered real images. (2) A novel shape descriptor is introduced for conducting partial matching between edge fragments and model contours. (3) An efficient search strategy is adopted to identify the location of target object hypotheses. In the hypotheses verification stage, an appearance-based (support vector machine on pyramid histogram of oriented gradients feature) method is adopted to verify the hypothesis, identify the object, and refine its location. We do extensive experiments on several benchmark datasets including ETHZ shape classes, INRIA horses, Weizmann horses, and the two classes (anchors and cups) from Caltech 101. Experimental results show that the proposed method can significantly improve the accuracy of object detection. Comparisons with other recent shape-based methods further demonstrate the effectiveness and robustness of the proposed method.",2017,Journal of Visual Communication and Image Representation
CZUNI201730,The use of IMUs for video object retrieval in lightweight devices,"Video object retrieval, View-centered retrieval, IMU, Camera sensor, Image recognition, Tracking, KD-Tree indexing","We introduce a new object retrieval approach where besides cameras, Inertial Measurement Unit (IMU) sensors are used for the retrieval of 3D objects. Contrary to computationally intensive deep learning recognition and retrieval solutions we focus on lightweight methods which could be utilized in handheld devices and autonomous systems equipped with moderate computing power and memory. We use fast and robust compact image descriptors and the relative orientation of the camera to build multi-view-centered retrieval object models. As for retrieval the Hough transformation paradigm is used to evaluate the results of queries applied on several frames of a video. We analyze the performance of our lightweight approach on several test datasets and with different comparisons, including automatic tracking for the generation of queries. These experiments show the advantages of our proposed techniques since retrieval rate could be significantly increased.",2017,Journal of Visual Communication and Image Representation
HAO2017453,Multi-view representation learning for multi-view action recognition,"Multi-view learning, Multi-task learning, Sparse coding, Action recognition","Although multiple methods have been proposed for human action recognition, the existing multi-view approaches cannot well discover meaningful relationship among multiple action categories from different views. To handle this problem, this paper proposes an multi-view learning approach for multi-view action recognition. First, the proposed method leverages the popular visual representation method, bag-of-visual-words (BoVW)/fisher vector (FV), to represent individual videos in each view. Second, the sparse coding algorithm is utilized to transfer the low-level features of various views into the discriminative and high-level semantics space. Third, we employ the multi-task learning (MTL) approach for joint action modeling and discovery of latent relationship among different action categories. The extensive experimental results on M2I and IXMAS datasets have demonstrated the effectiveness of our proposed approach. Moreover, the experiments further demonstrate that the discovered latent relationship can benefit multi-view model learning to augment the performance of action recognition.",2017,Journal of Visual Communication and Image Representation
JUNG2017195,Perceptual stereoscopic video coding using disparity just-noticeable-distortion model,"3DTV, Disparity estimation, Human visual system (HVS), Just-noticeable-distortion (JND), Perceptual redundancy, Stereo video coding","In this paper, we propose perceptual stereoscopic video coding using a disparity just-noticeable-distortion (JND) model. We obtain the disparity JND model in stereo videos by disparity masking effects of the human visual system (HVS). The disparity JND model represents the maximum distortion of stereo perception that HVS cannot perceive. Based on the disparity JND model, we adjust prediction residuals to remove the perceptual redundancy of stereo videos. Thus, we achieve significant bit-rate saving while maintaining visual quality. Experimental results demonstrate that the proposed method significantly improves coding efficiency without loss of stereoscopic perceptual quality.",2017,Journal of Visual Communication and Image Representation
SANGNOREE201788,Thermal-image processing and statistical analysis for vehicle category in nighttime traffic,"Thermal imaging, Vehicle category, Nighttime traffic, Traffic monitoring, ITS","The automatic tollgate at highway entrance and exit needs to categorize vehicle in order to collect highway passing fee especially at night time. This paper proposes a method of vehicle categorization in nighttime traffic using thermal-image processing and statistical analysis. To recognize the vehicular types, statistical relation between thermal features of engine heat, windscreen and others are utilized in this method. Firstly, appropriate threshold values for classifying the thermal features are automatically determined, entire area of the thermal image is then divided into blocks, and thermal features classified in all blocks by the threshold values are finally integrated for vehicle type categorization. To evaluate the performance of proposed method, experiments with 2937 samples of cars, vans and trucks are categorized, and the results approximately reveal 95.51% accuracy.",2017,Journal of Visual Communication and Image Representation
LIN2017136,Boundary points based scale invariant 3D point feature,"3D point clouds, Boundary points, Scale space, Scale invariant, 3D point feature","In this paper, we propose a method for encoding scale invariant 3D point features. We extract a set of boundary points from a point cloud. Next, we apply the scale-space concept on the boundary points to detect the scale invariant point border. We confirm three orthometric axes as the local reference frames. Three distribution matrices are generated by implementing the strategy of SPIN image method, and one-row-vector of descriptors are finally calculated. Experimental results on simulated and real scene point clouds demonstrate that the scale-invariant features of 3D point clouds can be effectively encoded by our method.",2017,Journal of Visual Communication and Image Representation
LIU2017502,Online multi-objective optimization for live video forwarding across video data centers,"Big video data, Video data center, Live video forwarding, Resource provisioning optimization","The proliferation of video surveillance has led to surveillance video forwarding services becoming a basic server in video data centers. End users in diverse locations require live video streams from the IP cameras through the inter-connected video data centers. Consequently, the resource scheduler, which is set up to assign the resources of the video data centers to each arriving end user, is in urgent need of achieving the global optimal resource cost and forwarding delay. In this paper, we propose a multi-objective resource provisioning (MORP) approach to minimize the resource provisioning cost during live video forwarding. Different from existed works, the MORP optimizes the resource provisioning cost from both the resource cost and forwarding delay. Moreover, as an approximate optimal approach, MORP adaptively assigns the proper media servers among video data centers, and connects these media servers together through network connections to provide system scalability and connectivity. Finally, we prove that the computational complexity of our online approach is only O(log(|U|)) (|U| is the number of arrival end users). The comprehensive evaluations show that our approach not only significantly reduces the resource provisioning cost, but also has a considerably shorter computational delay compared to the benchmark approaches.",2017,Journal of Visual Communication and Image Representation
JIN201754,Complex impulse noise removal from color images based on super pixel segmentation,"Color image, Blob noise, Super pixel segmentation, Quaternion","Impulse noise sometimes appears as blob or granular shapes in images, which are irregularly shaped with typically several pixels wide in different directions. Most existing methods are developed to remove only single-point impulse noise and usually perform poor when applied to blob noise removal. This paper presents a new method to suppress such complex blob noise with varying sizes and irregular shapes in color images. First, a noisy image is segmented into super pixels by mean shift filtering followed by a clustering operation based on quaternion color distance. Then, by analyzing the characteristics of super pixels, image pixels are classified into noise-free, blob-noisy, and single-point impulse ones. Finally, a selected recursive vector median filter with adaptive window sizes is employed on the noisy pixels detected. The experimental results exhibit the validity of the proposed solution by showing excellent denoising effect and performance, compared to other color image denoising methods.",2017,Journal of Visual Communication and Image Representation
YANG2017396,Representative band selection for hyperspectral image classification,"High dimensional image, Band selection, Pattern recognition, Feature selection, Disjoint information","High dimensional curse for hyperspectral images is one major challenge in image classification. In this work, we introduce a novel spectral band selection method by representative band mining. In the proposed method, the distance between two spectral bands is measured by using disjoint information. For band selection, all spectral bands are first grouped into clusters, and representative bands are selected from these clusters. Different from existing clustering-based band selection methods which select bands from each cluster individually, the proposed method aims to select representative bands simultaneously by exploring the relationship among all band clusters. The optimal representative band selection is based on the criteria of minimizing the distance inside each cluster and maximizing the distance among different representative bands. These selected bands can be further applied in hyperspectral image classification. Experiments are conducted on the 92AV3C Indian Pine data set. Experimental results show that the disjoint information-based spectral band distance measure is effective and the proposed representative band selection approach outperforms state-of-the-art methods for high dimensional image classification.",2017,Journal of Visual Communication and Image Representation
WENG2017317,Optimal PPVO-based reversible data hiding,"Reversible data hiding, Adaptive prediction pattern, Adaptive pixel-modification strategy, Two-stage embedding, PPVO","The optimal PPVO-based reversible data hiding (RDH) including adaptive prediction pattern and optimal bin selection is proposed in this paper. By reasonably designing the prediction pattern, each to-be-embedded pixel can be predicted by the n(n∈{4,…,13}) neighbors surrounding it. The larger n, the more accurate the prediction, and the higher embedding performance is achieved at low embedding capacity (EC) and vice versa. Since the neighbors surrounding each to-be-embedded pixel can be used for measuring the local complexity, the smoothness classification is more accurate, and furthermore, the prediction performance is increased. Two-stage embedding is exploited in this paper so as to ensure the implementation of full-enclosed-based prediction. Instead of treating separately two stages like in existing methods, two stages are treated jointly to optimize the selection of embedding bins at a given EC. In this way, the optimal embedding bins which can achieve as high visual quality as possible is obtained. Extensive experiments verify the proposed method is effective.",2017,Journal of Visual Communication and Image Representation
ZHANG2017471,Identifying source camera using guided image estimation and block weighted average,"Source camera identification, Guided image filtering, Block weighted average, Sensor pattern noise","Sensor pattern noise (SPN) has been widely used in source camera identification. However, the SPN extracted from natural image may be contaminated by its content and eventually introduce side effect to the identification accuracy. In this paper, an effective source camera identification scheme based on guided image estimation and block weighted average is proposed. Before the SPN extraction, an adaptive SPN estimator based on image content is implemented to reduce the influence of image scene and improve the quality of the SPN. Furthermore, a novel camera reference SPN construction method is put forward by using some ordinary images, instead of the blue sky images in the previous schemes, and a block weighted average approach is used to suppress the influence of the image scenes in the reference SPN. Experimental results and analysis indicate that the proposed method can effectively identify the source of the natural image, especially in actual forensics environment with a small number of images.",2017,Journal of Visual Communication and Image Representation
MENG2017404,Contextual aerial image categorization using codebook,"Aerial image, Contextual modeling, Efficient algorithm, Codebook","Effective categorization of the millions of aerial images from unmanned planes is a useful technique with several important applications. Previous methods on this task usually encountered such problems: (1) it is hard to represent the aerial images’ topologies efficiently, which are the key feature to distinguish the arial images rather than conventional appearance, and (2) the computational load is usually too high to build a realtime image categorization system. Addressing these problems, this paper proposes an efficient and effective aerial image categorization method based on a contextual topological codebook. The codebook of aerial images is learned with a multitask learning framework. The topology of each aerial image is represented with the region adjacency graph (RAG). Furthermore, a codebook containing topologies is learned by jointly modeling the contextual information, based on the extracted discriminative graphlets. These graphlets are integrated into a Bag-of-Words (BoW) representation for predicting aerial image categories. Contextual relation among local patches are taken into account in categorization to yield high categorization performance. Experimental results show that our approach is both effective and efficient.",2017,Journal of Visual Communication and Image Representation
WU2017461,Bilinear dynamics for crowd video analysis,"Bilinear dynamics, Curl and divergence, Motion representation, Crowd scene classification, Video retrieval","In this paper, a novel crowd descriptor, termed as bilinear CD (Curl and Divergence) descriptor, is proposed based on the bilinear interaction of curl and divergence. Specifically, the curl and divergence activation maps are computed from the normalized average flow. A local curl patch and the corresponding divergence patch are cropped respectively from the activation maps. The outer product of the two local patches is defined as the bilinear CD vector. Through sliding a window on the activation maps, we can get hundreds to thousands local bilinear CD vectors. To encode them into a compact representation, fisher vector pooling and PCA algorithms are applied on the local descriptors. Experiments on the CUHK crowd dataset show that the proposed bilinear dynamics can improve the performance of video classification and retrieval by a noticeable margin when compared with the existing crowd features.",2017,Journal of Visual Communication and Image Representation
LU2017205,Improved macroblock level rate control for the spatially scalable extension of H.264/AVC,"Interlayer prediction, MAD prediction, Rate control, Scalable video coding","An improved rate control algorithm, designed for scalable video coders incorporating interlayer prediction, is proposed. Firstly, a Rate Distortion (RD) model for interlayer prediction involving the spatial enhancement layers is devised. An optimised Mean Absolute Difference (MAD) prediction model for the spatial enhancement layers that considers both the MAD from the spatial base layer in the same frame and the MAD from the corresponding macroblock in previous frames is also proposed. Simulation results show that the resulting algorithm produces accurate rate control with an average bit rate error of less than 0.26%. Compared with the JVT-W043 default rate control algorithm of the JSVM, the proposed algorithm improves the average PSNR by up to 0.53dB or reduces the bit rate by an average of 10.95%. Furthermore, the proposed algorithm can be combined with the existing rate control scheme for H.264/AVC, resulting in further improvements.",2017,Journal of Visual Communication and Image Representation
ZHANG2017281,Detecting image seam carving with low scaling ratio using multi-scale spatial and spectral entropies,"Image forensics, Content-aware image retargeting, Seam carving, Low scaling ratios, Spatial and frequency entropy, Object removal","Seam carving is the most popular content-aware image retargeting technique. However, it may also be used to correct poor photo composition in photography competition or to remove object from image for malicious purpose. A blind detection approach is presented for seam carved image with low scaling ratio (LSR). It exploits spatial and spectral entropies (SSE) on multi-scale images (candidate image and its down-sampled versions). We observe that when a few seams are deleted from an original image, its SSE distribution is greatly changed. Forty-two features are designed to unveil the statistical properties of SSE in terms of centralized tendency, dispersion tendency and distribution tendency. They are combined with the local binary pattern (LBP)-based energy features to form ninety-six features. Finally, support vector machine (SVM) is exploited as classifier to determine whether an image is original or suffered from seam carving. Experimental results show that the proposed approach achieves superior detection accuracy over the state-of-the-art works, especially for resized image by seam carving with LSRs. Moreover, it is robust against JPEG compression and seam insertion.",2017,Journal of Visual Communication and Image Representation
ZHAN2017411,Graph-regularized concept factorization for multi-view document clustering,"Multi-view learning, Concept factorization, Document clustering, Manifold learning","We propose a novel multi-view document clustering method with the graph-regularized concept factorization (MVCF). MVCF makes full use of multi-view features for more comprehensive understanding of the data and learns weights for each view adaptively. It also preserves the local geometrical structure of the manifolds for multi-view clustering. We have derived an efficient optimization algorithm to solve the objective function of MVCF and proven its convergence by utilizing the auxiliary function method. Experiments carried out on three benchmark datasets have demonstrated the effectiveness of MVCF in comparison to several state-of-the-art approaches in terms of accuracy, normalized mutual information and purity.",2017,Journal of Visual Communication and Image Representation
WANG2017432,High-level background prior based salient object detection,"Salient object detection, Background prior, Superpixel, Objectness","Salient object detection is a fundamental problem in computer vision. Existing methods using only low-level features failed to uniformly highlight the salient object regions. In order to combine high-level saliency priors and low-level appearance cues, we propose a novel Background Prior based Salient detection method (BPS) for high-quality salient object detection. Different from other background prior based methods, a background estimation is added before performing saliency detection. We utilize the distribution of bounding boxes generated by a generic object proposal method to obtain background information. Three background priors are mainly considered to model the saliency, namely background connectivity prior, background contrast prior and spatial distribution prior, allowing the proposed method to highlight the salient object as a whole and suppress background clutters. Experiments conducted on two benchmark datasets validate that our method outperforms 11 state-of-the-art methods, while being more efficient than most leading methods.",2017,Journal of Visual Communication and Image Representation
GAO2017442,Collaborative sparse representation leaning model for RGBD action recognition,"RGBD action recognition, Collaborative sparse representation leaning model, Dense trajectory, Multi-modality, Depth feature","Multi-modalities action recognition becomes a hot research topic, and this paper proposes a collaborative sparse representation leaning model for RGB-D action recognition where RGB and depth information are adaptive fused. Specifically, dense trajectory feature is firstly extracted and Bag-of-Word (BoW) weight scheme is employed for RGB modality, and then for depth modality, the human pose representation model (HPM) and temporal modeling (TM) representation are utilized. Meanwhile, the collaborative reconstruction structure and corresponding objective functions for the multiple modalities are designed, and then the proposed model is collaboratively optimized which is used to discover the latent complementary information between RGB and depth data. Finally, the collaborative reconstruction error is employed as our classification scheme. Large scale experimental results on challenging and public DHA, M2I and Northwestern-UCLA action datasets show that the performances of our model on two modalities are much better than traditional sole modality, which can boost the performance of human action recognition by taking advance of complementary characteristics from both RGB and depth modalities.",2017,Journal of Visual Communication and Image Representation
YANG2017182,"Constructions of general (k,n) reversible AMBTC-based visual cryptography with two decryption options","Visual cryptography, Block truncation coding, Reversible, Meaningful shadows, OR decryption, XOR decryption","In this paper, a general method of (k,n) threshold Reversible Absolute moment block truncation coding Visual Cryptography Scheme (RAVCS) is introduced for sharing a binary secret image into multiple absolute moment block truncation coding (AMBTC) shadows. A (k,k) RAVCS is firstly proposed to encode a secret by referencing one ABMTC image. Then, the proposed (k,k) RAVCS is adopted to share the same secret into multiple groups of shadows by referencing multiple images. Those multiple groups of shadows are distributed to participants according to a matrix generated by the proposed shadow distribution algorithms. When any k or more participants share their shadows, the secret image is revealed by OR or XOR decryption. Further, those AMBTC shadows can be losslessly reverted to their original forms. Sufficient theoretical analysis and extensive experimental results are provided in this paper, showing the effectiveness and advantages of the proposed method.",2017,Journal of Visual Communication and Image Representation
PARK2017122,A 3D-DCT video encoder using advanced coding techniques for low power mobile device,"3D-DCT, Bit-plane coding, Video compression for low power","The three-dimensional discrete cosine transform (3D-DCT) has been researched as an alternative to existing dominant video standards based on motion estimation and compensation. Since it does not need to search macro block for inter/intra prediction, 3D-DCT has great advantages for complexity. However, it has not been developed well because of poor video quality while video standards such as H.263(+) and HEVC have been blooming. In this paper, we propose a new 3D-DCT video coding as a new video solution for low power mobile technologies such as Internet of Things (IoT) and Drone. We focus on overcoming drawbacks reported in previous research. We build a complete 3D-DCT video coding system by adopting existing advanced techniques and devising new coding algorithms to improve overall performance of 3D-DCT. Experimental results show proposed 3D-DCT outperforms H.264 low power profiles while offering less complexity. From GBD-PSNR, proposed 3D-DCT provides better performance by average 4.6dB.",2017,Journal of Visual Communication and Image Representation
HE2017149,Frame-wise detection of relocated I-frames in double compressed H.264 videos based on convolutional neural network,"Double compression detection, Data-driven methodology, Convolutional neural network, Video forensics","Relocated I-frames are a key type of abnormal inter-coded frame in double compressed videos with shifted GOP structures. In this work, a frame-wise detection method of relocated I-frame is proposed based on convolutional neural network (CNN). The proposed detection framework contains a novel network architecture, which initializes with a preprocessing layer and is followed by a well-designed CNN. In the preprocessing layer, the high-frequency component extraction operation is applied to eliminate the influence of diverse video contents. To mitigate overfitting, several advanced structures, such as 1×1 convolutional filter and the global average-pooling layer, are carefully introduced in the design of the CNN architecture. Public available YUV sequences are collected to construct a dataset of double compressed videos with different coding parameters. According to the experiments, the proposed framework can achieve a more promising performance of relocated I-frame detection than a well-known CNN structure (AlexNet) and the method based on average prediction residual.",2017,Journal of Visual Communication and Image Representation
YAN2017224,Salient object detection via boosting object-level distinctiveness and saliency refinement,"Saliency, Salient object detection, Object-level distinctiveness, Boosting algorithm, Saliency refinement","Many salient object detection approaches share the common drawback that they cannot uniformly highlight heterogeneous regions of salient objects, and thus, parts of the salient objects are not discriminated from background regions in a saliency map. In this paper, we focus on this drawback and accordingly propose a novel algorithm that more uniformly highlights the entire salient object as compared to many approaches. Our method consists of two stages: boosting the object-level distinctiveness and saliency refinement. In the first stage, a coarse object-level saliency map is generated based on boosting the distinctiveness of the object proposals in the test images, using a set of object-level features and the Modest AdaBoost algorithm. In the second stage, several saliency refinement steps are executed to obtain a final saliency map in which the boundaries of salient objects are preserved. Quantitative and qualitative comparisons with state-of-the-art approaches demonstrate the superior performance of our approach.",2017,Journal of Visual Communication and Image Representation
KUNCHEVA2018118,Edited nearest neighbour for selecting keyframe summaries of egocentric videos,"Keyframe summary, Nearest neighbour classifier, Instance selection, Egocentric video, Feature representations","A keyframe summary of a video must be concise, comprehensive and diverse. Current video summarisation methods may not be able to enforce diversity of the summary if the events have highly similar visual content, as is the case of egocentric videos. We cast the problem of selecting a keyframe summary as a problem of prototype (instance) selection for the nearest neighbour classifier (1-nn). Assuming that the video is already segmented into events of interest (classes), and represented as a dataset in some feature space, we propose a Greedy Tabu Selector algorithm (GTS) which picks one frame to represent each class. An experiment with the UT (Egocentric) video database and seven feature representations illustrates the proposed keyframe summarisation method. GTS leads to improved match to the user ground truth compared to the closest-to-centroid baseline summarisation method. Best results were obtained with feature spaces obtained from a convolutional neural network (CNN).",2018,Journal of Visual Communication and Image Representation
LIU2018159,Image restoration via Bayesian dictionary learning with nonlocal structured beta process,"Nonparametric Bayesian, Beta process, Image restoration, Nonlocal structure prior, Dictionary learning","Nonparametric Bayesian dictionary learning has shown a powerful potential in image restoration. However, it still lacks exploiting image structure to improve the performance. In this work, we propose a sparse Bayesian dictionary learning framework with structure prior called nonlocal structured beta process factor analysis (NLS-BPFA) which connects nonlocal self-similarity and sparse Bayesian dictionary learning. A nonlocal structured beta process is proposed to introduce the nonlocal self-similarity as a structure prior for image denoising and inpainting. Unlike most of the existing image denoising methods, our proposed method does not need to know noise variance in advance like an unsupervised learning. The experimental results demonstrate the effectiveness of our proposed model.",2018,Journal of Visual Communication and Image Representation
FURNARI20181,Personal-location-based temporal segmentation of egocentric videos for lifelogging applications,"Egocentric Vision, Lifelogging, Personal locations, Temporal segmentation","Temporal video segmentation is useful to exploit and organize long egocentric videos. Previous work has focused on general purpose methods designed to deal with data acquired by different users. In contrast, egocentric video tends to be very personal and meaningful for the specific user who acquires it. We propose a method to segment egocentric video according to the personal locations visited by the user. The method aims at providing a personalized output and allows the user to specify which locations he wants to keep track of. To account for negative locations (i.e., locations not specified by the user), we propose a negative rejection method which does not require any negative sample at training time. For the experiments, we collected a dataset of egocentric videos in 10 different personal locations, plus various negative ones. Results show that the method is accurate and compares favorably with the state of the art.",2018,Journal of Visual Communication and Image Representation
QU2018151,Fusion of hyperspectral and panchromatic images using an average filter and a guided filter,"Hyperspectral (HS) image, Panchromatic (PAN) image, Guided filter, Average filter, Component substitution (CS)","The fusion of hyperspectral and panchromatic images aims to generate a fused image with high spatial and high spectral resolutions. This paper proposes a novel hyperspectral pansharpening method using an average filter and a guided filter. Based on the traditional component substitution methods, we propose a new and simple method to extract the spatial information of the HS image by average filtering at first. Then to solve the significant spectral distortion, a guided filter is utilized to obtain more detailed spatial information from the PAN image which has been sharpened. The appropriate injection gains matrix is generated by selecting the optimal value of the tradeoff coefficient. The spatial detail is finally injected into each band of the interpolated HS image to achieve the fused image. Experimental results demonstrate that the proposed method can obtain more spatial information and preserve more spectral information in both subjective and objective evaluations.",2018,Journal of Visual Communication and Image Representation
GABARDA2018101,Anisotropic blind image quality assessment: Survey and analysis with current methods,"Image quality assessment, Pseudo-Wigner distribution, Rényi entropy, Anisotropy, Correlation, Mean opinion scores","The Anisotropic Quality Index (AQI) was previously introduced by the authors as a non-distortion-specific, no-reference image quality measure. AQI is based on measuring the variance of the expected entropy of a given image over a predefined set of orientations. In this paper, a statistical evaluation of AQI is provided using standard benchmarking parameters showing good match with observer’s response. Some AQI extensions are proposed for tackling ill-posed noise types that provide fair or poor performance. A comparison with other no-reference methods has been included showing good competitiveness with many of them.",2018,Journal of Visual Communication and Image Representation
UNDE201892,Fast BCS-FOCUSS and DBCS-FOCUSS with augmented Lagrangian and minimum residual methods,"Block compressive sensing, BCS-FOCUSS, DBCS-FOCUSS, BCS-augmented Lagrangian method, Minimum residual method","Block compressive sensing FOCal Underdetermined System Solver (BCS-FOCUSS) and distributed BCS-FOCUSS (DBCS-FOCUSS) are iterative algorithms for individual and joint recovery of correlated images. The performance of both these algorithms was noticed to be best within BCS framework. However, both these algorithms suffer from high computational complexity and recovery time. This is caused by the need for an explicit computation of matrix inverse in each iteration and a slow convergence from a poor starting point. In this paper, we propose a methodology to obtain fast and good initial solution using the augmented Lagrangian method to improve the convergence rate of both algorithms. We also propose to incorporate the minimum residual method to avoid matrix inversion to reduce the computational cost. Simulation studies with the proposed modified BCS-FOCUSS and DBCS-FOCUSS demonstrate a significant reduction in the computational cost and recovery time while improving reconstruction quality for both individual and joint reconstruction algorithms.",2018,Journal of Visual Communication and Image Representation
ZHANG2018131,Saliency detection via local structure propagation,"Saliency detection, Coarse-to-fine, Local structure propagation, Color distribution map, Global and local information, Multi-prior","Saliency detection is a popular topic in computer vision, especially propagation-based method. This paper proposes a novel and effective coarse-to-fine saliency detection framework. In the coarse map stage, color spatial distribution map based on hue cue and central compactness rule is proposed, and integrated with texture boundary contrast information and background information to construct multi-prior coarse saliency map. In the refining stage, saliency values are updated under the comprehensive guidance of local structure propagation which is a novel algorithm to preserve local structural integrity during saliency propagation. With the global and local information, the detection procedure enhances the correctness of salient object gradually. Demonstrated in the extensive experiments on the public benchmark datasets, the performance of the proposed framework is superior to the state-of-the-art methods.",2018,Journal of Visual Communication and Image Representation
ZHANG201813,Physical blob detector and Multi-Channel Color Shape Descriptor for human detection,"Human detection, RGB-D camera, Physical blob detector, Multi-Channel Color Shape Descriptor","Human detection is a very important research problem due to its relevance to a wide range of applications. This paper proposes a new method for human detection in RGB-D images. Based on the observation that human head often forms a distinguishable blob-like region in depth image and its physical size and height are in well-known ranges, we propose a physical blob detector to efficiently locate candidate human regions. Since color information and 3D physical structure information are both important cues for characterizing human upper body, we propose to incorporate these two sources of information and construct a novel Multi-Channel Color Shape Descriptor (MCSD) to further verify the candidate regions. The experimental results on four publicly available datasets consistently show that the proposed method can reliably detect humans in RGB-D video in real time.",2018,Journal of Visual Communication and Image Representation
ZHANG201845,Multiple-target tracking on mixed images with reflections and occlusions,"Multi-target tracking, Reflections, Occlusions, Multi-cue integration, Data association","Measurements arose from strong reflections combined with occlusions significantly degrade accuracy of multi-target tracking. Few methods have addressed this problem, and thus this paper proposes a robust multi-target tracker for mixed images with occlusions. For multi-cue integration using co-inference tracking, moving object detection significantly enhances motion cue based correction in the presence of reflections. Target templates are represented by sets of color and spatiality histograms. Joint likelihoods referring to both the target motion trajectory and appearance model of the co-inference fused state are computed. Thus each optimized particle weight with the criteria of maximum joint likelihood is more reliable in the face of reflections and inter-object occlusions. State estimation is achieved with the sample-based data association probability and occlusion confidence indicator. Experimental results show that the proposed tracker outperforms the-state-of-the-art multi-target trackers on images with strong reflections and inter-object occlusions.",2018,Journal of Visual Communication and Image Representation
CHIANG201833,Generation of Chinese ink portraits by blending face photographs with Chinese ink paintings,"Active shape model, Chinese portrait, Facial feature extraction, Non-photorealistic rendering","In this study, an interactive Chinese portrait rendering system was developed. This portrait rendering system can generate a user-lookalike ink portrait by blending the user’s face with a selected Chinese ink painting. It first automatically analyzes the user’s facial features and then integrates them into a selected Chinese painting. This system comprises two processes: an offline process and an online process. During the offline process, a collection of Chinese portrait paintings is configured (e.g., the face masks and facial coordinates of the paintings are determined). Subsequently, blending-ready templates (faces without facial features) are prepared for the online process. During the online process, the user integrates their photograph into our rendering system. The system automatically analyzes the face orientation, color, and facial features and adjusts the attributes of the photograph to match the template’s configuration. The produced facial image is blended into a selected template, which preserves the textures of the original Chinese painting. The results reveal that our system preserved both the user characteristics and original painting styles. In this study, user-portrait matching was experimentally evaluated, and a questionnaire survey on satisfaction with painting style was conducted.",2018,Journal of Visual Communication and Image Representation
CEDILLOHERNANDEZ2018106,A spatiotemporal saliency-modulated JND profile applied to video watermarking,"Video watermarking, Visual attention, Saliency regions, Just-Noticeable-Distortion (JND)","The just noticeable distortion (JND) has been considered a suitable solution for controlling the watermark strength and generating robust watermarking schemes with distortions that are below the sensitivity threshold. However, JND assumes the same attention level for all image regions, which does not reflect the behavior of an observer. Recently, several models have utilized the modulatory effect of visual attention over JND to improve the efficiency of watermarking schemes. However, most of them have focused on still images. In this paper, we propose a saliency-modulated JND profile for improving video watermarking schemes. Our method aims to adapt the watermark strength to obtain the most robust possible scheme with an imperceptible watermark. Moreover, it has the advantage of fully exploiting the spatiotemporal properties of video to minimize its perceptual redundancies and achieve low computational complexity. Experimental results show the effectiveness of our proposed method and its contributions to video watermarking process.",2018,Journal of Visual Communication and Image Representation
VENKATA201824,Eliminating the effects of illumination condition in feature based camera model identification,"Camera model identification, Classification, Digital forensics, Image features, Illumination dependency, Overfitting, Scene content","State-of-the-art techniques for Camera Model Identification operate by extracting different features from the training image set and incorporating those features to predict the source of test images using machine learning. Though the existing approaches perform efficiently for images captured in natural daylight or bright illumination conditions, the state-of-the-art lacks sufficient experiments and results to evaluate efficiency of such schemes for images captured in dark illumination conditions. In this paper, we present a set of experiments to assess the impact of illumination conditions, on image source classification problem, and also propose an image filtering based technique to eliminate the adverse effects of scene illumination on source classification accuracy. Our experimental results prove that the performance efficiency of existing feature based source classification techniques, is indeed dependent on the illumination conditions. The proposed strategy enables our source classification model to achieve high efficiency as compared to the state-of-the-art, under all illumination conditions.",2018,Journal of Visual Communication and Image Representation
JING201858,Video you only look once: Overall temporal convolutions for action recognition,"Video understanding, Video classification, Action recognition, Convolutional neural network","In this paper, we propose an efficient and straightforward approach, video you only look once (VideoYOLO), to capture the overall temporal dynamics from an entire video in a single process for action recognition. It remains an open question for action recognition on how to deal with the temporal dimension in videos. Existing methods subdivide a whole video into either individual frames or short clips and consequently have to process these fractions multiple times. A post process is then used to aggregate the partial dynamic cues to implicitly infer the whole temporal information. On the contrary, in VideoYOLO, we first generate a proxy video by selecting a subset of frames to roughly reserve the overall temporal dynamics presented in the original video. A 3D convolutional neural network (3D-CNN) is employed to learn the overall temporal characteristics from the proxy video and predict action category in a single process. Our proposed method is extremely fast. VideoYOLO-32 is able to process 36 videos per second that is 10 times and 7 times faster than prior 2D-CNN (Two-stream (Simonyan and Zisserman, 2014)) and 3D-CNN (C3D (Tran et al., 2015)) based models, respectively, while still achieves superior or comparable classification accuracies on the benchmark datasets, UCF101 and HMDB51.",2018,Journal of Visual Communication and Image Representation
NOURBAKHSHKAASHKI201866,RGB-D face recognition under various conditions via 3D constrained local model,"3D face recognition, Depth image, Face model, 3D constrained local model, Head pose, Lighting, Facial expression, Kinect, Feature descriptor","This research proposes a method for 3D face recognition in various conditions using 3D constrained local model (CLM-Z). In this method, a combination of 2D images (RGBs) and depth images (Ds) captured by Kinect has been used. After detecting the face and smoothing the depth image, CLM-Z model has been used to model and detect the important points of the face. These points are described using Histogram of Oriented Gradients (HOG), Local Binary Patterns (LBP), and 3D Local Binary Patterns (3DLBP). Finally, each face is recognized by a Support Vector Machine (SVM). The challenging situations are changes of lighting, facial expression and head pose. The results on CurtinFaces and IIIT-D datasets demonstrate that the proposed method outperformed state-of-the-art methods under illumination, expression and pitch pose conditions and comparable results were obtained in other cases. Additionally, our proposed method is robust even when the training data has not been carefully collected.",2018,Journal of Visual Communication and Image Representation
QIU201886,Lossless data hiding in JPEG bitstream using alternative embedding,"Information hiding, Lossless data hiding, Reversible data hiding","This paper proposes a lossless data hiding method for JPEG images using adaptive embedding. By constructing an optimal mapping between the used and unused Huffman codes in each category, we take full use of the combination of mapping to achieve a high embedding rate. In order to improve the payload, we further use a code reordering based embedding algorithm. Both algorithms are alternatively used during data hiding. After modifying the Huffman Table defined in JPEG header and substituting the codes in entropy-encoded segments, additional messages are embedded into the JPEG bitstream. The proposed method is lossless to the image, i.e., the decoded content of a marked JPEG bitstream is identical to the original JPEG image. Meanwhile, the file size can be well preserved after data hiding. Experimental results show that the proposed method has a better performance than state-of-the-art works.",2018,Journal of Visual Communication and Image Representation
CHEN2018143,Essential secret image sharing scheme with equal-sized shadows generation,"Secret image sharing, Essential, Non-essential, Three-layered structure","A (t, s, k, n) essential secret image sharing scheme (ESIS) shares a secret image between s essential and n-s non-essential shadows, where t essential shadows and total k shadows are needed to recover the secret image. This paper presents a three-layered structure for ESIS by generating equal-sized essential and non-essential shadows for security to prevent the discovery of essential shadows using only the size difference. In the first layer, two criteria of t essential shadows and totally k shadows are needed. The second and third layers generate essential and non-essential shadows to fit the requirement of the (t, s, k, n) thresholds. The proposed scheme is proved to fit ESIS and equal-sized requirements with properly chosen parameters. Theoretical analysis and experimental results show that the proposed scheme is superior to other schemes on the smallest shadow sizes among equal-sized ESIS schemes.",2018,Journal of Visual Communication and Image Representation
DING2018170,Sparsity constraint nearest subspace classifier for target recognition of SAR images,"Syntheticaperture radar (SAR), Target recognition, Sparsity constraint nearest subspace classifier (SNSC), Sparse representation based classification (SRC)","This paper proposes a sparsity constraint nearest subspace classifier (SNSC) for target recognition of synthetic aperture radar (SAR) images. Unlike optical images, SAR images are highly sensitive to target azimuth. Therefore, the global dictionary collaborated by samples from different classes has high between-class correlation, which will impair the performance of sparse representation-based classification (SRC). Furthermore, even on the subspace spanned by a single class, only a small number of samples with similar azimuths to the test image are highly correlated with the test image. Thus, the linear coefficients over the subspace are actually sparse ones. Therefore, in this paper we impose sparsity constraint on nearest subspace classifier (NSC) classifier and apply it to SAR target recognition. The target label of the test sample is decided to be the class with the minimum reconstruction error. The proposed method is tested on moving and stationary target acquisition and recognition (MSTAR) dataset and compared with several state-of-the-art methods and the experimental results verify the validity and robustness of the proposed method.",2018,Journal of Visual Communication and Image Representation
PRAKASH201892,Active learning for designing detectors for infrequently occurring objects in wide-area satellite imagery,"Object detection, Satellite imagery, Active learning, Distributed computing, Feature selection, Pattern recognition","Generating ground truth to design object detectors for large geographic areas covered by hundreds of satellite images poses two major challenges: one algorithmic and the other rooted in human–computer interaction considerations. The algorithmic challenge relates to minimizing the human annotation burden by collecting only those ground truth samples that are likely to improve the classifier. And the human–computer interaction challenge relates to the temporal latencies associated with scanning all the images to find those ground truth samples and eliciting annotations from a user. We address the algorithmic challenge by using the now well-known concepts from Active Learning, albeit with a significant departure from how Active Learning has traditionally been presented in the literature: we present a human-operated active learning framework, rather than relying on previously collected fully labeled datasets for simulated experiments. And, we address the human-computer interaction challenge by using a distributed approach that relies on multiple virtual machines working in parallel to carry out randomized scans in different portions of the geographic area in order to generate the active-learning based samples for human annotation. We demonstrate our wide-area framework for two infrequently occurring objects over large geographic areas in Australia. One is for detecting pedestrian crosswalks in a region that spans 180,000 sq. km, and the other is for detecting power transmission-line towers in a region that spans 150,000 sq. km. Using randomly selected unseen regions for measuring detector performance, the crosswalk detector works with 92% precision and 72% recall, and the transmission-line tower detector with 80% precision and 50% recall.",2018,Computer Vision and Image Understanding
GIRAUD20181,Robust superpixels using color and contour features along linear path,"Superpixels, Linear path, Segmentation, Contour detection","Superpixel decomposition methods are widely used in computer vision and image processing applications. By grouping homogeneous pixels, the accuracy can be increased and the decrease of the number of elements to process can drastically reduce the computational burden. For most superpixel methods, a trade-off is computed between 1) color homogeneity, 2) adherence to the image contours and 3) shape regularity of the decomposition. In this paper, we propose a framework that jointly enforces all these aspects and provides accurate and regular Superpixels with Contour Adherence using Linear Path (SCALP). During the decomposition, we propose to consider color features along the linear path between the pixel and the corresponding superpixel barycenter. A contour prior is also used to prevent the crossing of image boundaries when associating a pixel to a superpixel. Finally, in order to improve the decomposition accuracy and the robustness to noise, we propose to integrate the pixel neighborhood information, while preserving the same computational complexity. SCALP is extensively evaluated on standard segmentation dataset, and the obtained results outperform the ones of the state-of-the-art methods. SCALP is also extended for supervoxel decomposition on MRI images.",2018,Computer Vision and Image Understanding
TIAN201814,PA-Search: Predicting units adaptive motion search for surveillance video coding,"Surveillance video coding, Motion search, Predicting unit classification, PA-Search, HEVC","The large scale of surveillance video and the high requirement of compression in time requires a low complexity and high efficiency compression algorithm to compress surveillance video. Motion search is a very time-consuming procedure in video coding. In the recent video coding standards such as HEVC/H.265, this procedure becomes more flexible by utilizing the division structure of Coding Units (CUs) and Predicting Units (PUs). However, for surveillance videos that are often captured by fixed-view cameras, the used motion search strategy still does not make full use of their intrinsic characteristics. To address this problem, we propose a PU-Adaptive Search (PA-Search) method for surveillance videos. In PA-Search, a background model is firstly constructed for a super group of pictures and then a background-foreground representation (BFR) is derived for each frame in this group. Utilizing the BFR, PUs are classified into four categories, namely, Full Background PUs (FBPUs), Background PUs (BPUs), Foreground PUs (FPUs), and hybrid foreground-background PUs (XPUs). In PA-Search, zero motion vector (zero-MV) and non-sub-pixel search are assigned to FBPUs and an error-tolerant search algorithm is also performed to reduce the influence of PU mis-classifications; while for non-FBPUs, adaptive search range is calculated according to the PU category and its size, and a BFR-based early-termination algorithm is also used to reduce the search complexity. Moreover, an early terminate partition algorithm is adopted by Full Background CUs to further reduce the encoding time. Experimental results demonstrate the advantage of the proposed PA-Search on HEVC reference software HM-16.0. PA-Search can reduce the number of search points and the total encoding time averagely by 66.90% and 46.69% over TZ Search, while maintaining the coding efficiency.",2018,Computer Vision and Image Understanding
PHAM201851,Exploiting deep residual networks for human action recognition from skeletal data,"3D Action recognition, Deep residual networks, Skeletal data","The computer vision community is currently focusing on solving action recognition problems in real videos, which contain thousands of samples with many challenges. In this process, Deep Convolutional Neural Networks (D-CNNs) have played a significant role in advancing the state-of-the-art in various vision-based action recognition systems. Recently, the introduction of residual connections in conjunction with a more traditional CNN model in a single architecture called Residual Network (ResNet) has shown impressive performance and great potential for image recognition tasks. In this paper, we investigate and apply deep ResNets for human action recognition using skeletal data provided by depth sensors. Firstly, the 3D coordinates of the human body joints carried in skeleton sequences are transformed into image-based representations and stored as RGB images. These color images are able to capture the spatial-temporal evolutions of 3D motions from skeleton sequences and can be efficiently learned by D-CNNs. We then propose a novel deep learning architecture based on ResNets to learn features from obtained color-based representations and classify them into action classes. The proposed method is evaluated on three challenging benchmark datasets including MSR Action 3D, KARD, and NTU-RGB+D datasets. Experimental results demonstrate that our method achieves state-of-the-art performance for all these benchmarks whilst requiring less computation resource. In particular, the proposed method surpasses previous approaches by a significant margin of 3.4% on MSR Action 3D dataset, 0.67% on KARD dataset, and 2.5% on NTU-RGB+D dataset.",2018,Computer Vision and Image Understanding
UKITA201867,Semi- and weakly-supervised human pose estimation,"Human pose estimation, Semi-supervised learning, Weakly-supervised learning, Pose clustering","For human pose estimation in still images, this paper proposes three semi- and weakly-supervised learning schemes. While recent advances of convolutional neural networks improve human pose estimation using supervised training data, our focus is to explore the semi- and weakly-supervised schemes. Our proposed schemes initially learn conventional model(s) for pose estimation from a small amount of standard training images with human pose annotations. For the first semi-supervised learning scheme, this conventional pose model detects candidate poses in training images with no human annotation. From these candidate poses, only true-positives are selected by a classifier using a pose feature representing the configuration of all body parts. The accuracies of these candidate pose estimation and true-positive pose selection are improved by action labels provided to these images in our second and third learning schemes, which are semi- and weakly-supervised learning. While the first and second learning schemes select only poses that are similar to those in the supervised training data, the third scheme selects more true-positive poses that are significantly different from any supervised poses. This pose selection is achieved by pose clustering using outlier pose detection with Dirichlet process mixtures and the Bayes factor. The proposed schemes are validated with large-scale human pose datasets.",2018,Computer Vision and Image Understanding
HAJIRASSOULIHA201828,Subpixel phase-based image registration using Savitzky–Golay differentiators in gradient-correlation,"Subpixel image registration, Deformation measurement, Gradient-correlation, Phase-based methods, Savitzky–Golay differentiators","This paper presents a new two-step method for finding two-dimensional translational shifts with subpixel accuracy. This algorithm can measure subpixel shifts, even in images with few features, or in noisy images where many existing algorithms fail. In the first step of the algorithm (the integer part), the noise-robustness of the gradient correlation methods was improved by replacing central difference differentiators with Savitzky–Golay differentiators (SGDs). In the second step of the algorithm (the subpixel part), several modifications have been proposed to increase the accuracy and noise-robustness of phase-based methods for finding subpixel shifts. Moreover, two error metrics were introduced to quantify the output accuracy of the integer and subpixel parts of the algorithm. Comprehensive tests were conducted on 2400 standard 128 pixel × 128 pixel subimages subjected to synthetic shifts and rotations. Tests showed that the accuracy of the proposed method for finding translational shifts is of the order of a few ten-thousandths of a pixel, which is a substantial improvement over other state-of-the-art methods. For the rotation tests, the method outperformed comparable techniques. Furthermore, results showed that the proposed method generally provides better performance than other competing methods when images contained Gaussian or salt and pepper noise. The proposed method can be used in applications where high accuracy, robustness to noise, and/or computation efficiency are important.",2018,Computer Vision and Image Understanding
GUAN201879,Minimal solutions for the rotational alignment of IMU-camera systems using homography constraints,"IMU-camera calibration, Rotational alignment, Minimal solution, Homography constraint, Algebraic solution, Pure rotation","In this paper, we explore the different minimal case solutions to the rotational alignment of IMU-camera systems using homography constraints. The assumption that a ground plane is visible in the images can easily be created in many situations. This calibration process is relevant to many smart devices equipped with a camera and an inertial measurement unit (IMU), like micro aerial vehicles (MAVs), smartphones and tablets, and it is a fundamental step for vision and IMU data fusion. Our solutions are novel as they compute the rotational alignment of IMU-camera systems by utilizing a first-order rotation approximation and by solving a polynomial equation system derived from homography constraints. These solutions depend on the calibration case with respect to camera motion (general motion case or pure rotation case) and camera parameters (calibrated camera or partially uncalibrated camera). We then demonstrate that the number of matched points in an image pair can vary from 1.5 to 3. This enables us to calibrate using only one relative movement and provide the exact algebraic solution to the problem. The novel minimal case solutions are useful to reduce the computation time and increase the calibration robustness when using Random Sample Consensus (RANSAC) on the point correspondences between two images. Furthermore, a non-linear parameter optimization over all image pairs is performed. In contrast to the previous calibration methods, our solutions do not require any special hardware, and no problems are experienced with one image pair without special motion. Finally, by evaluating our algorithm on both synthetic and real scene data including data obtained from robots, smartphones and MAVs, we demonstrate that our methods are both efficient and numerically stable for the rotational alignment of IMU-camera systems.",2018,Computer Vision and Image Understanding
SANTINI201840,PuRe: Robust pupil detection for real-time pervasive eye tracking,"Pupil detection, Pervasive, Eye tracking, Embedded","Real-time, accurate, and robust pupil detection is an essential prerequisite to enable pervasive eye-tracking and its applications – e.g., gaze-based human computer interaction, health monitoring, foveated rendering, and advanced driver assistance. However, automated pupil detection has proved to be an intricate task in real-world scenarios due to a large mixture of challenges such as quickly changing illumination and occlusions. In this paper, we introduce the Pupil Reconstructor (PuRe), a method for pupil detection in pervasive scenarios based on a novel edge segment selection and conditional segment combination schemes; the method also includes a confidence measure for the detected pupil. The proposed method was evaluated on over 316,000 images acquired with four distinct head-mounted eye tracking devices. Results show a pupil detection rate improvement of over 10 percentage points w.r.t. state-of-the-art algorithms in the two most challenging data sets (6.46 for all data sets), further pushing the envelope for pupil detection. Moreover, we advance the evaluation protocol of pupil detection algorithms by also considering eye images in which pupils are not present and contributing a new data set of mostly closed eyes images. In this aspect, PuRe improved precision and specificity w.r.t. state-of-the-art algorithms by 25.05 and 10.94 percentage points, respectively, demonstrating the meaningfulness of PuRe’s confidence measure. PuRe operates in real-time for modern eye trackers (at 120 fps) and is fully integrated into EyeRecToo – an open-source state-of-the-art software for pervasive head-mounted eye tracking. The proposed method and data set are available at http://www.ti.uni-tuebingen.de/perception.",2018,Computer Vision and Image Understanding
BAI2018199,Saliency-based multi-feature modeling for semantic image retrieval,"Semantic gap, Bag of words, Visual saliency, Semantic image retrieval","Semantic gap is an important challenging problem in content-based image retrieval (CBIR) up to now. Bag-of-words (BOW) framework is a popular approach that tries to reduce the semantic gap in CBIR. In this paper, an approach integrating visual saliency model with BOW is proposed for semantic image retrieval. Images are firstly segmented into background regions and foreground objects by a visual saliency-based segmentation method. And then multi-features including Scale Invariant Feature Transform (SIFT) features packed in BOW are extracted from regions and objects respectively and fused considering different characteristics of background regions and foreground objects. Finally, a fusion of z-score normalized Chi-Square distance is adopted as the similarity measurement. This proposal has been implemented on two widely used benchmark databases and the results evaluated in terms of mean Average Precision (mAP) show that our proposal outperforms the referred state-of-the-art approaches.",2018,Journal of Visual Communication and Image Representation
JACINTO2018167,Multi-atlas automatic positioning of anatomical landmarks,"Orthopaedics, Knee, Landmarks, Atlas, Registration, Positioning","We propose a method for the automatic positioning of pre-defined landmarks on 3-D models of anatomical structures. We exploit a group of atlases consisting of multiple triangular meshes for which the defined landmarks have been placed by experts. We compute an initial coarse global registration of the patient mesh with an expert mesh by using a curvature-enhanced Iterative Closest Point (ICP) algorithm. Adaptive local rigid registrations refine the fit for the projection of reference landmarks onto the surface of the patient structure. An automatic selection based on a fit criterion computes a final position for each landmark. Our positioning method improves the efficiency of the positioning task, being completely unsupervised and yielding results competitive with those of the manual positioning. We provide comparisons with previous works of the literature. The automatic positioning for each target structure is completely reproducible as opposed to manual positioning, affected by intra-operator variability.",2018,Journal of Visual Communication and Image Representation
HU2018100,A note on patch-based low-rank minimization for fast image denoising,"Image denoising, Patch-based method, Low-rank minimization, Principal component analysis, Singular value decomposition, Hard thresholding","Patch-based low-rank minimization for image processing attracts much attention in recent years. The minimization of the matrix rank coupled with the Frobenius norm data fidelity can be solved by the hard thresholding filter with principle component analysis (PCA) or singular value decomposition (SVD). Based on this idea, we propose a patch-based low-rank minimization method for image denoising. The main denoising process is stated in three equivalent way: PCA, SVD and low-rank minimization. Compared to recent patch-based sparse representation methods, experiments demonstrate that the proposed method is rather rapid, and it is effective for a variety of natural grayscale images and color images, especially for texture parts in images. Further improvements of this method are also given. In addition, due to the simplicity of this method, we could provide an explanation of the choice of the threshold parameter, estimation of PSNR values, and give other insights into this method.",2018,Journal of Visual Communication and Image Representation
CHEN2018270,Salient object detection via spectral graph weighted low rank matrix recovery,"Saliency detection, Spectral graph, Low rank matrix recovery, Sparse decomposition, Feature matrix","A novel saliency detection method via spectral graph (SG) weighted low rank matrix recovery (LR) is presented in this paper. The location, color, and boundary priors are exploited in many LR-based saliency detection methods. However, these priors do not work well when the salient objects are far away from image center, especially when the background is complicated and has low contrast with objects. Because spectral graph contains rich image contrast, it is used as an efficient weight to obtain a much reasonable high-level prior in the proposed LR-based saliency model. Compared with previous LR-based methods, low rank matrix and sparse matrix rather than only sparse matrix are used to calculate the final saliency by an integration function and an activation function. The numerical and visual results on four challenging salient object datasets show that our method performs competitively for salient object detection task against some recent state-of-the-art algorithms.",2018,Journal of Visual Communication and Image Representation
XIANG2018280,A perceptually temporal adaptive quantization algorithm for HEVC,"Inter-frame dependency, AQ, QP offset, JND, SSIM, Subjective quality","Adaptive quantization (AQ) proves to be an effective coding tool to improve the performance of video coding. This paper presents a perceptually temporal AQ method to improve the subjective coding performance for High Efficiency Video Coding (HEVC). We first put forward a perceptual quality oriented motion estimation algorithm, which is conducted with a spatial-temporal just noticeable distortion (JND) model. Then one perceptual feature in temporal domain is proposed to develop our AQ method, which can generate different quantization parameter (QP) offsets for each coding unit (CU). The proposed method fully utilizes the temporal and perceptual characteristics of each CU, which can produce more visual-friendly QP offsets distribution. Experiments are conducted on HM16.0 (HEVC reference software), and with SSIM (Structure Similarity Index Metric) as the distortion metric, more than 8.08% and 7.95% rate savings can be obtained for Low-Delay-P (LDP) and Low-Delay-B (LDB) configurations on average, respectively. The subjective quality evaluation demonstrates that the proposed AQ method can achieve comparable visual quality as the HM16.0 while the proposed method can yield remarkable bitrate reductions.",2018,Journal of Visual Communication and Image Representation
EDMUNDS2018314,Motion-based countermeasure against photo and video spoofing attacks in face recognition,"Motion cues, Face anti-spoofing, Fisher kernel, Replay attacks","Facial biometric systems are vulnerable to fraudulent access attempts by presenting photographs or videos of a valid user in front of the sensor also known as “spoofing attacks”. Multiple protection measures have been proposed but limited attention has been dedicated to exclusive motion-based countermeasures since the arrival of video and mask attacks. A novel motion-based countermeasure which exploits natural and unnatural motion cues is presented. The proposed method takes advantage of the Conditional Local Neural Fields (CLNF) face tracking algorithm to extract rigid and non-rigid face motions. Similarly to the bag-of-words feature encoding, a vocabulary of motion sequences is constructed to derive discriminant mid-level motion features using the Fisher vector framework. Extensive experiments are conducted on ReplayAttack-DB, CASIA-FASD and MSU-MFSD databases. Complementary experiments on rigid mask attacks from the 3DMAD public database are also conducted and generalization issues are investigated via cross-database evaluation in particular.",2018,Journal of Visual Communication and Image Representation
KARINE201827,A novel statistical model for content-based stereo image retrieval in the complex wavelet domain,"Content-based stereo image retrieval, Gaussian copula, Non-Gaussian distribution, Jeffrey divergence, Complex wavelet transform, Feature extraction","This paper presents a new stereo image (SI) retrieval method based on a statistical model of complex wavelet coefficients subbands. In this context, a Gaussian copula-based multivariate model is used to capture the dependence between complex wavelet coefficients of both left and right images, and a non-Gaussian univariate model is used to characterize the statistical behavior of the disparity map. Thanks to its flexibility, the copula tool allows us to choose several marginal densities while keeping the multivariate properties. Features are extracted by estimating parameters for both multivariate and univariate models. Finally, a weighted Jeffrey divergence (JD) is used as a similarity measurement between the underlying models. Experimental results on a stereo image database demonstrate the performance of the proposed method in terms of the retrieval rates as well as the computational time.",2018,Journal of Visual Communication and Image Representation
REN2018227,Saliency integration driven by similar images,"Saliency integration, Saliency propagation, Similar image, Saliency model","This paper proposes a saliency integration approach via the use of similar images to elevate saliency detection performance. Given the input image, a group of similar images are first retrieved, and meanwhile, the corresponding multiple saliency maps of the input image are generated by using existing saliency models. Then, the saliency fusion map is generated by using an adaptive fusion method to integrate such saliency maps, for which the fusion weights are measured by the corresponding similarity between each similar image and the input image. Next, an inter-image graph, for each pair of input image and similar image, is constructed to propagate the confident saliency values from the similar image to the input image, yielding the saliency propagation map. Finally, the saliency fusion map and the saliency propagation map are integrated to obtain the final saliency map. Experimental results on two public datasets demonstrate that the proposed approach achieves the better saliency detection performance compared to the existing saliency models and other saliency integration approaches.",2018,Journal of Visual Communication and Image Representation
PAN2018186,Novel reversible data hiding scheme for Two-stage VQ compressed images based on search-order coding,"Reversible data hiding (RDH), Vector quantization (VQ), Side-match vector quantization (SMVQ), SOC (Search-order coding), Two-stage VQ, Difference image","In this paper, a novel reversible data hiding scheme for Two-stage VQ (Vector quantization) compressed images based on SOC (Search-order coding) scheme is proposed. Two-stage VQ improves VQ by obtaining better reconstructed image and generating indices with higher correlation. The difference image, as the input of Two-stage VQ, is produced by employing the first codeword in state codebook and the current image block. The main idea of SOC method is exploiting the correlation of indices to derive better compression performance. The combination of SOC and data hiding can achieve both high compression rate and high embedding capacity. Since Two-stage VQ can achieve indices with higher correlation, this advantage is applied to enhance the data hiding performance. Moreover, the cover image can be reconstructed by the receiver without using any side information. To show the superiority of our proposed scheme, several state-of-the-art schemes designed for compression domain are cited for comparison.",2018,Journal of Visual Communication and Image Representation
LI201816,Saliency ranker: A new salient object detection method,"Saliency detection, Label ranking, Matrix recovery","Recently, saliency detection has become an active research topic in learning from labeled image, where various supervised methods were designed. Many existing methods usually cast saliency detection as a binary classification or regression problem, in which saliency detection performance relies heavily on the expensive pixel-wise annotations of salient objects. This paper addresses the issue by developing a novel learning-to-rank model with a limited number of training data, which combines the strength of cost-sensitive label ranking methods with the power of low-rank matrix recovery theories. Rather than using a binary decision for each saliency value, our approach ranks saliency values in a descending order with the estimated relevance to the given saliency. Additionally, we also aggregate the prediction models for different saliency labels into a matrix, and solve saliency ranking via a low-rank matrix recovery problem. Extensive experiments over challenging benchmarks clearly validate advantage of our method.",2018,Journal of Visual Communication and Image Representation
GVOZDEN2018145,Blind image sharpness assessment based on local contrast map statistics,"No-reference, Image quality assessment, Contrast, Percentile, Dynamic range, Wavelet","This paper presents a fast blind image sharpness/blurriness assessment model (BISHARP) which operates in spatial and transform domain. The proposed model generates local contrast image maps by computing the root-mean-squared values for each image pixel within a defined size of local neighborhood. The resulting local contrast maps are then transformed into the wavelet domain where the reduction of high frequency content is evaluated in the presence of varying blur strengths. It was found that percentile values computed from sorted, level-shifted, high-frequency wavelet coefficients can serve as reliable image sharpness/blurriness estimators. Furthermore, it was found that higher dynamic range of contrast maps significantly improves model performance. The results of validation performed on seven image databases showed a very high correlation with perceptual scores. Due to low computational requirements the proposed model can be easily utilized in real-world image processing applications.",2018,Journal of Visual Communication and Image Representation
DING201893,An efficient weak sharpening detection method for image forensics,"Image forensics, Sharpening detection, Overshoot artifact, Edge perpendicular binary coding, Ternary coding","In recent years, image sharpening detection has become one of the main topics in the field of image forensics. It is, however, still a challenge to detect the images sharpened with weak sharpening strength. To address this challenge, we propose an efficient method for image sharpening detection. In the proposed method, a ternary coding strategy with adaptive threshold is introduced to reveal the overshoot artifacts caused by weak sharpening. Extensive experiments are conducted to illustrate the superiority of the proposed method. The experimental results show that the proposed method can achieve a considerable improvement in sharpening detection, especially for slightly sharpened images.",2018,Journal of Visual Communication and Image Representation
ROUHI2018263,Encoder settings impact on intra-prediction-based descriptors for video retrieval,"H.264/AVC, Encoder impact, Profile impact, Feature sensitivity, Video copy detection, Intra-prediction modes, I-frames, Correlogram, Visual features, Content-preserving transformations","Intra-prediction modes (IPMs) of H.264/AVC, as visual feature components, are easily extracted from the compressed domain. However, in spite of their efficiency and effectiveness, they can be sensitive to encoder settings such as encoder-type and encoding-profile. In content-based video retrieval using different encoders between a video and its copy can affect performance. Similarly, applying different encoding-profiles can also have a negative impact. Experiments with different IPM-based descriptors, on a subset of the TRECVID/CCD 2011 collection with content-preserving visual distortions, compare the performance of four H.264/AVC encoding profiles (High10, High, Baseline and Main) and also investigate the impact of three encoders (FFmpeg, MediaCoder and JM). The research shows that ordinal pattern distribution of unified IPMs can improve their tolerance to changes in encoder settings. Furthermore, it is shown that a Correlogram rather than a Histogram of the IPMs is more robust with respect to the impact of encoding-profiles and encoder-types.",2018,Journal of Visual Communication and Image Representation
BOLANOS2018205,Egocentric video description based on temporally-linked sequences,"Egocentric vision, Video description, Deep learning, Multi-modal learning","Egocentric vision consists in acquiring images along the day from a first person point-of-view using wearable cameras. The automatic analysis of this information allows to discover daily patterns for improving the quality of life of the user. A natural topic that arises in egocentric vision is storytelling, that is, how to understand and tell the story relying behind the pictures. In this paper, we tackle storytelling as an egocentric sequences description problem. We propose a novel methodology that exploits information from temporally neighboring events, matching precisely the nature of egocentric sequences. Furthermore, we present a new method for multimodal data fusion consisting on a multi-input attention recurrent network. We also release the EDUB-SegDesc dataset. This is the first dataset for egocentric image sequences description, consisting of 1339 events with 3991 descriptions, from 55 days acquired by 11 people. Finally, we prove that our proposal outperforms classical attentional encoder-decoder methods for video description.",2018,Journal of Visual Communication and Image Representation
WANG201840,An efficient method of content-targeted online video advertising,"Advertising insertion, Content-targeted, Key frame extraction, Scene boundary detection, Similarity measurement","With the rapid development of Internet, the views of the online video have increased dramatically. Meanwhile, the corresponding online video advertising market showed a momentum of rapid and sustained development. In order to attract more potential purchasers and reduce the interference on the ordinary video browsers, many researchers and enterprises have conducted the research of video online advertising. At present, the insertion methods of most video advertising are always position-fixed, mandatory timing, quantitative, and the relevance of advertisement content and the video content is usually ignored. These methods will inevitably reduce the advertising effect because of browsers’ dissatisfaction and resistance. In order to overcome the shortages of the existing methods of video advertisement insertion, this paper proposed an effective content-targeted method for online video advertising. The insertion of advertisement is determined by comparing the content of the videos and the advertisements. At the same time, the characteristics of the scene switching in the video are taken into account to select the appropriate position of the advertisement insertion. Experimental results show that our method can provide a better user experience than existing methods, and its attractiveness and comfortableness is greatly improved.",2018,Journal of Visual Communication and Image Representation
GAO20181,Optimal feature combination analysis for crowd saliency prediction,"Crowd, Saliency, Random forest, Visual attention, Face detection","Crowd saliency prediction refers to predicting where people look at in crowd scene. Humans have remarkable ability to rapidly direct their gaze to select visual information of interest when looking at a visual scene. Until now, research efforts are still focused on what type of feature is representative for crowd saliency, and which type of learning model is robust for crowd saliency prediction. In this paper, we propose a Random Forest (RF) based crowd saliency prediction approach with optimal feature combination, i.e., the Feature Combination Selection for Crowd Saliency (FCSCS) framework. More specifically, we first define three representative crowd saliency features, namely, FaceSizeDiff, FacePoseDiff and FaceWhrDiff. Next, we adopt the Random Forest (RF) algorithm to construct our saliency learning model. Then, we evaluate the performance of FCSCS framework with different feature combinations (fifteen combinations in our experiments). Those selected features include low-level features (i.e., color, intensity, orientation), four crowd features (i.e., face size, face density, frontal face, profile face) and three new defined features (i.e., FaceSizeDiff, FacePoseDiff and FaceWhrDiff). We use FCSCS framework to obtain the optimal feature combination that is most suitable for crowd saliency prediction and further train the saliency model based on the optimal feature combination. After that, we evaluate the performance of the crowd saliency prediction classifiers. Finally, we conduct extensive experiments and empirical evaluation to demonstrate the satisfactory performance of our approach.",2018,Journal of Visual Communication and Image Representation
YAN2018135,"Partial secret image sharing for (k,n) threshold based on image inpainting","Secret image sharing, Partial secret image sharing, Image inpainting, Linear congruence, Color image, Lossless recovery","The traditional (k,n) threshold secret image sharing (SIS) schemes dealt with the full secret image neglecting the possible situation that only part of the secret image needs protection. However, in some applications, only target part of the secret image may need to be protected while other parts may be not in a full image. In this paper, we consider the partial secret image sharing (PSIS) issue as well as propose a PSIS scheme for (k,n) threshold based on image inpainting and linear congruence (LC)-based SIS. The full secret image including the secret target part and other parts will be recovered by collecting any k or more shadow images, which can be further reconstructed losslessly by adding all the inpainted meaningful shadow images. Furthermore, the proposed scheme can share irregular target in a progressive way. Experiments are conducted to evaluate the efficiency of the proposed scheme.",2018,Journal of Visual Communication and Image Representation
GUO201865,Identifying facial expression using adaptive sub-layer compensation based feature extraction,"Marr-Hildreth detector, Adaptive sub-layer compensation, Elastic body spline, Discriminative Isomap","In this paper, an automatic facial expression recognition method is proposed to extract feature from video sequences. First, we modified the Marr-Hildreth detector with Wiener filtering, adaptive sub-layer compensation (ASLC) and hysteresis to alleviate the negative effects of traditional one and then, the deformable elastic body spline (EBS) model is extended by using different Poisson’s rate to model the facial muscle fiber, which accommodate the fact that different muscle fiber has a different way of deformation. The ASLC feature and the improved EBS feature are fused together to form the facial feature vector. Further, we utilize the Discriminative Isomap (D-Isomap) approach to embed the facial feature into a low dimensional space. The final decision is made by computing the nearest class center of the feature space. RML Emotion database and Cohn-Kanade (CK) database are both used for the experiment and the results demonstrate the effectiveness of the proposed method.",2018,Journal of Visual Communication and Image Representation
VITORINO2018303,Leveraging deep neural networks to fight child pornography in the age of social media,"Child pornography, SEIC content, Deep learning, Transfer learning, Fine tuning","Over the past two decades, the nature of child pornography in terms of generation, distribution and possession of images drastically changed, evolving from basically covert and offline exchanges of content to a massive network of contacts and data sharing. Nowadays, the internet has become not only a transmission channel but, probably, a child pornography enabling factor by itself. As a consequence, most countries worldwide consider a crime to take, or permit to be taken, to store or to distribute images or videos depicting any child pornography grammar. But before action can even be taken, we must detect the very existence or presence of sexually exploitative imagery of children when gleaning over vast troves of data. With this backdrop, veering away from virtually all off-the-shelf solutions and existing methods in the literature, in this work, we leverage cutting-edge data-driven concepts and deep convolutional neural networks (CNNs) to harness enough characterization aspects from a wide range of images and point out the presence of child pornography content in an image. We explore different transfer-learning strategies for CNN modeling. CNNs are first trained with problems for which we can gather more training examples and upon which there are no serious concerns regarding collection and storage and then fine-tuned with data from the target problem of interest. The learned networks outperform different existing solutions and seem to represent an important step forward when dealing with child pornography content detection. The proposed solutions are encapsulated in a sandbox virtual machine ready for deployment by experts and practitioners. Experimental results with tens of thousands of real cases show the effectiveness of the proposed methods.",2018,Journal of Visual Communication and Image Representation
RAO2018217,High dynamic range 3D shape determination based on automatic exposure selection,"3D measurement, Fringe projection, Random noises, High dynamic range, Multiple exposures","Traditional multi-exposure based high dynamic range fringe projection profilometry (FPP) technique is an effective method to obtain the 3D profiles of objects with drastic surface reflectivity variations. However, in this technique different exposure times often need to be selected empirically, making this method rather complicated. In this paper a completely automatic multi-exposure based FPP technique is proposed. No human intervention is required while applying the proposed method, which greatly simplify the whole reconstruction process. It is mathematically proved that once a pixel’s modulation is larger than a threshold, the phase quality of this pixel can be considered satisfactory. This threshold can be used to guide the calculation of the needed exposure times. The software then automatically adjusts the camera’s exposure time and captures the needed fringe images. Experiments show that with these captured images, the final reconstruction with a high dynamic range can be readily obtained.",2018,Journal of Visual Communication and Image Representation
YAO2018111,Principal component dictionary-based patch grouping for image denoising,"Nonlocal self-similarity, Transform-domain, External knowledge, Image denoising","Improving denoising algorithms based on nonlocal self-similarity (NSS) to cope with increasing noise levels has become difficult. This is primarily because of difficulty in accurately grouping similar image patches solely on original spatial-domain of noisy images. To solve this problem, we propose to group similar patches on transform-domain learned from clean natural images. In this paper, we introduce a denoising algorithm comprising principal component dictionary (PCD)-based patch grouping and a low-rank approximation process. In the proposed algorithm, PCD learns from clean natural images and uses the knowledge gained to guide similar patches grouping results in noisy images. Patch grouping is directly implemented on PCD-based transform-domain. And, external knowledge and internal NSS prior are used jointly for image denoising. The results of experiments conducted indicate that the proposed denoising algorithm outperforms several state-of-the-art denoising algorithms, especially in heavy noise conditions.",2018,Journal of Visual Communication and Image Representation
NAIR20189,Color image dehazing using surround filter and dark channel prior,"Atmospheric light, Color space, Dark channel prior, Dehazing, No reference quality assessment, Transmission map","Outdoor images are often degraded by haze, resulting in a distinctive gray or bluish hue which diminishes visibility. Of the existing haze removal methods, the ones that are effective are computationally complex and memory intensive. In this paper, we propose a simple haze removal technique, whose computational complexity is that of a simple convolution. To this purpose, a center surround filter is employed to improve speed and memory requirements of the transmission estimation in image dehazing. This can be useful for real time applications such as driver assistance, runway hazard detection and surveillance. The proposed technique relies on deriving an alternative transmission estimate by filtering the input image in three different color spaces, namely RGB, Lab and HSV. The effectiveness of the proposed method is compared with that of other state of the art methods using a subjective quality assessment method and a number of objective quality assessment methods.",2018,Journal of Visual Communication and Image Representation
WANG2018178,Extended smoothlets: An efficient multi-resolution adaptive transform,"Smoothlets, Wedgelets, Multiresolution, Adaptive transform, Approximation, Denoising","As a family of multiresolution adaptive transforms and a generalization of wedgelets, smoothlets are more efficient in representing images with various sharp edges than other “X-lets”. Smoothlets use a horizon function to model an edge and define transition in a fixed axis direction. Furthermore, the conventional elliptical smoothlets (ES) use half of an ellipse to model edges. Various sharp edges of images may not be expressed well by half of an ellipse with transition only in a fixed axis direction. In this paper, we propose extended smoothlets (ExSmoothlets) framework by using more general characteristic functions with adaptive transition directions. Specifically, two methods of ExSmoothlets, the elliptical ExSmoothlets (EES) and homocentric elliptical ExSmoothlets (HEES) are developed and evaluated in the experiments against the ES. The results show that the proposed EES and HEES can effectively improve the image quality in image approximation and denoising in terms of PSNR.",2018,Journal of Visual Communication and Image Representation
LIN201883,Advanced texture and depth coding in 3D-HEVC,"3D-HEVC, Inter-view motion prediction, Disparity derivation, Depth coding","The 3D extension of High Efficiency Video Coding (3D-HEVC) is a new international video coding standard developed by the Joint Collaborative Team on 3D Video Coding Extensions (JCT-3V) in order to support coding of multiple views and its associated depth data. 3D-HEVC aims at improving the coding efficiency of 3D and multi-view videos by introducing new coding tools to utilize the correlations between views and between texture and depth components. In this paper, an inter-view motion prediction (inter-view merge candidate) and an inter-component motion prediction (texture merge candidate) are proposed to explore the inter-view and the inter-component redundancies for texture and depth components, respectively. Moreover, a new coding mode termed as single depth mode which simply reconstructs a coding block with a single depth value based on block merging scheme under the HEVC quad-tree based block partitioning is also introduced. All the proposed schemes are adopted in 3D-HEVC. The experimental results evaluated under the common test conditions (CTC) for developing 3D-HEVC show that the proposed inter-view merge candidate, texture merge candidate, and single depth mode achieve significant BD-rate reductions of 19.5% for dependent texture views and 8.3% for the synthesized texture views.",2018,Journal of Visual Communication and Image Representation
HONG2018159,Low-complexity direct computation algorithm for cubic-spline interpolation scheme,"Cubic-spline interpolation, Direct computation algorithm, Fast Fourier transform, Low-complexity direct computation algorithm","Cubic-spline interpolation (CSI) scheme is known to be designed to resample the discrete image data based on the least-square method in conjunction with the cubic convolution interpolation (CCI) function. It is superior in performance and can be used together with the discrete cosine transform (DCT)-based image or video codec to improve the coding performance for a variety of high compression ratios. In this paper, we firstly make some comments on the direct computation algorithm for CSI scheme developed by Lin et al. Moreover, a low-complexity direct computation algorithm for CSI scheme is developed to further improve the computational efficiency. The mathematical derivations and simulation results indicate that such simplified CSI scheme using the proposed low-complexity direct computation algorithm can achieve almost the same objective and subjective performance with much fewer arithmetic operations in comparison with the CSI scheme using the direct computation algorithm.",2018,Journal of Visual Communication and Image Representation
PRAMANIK2018123,Shape decomposition-based handwritten compound character recognition for Bangla OCR,"Bangla OCR, Chain code histogram, Handwritten compound character, MLP, Segmentation, Shape decomposition","Proper recognition of complex-shaped handwritten compound characters is still a big challenge for Bangla OCR systems. In this paper, we propose a novel shape decomposition-based segmentation technique to decompose the compound characters into prominent shape components. This shape decomposition reduces the classification complexity in terms of less number of classes to recognize, and at the same time improves the recognition accuracy. The decomposition is done at the segmentation area where the two basic shapes are joined to form a compound character. We use chain code histogram feature set with multi-layer perceptron (MLP) based classifier with backpropagation learning for classification. On experimentation, the proposed method is observed to provide good recognition accuracy comparing with other existing methods.",2018,Journal of Visual Communication and Image Representation
GAO201874,Improved kernelized correlation filter tracking by using spatial regularization,"Visual tracking, Correlation filter, Spatial regularization, Kernel method","The correlation filter based trackers have drawn much attention due to their encouraging performance on precision, robustness and speed. In this paper, we introduce the spatial regularization component into the ridge regression model used by classical kernelized correlation filter (KCF) to improve its performance. It overcomes the fact that the traditional KCF does not consider the prior spatial constraint of the feature distribution of the target. We found that, after adding the spatial regularized function, we can solve the ridge regression formula efficiently with the property of circulant matrices. In this way, we can simultaneously keep the realtime and improve the tracking performance. Finally, we evaluate the proposed SRKCF tracker on the OTB-2013 and OTB-2015 comparing with 36 trackers and our tracker achieves state-of-art. Comparing with the SRDCF which applies the spatial regularized function, our algorithm achieves comparable performance with the obvious advantages in speed.",2018,Journal of Visual Communication and Image Representation
HU2018290,A highly efficient method for improving the performance of GLA-based algorithms,"Generalized Lloyd algorithm, Reduction method, Multiple stage vector quantization","Motivated by the observation that most methods for accelerating the generalized Lloyd algorithm (GLA) normally lack the capability to improve the quality of its end result and that most methods for improving the quality of the end result of GLA usually lack the capability to speed it up, an efficient and effective method is presented in this paper to enhance the performance of GLA and its variants, in terms of both the computation time and the quality of the end result, by leveraging the strengths of several reduction methods and the multiple stage mechanism. Simulation results show that the proposed method can efficiently and effectively reduce the computation time of GLA by up to about 93% while at the same time improving its quality by up to about 1 dB in terms of the peak-signal-to-noise-ratio in most cases.",2018,Journal of Visual Communication and Image Representation
JAYKUO2018237,On data-driven Saak transform,"Data-driven transform, RECOS transform, Saak transform, The Karhunen-Loéve transform (KLT), Linear subspace approximation, Principal component analysis","Being motivated by the multilayer RECOS (REctified-COrrelations on a Sphere) transform, we develop a data-driven Saak (Subspace approximation with augmented kernels) transform in this work. The Saak transform consists of three steps: (1) building the optimal linear subspace approximation with orthonormal bases using the second-order statistics of input vectors, (2) augmenting each transform kernel with its negative, (3) applying the rectified linear unit (ReLU) to the transform output. The Karhunen-Loéve transform (KLT) is used in the first step. The integration of Steps 2 and 3 is powerful since they resolve the sign confusion problem, remove the rectification loss and allow a straightforward implementation of the inverse Saak transform at the same time. Multiple Saak transforms are cascaded to transform images of a larger size. All Saak transform kernels are derived from the second-order statistics of input random vectors in a one-pass feedforward manner. Neither data labels nor backpropagation is used in kernel determination. Multi-stage Saak transforms offer a family of joint spatial-spectral representations between two extremes; namely, the full spatial-domain representation and the full spectral-domain representation. We select Saak coefficients of higher discriminant power to form a feature vector for pattern recognition, and use the MNIST dataset classification problem as an illustrative example.",2018,Journal of Visual Communication and Image Representation
BOLOURIANHAGHIGHI201849,TRLH: Fragile and blind dual watermarking for image tamper detection and self-recovery based on lifting wavelet transform and halftoning technique,"Data hiding, Watermarking, Tamper detection and self-recovery, Image authentication, Lifting wavelet transform, Halftoning technique","This paper proposes a fragile and blind dual watermarking method for tamper detection and self-recovery. This method generates two image digests from the host image, based on the lifting wavelet and the halftoning technique. Therefore, for each 2×2 non-overlapping blocks, two chances for recovering tampered blocks is provided. Then, the authentication bit is obtained by using the image digests. Totally, eight bits are embedded in two LSBs for each block of image. To enhance the quality of the digest, a new LSBRounding technique is proposed. Additionally, to determine the mapping blocks and shuffling LSBs, the Arnold Cat Map is utilized. To improve the recovery rate, a Shift-aside operation is proposed. For preventing copy-move, vector-quantization attacks, and any manipulation in LSBs, the information embedded in each block depends on the key which is assigned to it. Experimental results show the efficiency of TRLH compared to the state of the art methods.",2018,Journal of Visual Communication and Image Representation
JIANG2018247,No reference stereo video quality assessment based on motion feature in tensor decomposition domain,"No reference stereo video quality assessment, Tensor decomposition, Motion feature, Entropy, Random forest","A no reference stereo video quality assessment method based on motion features extracted in tensor decomposition domain is proposed. Tensor decomposition is used to reduce dimension of color, view and time of stereo video, and motion information maps containing time-varying information of inter-views and intra-views are obtained. Statistical features such as generalized Gaussian distribution (GGD), asymmetric GGD, spatial entropy, spectral entropy associated with two views, and spectral entropy related to depth perception of stereo video, are extracted. Random forest is utilized to establish relationship between stereo video quality and the extracted features. Experimental results on NAMA3DS1-COSPAD1 database demonstrate that the proposed method achieves good performance on JP2K, resolution reduction, sharpening and their combination distortions, Pearson linear correlation coefficient (PLCC) values of these types of distortions are higher than 0.97, while for H.264 distortion the PLCC value is 0.8850, which means that the proposed metric is consistent with human visual perception.",2018,Journal of Visual Communication and Image Representation
CABRERA201724,Ontology-based context modeling in service-oriented computing: A systematic mapping,"Context-aware computing, Context modeling, Ontology, Service-oriented computing, Systematic mapping","Context Service-oriented computing and context-aware computing are two consolidated paradigms that are changing the way of providing and consuming software services. Whilst service-oriented computing is based on service-oriented architectures for providing flexible software services, context-aware computing articulates different phases of a context life cycle for changing the behavior of such services. The synergy between both paradigms provides the context to this study. Objective This study analyzes the current state of the art of context models, specifically: (1) which are these proposals and how are they related; (2) what are their structural characteristics; (3) what context information is the most addressed; and (4) what are their most consolidated definitions. Given their dominance on the field, the study focuses on ontology-based approaches. Method We conducted a systematic mapping by establishing a review protocol that integrates automatic and manual searches from different sources. We applied a rigorous method to elicit the keywords from the research questions and selection criteria to retrieve the papers to evaluate. Results Overall, 138 primary studies were selected to answer our research questions. These proposals were studied in depth by analyzing: 1) distribution along time and their relationships; 2) size correlated with the number of classes and levels of the context model, and coverage of the definitions provided as indicator of quality provided; 3) most addressed context information; 4) most consolidated definitions of context information. Conclusions The contribution of this survey is to make available a unified and consolidated body of knowledge on context for service-oriented computing that could be instantiated and used as starting point in a variety of use cases. This sweeping view on the anatomy of context models may help avoiding the postulation of new proposals not aligned with the current research.",2017,Data & Knowledge Engineering
SHAN20171,Constructing target-aware results for keyword search on knowledge graphs,"Knowledge graphs, Entity relationship model, Conceptual modeling, Meta-data, Semi-structured data, XML, Keyword search, Query semantics, INEX","Existing work of processing keyword searches on graph data focuses on efficiency of result generation. However, being oblivious to user search intention, a query result may contain multiple instances of user search target, and multiple query results may contain information for the same instance of user search target. With the misalignment between query results and search targets, a ranking function is unable to effectively rank the instances of search targets. In this paper we propose the concept of target-aware query results driven by inferred user search intention. We leverage the Information Theory and develop a general probability model to infer search targets by analyzing return specifiers, modifiers, relatedness relationships, and query keywords' information gain. Then we propose two important properties for a target-aware result: atomicity and intactness. We develop techniques to efficiently generate target-aware results. Extensive experimental evaluation shows the effectiveness and efficiency of our approach.",2017,Data & Knowledge Engineering
AMPLAYO201754,An adaptable fine-grained sentiment analysis for summarization of multiple short online reviews,"Review summarization, Aspect extraction, Sentiment analysis, Short texts, Online reviews","In this study, we present a novel method in generating summaries of multiple online reviews using a fine-grained sentiment extraction model for short texts, which is adaptable to different domains and languages. Adaptability of a model is defined as its ability to be easily modified and be usable on different domains and languages. This is important because of the diversity of domains and languages available. The fine-grained sentiment extraction model is divided into two methods: sentiment classification and aspect extraction. The sentiment classifier is built using a three-level classification approach, while the aspect extractor is built using extended biterm topic model (eBTM), an extension of LDA topic model for short texts. Overall, results show that the sentiment classifier outperforms baseline models and industry-standard classifiers while the aspect extractor outperforms other topic models in terms of aspect diversity and aspect extracting power. In addition, using the Naver movies dataset, we show that online review summarization can be effectively constructed using the proposed methods by comparing the results of our method and the results of a movie awards ceremony.",2017,Data & Knowledge Engineering
XUE20171,Improving the efficiency of NSGA-II based ontology aligning technology,"Ontology alignment, Dynamic Alignment Candidates Selection, Metamodel, NSGA-II","There is evidence from Ontology Alignment Evaluation Initiative (OAEI) that ontology matchers do not necessarily find the same correct correspondences. Therefore, usually several competing matchers are applied to the same pair of entities in order to increase evidence towards a potential match or mismatch. How to select the proper matcher's alignments and efficiently tune them becomes one of the challenges in ontology matching domain. To this end, in this paper, we propose to use the Dynamic Alignment Candidates Selection Strategy and Metamodel to raise the efficiency of the process of using NSGA-II to optimize the ontology alignment by prescreening the less promising aligning results to be combined and individuals to be evaluated in the NSGA-II, respectively. The experiment results show that, comparing with the approach by using NSGA-II solely, the utilization of Dynamic Alignment Candidates Selection Strategy and Metamodel is able to highly reduce the time and main memory consumption of the tuning process while at the same time ensures the correctness and completeness of the alignments. Moreover, our proposal is also more efficient than the state-of-the-art ontology aligning systems.",2017,Data & Knowledge Engineering
MATE201730,Specification and derivation of key performance indicators for business analytics: A semantic approach,"Business intelligence, Conceptual data warehouse models, Key performance indicators, Strategic models, Business analytics","Key Performance Indicators (KPI) measure the performance of an enterprise relative to its objectives thereby enabling corrective action where there are deviations. In current practice, KPIs are manually integrated within dashboards and scorecards used by decision makers. This practice entails various shortcomings. First, KPIs are not related to their business objectives and strategy. Consequently, decision makers often obtain a scattered view of the business status and business concerns. Second, while KPIs are defined by decision makers, their implementation is performed by IT specialists. This often results in discrepancies that are difficult to identify. In this paper, we propose an approach that provides decision makers with an integrated view of strategic business objectives and conceptual data warehouse KPIs. The main benefit of our proposal is that it links strategic business models to the data for monitoring and assessing them. In our proposal, KPIs are defined using a modeling language where decision makers specify KPIs using business terminology, but can also perform quick modifications and even navigate data while maintaining a strategic view. This enables monitoring and what-if analysis, thereby helping analysts to compare expectations with reported results.",2017,Data & Knowledge Engineering
MEZGHANI201715,Producing relevant interests from social networks by mining users' tagging behaviour: A first step towards adapting social information,"User interests, Tagging behaviour, Resource, Indexation, Social network, Adaptation, Indexing methods, Semi-structured data and XML","Social media provides an environment of information exchange. They principally rely on their users to create content, to annotate others’ content and to make on-line relationships. The user activities reflect his opinions, interests, etc. in this environment. We focus on analysing this social environment to detect user interests which are the key elements for improving adaptation. This choice is motivated by the lack of information in the user profile and the inefficiency of the information issued from methods that analyse the classic user behaviour (e.g. navigation, time spent on web page, etc.). So, having to cope with an incomplete user profile, the user social network can be an important data source to detect user interests. The originality of our approach is based on the proposal of a new technique of interests' detection by analysing the accuracy of the tagging behaviour of a user in order to figure out the tags which really reflect the content of the resources. So, these tags are somehow comprehensible and can avoid tags “ambiguity” usually associated to these social annotations. The approach combines the tag, user and resource in a way that guarantees a relevant interests detection. The proposed approach has been tested and evaluated in the Delicious social database. For the evaluation, we compare the result issued from our approach using the tagging behaviour of the neighbours (the egocentric network and the communities) with the information yet known for the user (his profile). A comparative evaluation with the classical tag-based method of interests detection shows that the proposed approach is better.",2017,Data & Knowledge Engineering
ZONG201779,Constructing faceted taxonomy for heterogeneous entities based on object properties in linked data,"Ontology learning, Taxonomy construction, T-Box learning, Faceted taxonomy, Linked data","The interlinking of data across the web, a concept known as Linked Data, fosters opportunities in data sharing and reusability. However, it may also pose some challenges, which includes the absence of concept taxonomies by which to organize heterogeneous entities that are from different data sources and diverse domains. Learning T-Box (Terminology Box) from A-Box (Assertion Box) has been studied to provide users with concept taxonomies, and is considered a better solution than mapping Linked Data sets with published ontologies. Yet, the existing process of automatically generated taxonomies that classify entities in a particular manner can be improved. Thus, this study aims to automatically create a faceted taxonomy to organize heterogeneous entities, enabling varying classifications of entities by diverse sub-taxonomies, to support faceted search and navigation for linked data applications. The authors have developed a framework on which each facet represented by an object property is used to extract portions of data in the data space, and an Instance-based Concept Taxonomy generation algorithm is developed to build a sub-taxonomy. Additionally, the strategies for sub-taxonomy refinement are proposed. Two experiments have been conducted to prove the promising performances of the proposed method in terms of efficiency and effectiveness.",2017,Data & Knowledge Engineering
STOCKINGER201738,ZNS - Efficient query processing with ZurichNoSQL,"NoSQL, Main memory database, Query processing","NoSQL data stores have recently gained popularity as an alternative to relational database management systems since they typically do not require a fixed schema and scale well for large data sets. These systems have often been tuned to a number of very specific operations such as writing or reading of large data sets. However, none of these novel systems has been demonstrated to efficiently perform multi-dimensional range queries incorporating many boolean operators, a task which is commonly used in scientific data exploration, data warehousing and business analytics. In this paper we introduce ZurichNoSQL (ZNS) - a novel NoSQL main memory store that supports efficient processing of multi-dimensional point queries and range queries. The key idea of ZNS is to store the data in a column format (compressed column storage) similar to systems used in high performance computing. Moreover, the ZNS architecture is based on a set of low-level main memory techniques ensuring that CPU caches are being used efficiently. Our experimental results comparing to popular NoSQL stores such as FastBit, MongoDB and Spark SQL demonstrate that ZNS significantly outperforms these systems in most cases.",2017,Data & Knowledge Engineering
BALDACCI201717,QETL: An approach to on-demand ETL from non-owned data sources,"On-demand ETL, Incremental loading, OLAP","In traditional OLAP systems, the ETL process loads all available data in the data warehouse before users start querying them. In some cases, this may be either inconvenient (because data are supplied from a provider for a fee) or unfeasible (because of their size); on the other hand, directly launching each analysis query on source data would not enable data reuse, leading to poor performance and high costs. The alternative investigated in this paper is that of fetching and storing data on-demand, i.e., as they are needed during the analysis process. In this direction we propose the Query-Extract-Transform-Load (QETL) paradigm to feed a multidimensional cube; the idea is to fetch facts from the source data provider, load them into the cube only when they are needed to answer some OLAP query, and drop them when some free space is needed to load other facts. Remarkably, QETL includes an optimization step to cheaply extract the required data based on the specific features of the data provider. The experimental tests, made on a real case study in the genomics area, show that QETL effectively reuses data to cut extraction costs, thus leading to significant performance improvements.",2017,Data & Knowledge Engineering
THEODOROU20171,Frequent patterns in ETL workflows: An empirical approach,"ETL, Patterns, Empirical, Graph matching","The complexity of Business Intelligence activities has driven the proposal of several approaches for the effective modeling of Extract-Transform-Load (ETL) processes, based on the conceptual abstraction of their operations. Apart from fostering automation and maintainability, such modeling also provides the building blocks to identify and represent frequently recurring patterns. Despite some existing work on classifying ETL components and functionality archetypes, the issue of systematically mining such patterns and their connection to quality attributes such as performance has not yet been addressed. In this work, we propose a methodology for the identification of ETL structural patterns. We logically model the ETL workflows using labeled graphs and employ graph algorithms to identify candidate patterns and to recognize them on different workflows. We showcase our approach through a use case that is applied on implemented ETL processes from the TPC-DI specification and we present mined ETL patterns. Decomposing ETL processes to identified patterns, our approach provides a stepping stone for the automatic translation of ETL logical models to their conceptual representation and to generate fine-grained cost models at the granularity level of patterns.",2017,Data & Knowledge Engineering
REYESGALAVIZ2017106,A supervised gradient-based learning algorithm for optimized entity resolution,"Record linkage, Entity resolution, Field selection, Comparison functions, Clerical review threshold, Autolink threshold, Gradient-descent, Decision model","The task of probabilistic record linkage is to find and link records that refer to the same entity across several disparate data sources. The accurate linking of records (entity resolution) is an important task for the healthcare industry, government, law enforcement, and the private sector, for obvious reasons. However, finding exact matches of an entity can be challenging due to records with typographical, phonetical or other types of errors (noise) found across real-world data sources. Over the years, many comparison functions have been developed to relate pairs of records and produce a similarity score. With a pair of predefined thresholds, one may decide if records pairs match, do not match, or if they require further clerical review. Nevertheless, finding appropriate comparison functions, identity descriptors (fields), threshold values, and efficient classifiers remains a challenging task. In this study, we propose a supervised gradient-based learning model that can adjust its structure and parameters based on matching scores coming from many comparison functions (and applied to many fields), to efficiently classify the records. The design of this structure is transparent, and can potentially allow us to locate which comparison functions and fields are more significant to correctly link the records. To train this structure, we propose a novel performance index that can help learn how to separate matched from non-matched records. Results completed with the use of synthetic datasets affected by different levels of noise and real-world datasets show the effectiveness of the algorithm, which can significantly reduce the number of false positives, false negatives, and the number of records selected for review.",2017,Data & Knowledge Engineering
COETZER201755,A knowledge-based system for generating interaction networks from ecological data,"Semantic heterogeneity, Ontologies, Bayesian network, Knowledge discovery, Semantic architecture, Interaction network, Ecological interactions","Semantic heterogeneity hampers efforts to find, integrate, analyse and interpret ecological data. An application case-study is described, in which the objective was to automate the integration and interpretation of heterogeneous, flower-visiting ecological data. A prototype knowledge-based system is described and evaluated. The system's semantic architecture uses a combination of ontologies and a Bayesian network to represent and reason with qualitative, uncertain ecological data and knowledge. This allows the high-level context and causal knowledge of behavioural interactions between individual plants and insects, and consequent ecological interactions between plant and insect populations, to be discovered. The system automatically assembles ecological interactions into a semantically consistent interaction network (a new design of a useful, traditional domain model). We discuss the contribution of probabilistic reasoning to knowledge discovery, the limitations of knowledge discovery in the application case-study, the impact of the work and the potential to apply the system design to the study of ecological interaction networks in general.",2017,Data & Knowledge Engineering
CANO201794,Training set selection for monotonic ordinal classification,"Monotonic classification, Ordinal classification, Training set selection, Data preprocessing, Machine learning","In recent years, monotonic ordinal classification has increased the focus of attention for machine learning community. Real life problems frequently have monotonicity constraints. Many of the monotonic classifiers require that the input data sets satisfy the monotonicity relationships between its samples. To address this, a conventional strategy consists of relabeling the input data to achieve complete monotonicity. As an alternative, we explore the use of preprocessing algorithms without modifying the class label of the input data. In this paper we propose the use of training set selection to choose the most effective instances which lead the monotonic classifiers to obtain more accurate and efficient models, fulfilling the monotonic constraints. To show the benefits of our proposed training set selection algorithm, called MonTSS, we carry out an experimentation over 30 data sets related to ordinal classification problems.",2017,Data & Knowledge Engineering
PHAN201812,Automatically classifying source code using tree-based approaches,"Abtract Syntax Tree (AST), Tree-based convolutional neural networks(TBCNN), Support Vector Machines (SVMs), K-Nearest Neighbors (kNN)","Analyzing source code to solve software engineering problems such as fault prediction, cost, and effort estimation always receives attention of researchers as well as companies. The traditional approaches are based on machine learning, and software metrics obtained by computing standard measures of software projects. However, these methods have faced many challenges due to limitations of using software metrics which were not enough to capture the complexity of programs. To overcome the limitations, this paper aims to solve software engineering problems by exploring information of programs' abstract syntax trees (ASTs) instead of software metrics. We propose two combination models between a tree-based convolutional neural network (TBCNN) and k-Nearest Neighbors (kNN), support vector machines (SVMs) to exploit both structural and semantic ASTs' information. In addition, to deal with high-dimensional data of ASTs, we present several pruning tree techniques which not only reduce the complexity of data but also enhance the performance of classifiers in terms of computational time and accuracy. We survey many machine learning algorithms on different types of program representations including software metrics, sequences, and tree structures. The approaches are evaluated based on classifying 52000 programs written in C language into 104 target labels. The experiments show that the tree-based classifiers dramatically achieve high performance in comparison with those of metrics-based or sequences-based; and two proposed models TBCNN + SVM and TBCNN + kNN rank as the top and the second classifiers. Pruning redundant AST branches leads to not only a substantial reduction in execution time but also an increase in accuracy.",2018,Data & Knowledge Engineering
DUONG20181,Exploring alignment-classification methods in the context of professional writing assistance,"Writing assistance, Alignment classification, Word alignment, Second language learning","Proofreading, the act of checking first-draft writings performed by native experts, is essential for professional writing by non-native speakers. Usually, proofreading experts return the corrected texts to the writer without reasons of correction, which makes it difficult for the writer to learn from their errors. The combination of word alignment and classification techniques can help us to analyze the original and corrected texts and use them for language learning. In this study, we explore different alignment-classification methods for this task. Our experimental results show that the best method achieved 71.8% in accuracy. We also propose a new error taxonomy for tagging learner corpora, and present our alignment-classification results on the corpus tagged with this new tagset.",2018,Data & Knowledge Engineering
PHAM201826,Learning multiple layers of knowledge representation for aspect based sentiment analysis,"Sentiment analysis, Aspect based sentiment analysis, Representation learning, Multiple layer representation, Compositional vector models, Word embeddings","Sentiment Analysis is the task of automatically discovering the exact sentimental ideas about a product (or service, social event, etc.) from customer textual comments (i.e. reviews) crawled from various social media resources. Recently, we can see the rising demand of aspect-based sentiment analysis, in which we need to determine sentiment ratings and importance degrees of product aspects. In this paper we propose a novel multi-layer architecture for representing customer reviews. We observe that the overall sentiment for a product is composed from sentiments of its aspects, and in turn each aspect has its sentiments expressed in related sentences which are also the compositions from their words. This observation motivates us to design a multiple layer architecture of knowledge representation for representing the different sentiment levels for an input text. This representation is then integrated into a neural network to form a model for prediction of product overall ratings. We will use the representation learning techniques including word embeddings and compositional vector models, and apply a back-propagation algorithm based on gradient descent to learn the model. This model consequently generates the aspect ratings as well as aspect weights (i.e. aspect importance degrees). Our experiment is conducted on a data set of reviews from hotel domain, and the obtained results show that our model outperforms the well-known methods in previous studies.",2018,Data & Knowledge Engineering
DO201867,A time-dependent model with speed windows for share-a-ride problems: A case study for Tokyo transportation,"Passenger and parcels sharing, Share-a-ride, Tokyo Taxi, Dynamic graphs, Heuristic algorithms","This paper introduces a new fully time-dependent model of a public transportation system in the urban context that allows sharing a taxi between one passenger and parcels with speed widows consideration. The model contains many real-life case features and is presented by a mathematical formulation. We study both static and dynamic scenarios in comparison to traditional strategies, i.e., the direct delivery model. Moreover, we classify speed windows by different zones and congestion levels during a day in the urban context. Different speed windows induce the dynamic graph model for road networks and make the problem much more difficult to solve. Because of the complex model, the preprocessing steps on data as well as on dynamic graphs are very important. We use a greedy algorithm to initiate the solution and then use some local search techniques to improve the solution quality. The experimental data set is recorded by Tokyo-Musen Taxi company. The data set includes more than 20000 requests per day, more than 4500 used taxis per day and more than 130000 crossing points on the Tokyo map. Experimental results are analyzed on various factors such as the total benefit, the accumulating traveling time during the day, the number of used taxis and the number of shared requests.",2018,Data & Knowledge Engineering
BUI201840,A novel evolutionary multi-objective ensemble learning approach for forecasting currency exchange rates,"Currency exchange rates forecasting, Ensemble learning, Multi-objective evolutionary, Non-dominated differential evolution","Due to the potential impact of the (currency) exchange rate risk in the financial market, forecasting exchange rate (FET) has become a hot topic in both academic and practical worlds. For many years, the various methods have been proposed and used for FET problems including the method of the artificial neural network (ANN). However, in many cases of FET, there is the limitation of using separate methods since they are not able to fully capture financial characteristics. Recently, more researchers have been beginning to pay attention to FET based on an ensemble of forecasting models (in other words, the combination of individual methods). Previous studies of ensemble methods have shown that the performance of an ensemble depends on two key elements (1) The individual performance and (2) diversity degree of base learners. The main idea behind this paper comes from these key elements, the authors use ANNs as the base method (or weak learners), and weights of these ANNs will be optimized by using multi-objective evolutionary algorithms (MOEAs) including the Non-Dominated Sorting Genetic Algorithm II (NSGA-II) and the Non-Dominated Sorting Differential Evolution (NSDE) using directional information. To assist MOEAs, a number of diversity-preservation mechanisms are used to generate diverse sets of base classifiers and finally we propose to use modified Adaboost algorithms to combine the results of weak learners for overall forecasts. The results show that the proposed novel ensemble learning approach can achieve higher forecasting performance than those of individual ones.",2018,Data & Knowledge Engineering
GUERRA20171,Automated analysis of integrity constraints in multi-level models,"Multi-level modelling, Deep meta-modelling, Conceptual modelling, Management of integrity constraints, Meta-level flattening, Model finders, Constraint solving, MetaDepth","Multi-level modelling is a technology for model-based development that enables the incremental refinement of models in successive meta-levels, which results in simpler and more intentional system descriptions in some scenarios. In this approach, integrity constraints can be placed at any meta-level, and need to indicate the meta-level below at which they should hold. This requires a careful design, as constraints defined at different meta-levels may interact in unexpected ways. Unfortunately, current techniques for the analysis of the satisfiability of constraints are designed for two meta-levels only. Hence, nowadays, the analysis of multi-level solutions is performed by hand, which is tedious and error-prone. In this paper, we define an automated procedure to check the satisfiability of integrity constraints in a multi-level setting, leveraging on “off-the-shelf” model finders. This procedure is supported by our multi-level modelling tool MetaDepth, which has been extended to reason on the satisfiability of constraints in multi-level models, and to perform automated model completion.",2017,Data & Knowledge Engineering
GALITSKY201724,Matching parse thickets for open domain question answering,"Question-answering systems, Discourse analysis, Rhetoric structure, Parse tree, Parse thicket","Traditional parse trees are combined together and enriched with anaphora and rhetoric information to form a unified representation for a paragraph of text. We refer to these representations as parse thickets. They are introduced to support answering complex questions, which include multiple sentences, to tackle as many constraints expressed in this question as possible. The question answering system is designed so that an initial set of answers, which is obtained by a TF*IDF or other keyword search model, is re-ranked. Passage re-ranking is performed using matching of the parse thickets of answers with the parse thicket of the question. To do that, a graph representation and matching technique for parse structures for paragraphs of text have been developed. We define the operation of generalization of two parse thickets as a measure of the distance between paragraphs of text to be the maximal common sub-graph of these parse thickets. A partial case of parse thickets, a rhetoric map of an answer, allows leveraging discourse for relevance in a rule-based manner. Passage re-ranking improvement via parse thickets is evaluated in a variety of search domains with long questions. Using parse thickets improves search accuracy compared with the bag-of words, the pairwise matching of parse trees for sentences, and the tree kernel approaches. As a baseline, we use a web search engine API, which provides much more accurate search results than the majority of search benchmarks, such as TREC. A comparative analysis of the impact of various sources of discourse information on the search accuracy is conducted. An open source plug-in for SOLR is developed so that the proposed technology can be easily integrated with industrial search engines.",2017,Data & Knowledge Engineering
MIRANDA201751,An ontology-based model for competence management,"Ontology engineering, Competence-based management, Semantic web, Context space theory, Fuzzy logic","In the last years, the need for developing strategies, models and tools to manage competences clearly emerges in numerous scenarios. For instance, this emergence especially raises when it is required to realize effective recruiting platforms, decision support systems for human resource management, learning management systems and so on. This work proposes an ontology-based model for the representation of competences able to support a wide range of scenarios where it is fundamental to model, organize and represent professional competences, enable interoperability and co-operation among different and heterogeneous tools and, lastly, execute queries and inference operations over these competences. The proposed model starts from the outcomes of the specialized literature and the related R&D projects and produces a novel integrated model that represents both job offers and demands to support recruiting initiatives and to develop employability strategies aiming at a best matching as well as a careful skill gap analysis. The model has been evaluated by means of a three-level approach also in the context of the SIRET project whose goal is defining a recruiting and training integrated system able to represent the professional competences of users and to understand the supplies and the demands in order to find optimal agreements in the job market.",2017,Data & Knowledge Engineering
